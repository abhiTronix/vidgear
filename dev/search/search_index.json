{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#introduction","title":"Introduction","text":"<p>VidGear is a cross-platform High-Performance Video-Processing Framework for building complex real-time media applications in python </p> <p>VidGear provides an easy-to-use, highly extensible, Multi-Threaded + Asyncio API Framework on top of many state-of-the-art specialized libraries like OpenCV, FFmpeg, ZeroMQ, picamera2, starlette, yt_dlp, pyscreenshot, dxcam, aiortc and python-mss at its backend, and enable us to flexibly exploit their internal parameters and methods, while silently delivering robust error-handling and real-time performance \u26a1\ufe0f.</p> <p>\"Write Less and Accomplish More\" \u2014 VidGear's Motto</p> <p>VidGear focuses on simplicity, and thereby lets programmers and software developers to easily integrate and perform Complex Video Processing Tasks without going through hefty documentation and in just a few lines of code.</p> <p> </p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>In case you're run into any problems, consult the Help section.</p> <ul> <li> <p> If this is your first time using VidGear, head straight to the Installation to install VidGear.</p> </li> <li> <p> Once you have VidGear installed, Checkout its Function-Specific Gears.</p> </li> <li> <p> Also, if you're already familar with OpenCV library, then see Switching from OpenCV Library.</p> </li> </ul> <p>If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6</p> <p> </p>"},{"location":"#gears","title":"Gears","text":"<p>VidGear is built with multiple Gears each with some unique functionality.</p> <p>Each Gear is designed exclusively to handle/control/process different data-specific &amp; device-specific video streams, network streams, and media encoders/decoders.</p> <p>These Gears can be classified as follows:</p>"},{"location":"#videocapture-gears","title":"VideoCapture Gears","text":"<ul> <li>CamGear: Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs.</li> <li>PiGear: Multi-Threaded API targeting various Camera Modules and (limited) USB cameras on Raspberry Pis .</li> <li>ScreenGear: High-performance API targeting rapid Screencasting Capabilities.    </li> <li>VideoGear: Common Video-Capture API with internal Video Stabilizer wrapper.</li> </ul>"},{"location":"#videowriter-gears","title":"VideoWriter Gears","text":"<ul> <li>WriteGear: Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.</li> </ul>"},{"location":"#streaming-gears","title":"Streaming Gears","text":"<ul> <li> <p>StreamGear: Handles Transcoding of High-Quality, Dynamic &amp; Adaptive Streaming Formats.</p> </li> <li> <p>Asynchronous I/O Streaming Gear:</p> <ul> <li>WebGear: ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network.</li> <li>WebGear_RTC: Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.</li> </ul> </li> </ul>"},{"location":"#network-gears","title":"Network Gears","text":"<ul> <li> <p>NetGear: Handles High-Performance Video-Frames &amp; Data Transfer between interconnecting systems over the network.</p> </li> <li> <p>Asynchronous I/O Network Gear:</p> <ul> <li>NetGear_Async: Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework. </li> </ul> </li> </ul> <p> </p>"},{"location":"#contributions","title":"Contributions","text":"<p>Contributions are welcome, and greatly appreciated!  </p> <p>Please see our Contribution Guidelines for more details.</p> <p> </p>"},{"location":"#community-channel","title":"Community Channel","text":"<p>If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6</p> <p> </p>"},{"location":"#become-a-stargazer","title":"Become a Stargazer","text":"<p>You can be a Stargazer  by starring us on Github, it helps us a lot and you're making it easier for others to find &amp; trust this library. Thanks!</p> <p> </p>"},{"location":"#donations","title":"Donations","text":"<p>VidGear is free and open source and will always remain so. </p> <p>It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference </p> <p></p> <p> </p>"},{"location":"#citation","title":"Citation","text":"<p>Here is a Bibtex entry you can use to cite this project in a publication:</p> <p></p> <pre><code>@software{vidgear,\n  author       = {Abhishek Thakur and\n                  Zoe Papakipos and\n                  Christian Clauss and\n                  Christian Hollinger and\n                  Ian Max Andolina and\n                  Vincent Boivin and\n                  Kyle Ahn and\n                  freol35241 and\n                  Benjamin Lowe and\n                  Micka\u00ebl Schoentgen and\n                  Renaud Bouckenooghe and\n                  Ibtsam Ahmad},\n  title        = {abhiTronix/vidgear: VidGear Stable v0.3.2},\n  month        = sep,\n  year         = 2023,\n  publisher    = {Zenodo},\n  version      = {vidgear-0.3.2},\n  doi          = {10.5281/zenodo.8332548},\n  url          = {https://doi.org/10.5281/zenodo.8332548}\n}\n</code></pre> <p> </p>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#release-notes","title":"Release Notes","text":""},{"location":"changelog/#v032-2023-09-10","title":"v0.3.2 (2023-09-10)","text":"New Features <ul> <li> NetGear: <ul> <li>Added new <code>kill</code> parameter to <code>close()</code> method to forcefully kill ZMQ context instead of graceful exit only in the <code>receive</code> mode.</li> <li>Added new <code>subscriber_timeout</code> integer optional parameter to support timeout with <code>pattern=2</code> (or Publisher-Subscriber) pattern.<ul> <li>Receiver will exit safely if timeout defined(any value(in milliseconds) &gt; 0), and timeout occurs in Receiver Mode with <code>pattern=2</code>.</li> <li>\ud83d\udcac Note: Default behavior still is to block the thread till infinite time.</li> </ul> </li> </ul> </li> <li> WriteGear: <ul> <li>Added new <code>-disable_ffmpeg_window</code> optional Boolean flag to enable patch that prevents FFmpeg creation window from opening when building <code>.exe</code> files on Windows OS. (PR by @ibtsam3301)<ul> <li>\ud83d\udcac Note: <code>-disable_ffmpeg_window</code> optional Boolean flag is only available on Windows OS with logging disabled(<code>logging=False</code>) in compression mode.</li> <li>Use Case: This flag can be useful while creating an <code>.exe</code> file for a python script that uses WriteGear API. On windows even after creating the <code>.exe</code> file in windowed mode or no-console mode, the <code>ffmpeg.exe</code> command line window would pop up while its being used by WriteGear API.</li> </ul> </li> </ul> </li> <li> Setup.py<ul> <li>Added official support for python <code>3.11.x</code> legacies.</li> <li>Bumped version to <code>0.3.1</code>. </li> </ul> </li> <li> Docs<ul> <li>Added doc for <code>subscriber_timeout</code> optional Integer parameter in NetGear.</li> <li>Added doc for <code>disable_ffmpeg_window</code> optional Boolean parameter in WriteGear.</li> <li>Added new asset <code>screengear_region.png</code>.</li> </ul> </li> <li> CI<ul> <li>Added python 3.11 legacy support for MacOS, Windows and Linux environments.</li> <li>Added kill argument to close() method in various NetGear tests.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Asyncio: <ul> <li>Formatted TemplateResponse class parameters w.r.t new changes in backend Starlette API.</li> </ul> </li> <li> Setup.py:<ul> <li>Readded latest patch to <code>uvicorn</code>, <code>starlette</code>, <code>pyzmq</code> dependencies.</li> <li>Removed <code>3.7</code> legacy from Programming Language metadata.</li> </ul> </li> <li> Maintenance: <ul> <li>Added GitHub sponsors and dropped liberapay from <code>Funding.yml</code>.</li> <li>Removed redundant code.</li> </ul> </li> <li> Docs:<ul> <li>Updated information related to Supported Dimensional Attributes in ScreenGear docs.</li> <li>Updated minimum python to version <code>3.8</code> while installing vidgear in docs.</li> <li>Updated API-specific dependencies in docs.</li> <li>Updated changelog.md</li> </ul> </li> <li> CI:<ul> <li>Updated Azure Pipeline workflow. </li> <li>Updated Appveyor Pipeline workflow.</li> <li>Updated GitHub Actions Pipeline workflow.</li> <li>Migrated python version to <code>3.9</code> in <code>deploy_docs.yml</code> workflow.</li> <li>Removed deprecated python <code>3.7</code> legacy support.</li> <li>Increased code coverage by updating tests.</li> <li>Updated tests for <code>subscriber_timeout</code> optional Integer parameter in NetGear.</li> <li>Updated tests for <code>disable_ffmpeg_window</code> optional Boolean parameter in WriteGear.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Setup.py:<ul> <li>Removed support for python-3.7 legacies <ul> <li>Raised <code>python_requires</code> to <code>&gt;=3.8</code>. Thereby python <code>3.7</code> and any before legacy are no longer supported.</li> </ul> </li> </ul> </li> </ul> Bug-fixes <ul> <li> ScreenGear:<ul> <li>Fixed swapped region dimensions bug with dxcam backend.</li> <li>Fixed \"mss\" backend disabled when <code>monitor</code> parameter is not defined.</li> </ul> </li> <li> Docs:<ul> <li>Fixed missing <code>compression_mode</code> flags in WriteGear API docs.</li> <li>Fixed missing hyperlinks.</li> <li>Fixed typos and context.</li> </ul> </li> <li> CI:<ul> <li>Temporary fix for AST constructor depth mismatch in pytest on python <code>3.11.x</code>, More information: pytest-dev/pytest#10874<ul> <li>Made temporary fix platform independent. </li> <li>Extended fix to all Webgear_RTC tests.</li> </ul> </li> <li>Fixed NetGear tests bugs.</li> <li>Fixed condition logic bug.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #378</li> <li>PR #375</li> <li>PR #370</li> </ul> New Contributors <ul> <li>@ibtsam3301</li> </ul>"},{"location":"changelog/#v031-2023-07-22","title":"v0.3.1 (2023-07-22)","text":"New Features <ul> <li> WebGear: <ul> <li>Added an option to add a custom video endpoint path.<ul> <li>Users can now change the video endpoint path from <code>\"/video\"</code> to any alphanumeric string.</li> <li>Added the <code>custom_video_endpoint</code> optional string attribute for this purpose.</li> <li>Only alphanumeric strings with no spaces in between are allowed as its value.</li> </ul> </li> </ul> </li> <li> ScreenGear: <ul> <li>Added <code>dxcam</code> support for Windows machines.<ul> <li>Implemented a complete end-to-end workflow for the <code>dxcam</code> backend.</li> <li><code>dxcam</code> is now the default backend for Windows machines when no backend is defined.</li> <li>Added support for variable screen dimensions to capture an area from the screen.</li> <li>Added the optional flag <code>dxcam_target_fps</code> to control the target fps in <code>dxcam</code>. Defaults to <code>0</code> (disabled).</li> <li>RGB frames from <code>dxcam</code> are automatically converted into BGR.</li> <li>For better performance, <code>video_mode</code> is enabled by default in <code>dxcam</code> backend.</li> <li>Added necessary imports.</li> </ul> </li> <li>Added support for tuple values in the monitor parameter to specify device and output indexes as <code>(int[device_idx], int[output_idx])</code> in the <code>dxcam</code> backend only.<ul> <li>Default <code>int</code> index is also allowed as a value for selecting device index.</li> </ul> </li> </ul> </li> <li> Helper<ul> <li>Added multiple servers support for downloading assets.<ul> <li>Added GitHub server to the <code>generate_webdata</code> method to make it more robust for rate limits and other shortcomings.</li> <li>Now, the <code>generate_webdata</code> method will retry a different server when one fails.</li> </ul> </li> </ul> </li> <li> Setup.py<ul> <li>Added <code>dxcam</code> dependency in <code>core</code> and <code>asyncio</code> extra requires.</li> <li>Bumped version to <code>0.3.1</code>. </li> </ul> </li> <li> Docs<ul> <li>Added <code>dxcam</code> API specific prerequisites for ScreenGear API when installing on Windows via pip.</li> <li>Added documentation for the <code>custom_video_endpoint</code> optional string attribute.</li> <li>Added documentation for controlling Chunk size in HLS stream.</li> <li>Added new hyperlinks for <code>dxcam</code> dependency.</li> </ul> </li> <li> CI<ul> <li>Added a test case for <code>ndim==3</code> grayscale frames.<ul> <li>Added the <code>Custom_Grayscale_class</code> to generate <code>ndim==3</code> grayscale frames.</li> </ul> </li> <li>Added test cases for the <code>custom_video_endpoint</code> optional string attribute.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> WebGear: <ul> <li>Improved the conditions logic to check if non-empty values are assigned to optional parameters.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Improved the handling of the <code>format</code> parameter when constructing a <code>VideoFrame</code> from ndarray frames.</li> </ul> </li> <li> ScreenGear: <ul> <li>Enforced <code>dxcam</code> backend (if installed) when <code>monitor</code> is defined on Windows machines.</li> <li>Refactored code blocks to ensure backward compatibility.</li> </ul> </li> <li> Maintenance:<ul> <li>Cleaned up unused imports and code blocks.</li> <li>Cleaned redundant code.</li> <li>Improved logging.</li> <li>Implemented short-circuiting.</li> <li>Fixed comment typos.</li> <li>Updated comments.</li> </ul> </li> <li> Docs:<ul> <li>Updated ScreenGear API usage example docs, added new relevant information, updated requirements for <code>dxcam</code> support in Windows machines.</li> <li>Refactored <code>monitor</code> and <code>backend</code> parameters docs of ScreenGear.</li> <li>Updated class and class parameters descriptions in ScreenGear docs.</li> <li>Updated a new description for ScreenGear API.</li> <li>Updated Zenodo badge and the BibTeX entry.</li> <li>Relocated some docs for a better context.</li> <li>Removed ScreenGear name from Threaded Queue Mode doc.</li> <li>Updated ScreenGear FAQs.</li> <li>Updated changelog.md</li> </ul> </li> <li> CI:<ul> <li>Updated the <code>test_webgear_rtc_custom_stream_class</code> method.</li> <li>Updated the <code>test_webgear_options</code> method.</li> <li>Updated the <code>test_webgear_routes</code> test to validate the new custom endpoint.</li> <li>Increased code coverage by updating tests.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> ScreenGear: <ul> <li>Previously enforced threaded queue mode is now completely removed, resulting in a potential performance boost.<ul> <li>\ud83d\udcac Reason: The IO is automatically blocked by the screen refresh rate, so adding the overhead of maintaining a separate queue is pointless.</li> </ul> </li> <li>Removed the <code>THREAD_TIMEOUT</code> optional flag.</li> </ul> </li> </ul> Bug-fixes <ul> <li> WebGear_RTC: <ul> <li>Fixed a bug caused by PyAV's error when <code>ndim==3</code> grayscale frames are encountered. <ul> <li>The API will now drop the third dimension if <code>ndim==3</code> grayscale frames are detected.</li> </ul> </li> </ul> </li> <li> ScreenGear:<ul> <li>Fixed backend not defined while logging.</li> </ul> </li> <li> Setup.py:<ul> <li>Starting from version <code>8.0.0</code>, the python-mss library dropped support for Python <code>3.7</code>, so as a temporary measure, <code>mss</code> dependency has been pinned to version <code>7.0.1</code>.</li> </ul> </li> <li> Docs:<ul> <li>Fixed context and added separate code for controlling chunk size in HLS and DASH streams in StreamGear docs.</li> <li>Fixed naming conventions for the recently added DXcam backend in ScreenGear docs.</li> <li>Fixed missing hyperlinks.</li> </ul> </li> <li> CI:<ul> <li>Fixed m3u8 module failing to recognize Windows paths in ScreenGear tests.</li> <li>Fixed a path bug by replacing the absolute file path with the decoded file content as a string in its <code>loads()</code> </li> </ul> </li> </ul> Pull Requests <ul> <li>PR #367</li> <li>PR #366</li> <li>PR #365</li> </ul>"},{"location":"changelog/#v030-2023-01-26","title":"v0.3.0 (2023-01-26)","text":"New Features <ul> <li> WriteGear: <ul> <li>Added support for user-defined and higher than 8-bit depth input frames pixel-format.<ul> <li>Added support for higher than 8-bit depth frames with datatypes of unsigned integer(<code>uint</code>) kind and element size <code>2</code>.</li> <li>Added <code>dtype</code> parameter to internal <code>Preprocess</code> method for passing input frames datatype.</li> <li>Implemented auto-calculation of input pixel-format based on number of channels in higher than 8-bit depth frames.</li> <li>Added various known working pixel-formats(based on number of channels), supported by all prominent computer vision libraries.</li> <li>Added support for up to 1-channel(<code>gray16-le/be</code>) to all the way up to 4-channels(<code>bgra64-le/be</code>) in input frames.</li> <li>Added endianness little(<code>le</code>) or big(<code>be</code>) at the suffix of pixel-format based on byte-order of input frames datatypes.</li> <li>Extended support for higher RGB 8-bit depth frames through RGB mode.</li> </ul> </li> <li>Added support for user-defined custom input pixel-format.<ul> <li>Added new <code>-input_pixfmt</code> attribute to <code>output_params</code> dictionary parameter for easily specifying custom input pixel-format.</li> <li>Added newly implemented <code>get_supported_pixfmts</code> method import for verifying user-defined input pixel-format against Installed FFmpeg supported pixel-formats. Unsupported values will be discarded. </li> <li>Implemented runtime datatype validation check, such that all input frames must have same datatype.</li> </ul> </li> <li>Added support for Context Managers for proper handling of resources via <code>with</code> statement for allocating and releasing resources precisely. (Suggested by @sueskind)<ul> <li>Implement the <code>__enter__()</code> and <code>__exit__()</code> methods.</li> <li>Added <code>__enter__</code> method that returns reference to the WriteGear Class.</li> <li>Added <code>__exit__</code> method that automatically executes <code>close()</code> for performing the cleanup operations and handling exception gracefully. </li> </ul> </li> </ul> </li> <li> StreamGear: <ul> <li>Added support for Context Managers for proper handling of resources via <code>with</code> statement for allocating and releasing resources precisely. (Suggested by @sueskind)<ul> <li>Implement the <code>__enter__()</code> and <code>__exit__()</code> methods.</li> <li>Added <code>__enter__</code> method that returns reference to the StreamGear Class.</li> <li>Added <code>__exit__</code> method that automatically executes <code>close()</code> for performing the cleanup operations and handling exception gracefully. </li> </ul> </li> </ul> </li> <li> WebGear:<ul> <li>Added way to completely disable Data-Files Auto-Generation WorkFlow.<ul> <li>Added new <code>skip_generate_webdata</code> boolean optional attribute(<code>False</code> by default) to completely disable Data-Files Auto-Generation WorkFlow.</li> <li>This flag enables only <code>/video</code> route for disabled Data-Files Auto-Generation WorkFlow.</li> <li>Implemented JSONResponse as placeholder response instead of Index, <code>404</code> and <code>500</code> HTML pages, when workflow is disabled. (Note: Index HTML page will throw <code>404</code> status code.)</li> <li>Added necessary imports.</li> </ul> </li> </ul> </li> <li> Helper:<ul> <li>Added more robust implementation of validate_audio method.<ul> <li>Added new more robust regex pattern for extracting audio-samplerate.</li> <li>Added new <code>validate_audio</code> method for calculating accurate bitrate(in kbps) from audio samplerate, channels, bit-depth values.</li> <li>Implemented new patterns and logic for accurately extracting audio channels and bit-depth from given metadata.</li> </ul> </li> <li>Added support for Linux video device path (such as <code>/dev/video0</code>).</li> </ul> </li> <li> Maintenance: <ul> <li>Logging current vidgear version when vidgear APIs are called, not at import.<ul> <li>Added <code>logcurr_vidgear_ver</code> helper function to facilitate logging current vidgear version, when called within a API.</li> <li>Implemented <code>ver_is_logged</code> global variable in helper to log version only once, which can modifiable with <code>logcurr_vidgear_ver</code> method only. Followed recommendation given in official python docs: https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-modules</li> <li>Current version can only be logged by VidGear APIs with the logging turned on (i.e. <code>logging=True</code>).</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added new WriteGear Bonus Example:<ul> <li>Added \"Using WriteGear's Compression Mode with <code>v4l2loopback</code> Virtual Cameras bonus python example.</li> <li>Added related prerequisites and dependencies for creating <code>v4l2loopback</code> Virtual Cameras on Linux machines.</li> <li>Added both With/Without-Audio cases for \"Using WriteGear's Compression Mode for YouTube-Live Streaming\".</li> </ul> </li> <li>Added <code>content.code.copy</code> and <code>content.tabs.link</code> features.</li> <li>Added docs related to <code>skip_generate_webdata</code> optional attribute.</li> <li>Added feedback features to mkdocs.yml.</li> <li>Added <code>404.html</code> static template to <code>mkdocs.yml</code>.</li> </ul> </li> <li> CI:<ul> <li>Added v4l2loopback support for testing <code>/dev/video0</code> device on Linux machines.</li> <li>Added test cases for newer implementation of <code>validate_audio</code> method.</li> <li>Added <code>test_skip_generate_webdata</code> to test <code>skip_generate_webdata</code> optional attribute.</li> <li>Added tests for user-defined and higher than 8-bit depth input frames pixel-format.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> WriteGear: <ul> <li>Completely revamped code structure and comments.<ul> <li>Updated comments, description, and logging messages to more sensible and developer friendly.</li> <li>Implemented operator short-circuiting to cleanup code as much as possible.</li> <li>Renamed <code>startFFmpeg_Process</code> internal class method to <code>start_FFProcess</code>.</li> <li>Renamed <code>Preprocess</code> internal class method to <code>PreprocessFFParams</code>.</li> <li>Renamed <code>startCV_Process</code> internal class method to <code>start_CVProcess</code>.</li> <li>Renamed <code>initiate</code> internal class parameter to <code>initiate_process</code>.</li> <li>Renamed <code>force_termination</code> internal class parameter to <code>forced_termination</code>.</li> <li>Enabled <code>output_params</code> parameters logging in both modes.</li> <li>Improved <code>compression</code> and <code>logging</code> parameters boolean value handling.</li> <li>Implemented <code>stdout</code> closing to cleanup pipeline before terminating.</li> </ul> </li> </ul> </li> <li> Helper:<ul> <li>Updated <code>validate_audio</code> method with improved and more robust regex patterns for identifying audio bitrate in ay audio file.</li> </ul> </li> <li> Setup.py:<ul> <li>Bumped version to <code>0.3.0</code>.</li> <li>Replaced <code>&gt;=</code> comparison operator with more flexible <code>~=</code>.</li> <li>Replaced <code>distutils.version.LooseVersion</code> with <code>pkg_resources.parse_version</code>.</li> </ul> </li> <li> Maintenance: <ul> <li>Replaced depreciated <code>LooseVersion</code> with <code>parse_version</code>.</li> <li>Updated <code>Retry</code> package to be imported from <code>requests.adapters</code>.</li> <li>Moved terminal and python code text area to Question GitHub Form Schema.</li> <li>Removed unnecessary imports.</li> <li>Removed redundant code.</li> <li>Improved logging messages.</li> <li>Updated code comments.</li> <li>Updated method descriptions.</li> <li>Refactored code.</li> <li>Increased coverage.</li> </ul> </li> <li> Bash Script:<ul> <li>Updated FFmpeg Static Binaries links to latest date/version tag to <code>12-07-2022</code>.</li> <li>Removed depreciated binaries download links and code.</li> </ul> </li> <li> Docs:<ul> <li>Replaced all <code>raw.githubusercontent.com</code> GIF URLs with <code>user-images.githubusercontent.com</code>.</li> <li>Reformatted <code>custom.css</code> and added missing comments.</li> <li>Updated sponsor block.</li> <li>Enabled Code Highlights.</li> <li>Updated announcement bar.</li> <li>Updated <code>changelog.md</code>.</li> <li>Reduced <code>webgear_rtc.gif</code> size.</li> <li>Updated Zenodo badge and the BibTeX entry.</li> </ul> </li> <li> CI:<ul> <li>Added more flexible formats to <code>return_testvideo_path</code> function.</li> <li>Updated <code>test_write</code> test for higher than 8-bit depth input frames pixel-format in WriteGear's Compression Mode.</li> <li>Updated <code>actions/checkout</code> to <code>v3</code>.</li> <li>Updated <code>actions/setup-python</code> to <code>v4</code>.</li> <li>Updated <code>codecov/codecov-action</code> to <code>v3</code>.</li> <li>Moved <code>test_colorspaces</code> test to CamGear tests.</li> <li>Added deffcode library import.</li> </ul> </li> <li>Re-stuctured yaml code.</li> </ul> Breaking Updates/Changes <ul> <li> WriteGear: <ul> <li>Renamed <code>output_filename</code> string parameter to <code>output</code>.<ul> <li>Since WriteGear API accepts all sorts of streams (such as valid filename/path/URL) for encoding, thereby changing parameter name to <code>output</code> will be more true to its purpose.</li> <li>Renaming <code>output_filename</code> to <code>output</code> in WriteGear API will also help user to not accidentally assume WriteGear supports only encoding of video files.</li> <li>It matches the <code>output</code> parameter in StreamGear which basically does the same thing.</li> </ul> </li> <li>Renamed <code>cmd</code> parameter in <code>execute_ffmpeg_cmd()</code> class method to more sensible <code>command</code>.</li> <li><code>ValueError</code> will be raised if datatype of input frames mismatches Writegear API</li> </ul> </li> </ul> Bug-fixes <ul> <li> Camgear: <ul> <li>Fixed <code>CamGear.read()</code> blocked unnecessarily.<ul> <li>\ud83d\udcac When <code>THREADED_QUEUE_MODE</code> is enabled <code>CamGear.read()</code> blocks for an excessive duration when attempting to read past the end of a stream.</li> <li>Added <code>None</code> frame to the queue at the end to signal we're done.</li> <li>Added <code>terminate</code> Event check before continuing.</li> </ul> </li> <li>Fixed deadlock on exit.<ul> <li>\ud83d\udcac The deadlock is due to <code>self.__queue.get(timeout=self.__thread_timeout)</code> line in <code>read()</code> method, which still waits for timeout(thread_timeout) to happen when main <code>update()</code> thread was already terminated on exit and queue was empty. Since there was no way to signal queue that stream is already ended, the blocking <code>queue.get()</code> keeps on waiting until timeout occurs.</li> <li>The solution was to signal <code>queue.get()</code> that stream is already ended by putting <code>None</code> in queue on exiting the main <code>update()</code> thread.</li> </ul> </li> </ul> </li> <li> ScreenGear: <ul> <li>Fixed <code>ScreenGear.read()</code> blocked during cold startup.</li> <li>\ud83d\udcac During startup, <code>ScreenGear.read()</code> doesn't checks if queue is empty before continuing.</li> </ul> </li> <li> WriteGear: <ul> <li>Fixed gstpipeline_mode not activating when wrongly assuming <code>output</code> value as valid path.</li> <li>Fixed name 'compression' is not defined bug.</li> <li>Fixed <code>AttributeError</code>.</li> </ul> </li> <li> Helper:<ul> <li>Fixed <code>fltp</code> keyword in regex pattern causing non-ftlp streams to be not recognized.</li> <li>Fixed response.headers returning <code>content-length</code> as Nonetype since it may not necessarily have the Content-Legth header set.<ul> <li>Reason: The response from gitlab.com  contains a Transfer-Encoding field as <code>'Transfer-Encoding': 'chunked'</code>, which means data is sent in a series of chunks, so the Content-Length header is emitted. More info: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding#Directives</li> </ul> </li> <li>Fixed Linux video device paths still not working. <ul> <li>Moved <code>helper.py</code> logic to WriteGear and StreamGear APIs resp.</li> </ul> </li> <li>Fixed KeyError for empty metadata.</li> </ul> </li> <li> Setup:<ul> <li>Pinned <code>pyzmq==24.0.1</code> working version.</li> <li>Removed redundant patch for the issue.</li> </ul> </li> <li> Maintaince:<ul> <li>Fixed missing pkg name <code>import_dependency_safe</code> functions calls.</li> </ul> </li> <li> Bash Script: <ul> <li>Fixed gstreamer installation.</li> </ul> </li> <li> CI:<ul> <li>Fixed missing v4l2loopback apt dependency on Linux envs.</li> <li>Added fix for RTCPeerConnection fails to create RTCDtlsTransport (Related issue: aiortc/aiortc#804)<ul> <li>Pinned <code>cryptography==38.0.4</code> in dependencies.</li> </ul> </li> <li>Pinned Linux image to <code>ubuntu-20.04</code> in github actions.</li> <li>Fixed No module named 'httpx' bug.<ul> <li>Added <code>httpx</code> library import.</li> </ul> </li> <li>Fixed F821 undefined name bug.</li> <li>Fixed Gstreamer bug.</li> </ul> </li> <li> Docs:<ul> <li>Fixed hyperlinks to new GitHub's form schemas. </li> <li>Fixed non-rendering images in README.md <ul> <li>Replaced all relative image/gifs paths with absolute URLs in README.md.</li> </ul> </li> <li>Fixed badges/shields#8671 badge issue in README.md</li> <li>Fixed GitLab CDN links throwing blocked by CORS policy bug.<ul> <li>Replaced gitlab GitHack CDN links with with bitbucket.</li> </ul> </li> <li>Fixed DASH playback failing by setting the <code>maxAttempts</code> to Infinity.</li> <li>Removed <code>x-sign</code> glow-text effect CSS.</li> <li>Fixed several typos (suggested by @timgates42)</li> <li>Fixed coverage badge.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #346</li> <li>PR #348</li> <li>PR #349</li> <li>PR #350</li> <li>PR #351</li> </ul> New Contributors <ul> <li>@sueskind</li> </ul>"},{"location":"changelog/#v026-2022-07-05","title":"v0.2.6 (2022-07-05)","text":"New Features <ul> <li> Docs:<ul> <li>Added new bonus example for RTSP/RTP Live-Streaming using WriteGear's Compression Mode.</li> <li>Added \"How to resolve zmq.error.ZMQError\" FAQ for NetGear API.(PR by @iandol)</li> <li>Added new ko-fi button to README.md</li> <li>Added new contributors block to changelog.md</li> </ul> </li> <li> Maintenance: <ul> <li>Added new patterns to <code>.gitignore</code> to ignore pypi's <code>build</code> directory and <code>egg-info</code> files.</li> </ul> </li> <li> CI:<ul> <li>Switched to new Issue GitHub's form schema using YAML<ul> <li>Added new <code>bug_report.yaml</code>.</li> <li>Added new <code>question.yaml</code>.</li> <li>Added new <code>proposal.yaml</code>.</li> <li>Deleted depreciated markdown files.</li> <li>Polished forms.</li> </ul> </li> </ul> </li> </ul> Updates/Improvements <ul> <li> Setup.py:<ul> <li>Bumped version to <code>0.2.6</code>.</li> <li>Updated logic operators and dependency.<ul> <li>Replaced <code>&gt;=</code> comparsion operator with more flexible <code>~=</code>.</li> <li>Replaced <code>distutils.version.LooseVersion</code> with <code>pkg_resources.parse_version</code>.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Updated Site Navigation.<ul> <li>Added new notices to inform users more effectively about bonus examples.</li> <li>Added new <code>Bonus</code> section to navigation and moved suitable pages under it.</li> <li>Updated headings and URLs.</li> </ul> </li> <li>Redesigned and Rewritten Donation and Contribution section to README.md</li> <li>Updated Zenodo badge and Bibtex entry.</li> <li>Updated Admonition Icon, FAQs and site-links.</li> <li>Reformatted code and its comments.</li> <li>Updated <code>changelog.md</code>.</li> </ul> </li> <li> API:<ul> <li>Updated depreciated tostring() to tobytes(). <code>tostring</code> was renamed to <code>tobytes</code> for the purposes for clarity in Python 3.2. https://docs.python.org/3/library/array.html#array.array.tobytes</li> </ul> </li> <li> CI:<ul> <li>Added more paths and files to skip commits.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> <code>-input_framerate</code> parameter now accepts any positive value for WriteGear and StreamGear APIs.</li> </ul> Bug-fixes <ul> <li> API:<ul> <li>Fixed <code>-input_framerate</code> less than 5 does not get used in WriteGear and StreamGear APIs.(PR by @freol35241)</li> </ul> </li> <li> CamGear: Fixed Yt-dlp generated HTTP DASH Segments URLs not supported by OpenCV's VideoCapture(PR by @DynamiteC)</li> <li> StreamGear: <ul> <li>Fixed <code>hls_segment_type</code> not working bug. (PR by @enarche-ahn)</li> <li>Fixed critical logging parameter bug<ul> <li>Fixed debug logs even when <code>logging=False</code> in StreamGear's Real-time Mode. (patch suggested by @enarche-ahn)</li> <li>Added length check to <code>-video_source</code> attribute to correctly infers it as empty(or invalid).</li> </ul> </li> </ul> </li> <li> CI:<ul> <li>Xfailed RTSP CamGear CI test.</li> <li>Fixed pinned version syntax bug in docs_deployer workflow.</li> <li>Fixed typos in Github forms and its context.</li> <li>Added missing dependency.</li> </ul> </li> <li> Docs:<ul> <li>Fixed jinja2 <code>3.1.0</code> or above breaks mkdocs.<ul> <li><code>jinja2&gt;=3.1.0</code> breaks mkdocs (mkdocs/mkdocs#2799), therefore pinned jinja2 version to <code>&lt;3.1.0</code>.</li> </ul> </li> <li>Fixed support for new <code>mkdocstring</code> versions<ul> <li>Replaced rendering sub-value with options.</li> <li>Removed pinned <code>mkdocstrings==0.17.0</code> version.</li> </ul> </li> <li>Fixed Netgear+Webgear bonus example code bugs.(PR by @iandol)<ul> <li>Added a missing import.</li> <li>Removed <code>self.</code> typo.</li> <li>Replaced the <code>return</code> value with <code>break</code> in the async as it triggers an error. </li> </ul> </li> <li>Fixed external bug that causing \"Home\" tab to irresponsive randomly when accessed from other tabs.</li> <li>Fixed indentation and spacing.</li> <li>Fixed typos and updated context.</li> <li>Removed dead code.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #288</li> <li>PR #290</li> <li>PR #293</li> <li>PR #295</li> <li>PR #307</li> <li>PR #313</li> <li>PR #320</li> </ul> New Contributors <ul> <li>@iandol</li> <li>@freol35241</li> <li>@enarche-ahn</li> <li>@DynamiteC</li> </ul>"},{"location":"changelog/#v025-2021-02-11","title":"v0.2.5 (2021-02-11)","text":"New Features <ul> <li> WriteGear: <ul> <li>Add support for GStreamer pipeline in WriteGear API's Non-Compression mode:<ul> <li>Implemented GStreamer Pipeline Mode to accept GStreamer pipeline as string to its output_filename parameter.</li> <li>Added new special <code>-gst_pipeline_mode</code> attribute for its output_params parameter.</li> <li>This feature provides flexible way to directly write video frames into GStreamer Pipeline with controlled bitrate. </li> <li>Added new docs and updated existing docs with related changes.</li> </ul> </li> <li>Added new <code>-ffpreheaders</code> special attribute to WriteGear's options parameter:<ul> <li>This attribute is specifically required to set special FFmpeg parameters in Compression Mode that are present at the starting of command(such as <code>-re</code>).</li> <li>This attribute only accepts list datatype as value.</li> <li>Added related docs.</li> </ul> </li> </ul> </li> <li> NetGear: <ul> <li>Added bidirectional data transfer support by extending Bidirectional mode support to exclusive Multi-Clients and Multi-Servers modes:<ul> <li>Users will now able to send data bidirectionally in both Multi-Clients and Multi-Servers exclusive modes.</li> <li>Bidirectional mode will no longer disables automatically when Multi-Clients and Multi-Servers modes already enabled.</li> <li>Added new docs and updated existing docs with related changes.</li> </ul> </li> </ul> </li> <li> Maintenance: <ul> <li>Added official support for Python-3.10 legacies.</li> <li>Added <code>float</code> value support to <code>THREAD_TIMEOUT</code> optional parameter.</li> <li>Added info about dropped support for Python-3.6 legacies through announcement bar.</li> <li>Added <code>config.md</code> file for Issue templates.</li> <li>Added title to Issue templates.</li> </ul> </li> <li> Docs:<ul> <li>Added new Code Annotations</li> <li>Added new icons to headings.</li> <li>Added Advanced VideoGear usage example with CamGear backend.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Setup.py:<ul> <li>Dropped support for Python-3.6 and below legacies.</li> <li>Updated logging formatting.</li> <li>Updated python_requires to <code>&gt;=3.7</code>.</li> <li>Bumped version to <code>0.2.5</code>.</li> </ul> </li> <li> Helper:<ul> <li>Vidgear will now report current version on every run.</li> </ul> </li> <li> Docs: <ul> <li>Updated SSH tunneling docs context.</li> <li>Excluded <code>docs</code> directory from CI envs.</li> <li>Updated Zenodo badge and BibTeX entry.</li> <li>Updated dark theme hue to <code>260</code>.</li> <li>Updated Admonitions.</li> <li>Additional warnings against pushing PR against VidGear's <code>testing</code> branch only.</li> <li>Updated code comments.</li> </ul> </li> <li> CI:<ul> <li>Removed support for Python-3.6 legacies from all workflows.</li> <li>Updated NetGear's Exclusive Mode tests.</li> <li>Added GStreamer Pipeline Mode tests.</li> </ul> </li> <li> Maintenance: <ul> <li>Updated Issue and PR templates.</li> <li>Updated metadata.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Dropped support for Python-3.6 legacies from vidgear.</li> </ul> Bug-fixes <ul> <li> NetGear: Fixed bidirectional mode overriding multi-clients mode's data.</li> <li> WriteGear: <ul> <li>Fixed wrongly defined ffmpeg_preheaders.</li> <li>Fixed condition logic bugs.</li> <li>Fixed UnboundLocalError bug.</li> </ul> </li> <li> Setup: Fixed uvicorn and aiortc dropped support for Python-3.6 legacies.</li> <li> CI: <ul> <li>Fixed GitHub Actions interprets <code>3.10</code> as <code>3.1</code> if used without strings.</li> <li>Fixed naming error in azure YAML.</li> </ul> </li> <li> Docs:<ul> <li>Fixed codecov badge URL in README.md</li> <li>Fixed hyperlinks in README.</li> <li>Fixed indentation and spacing.</li> <li>Fixed typos and updated context.</li> <li>Removed dead code.</li> </ul> </li> <li> Maintenance: <ul> <li>Removed depreciated condition checks.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #283</li> <li>PR #284</li> </ul>"},{"location":"changelog/#v024-2021-12-05","title":"v0.2.4 (2021-12-05)","text":"New Features <ul> <li> CamGear: <ul> <li>Added a new YT_backend Internal Class with YT-DLP backend:<ul> <li>Implemented <code>YT_backend</code> a new CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs.</li> <li>Added support for pipeling (live) video-frames from all yt-dlp supported streaming sites: https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites</li> <li>Implemented algorithm from scratch for auto-extracting resolution specific streamable URLs for pipelineing.</li> <li>Implemented logic for auto-calculating <code>best</code> and <code>worst</code> resolutions.</li> <li>Added new <code>ytv_metadata</code> global parameter to CamGear for accessing video's metadata(such as duration, title, description) on-the-go.</li> <li>\u26a0\ufe0f Playlists are still unsupported.</li> </ul> </li> </ul> </li> <li> WebGear_RTC: <ul> <li>Implemented a new easy way of defining Custom Streaming Class with suitable source(such as OpenCV):<ul> <li>Added new <code>custom_stream</code> attribute with WebGear_RTC <code>options</code> parameter that allows you to easily define your own Custom Streaming Class with suitable source(such as OpenCV).</li> <li>This implementation supports repeated Auto-Reconnection or Auto-Refresh out-of-the-box.</li> <li>This implementation is more user-friendly and easy to integrate within complex APIs.</li> <li>This implementation requires at-least <code>read()</code> and <code>stop()</code> methods implemented within Custom Streaming Class, otherwise WebGear_RTC will throw ValueError.</li> <li>This implementation supports all vidgear's VideoCapture APIs readily as input.</li> </ul> </li> </ul> </li> <li> Maintenance:<ul> <li>Added new <code>.gitignore</code>  for specifying intentionally untracked files to ignore<ul> <li>Added more files entries to <code>.gitignore</code>.</li> </ul> </li> <li>Added new <code>.gitattributes</code> to manage how Git reads line endings.<ul> <li>Enabled <code>auto</code> default behavior, in case people don't have <code>core.autocrlf</code> set.</li> <li>Enforced LF line-endings for selective files types.</li> <li>Added Binary data files that specifies they are not text, and git should not try to change them.</li> <li>Added Language aware diff headers.</li> <li>Added Linguist language overrides.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added bonus example to add real-time file audio encoding with VideoGear and Stabilizer class.</li> <li>Added complete usage docs with new CamGear's Internal Class with YT-DLP backend.</li> <li>Added instructions to extract video's metadata in CamGear.</li> <li>Added donation link in page footer with bouncing heart animation through pure CSS.</li> <li>Added info about critical changes in <code>v0.2.4</code> and above installation through new announcement bar.</li> <li>Added related usage docs for new WebGear_RTC custom streaming class.</li> <li>Added changes for upgrading mkdocs-material from <code>v7.x</code> to newer <code>v8.x</code>.</li> <li>Added outdated version warning block.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> CamGear:<ul> <li>Added <code>is_livestream</code> global YT_backend parameters.</li> <li>Added default options for yt-dlp for extracting info_dict(metadata) of the video as a single JSON line.</li> <li>Completely removed old logic for extracting streams using pafy.</li> <li>Removed all dead code related to streamlink backend.</li> </ul> </li> <li> Setup.py:<ul> <li>Moved all API specific dependencies to <code>extra_requires</code> under the name <code>\"core\"</code>. [PR #268 by @zpapakipos]</li> <li>Added rule to replace GitHub heading links in description.</li> <li>Updated <code>extra_require</code> dependencies.</li> <li>Removed <code>streamlink</code> dependency.</li> <li>Removed <code>pafy</code> dependency.</li> <li>Removed <code>pyzmq</code> from latest_version group.</li> <li>Updated SEO Keywords.</li> </ul> </li> <li> Docs: <ul> <li>Re-written <code>pip</code> and <code>source</code> installation docs. </li> <li>Added warning for using <code>-disable_force_termination</code> flag for short duration videos.</li> <li>Added <code>permalink_title</code> entry to mkdocs.yml.</li> <li>Updated CamGear parameters.</li> <li>Updated Admonitions with related information.</li> <li>Updated Functional Block Diagram(<code>gears_fbd.png</code>) image.</li> <li>Updated installation instructions.</li> <li>Updated Advanced examples using WebGear_RTC's custom streaming class.</li> <li>Updated code highlighting.</li> <li>Updated zenodo badge.</li> <li>Updated BibTex for project citation.</li> <li>Replaced incorrect API parameter docs.</li> <li>Updated WebGear_RTC parameters.</li> </ul> </li> <li> CI:<ul> <li>Updated CI tests for new WebGear_RTC custom streaming class.</li> <li>Restored <code>test_stream_mode</code> CamGear test.</li> <li>Updated Streaming Sites test links.</li> <li>Added more tests cases.</li> </ul> </li> <li> Maintenance: <ul> <li>Updated spacing in logger formatting.</li> <li>Renamed Asyncio Helper logger name.</li> <li>Changed logging colors.</li> <li>Updated logging messages.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Installation command with <code>pip</code> has been changed in <code>v0.2.4</code>:<ul> <li>The legacy <code>pip install vidgear</code> command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use <code>pip install vidgear[core]</code> command instead.</li> </ul> </li> <li> CamGear:<ul> <li>Removed <code>streamlink</code> backend support from <code>stream_mode</code> in favor of more reliable CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs.<ul> <li>CamGear will raise <code>ValueError</code> if streaming site URL is unsupported by yt-dlp backend.</li> <li>CamGear will raise <code>ValueError</code> if <code>yt-dlp</code> isn't installed and <code>stream_mode</code> is enabled.</li> </ul> </li> <li>Removed automatic enforcing of GStreamer backend for YouTube-livestreams and made it optional.<ul> <li>The CamGear will not raise ValueError if GStreamer support is missing in OpenCV backends.</li> </ul> </li> </ul> </li> <li> WebGear_RTC:<ul> <li>Removed support for assigning Custom Media Server Class(inherited from aiortc's VideoStreamTrack) in WebGear_RTC through its <code>config</code> global parameter.</li> <li>WebGear_RTC API will now throws ValueError if <code>source</code> parameter is NoneType as well as <code>custom_stream</code> attribute is undefined.</li> </ul> </li> <li> Helper: <ul> <li>Removed <code>restore_levelnames</code> method.</li> <li>Removed <code>youtube_url_validator</code> helper method.</li> </ul> </li> </ul> Bug-fixes <ul> <li> CamGear:<ul> <li>Fixed KeyError Bug for missing attributed in meta_data json in some streaming sites.</li> </ul> </li> <li> Helper: <ul> <li>Removed unused imports.</li> </ul> </li> <li> Docs:<ul> <li>Removed slugify from mkdocs which was causing invalid hyperlinks in docs.</li> <li>Fixed GitHub hyperlinks in README.md.</li> <li>Fixed hyperlink in announcement bar.</li> <li>Fixed content tabs failing to work.</li> <li>Fixed line-endings and usage example code.</li> <li>Removed any <code>pafy</code> and <code>streamlink</code> references.</li> <li>Fixed context and typos.</li> </ul> </li> <li> CI: <ul> <li>Fixed NameError bugs in WebGear_RTC CI test.</li> </ul> </li> <li> Maintenance: <ul> <li>Removed dead logger code causing Python's Built-in logging module to hide logs.</li> <li>Removed unused <code>logging</code> import.</li> <li>Updated code comments.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #268</li> <li>PR #272</li> <li>PR #274</li> </ul> New Contributors <ul> <li>@zpapakipos</li> </ul>"},{"location":"changelog/#v023-2021-10-27","title":"v0.2.3 (2021-10-27)","text":"New Features <ul> <li> CamGear: <ul> <li>Added support for <code>4K</code> Streaming URLs.</li> </ul> </li> <li> Helper: <ul> <li>Implemented logging ColorFormatter string alignment.<ul> <li>Center aligned logging Level-name and Class-name.</li> <li>Changed <code>%</code> formatting style with modern <code>{</code>.</li> <li>Re-added <code>asctime</code> value to Formatter string.</li> <li>Re-arranged parameter positions in Formatter string.</li> </ul> </li> </ul> </li> <li> Maintenance:<ul> <li>Added new <code>.gitignore</code>  for specifying intentionally untracked files to ignore<ul> <li>Added more files entries to <code>.gitignore</code>.</li> </ul> </li> <li>Added new <code>.gitattributes</code> to manage how Git reads line endings.<ul> <li>Enabled <code>auto</code> default behavior, in case people don't have <code>core.autocrlf</code> set.</li> <li>Enforced LF line-endings for selective files types.</li> <li>Added Binary data files that specifies they are not text, and git should not try to change them.</li> <li>Added Language aware diff headers.</li> <li>Added Linguist language overrides.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added new ScreenGear with WebGear_RTC API bonus example.</li> <li>Added support for <code>hl_lines</code> argument for highlighting specific code lines.</li> <li>Added drop-shadow effects for its <code>slate</code> theme to improve visibility.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> CamGear:<ul> <li>Replaced <code>youtube-dl</code> with <code>yt-dlp</code> as pafy backend for YouTube videos pipelining.<ul> <li>Implemented hack to trick pafy into assuming <code>yt-dlp</code> as <code>youtube-dl</code>.</li> <li>Using <code>sys.modules</code> to present <code>yt-dlp</code> as <code>youtube-dl</code>.</li> <li><code>yt-dlp</code> python API functions exactly similar to <code>youtube-dl</code>.</li> <li>Replaced <code>youtube-dl</code> dependency with <code>yt-dlp</code>.</li> <li>Replaced <code>youtube-dl</code> imports with <code>yt-dlp</code>.</li> </ul> </li> </ul> </li> <li> StreamGear: <ul> <li>Updated default <code>stream_count</code> internal dict key value to 1.</li> </ul> </li> <li> Maintenance:<ul> <li>Introduced python short-circuiting for handling logging logic.</li> <li>Enabled logging for <code>check_WriteAccess</code> method in WriteGear, StreamGear and NetGear APIs.</li> </ul> </li> <li> Docs:<ul> <li>Added warning for ScreenGear outputting RGBA frames instead of default BGR frames with <code>mss</code> backend.</li> <li>Added warnings for properly formatting <code>output_params</code> when assigning external audio-source in WriteGear.</li> <li>Added depreciation notice for Python 3.6 legacies.</li> <li>Restructured docs to make it more user-friendly.</li> <li>Updated, Extended and Improved context.</li> <li>Improved code comments.</li> <li>Updated docs admonitions.</li> <li>Updated <code>Zenodo</code> badge.</li> </ul> </li> <li> CI: <ul> <li>Migrated to new Codecov Uploader in Azure Pipelines.<ul> <li>Support for the Bash Uploader will be deprecated on February 1<sup>st</sup>, 2022. See: https://docs.codecov.com/docs/about-the-codecov-bash-uploader</li> <li>Added commands for signature and SHASUM verification to ensure integrity of the Uploader before use.</li> <li>Replaced related bash commands.</li> </ul> </li> <li>Replaced <code>env</code> with <code>export</code> in ci_linux.yml.</li> <li>Replaced <code>bubkoo/needs-more-info@v1</code> with <code>wow-actions/needs-more-info@v1</code>.</li> <li>Added codecov secret token through <code>env</code> variable. </li> <li>Added wildcard to skip CI tests for doc(<code>.md</code>) files.</li> <li>Added <code>.md</code> files to Codecov ignore list.</li> <li>Update vidgear's banner image.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> <code>check_WriteAccess</code> will now return as invalid path if writing directory does not exists. This will effect output file handling in WriteGear and StreamGear APIs.</li> </ul> Bug-fixes <ul> <li> StreamGear:<ul> <li>Fixed StreamGear Malformed URI Error with HLS Segments [PR #243 by @Vboivin]<ul> <li>Removed the extra <code>'%'</code> character from the naming convention for segment files.</li> <li>Used <code>stream_count</code> internal dict variable to alter template for HLS segment filenames.</li> </ul> </li> </ul> </li> <li> WriteGear: <ul> <li>Fixed bug in disable_force_termination logic which accidentally disables force termination.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Fixed <code>name 'VideoStreamTrack' is not defined</code> bug.</li> </ul> </li> <li> Setup.py: <ul> <li>Fixed <code>TypeError</code> bug.</li> <li>Fixed invalid <code>latest_version</code> retrieval.</li> </ul> </li> <li> Helper:<ul> <li>Fixed <code>check_WriteAccess</code> failing to recognize correct permission for writing the output file on windows platform. <ul> <li>Implemented separate logic for <code>Windows</code> and <code>*nix</code> platforms.</li> <li>Added new <code>stat</code> import.</li> <li>Improved warnings and error handling.</li> <li>Added logging parameter to <code>check_WriteAccess</code>.</li> </ul> </li> <li>Fixed bug in check_WriteAccess that throws <code>OSError</code> while handling URLs.</li> </ul> </li> <li> Docs:<ul> <li>Fixed bugs in WriteGear's Compression Mode with Live Audio Input example.</li> <li>Fixed \"drop-shadow\" property via <code>filter</code> function conflicting with sidecard button.<ul> <li>Added new CSS classes for image, admonitions and code highlight in dark theme.</li> </ul> </li> <li>Several internal and external webpage links typos fixed.</li> <li>Fixed several language typos.</li> </ul> </li> <li> CI: <ul> <li>Fixed Azure Pipeline coverage upload bugs.</li> <li>Fixed random errors in CamGear <code>stream_mode</code> test.</li> </ul> </li> <li> Bash:<ul> <li>Removed the Windows carriage returns from the shell scripts to be able to execute them on Linux. </li> </ul> </li> <li> Fixed logging comments.</li> </ul> Pull Requests <ul> <li>PR #249</li> <li>PR #262</li> </ul> New Contributors <ul> <li>@Vboivin</li> </ul>"},{"location":"changelog/#v022-2021-09-02","title":"v0.2.2 (2021-09-02)","text":"New Features <ul> <li> StreamGear: <ul> <li>Native Support for Apple HLS Multi-Bitrate Streaming format:<ul> <li>Added support for new Apple HLS (HTTP Live Streaming) HTTP streaming format in StreamGear.</li> <li>Implemented default workflow for auto-generating primary HLS stream of same resolution and framerate as source.</li> <li>Added HLS support in Single-Source and Real-time Frames Modes.</li> <li>Implemented inherit support for <code>fmp4</code> and <code>mpegts</code> HLS segment types.</li> <li>Added adequate default parameters required for trans-coding HLS streams.</li> <li>Added native support for HLS live-streaming.</li> <li>Added <code>\"hls\"</code> value to <code>format</code> parameter for easily selecting HLS format.</li> <li>Added HLS support in <code>-streams</code> attribute for transcoding additional streams.</li> <li>Added support for <code>.m3u8</code> and <code>.ts</code> extensions in <code>clear_prev_assets</code> workflow.</li> <li>Added validity check for <code>.m3u8</code> extension in output when HLS format is used.</li> <li>Separated DASH and HLS command handlers.</li> <li>Created HLS format exclusive parameters.</li> <li>Implemented <code>-hls_base_url</code> FFMpeg parameter support.</li> </ul> </li> <li>Added support for audio input from external device:<ul> <li>Implemented support for audio input from external device.</li> <li>Users can now easily add audio device and decoder by formatting them as python list.</li> <li>Modified <code>-audio</code> parameter to support <code>list</code> data type as value.</li> <li>Modified <code>validate_audio</code> helper function to validate external audio devices.</li> </ul> </li> <li>Added <code>-seg_duration</code> to control segment duration.</li> </ul> </li> <li> NetGear:<ul> <li>New SSH Tunneling Mode for remote connection:<ul> <li>New SSH Tunneling Mode for connecting ZMQ sockets across machines via SSH tunneling.</li> <li>Added new <code>ssh_tunnel_mode</code> attribute to enable ssh tunneling at provide address at server end only.</li> <li>Implemented new <code>check_open_port</code> helper method to validate availability of host at given open port.</li> <li>Added new attributes <code>ssh_tunnel_keyfile</code> and <code>ssh_tunnel_pwd</code> to easily validate ssh connection.</li> <li>Extended this feature to be compatible with bi-directional mode and auto-reconnection.</li> <li>Disabled support for exclusive Multi-Server and Multi-Clients modes.</li> <li>Implemented logic to automatically enable <code>paramiko</code> support if installed.</li> <li>Reserved port-<code>47</code> for testing.</li> </ul> </li> <li>Additional colorspace support for input frames with Frame-Compression enabled:<ul> <li>Allowed to manually select colorspace on-the-fly with JPEG frame compression.</li> <li>Updated <code>jpeg_compression</code> dict parameter to support colorspace string values.</li> <li>Added all supported colorspace values by underline <code>simplejpeg</code> library.</li> <li>Server enforced frame-compression colorspace on client(s).</li> <li>Enable \"BGR\" colorspace by default.</li> <li>Added Example for changing incoming frames colorspace with NetGear's Frame Compression.</li> <li>Updated Frame Compression parameters in NetGear docs.</li> <li>Updated existing CI tests to cover new frame compression functionality.</li> </ul> </li> </ul> </li> <li> NetGear_Async:<ul> <li>New exclusive Bidirectional Mode for bidirectional data transfer:<ul> <li>NetGear_Async's first-ever exclusive Bidirectional mode with pure asyncio implementation.</li> <li>Bidirectional mode is only available with User-defined Custom Source(i.e. <code>source=None</code>)</li> <li>Added support for <code>PAIR</code> &amp; <code>REQ/REP</code> bidirectional patterns for this mode.</li> <li>Added powerful <code>asyncio.Queues</code> for handling user data and frames in real-time.</li> <li>Implemented new <code>transceive_data</code> method  to Transmit (in Recieve mode) and Receive (in Send mode) data in real-time.</li> <li>Implemented <code>terminate_connection</code> internal asyncio method to safely terminate ZMQ connection and queues.</li> <li>Added <code>msgpack</code> automatic compression encoding and decoding of data and frames in bidirectional mode.</li> <li>Added support for <code>np.ndarray</code> video frames.</li> <li>Added new <code>bidirectional_mode</code> attribute for enabling this mode.</li> <li>Added 8-digit random alphanumeric id generator for each device.</li> <li>NetGear_Async will throw <code>RuntimeError</code> if bidirectional mode is disabled at server or client but not both.</li> </ul> </li> <li>Added new <code>disable_confirmation</code> used to force disable termination confirmation from client in <code>terminate_connection</code>.</li> <li>Added <code>task_done()</code> method after every <code>get()</code> call to gracefully terminate queues.</li> <li>Added new <code>secrets</code> and <code>string</code> imports.</li> </ul> </li> <li> WebGear: <ul> <li>Updated JPEG Frame compression with <code>simplejpeg</code>:<ul> <li>Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality.</li> <li>Utilized <code>encode_jpeg</code> and <code>decode_jpeg</code> methods to implement turbo-JPEG transcoding with <code>simplejpeg</code>.</li> <li>Added new options to control JPEG frames quality, enable fastest dct, fast upsampling  to boost performance.</li> <li>Added new <code>jpeg_compression</code>, <code>jpeg_compression_quality</code>, <code>jpeg_compression_fastdct</code>, <code>jpeg_compression_fastupsample</code> attributes.</li> <li>Enabled fast dct by default with JPEG frames at <code>90%</code>.</li> <li>Incremented default frame reduction to <code>25%</code>.</li> <li>Implemented automated grayscale colorspace frames handling.</li> <li>Updated old and added new usage examples.</li> <li>Dropped support for depreciated attributes from WebGear and added new attributes.</li> </ul> </li> <li>Added new WebGear Theme: (Checkout at https://github.com/abhiTronix/vidgear-vitals)<ul> <li>Added responsive image scaling according to screen aspect ratios.</li> <li>Added responsive text scaling.</li> <li>Added rounded border and auto-center to image tag.</li> <li>Added bootstrap css properties to implement auto-scaling.</li> <li>Removed old <code>resize()</code> hack.</li> <li>Improved text spacing and weight.</li> <li>Integrated toggle full-screen to new implementation.</li> <li>Hide Scrollbar both in WebGear_RTC and WebGear Themes.</li> <li>Beautify files syntax and updated files checksum.</li> <li>Refactor files and removed redundant code.</li> <li>Bumped theme version to <code>v0.1.2</code>.</li> </ul> </li> </ul> </li> <li> WebGear_RTC:<ul> <li>Added native support for middlewares:<ul> <li>Added new global <code>middleware</code> variable for easily defining Middlewares as list.</li> <li>Added validity check for Middlewares.</li> <li>Added tests for middlewares support.</li> <li>Added example for middlewares support.</li> <li>Extended middlewares support to WebGear API too.</li> <li>Added related imports.</li> </ul> </li> <li>Added new WebGear_RTC Theme:  (Checkout at https://github.com/abhiTronix/vidgear-vitals)<ul> <li>Implemented new responsive video scaling according to screen aspect ratios.</li> <li>Added bootstrap CSS properties to implement auto-scaling.</li> <li>Removed old <code>resize()</code> hack.</li> <li>Beautify files syntax and updated files checksum.</li> <li>Refactored files and removed redundant code.</li> <li>Bumped theme version to <code>v0.1.2</code></li> </ul> </li> </ul> </li> <li> Helper: <ul> <li>New automated interpolation selection for gears:<ul> <li>Implemented <code>retrieve_best_interpolation</code> method to automatically select best available interpolation within OpenCV.</li> <li>Added support for this method in WebGear, WebGear_RTC and Stabilizer Classes/APIs.</li> <li>Added new CI tests for this feature.</li> </ul> </li> <li>Implemented <code>get_supported_demuxers</code> method to get list of supported demuxers.</li> </ul> </li> <li> CI:<ul> <li>Added new <code>no-response</code> work-flow for stale issues.</li> <li>Added new CI tests for SSH Tunneling Mode.</li> <li>Added <code>paramiko</code> to CI dependencies.</li> <li>Added support for <code>\"hls\"</code> format in existing CI tests.</li> <li>Added new functions <code>check_valid_m3u8</code> and <code>extract_meta_video</code> for validating HLS files.</li> <li>Added new <code>m3u8</code> dependency to CI workflows.</li> <li>Added complete CI tests for NetGear_Async's new Bidirectional Mode:<ul> <li>Implemented new exclusive <code>Custom_Generator</code> class for testing bidirectional data dynamically on server-end.</li> <li>Implemented new exclusive <code>client_dataframe_iterator</code> method for testing bidirectional data on client-end.</li> <li>Implemented <code>test_netgear_async_options</code> and <code>test_netgear_async_bidirectionalmode</code> two new tests.</li> <li>Added <code>timeout</code> value on server end in CI tests.</li> </ul> </li> </ul> </li> <li> Setup.py:<ul> <li>Added new <code>cython</code> and <code>msgpack</code> dependency.</li> <li>Added <code>msgpack</code> and <code>msgpack_numpy</code> to auto-install latest.</li> </ul> </li> <li> BASH: <ul> <li>Added new <code>temp_m3u8</code> folder for generating M3U8 assets in CI tests.</li> </ul> </li> <li> Docs:<ul> <li>Added docs for new Apple HLS StreamGear format:<ul> <li>Added StreamGear HLS transcoding examples for both StreamGear modes.</li> <li>Updated StreamGear parameters to w.r.t new HLS configurations.</li> <li>Added open-sourced \"Sintel\" - project Durian Teaser Demo with StreamGear's HLS stream using <code>Clappr</code> and raw.githack.com.</li> <li>Added new HLS chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear</li> <li>Added support for HLS video in Clappr within <code>custom.js</code> using HlsjsPlayback plugin.</li> <li>Added support for Video Thumbnail preview for HLS video in Clappr within <code>custom.js</code></li> <li>Added <code>hlsjs-playback.min.js</code> JS script and suitable configuration for HlsjsPlayback plugin.</li> <li>Added custom labels for quality levels selector in <code>custom.js</code>.</li> <li>Added new docs content related to new Apple HLS format.</li> <li>Updated DASH chunk folder at https://github.com/abhiTronix/vidgear-docs-additionals.</li> <li>Added example for audio input support from external device in StreamGear.</li> <li>Added steps for using <code>-audio</code> attribute on different OS platforms in StreamGear.</li> </ul> </li> <li>Added usage examples for NetGear_Async's Bidirectional Mode:<ul> <li>Added new Usage examples and Reference doc for NetGear_Async's Bidirectional Mode.</li> <li>Added new image asset for NetGear_Async's Bidirectional Mode.</li> <li>Added NetGear_Async's <code>option</code> parameter reference.</li> <li>Updated NetGear_Async definition in docs.</li> <li>Changed font size for Helper methods.</li> <li>Renamed <code>Bonus</code> section to <code>References</code> in <code>mkdocs.yml</code>.</li> </ul> </li> <li>Added Gitter sidecard embed widget:<ul> <li>Imported gitter-sidecar script to <code>main.html</code>.</li> <li>Updated <code>custom.js</code> to set global window option.</li> <li>Updated Sidecard UI in <code>custom.css</code>.</li> </ul> </li> <li>Added bonus examples to help section:<ul> <li>Implemented a curated list of more advanced examples with unusual configuration for each API.</li> </ul> </li> <li>Added several new contents and updated context.</li> <li>Added support for search suggestions, search highlighting and search sharing (i.e. deep linking)</li> <li>Added more content to docs to make it more user-friendly.</li> <li>Added warning that JPEG Frame-Compression is disabled with Custom Source in WebGear.</li> <li>Added steps for identifying and specifying sound card on different OS platforms in WriteGear.</li> <li>Added Zenodo DOI badge and its reference in BibTex citations.</li> <li>Added <code>extra.homepage</code> parameter, which allows for setting a dedicated URL for <code>site_url</code>.</li> <li>Added <code>pymdownx.striphtml</code> plugin for stripping comments.</li> <li>Added complete docs for SSH Tunneling Mode.</li> <li>Added complete docs for NetGear's SSH Tunneling Mode.</li> <li>Added <code>pip</code> upgrade related docs.</li> <li>Added docs for installing vidgear with only selective dependencies</li> <li>Added new <code>advance</code>/<code>experiment</code> admonition with new background color.</li> <li>Added new icons SVGs for <code>advance</code> and <code>warning</code> admonition.</li> <li>Added new usage example and related information.</li> <li>Added new image assets for ssh tunneling example.</li> <li>Added new admonitions</li> <li>Added new FAQs.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> VidGear Core: <ul> <li>New behavior to virtually isolate optional API specific dependencies by silencing <code>ImportError</code> on all VidGear's APIs import.</li> <li>Implemented algorithm to cache all imports on startup but silence any <code>ImportError</code> on missing optional dependency.</li> <li>Now <code>ImportError</code> will be raised only any certain API specific dependency is missing during given API's initialization.</li> <li>New <code>import_dependency_safe</code> to imports specified dependency safely with <code>importlib</code> module.</li> <li>Replaced all APIs imports with <code>import_dependency_safe</code>.</li> <li>Added support for relative imports in <code>import_dependency_safe</code>.</li> <li>Implemented <code>error</code> parameter to by default <code>ImportError</code> with a meaningful message if a dependency is missing, Otherwise if <code>error = log</code> a warning will be logged and on <code>error = silent</code> everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified.</li> <li>Implemented behavior that if a dependency is present, but older than <code>min_version</code> specified, an error is raised always.</li> <li>Implemented <code>custom_message</code> to display custom message on error instead of default one.</li> <li>Implemented separate <code>import_core_dependency</code> function to import and check for specified core dependency. </li> <li><code>ImportError</code> will be raised immediately if core dependency not found.</li> </ul> </li> <li> StreamGear: <ul> <li>Replaced depreciated <code>-min_seg_duration</code> flag with <code>-seg_duration</code>.</li> <li>Removed redundant <code>-re</code> flag from RTFM.</li> <li>Improved Live-Streaming performance by disabling SegmentTimline</li> <li>Improved DASH assets detection for removal by using filename prefixes.</li> </ul> </li> <li> NetGear:<ul> <li>Replaced <code>np.newaxis</code> with <code>np.expand_dims</code>.</li> <li>Replaced <code>random</code> module with <code>secrets</code> while generating system ID.</li> <li>Update array indexing with <code>np.copy</code>.</li> </ul> </li> <li> NetGear_Async:<ul> <li>Improved custom source handling.</li> <li>Removed deprecated <code>loop</code> parameter from asyncio methods.</li> <li>Re-implemented <code>skip_loop</code> parameter in <code>close()</code> method.</li> <li><code>run_until_complete</code> will not used if <code>skip_loop</code> is enabled.</li> <li><code>skip_loop</code> now will create asyncio task instead and will enable <code>disable_confirmation</code> by default.</li> <li>Replaced <code>create_task</code> with <code>ensure_future</code> to ensure backward compatibility with python-3.6 legacies.</li> <li>Simplified code for <code>transceive_data</code> method.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Improved handling of failed ICE connection.</li> <li>Made <code>is_running</code> variable globally available for internal use.</li> </ul> </li> <li> Helper: <ul> <li>Added <code>4320p</code> resolution support to <code>dimensions_to_resolutions</code> method.</li> <li>Implemented new <code>delete_file_safe</code> to safely delete files at given path.</li> <li>Replaced <code>os.remove</code> calls with <code>delete_file_safe</code>.</li> <li>Added support for filename prefixes in <code>delete_ext_safe</code> method.</li> <li>Improved and simplified <code>create_blank_frame</code> functions frame channels detection.</li> <li>Added <code>logging</code> parameter to capPropId function to forcefully discard any error(if required).</li> </ul> </li> <li> Setup.py: <ul> <li>Added patch for <code>numpy</code> dependency, <code>numpy</code> recently dropped support for python 3.6.x legacies. See https://github.com/numpy/numpy/releases/tag/v1.20.0</li> <li>Removed version check on certain dependencies.</li> <li>Re-added <code>aiortc</code> to auto-install latest version.</li> </ul> </li> <li> Asyncio: <ul> <li>Changed <code>asyncio.sleep</code> value to <code>0</code>.<ul> <li>The amount of time sleep is irrelevant; the only purpose await asyncio.sleep() serves is to force asyncio to suspend execution to the event loop, and give other tasks a chance to run. Also, <code>await asyncio.sleep(0)</code> will achieve the same effect. https://stackoverflow.com/a/55782965/10158117</li> </ul> </li> </ul> </li> <li> License: <ul> <li>Dropped publication year range to avoid confusion. (Signed and Approved by @abhiTronix)</li> <li>Updated Vidgear license's year of first publication of the work in accordance with US copyright notices defined by Title 17, Chapter 4(Visually perceptible copies): https://www.copyright.gov/title17/92chap4.html</li> <li>Reflected changes in all copyright notices.</li> </ul> </li> <li> CI: <ul> <li>Updated macOS VM Image to latest in azure devops.</li> <li>Updated VidGear Docs Deployer Workflow.</li> <li>Updated WebGear_RTC CI tests.</li> <li>Removed redundant code from CI tests.</li> <li>Updated tests to increase coverage.</li> <li>Enabled Helper tests for python 3.8+ legacies.</li> <li>Enabled logging in <code>validate_video</code> method.</li> <li>Added <code>-hls_base_url</code> to streamgear tests.</li> <li>Update <code>mpegdash</code> dependency to <code>0.3.0-dev2</code> version in Appveyor.</li> <li>Updated CI tests for new HLS support</li> <li>Updated CI tests from scratch for new native HLS support in StreamGear.</li> <li>Updated test patch for StreamGear.</li> <li>Added exception for RunTimeErrors in NetGear CI tests.</li> <li>Added more directories to Codecov ignore list.</li> <li>Imported relative <code>logger_handler</code> for asyncio tests.</li> </ul> </li> <li> Docs:<ul> <li>Re-positioned few docs comments at bottom for easier detection during stripping.</li> <li>Updated to new extra <code>analytics</code> parameter in Material Mkdocs.</li> <li>Updated dark theme to <code>dark orange</code>.</li> <li>Changed fonts =&gt; text: <code>Muli</code> &amp; code: <code>Fira Code</code></li> <li>Updated fonts to <code>Source Sans Pro</code>.</li> <li>Updated <code>setup.py</code> update-link for modules.</li> <li>Re-added missing StreamGear Code docs.</li> <li>Several minor tweaks and typos fixed.</li> <li>Updated <code>404.html</code> page.</li> <li>Updated admonitions colors and beautified <code>custom.css</code>.</li> <li>Replaced VideoGear &amp; CamGear with OpenCV in CPU intensive examples.</li> <li>Updated <code>mkdocs.yml</code> with new changes and URLs.</li> <li>Moved FAQ examples to bonus examples.</li> <li>Moved StreamGear primary modes to separate sections for better readability.</li> <li>Implemented separate overview and usage example pages for StreamGear primary modes.</li> <li>Improved StreamGear docs context and simplified language.</li> <li>Renamed StreamGear <code>overview</code> page to <code>introduction</code>.</li> <li>Re-written Threaded-Queue-Mode from scratch with elaborated functioning.</li> <li>Replace Paypal with Liberpay in <code>FUNDING.yml</code>.</li> <li>Updated FFmpeg Download links.</li> <li>Reverted UI change in CSS.</li> <li>Updated <code>changelog.md</code> and fixed clutter.</li> <li>Updated <code>README.md</code> and <code>mkdocs.yml</code> with new additions</li> <li>Updated context for CamGear example.</li> <li>Restructured and added more content to docs.</li> <li>Updated comments in source code.</li> <li>Removed redundant data table tweaks from <code>custom.css</code>.</li> <li>Re-aligned badges in README.md.</li> <li>Beautify <code>custom.css</code>.</li> <li>Updated <code>mkdocs.yml</code>.</li> <li>Updated context and fixed typos.</li> <li>Added missing helper methods in Reference.</li> <li>Updated Admonitions.</li> <li>Updates images assets.</li> <li>Bumped CodeCov.</li> </ul> </li> <li> Logging:<ul> <li>Improved logging level-names.</li> <li>Updated logging messages.</li> </ul> </li> <li> Minor tweaks to <code>needs-more-info</code> template.</li> <li> Updated issue templates and labels.</li> <li> Removed redundant imports.</li> </ul> Breaking Updates/Changes <ul> <li> Virtually isolated all API specific dependencies, Now <code>ImportError</code> for API-specific dependencies will be raised only when any of them is missing at API's initialization.</li> <li> Renamed <code>delete_safe</code> to <code>delete_ext_safe</code>.</li> <li> Dropped support for <code>frame_jpeg_quality</code>, <code>frame_jpeg_optimize</code>, <code>frame_jpeg_progressive</code> attributes from WebGear.</li> </ul> Bug-fixes <ul> <li> CamGear:<ul> <li>Hot-fix for Live Camera Streams:<ul> <li>Added new event flag to keep check on stream read.</li> <li>Implemented event wait for  <code>read()</code> to block it when source stream is busy.</li> <li>Added and Linked <code>THREAD_TIMEOUT</code> with event wait timout.</li> <li>Improved backward compatibility of new additions.</li> </ul> </li> <li>Enforced logging for YouTube live.</li> </ul> </li> <li> NetGear: <ul> <li>Fixed Bidirectional Video-Frame Transfer broken with frame-compression:<ul> <li>Fixed <code>return_data</code> interfering with return JSON-data in receive mode.</li> <li>Fixed logic.</li> </ul> </li> <li>Fixed color-subsampling interfering with colorspace.</li> <li>Patched external <code>simplejpeg</code> bug. Issue: https://gitlab.com/jfolz/simplejpeg/-/issues/11<ul> <li>Added <code>np.squeeze</code> to drop grayscale frame's 3<sup>rd</sup> dimension on Client's end.</li> </ul> </li> <li>Fixed bug that cause server end frame dimensions differ from client's end when frame compression enabled.</li> </ul> </li> <li> NetGear_Async: <ul> <li>Fixed bug related asyncio queue freezing on calling <code>join()</code>.</li> <li>Fixed ZMQ connection bugs in bidirectional mode.</li> <li>Fixed several critical bugs in event loop handling.</li> <li>Fixed several bugs in bidirectional mode implementation.</li> <li>Fixed missing socket termination in both server and client end.</li> <li>Fixed <code>timeout</code> parameter logic.</li> <li>Fixed typos in error messages.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Fixed stream freezes after web-page reloading:<ul> <li>Implemented new algorithm to continue stream even when webpage is reloaded.</li> <li>Inherit and modified <code>next_timestamp</code> VideoStreamTrack method for generating accurate timestamps.</li> <li>Implemented <code>reset_connections</code> callable to reset all peer connections and recreate Video-Server timestamps. (Implemented by @kpetrykin)</li> <li>Added <code>close_connection</code> endpoint in JavaScript to inform server page refreshing.(Thanks to @kpetrykin)</li> <li>Added exclusive reset connection node <code>/close_connection</code> in routes.</li> <li>Added <code>reset()</code> method to Video-Server class for manually resetting timestamp clock.</li> <li>Added <code>reset_enabled</code> flag to keep check on reloads.</li> <li>Fixed premature webpage auto-reloading.</li> <li>Added additional related imports.</li> </ul> </li> <li>Fixed web-page reloading bug after stream ended:<ul> <li>Disable webpage reload behavior handling for Live broadcasting.</li> <li>Disable reload CI test on Windows machines due to random failures.</li> <li>Improved handling of failed ICE connection.</li> </ul> </li> <li>Fixed Assertion error bug:<ul> <li>Source must raise MediaStreamError when stream ends instead of returning None-type.</li> </ul> </li> </ul> </li> <li> WebGear<ul> <li>Removed format specific OpenCV decoding and encoding support for WebGear.</li> </ul> </li> <li> Helper: <ul> <li>Regex bugs fixed:<ul> <li>New improved regex for discovering supported encoders in <code>get_supported_vencoders</code>.</li> <li>Re-implemented check for extracting only valid output protocols in <code>is_valid_url</code>.</li> <li>Minor tweaks for better regex compatibility.</li> </ul> </li> <li>Bugfix related to OpenCV import:<ul> <li>Bug fixed for OpenCV import comparison test failing with Legacy versions and throwing <code>ImportError</code>.</li> <li>Replaced <code>packaging.parse_version</code> with more robust <code>distutils.version</code>.</li> </ul> </li> <li>Fixed bug with <code>create_blank_frame</code> that throws error with gray frames:<ul> <li>Implemented automatic output channel correction inside <code>create_blank_frame</code> function.</li> <li>Extended automatic output channel correction support to asyncio package.</li> </ul> </li> <li>Implemented <code>RTSP</code> protocol validation as demuxer, since it's not a protocol but a demuxer.</li> <li>Removed redundant <code>logger_handler</code>, <code>mkdir_safe</code>, <code>retrieve_best_interpolation</code>, <code>capPropId</code> helper functions from asyncio package. Relatively imported helper functions from non-asyncio package.</li> <li>Removed unused <code>aiohttp</code> dependency.</li> <li>Removed <code>asctime</code> formatting from logging.</li> </ul> </li> <li> StreamGear: <ul> <li>Fixed Multi-Bitrate HLS VOD streams:<ul> <li>Re-implemented complete workflow for Multi-Bitrate HLS VOD streams.</li> <li>Extended support to both Single-Source and Real-time Frames Modes.</li> </ul> </li> <li>Fixed bugs with audio-video mapping.</li> <li>Fixed master playlist not generating in output.</li> <li>Fixed improper <code>-seg_duration</code> value resulting in broken pipeline.</li> <li>Fixed expected aspect ratio not calculated correctly for additional streams.</li> <li>Fixed stream not terminating when provided input from external audio device.</li> <li>Fixed bugs related to external audio not mapped correctly in HLS format.</li> <li>Fixed OPUS audio fragments not supported with MP4 video in HLS.</li> <li>Fixed unsupported high audio bit-rate bug.</li> </ul> </li> <li> Setup.py: <ul> <li>Fixed <code>latest_version</code> returning incorrect version for some PYPI packages.</li> <li>Removed <code>latest_version</code> variable support from <code>simplejpeg</code>.</li> <li>Fixed <code>streamlink</code> only supporting requests==2.25.1 on Windows.</li> <li>Removed all redundant dependencies like <code>colorama</code>, <code>aiofiles</code>, <code>aiohttp</code>.</li> <li>Fixed typos in dependencies.</li> </ul> </li> <li> Setup.cfg: <ul> <li>Replaced dashes with underscores to remove warnings.</li> </ul> </li> <li> CI:<ul> <li>Replaced buggy <code>starlette.TestClient</code> with <code>async-asgi-testclient</code> in WebGear_RTC</li> <li>Removed <code>run()</code> method and replaced with pure asyncio implementation.</li> <li>Added new <code>async-asgi-testclient</code> CI dependency.</li> <li>Fixed <code>fake_picamera</code> class logger calling <code>vidgear</code> imports prematurely before importing <code>picamera</code> class in tests.<ul> <li>Implemented new <code>fake_picamera</code> class logger inherently with <code>logging</code> module.</li> <li>Moved <code>sys.module</code> logic for faking to <code>init.py</code>.</li> <li>Added <code>__init__.py</code> to ignore in Codecov.</li> </ul> </li> <li>Fixed event loop closing prematurely while reloading:<ul> <li>Internally disabled suspending event loop while reloading.</li> </ul> </li> <li>Event Policy Loop patcher added for WebGear_RTC tests.</li> <li>Fixed <code>return_assets_path</code> path bug.</li> <li>Fixed typo in <code>TimeoutError</code> exception import.</li> <li>Fixed eventloop is already closed bug.</li> <li>Fixed eventloop bugs in Helper CI tests.</li> <li>Fixed several minor bugs related to new CI tests.</li> <li>Fixed bug in PiGear tests. </li> </ul> </li> <li> Docs:<ul> <li>Fixed 404 page does not work outside the site root with mkdocs.</li> <li>Fixed markdown files comments not stripped when converted to HTML.</li> <li>Fixed missing heading in VideoGear.</li> <li>Typos in links and code comments fixed.</li> <li>Several minor tweaks and typos fixed.</li> <li>Fixed improper URLs/Hyperlinks and related typos.</li> <li>Fixed typos in usage examples.</li> <li>Fixed redundant properties in CSS.</li> <li>Fixed bugs in <code>mkdocs.yml</code>.</li> <li>Fixed docs contexts and typos.</li> <li>Fixed <code>stream.release()</code> missing in docs.</li> <li>Fixed several typos in code comments.</li> <li>Removed dead code from docs.</li> </ul> </li> <li> Refactored Code and reduced redundancy.</li> <li> Fixed shutdown in <code>main.py</code>.</li> <li> Fixed logging comments.</li> </ul> Pull Requests <ul> <li>PR #210</li> <li>PR #215</li> <li>PR #222</li> <li>PR #223</li> <li>PR #227</li> <li>PR #231</li> <li>PR #233</li> <li>PR #237 </li> <li>PR #239 </li> <li>PR #243 </li> </ul> New Contributors <ul> <li>@kpetrykin</li> </ul>"},{"location":"changelog/#v021-2021-04-25","title":"v0.2.1 (2021-04-25)","text":"New Features <ul> <li> WebGear_RTC:<ul> <li>A new API that is similar to WeGear API in all aspects but utilizes WebRTC standard instead of Motion JPEG for streaming.</li> <li>Now it is possible to share data and perform teleconferencing peer-to-peer, without requiring that the user install plugins or any other third-party software.</li> <li>Added a flexible backend for <code>aiortc</code> - a python library for Web Real-Time Communication (WebRTC).</li> <li>Integrated all functionality and parameters of WebGear into WebGear_RTC API.</li> <li>Implemented JSON Response with a WebRTC Peer Connection of Video Server.</li> <li>Added a internal <code>RTC_VideoServer</code> server on WebGear_RTC, a inherit-class to aiortc's VideoStreamTrack API.</li> <li>New Standalone UI Default theme v0.1.1 for WebGear_RTC from scratch without using 3<sup>rd</sup>-party assets. (by @abhiTronix)</li> <li>New <code>custom.js</code> and <code>custom.css</code> for custom responsive behavior.</li> <li>Added WebRTC support to <code>custom.js</code> and ensured compatibility with WebGear_RTC.</li> <li>Added example support for ICE framework and STUN protocol like WebRTC features to <code>custom.js</code>.</li> <li>Added <code>resize()</code> function to <code>custom.js</code> to automatically adjust <code>video</code> &amp; <code>img</code> tags for smaller screens.</li> <li>Added WebGear_RTC support in main.py for easy access through terminal using <code>--mode</code> flag.</li> <li>Integrated all WebGear_RTC enhancements to WebGear Themes.</li> <li>Added CI test for WebGear_RTC.</li> <li>Added complete docs for WebGear_RTC API.</li> <li>Added bare-minimum as well as advanced examples usage code.</li> <li>Added new theme images.</li> <li>Added Reference and FAQs.</li> </ul> </li> <li> CamGear API:<ul> <li>New Improved Pure-Python Multiple-Threaded Implementation:<ul> <li>Optimized Threaded-Queue-Mode Performance. (PR by @bml1g12)</li> <li>Replaced regular <code>queue.full</code> checks followed by sleep with implicit sleep with blocking <code>queue.put</code>.</li> <li>Replaced regular <code>queue.empty</code> checks followed by queue.</li> <li>Replaced <code>nowait_get</code> with a blocking <code>queue.get</code> natural empty check.</li> <li>Up-to 2x performance boost than previous implementations. </li> </ul> </li> <li>New <code>THREAD_TIMEOUT</code> attribute to prevent deadlocks:<ul> <li>Added support for <code>THREAD_TIMEOUT</code> attribute to its <code>options</code> parameter.</li> <li>Updated CI Tests and docs.</li> </ul> </li> </ul> </li> <li> WriteGear API:<ul> <li>New more robust handling of default video-encoder in compression mode:<ul> <li>Implemented auto-switching of default video-encoder automatically based on availability.</li> <li>API now selects Default encoder based on priority: <code>\"libx264\" &gt; \"libx265\" &gt; \"libxvid\" &gt; \"mpeg4\"</code>.</li> <li>Added <code>get_supported_vencoders</code> Helper method to enumerate Supported Video Encoders.</li> <li>Added common handler for <code>-c:v</code> and <code>-vcodec</code> flags.</li> </ul> </li> </ul> </li> <li> NetGear API:<ul> <li>New Turbo-JPEG compression with simplejpeg<ul> <li>Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality.</li> <li>Utilized <code>encode_jpeg</code> and <code>decode_jpeg</code> methods to implement turbo-JPEG transcoding with <code>simplejpeg</code>.</li> <li>Added options to control JPEG frames quality, enable fastest dct, fast upsampling  to boost performance.</li> <li>Added new <code>jpeg_compression</code>, <code>jpeg_compression_quality</code>, <code>jpeg_compression_fastdct</code>, <code>jpeg_compression_fastupsample</code> attributes.</li> <li>Enabled fast dct by default with JPEG frames at 90%.</li> <li>Added Docs for JPEG Frame Compression.</li> </ul> </li> </ul> </li> <li> WebGear API: <ul> <li>New modular and flexible configuration for Custom Sources:<ul> <li>Implemented more convenient approach for handling custom source configuration.</li> <li>Added new <code>config</code> global variable for this new behavior.</li> <li>Now None-type <code>source</code> parameter value is allowed for defining own custom sources.</li> <li>Added new Example case and Updates Docs for this feature.</li> <li>Added new CI Tests.</li> </ul> </li> <li>New Browser UI Updates:<ul> <li>New Standalone UI Default theme v0.1.0 for browser (by @abhiTronix)</li> <li>Completely rewritten theme from scratch with only local resources.</li> <li>New <code>custom.js</code> and <code>custom.css</code> for custom responsive behavior.</li> <li>New sample glow effect with css.</li> <li>New sample click to full-screen behavior with javascript.</li> <li>Removed all third-party theme dependencies.</li> <li>Update links to new github server <code>abhiTronix/vidgear-vitals</code></li> <li>Updated docs with new theme's screenshots.</li> </ul> </li> <li>Added <code>enable_infinite_frames</code> attribute for enabling infinite frames.</li> <li>Added New modular and flexible configuration for Custom Sources.</li> <li>Bumped WebGear Theme Version to v0.1.1.</li> <li>Updated Docs and CI tests.</li> </ul> </li> <li> ScreenGear API:<ul> <li>Implemented Improved Pure-Python Multiple-Threaded like CamGear.</li> <li>Added support for <code>THREAD_TIMEOUT</code> attribute to its <code>options</code> parameter.</li> </ul> </li> <li> StreamGear API:<ul> <li>Enabled pseudo live-streaming flag <code>re</code> for live content.</li> </ul> </li> <li> Docs:<ul> <li>Added new native docs versioning to mkdocs-material.</li> <li>Added new examples and few visual tweaks.</li> <li>Updated Stylesheet for versioning.</li> <li>Added new DASH video chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear and Stabilizer streams.</li> <li>Added open-sourced \"Tears of Steel\" * project Mango Teaser video chunks.</li> <li>Added open-sourced \"Subspace Video Stabilization\" http://web.cecs.pdx.edu/~fliu/project/subspace_stabilization/ video chunks.</li> <li>Added support for DASH Video Thumbnail preview in Clappr within <code>custom.js</code>.</li> <li>Added responsive clappr DASH player with bootstrap's <code>embed-responsive</code>.</li> <li>Added new permalink icon and slugify to toc.</li> <li>Added \"back-to-top\" button for easy navigation.</li> </ul> </li> <li> Helper:<ul> <li>New GitHub Mirror with latest Auto-built FFmpeg Static Binaries:<ul> <li>Replaced new GitHub Mirror <code>abhiTronix/FFmpeg-Builds</code> in helper.py</li> <li>New CI maintained Auto-built FFmpeg Static Binaries.</li> <li>Removed all 3<sup>rd</sup>-party and old links for better compatibility and Open-Source reliability.</li> <li>Updated Related CI tests.</li> </ul> </li> <li>Added auto-font-scaling for <code>create_blank_frame</code> method.</li> <li>Added <code>c_name</code> parameter to <code>generate_webdata</code> and <code>download_webdata</code> to specify class.</li> <li>A more robust Implementation of Downloading Artifacts:<ul> <li>Added a custom HTTP <code>TimeoutHTTPAdapter</code> Adapter with a default timeout for all HTTP calls based on this GitHub comment.</li> <li>Implemented http client and the <code>send()</code> method to ensure that the default timeout is used if a timeout argument isn't provided.</li> <li>Implemented Requests session<code>with</code> block to exit properly even if there are unhandled exceptions.</li> <li>Add a retry strategy to custom <code>TimeoutHTTPAdapter</code> Adapter with max 3 retries and sleep(<code>backoff_factor=1</code>) between failed requests.</li> </ul> </li> <li>Added <code>create_blank_frame</code> method to create bland frames with suitable text.</li> </ul> </li> <li> [CI] Continuous Integration:<ul> <li>Added new fake frame generated for fake <code>picamera</code> class with numpy.</li> <li>Added new <code>create_bug</code> parameter to fake <code>picamera</code> class for emulating various artificial bugs.</li> <li>Added float/int instance check on <code>time_delay</code> for camgear and pigear.</li> <li>Added <code>EXIT_CODE</code> to new timeout implementation for pytests to upload codecov report when no timeout.</li> <li>Added auxiliary classes to  fake <code>picamera</code> for facilitating the emulation.</li> <li>Added new CI tests for PiGear Class for testing on all platforms.</li> <li>Added <code>shutdown()</code> function to gracefully terminate WebGear_RTC API.</li> <li>Added new <code>coreutils</code> brew dependency.</li> <li>Added handler for variable check on exit and codecov upload.</li> <li>Added <code>is_running</code> flag to WebGear_RTC to exit safely.    </li> </ul> </li> <li> Setup:<ul> <li>New automated latest version retriever for packages:<ul> <li>Implemented new <code>latest_version</code> method to automatically retrieve latest version for packages.</li> <li>Added Some Dependencies.</li> </ul> </li> <li>Added <code>simplejpeg</code> package for all platforms.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Added exception for RunTimeErrors in NetGear CI tests.</li> <li> WriteGear: Critical file write access checking method:<ul> <li>Added new <code>check_WriteAccess</code> Helper method.</li> <li>Implemented a new robust algorithm to check if given directory has write-access.</li> <li>Removed old behavior which gives irregular results.</li> </ul> </li> <li> Helper: Maintenance Updates<ul> <li>Added workaround for Python bug.</li> <li>Added <code>safe_mkdir</code> to <code>check_WriteAccess</code> to automatically create non-existential parent folder in path.</li> <li>Extended <code>check_WriteAccess</code> Patch to StreamGear.</li> <li>Simplified <code>check_WriteAccess</code> to handle Windows envs easily.</li> <li>Updated FFmpeg Static Download URL for WriteGear.</li> <li>Implemented fallback option for auto-calculating bitrate from extracted audio sample-rate in <code>validate_audio</code> method.</li> </ul> </li> <li> Docs: General UI Updates<ul> <li>Updated Meta tags for og site and twitter cards.</li> <li>Replaced Custom dark theme toggle with mkdocs-material's official Color palette toggle</li> <li>Added example for external audio input and creating segmented MP4 video in WriteGear FAQ.</li> <li>Added example for YouTube streaming with WriteGear.</li> <li>Removed custom <code>dark-material.js</code> and <code>header.html</code> files from theme.</li> <li>Added blogpost link for detailed information on Stabilizer Working.</li> <li>Updated <code>mkdocs.yml</code> and <code>custom.css</code> configuration.</li> <li>Remove old hack to resize clappr DASH player with css.</li> <li>Updated Admonitions.</li> <li>Improved docs contexts.</li> <li>Updated CSS for version-selector-button.</li> <li>Adjusted files to match new themes.</li> <li>Updated welcome-bot message for typos.</li> <li>Removed redundant FAQs from NetGear Docs.</li> <li>Updated Assets Images.</li> <li>Updated spacing.</li> </ul> </li> <li> CI:<ul> <li>Removed unused <code>github.ref</code> from yaml.</li> <li>Updated OpenCV Bash Script for Linux envs.</li> <li>Added <code>timeout-minutes</code> flag to github-actions workflow.</li> <li>Added <code>timeout</code> flag to pytest.</li> <li>Replaced Threaded Gears with OpenCV VideoCapture API.</li> <li>Moved files and Removed redundant code.</li> <li>Replaced grayscale frames with color frames for WebGear tests. </li> <li>Updated pytest timeout value to 15mins.</li> <li>Removed <code>aiortc</code> automated install on Windows platform within setup.py.</li> <li>Added new timeout logic to continue to run on external timeout for GitHub Actions Workflows.</li> <li>Removed unreliable old timeout solution from WebGear_RTC.</li> <li>Removed <code>timeout_decorator</code> and <code>asyncio_timeout</code> dependencies for CI.</li> <li>Removed WebGear_RTC API exception from codecov.</li> <li>Implemented new fake <code>picamera</code> class to CI utils for emulating RPi Camera-Module Real-time capabilities.</li> <li>Implemented new <code>get_RTCPeer_payload</code> method to receive WebGear_RTC peer payload.</li> <li>Removed PiGear from Codecov exceptions.</li> <li>Disable Frame Compression in few NetGear tests failing on frame matching.</li> <li>Updated NetGear CI  tests to support new attributes</li> <li>Removed warnings and updated yaml<ul> <li>Added <code>pytest.ini</code> to address multiple warnings.</li> <li>Updated azure workflow condition syntax.</li> </ul> </li> <li>Update <code>mike</code> settings for mkdocs versioning.</li> <li>Updated codecov configurations.</li> <li>Minor logging and docs updates.</li> <li>Implemented pytest timeout for azure pipelines for macOS envs.</li> <li>Added <code>aiortc</code> as external dependency in <code>appveyor.yml</code>.</li> <li>Re-implemented WebGear_RTC improper offer-answer handshake in CI tests.</li> <li>WebGear_RTC CI Updated with <code>VideoTransformTrack</code> to test stream play.</li> <li>Implemented fake <code>AttributeError</code> for fake picamera class.</li> <li>Updated PiGear CI tests to increment codecov.</li> <li>Update Tests docs and other minor tweaks to increase overall coverage.</li> <li>Enabled debugging and disabled exit 1 on error in azure pipeline.</li> <li>Removed redundant benchmark tests.</li> </ul> </li> <li> Helper: Added missing RTSP URL scheme to <code>is_valid_url</code> method.</li> <li> NetGear_Async: Added fix for uvloop only supporting python&gt;=3.7 legacies.</li> <li> Extended WebGear's Video-Handler scope to <code>https</code>.</li> <li> CI: Remove all redundant 32-bit Tests from Appveyor:<ul> <li>Appveyor 32-bit Windows envs are actually running on 64-bit machines.</li> <li>More information here: https://help.appveyor.com/discussions/questions/20637-is-it-possible-to-force-running-tests-on-both-32-bit-and-64-bit-windows</li> </ul> </li> <li> Setup: Removed <code>latest_version</code> behavior from some packages.</li> <li> NetGear_Async: Revised logic for handling uvloop for all platforms and legacies.</li> <li> Setup: Updated logic to install uvloop-\"v0.14.0\" for python-3.6 legacies.</li> <li> Removed any redundant code from webgear.</li> <li> StreamGear:<ul> <li>Replaced Ordinary dict with Ordered Dict to use <code>move_to_end</code> method.</li> <li>Moved external audio input to output parameters dict.</li> <li>Added additional imports.</li> <li>Updated docs to reflect changes.</li> </ul> </li> <li> Numerous Updates to Readme and <code>mkdocs.yml</code>.</li> <li> Updated font to <code>FONT_HERSHEY_SCRIPT_COMPLEX</code> and enabled logging in create_blank_frame.</li> <li> Separated channels for downloading and storing theme files for WebGear and WebGear_RTC APIs.</li> <li> Removed <code>logging</code> condition to always inform user in a event of FFmpeg binary download failure.</li> <li> WebGear_RTC: <ul> <li>Improved auto internal termination.</li> <li>More Performance updates through <code>setCodecPreferences</code>.</li> <li>Moved default Video RTC video launcher to <code>__offer</code>.</li> </ul> </li> <li> NetGear_Async: Added timeout to client in CI tests.</li> <li> Reimplemented and updated <code>changelog.md</code>.</li> <li> Updated code comments.</li> <li> Setup: Updated keywords and classifiers.</li> <li> Bumped codecov.</li> </ul> Breaking Updates/Changes <ul> <li> WriteGear will automatically switch video encoder to default if specified encoder not found.</li> <li> WriteGear will throw <code>RuntimeError</code> if no suitable default encoder found!</li> <li> Removed format specific OpenCV decoding and encoding support for NetGear.</li> <li> Dropped support for <code>compression_format</code>, <code>compression_param</code> attributes from NetGear.</li> <li> Non-existent parent folder in <code>output_filename</code> value will no longer be considered as invalid in StreamGear and WriteGear APIs.</li> <li> None-type <code>source</code> parameter value is allowed for WebGear and NetGear_Async for defining custom sources.</li> </ul> Bug-fixes <ul> <li> CamGear: Fixed F821 undefined name 'queue' bug.</li> <li> NetGear_Async: Fixed <code>source</code> parameter missing <code>None</code> as default value.</li> <li> Fixed uvloops only supporting python&gt;=3.7 in NetGear_Async.</li> <li> Helper:<ul> <li>Fixed Zombie processes in <code>check_output</code> method due a hidden bug in python. For reference: https://bugs.python.org/issue37380</li> <li>Fixed regex in <code>validate_video</code> method.</li> </ul> </li> <li> Docs: <ul> <li>Invalid <code>site_url</code> bug patched in mkdocs.yml</li> <li>Remove redundant mike theme support and its files.</li> <li>Fixed video not centered when DASH video in fullscreen mode with clappr.</li> <li>Fixed Incompatible new mkdocs-docs theme.</li> <li>Fixed missing hyperlinks.</li> </ul> </li> <li> CI: <ul> <li>Fixed NetGear Address bug</li> <li>Fixed bugs related to termination in WebGear_RTC.</li> <li>Fixed random CI test failures and code cleanup.</li> <li>Fixed string formating bug in Helper.py.</li> <li>Fixed F821 undefined name bugs in WebGear_RTC tests.</li> <li>NetGear_Async Tests fixes.</li> <li>Fixed F821 undefined name bugs.</li> <li>Fixed typo bugs in <code>main.py</code>.</li> <li>Fixed Relative import bug in PiGear.</li> <li>Fixed regex bug in warning filter.</li> <li>Fixed WebGear_RTC frozen threads on exit.</li> <li>Fixed bugs in codecov bash uploader setting for azure pipelines.</li> <li>Fixed False-positive <code>picamera</code> import due to improper sys.module settings.</li> <li>Fixed Frozen Threads on exit in WebGear_RTC API.</li> <li>Fixed deploy error in <code>VidGear Docs Deployer</code> workflow</li> <li>Fixed low timeout bug.</li> <li>Fixed bugs in PiGear tests.</li> <li>Patched F821 undefined name bug.</li> </ul> </li> <li> StreamGear:<ul> <li>Fixed StreamGear throwing <code>Picture size 0x0 is invalid</code> bug with external audio.</li> <li>Fixed default input framerate value getting discarded in Real-time Frame Mode.</li> <li>Fixed internal list-formatting bug.</li> </ul> </li> <li> Fixed E999 SyntaxError bug in <code>main.py</code>.</li> <li> Fixed Typo in bash script.</li> <li> Fixed WebGear freeze on reloading bug.</li> <li> Fixed anomalies in <code>install_opencv</code> bash script.</li> <li> Helper: Bug Fixed in <code>download_ffmpeg_binaries</code> method.</li> <li> Helper: Fixed OSError bug in <code>check_WriteAccess</code> method.</li> <li> Helper: Fixed Input Audio stream bitrate test failing to detect audio-bitrate in certain videos with <code>validate_audio</code> method.</li> <li> Fixed bugs in <code>requests</code> module's function arguments.</li> <li> Fixed None-type stream bug in WebGear.</li> <li> Fixed random crashes in WebGear.</li> <li> Fixed numerous CI test bugs.</li> <li> Fixed several typos.</li> </ul> Pull Requests <ul> <li>PR #192</li> <li>PR #196</li> <li>PR #203</li> <li>PR #206</li> </ul> New Contributors <ul> <li>@bml1g12</li> </ul>"},{"location":"changelog/#v020-2021-01-01","title":"v0.2.0 (2021-01-01)","text":"New Features <ul> <li> CamGear API:<ul> <li>Support for various Live-Video-Streaming services:<ul> <li>Added seamless support for live video streaming sites like Twitch, LiveStream, Dailymotion etc.</li> <li>Implemented flexible framework around <code>streamlink</code> python library with easy control over parameters and quality.</li> <li>Stream Mode can now automatically detects whether <code>source</code> belong to YouTube or elsewhere, and handles it with appropriate API.</li> </ul> </li> <li>Re-implemented YouTube URLs Handler:<ul> <li>Re-implemented CamGear's YouTube URLs Handler completely from scratch.</li> <li>New Robust Logic to flexibly handing video and video-audio streams.</li> <li>Intelligent stream selector for selecting best possible stream compatible with OpenCV.</li> <li>Added support for selecting stream qualities and parameters.</li> <li>Implemented new <code>get_supported_quality</code> helper method for handling specified qualities</li> <li>Fixed Live-Stream URLs not supported by OpenCV's Videocapture and its FFmpeg.</li> </ul> </li> <li>Added additional <code>STREAM_QUALITY</code> and <code>STREAM_PARAMS</code> attributes.</li> </ul> </li> <li> ScreenGear API:<ul> <li>Multiple Backends Support:<ul> <li>Added new multiple backend support with new <code>pyscreenshot</code> python library.</li> <li>Made <code>pyscreenshot</code> the default API for ScreenGear, replaces <code>mss</code>.</li> <li>Added new <code>backend</code> parameter for this feature while retaining previous behavior.</li> <li>Added native automated RGB to BGR conversion for default PIL backend.</li> <li>Kept support for old <code>mss</code> for old compatibility and multi-screen support.</li> <li>Added native dimensional support for multi-screen.</li> <li>Added support all input from all multiple screens.</li> <li>Updated ScreenGear Docs.</li> <li>Updated ScreenGear CI tests.</li> </ul> </li> </ul> </li> <li> StreamGear API:<ul> <li>Changed default behaviour to support complete video transcoding.</li> <li>Added <code>-livestream</code> attribute to support live-streaming.</li> <li>Added additional parameters for <code>-livestream</code> attribute functionality.</li> <li>Updated StreamGear Tests.</li> <li>Updated StreamGear docs.</li> </ul> </li> <li> Stabilizer Class: <ul> <li>New Robust Error Handling with Blank Frames:<ul> <li>Elegantly handles all crashes due to Empty/Blank/Dark frames.</li> <li>Stabilizer throws Warning with this new behavior instead of crashing.</li> <li>Updated CI test for this feature.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Automated Docs Versioning:<ul> <li>Implemented Docs versioning through <code>mike</code> API.</li> <li>Separate new workflow steps to handle different versions.</li> <li>Updated docs deploy worflow to support <code>release</code> and <code>dev</code> builds.</li> <li>Added automatic version extraction from github events.</li> <li>Added <code>version-select.js</code> and <code>version-select.css</code> files.</li> </ul> </li> <li>Toggleable Dark-White Docs Support:<ul> <li>Toggle-button to easily switch dark, white and preferred theme.</li> <li>New Updated Assets for dark backgrounds</li> <li>New css, js files/content to implement this behavior.</li> <li>New material icons for button.</li> <li>Updated scheme to <code>slate</code> in <code>mkdocs.yml</code>.</li> </ul> </li> <li>New Theme and assets:<ul> <li>New <code>purple</code> theme with <code>dark-purple</code> accent color.</li> <li>New images assets with updated transparent background.</li> <li>Support for both dark and white theme.</li> <li>Increased <code>rebufferingGoal</code> for dash videos.</li> <li>New updated custom 404 page for docs.</li> </ul> </li> <li>Issue and PR automated-bots changes<ul> <li>New <code>need_info.yml</code> YAML Workflow.</li> <li>New <code>needs-more-info.yml</code> Request-Info template.</li> <li>Replaced Request-Info templates.</li> <li>Improved PR and Issue welcome formatting.</li> </ul> </li> <li>Added custom HTML pages.</li> <li>Added <code>show_root_heading</code> flag to disable headings in References.</li> <li>Added new <code>inserAfter</code> function to version-select.js.</li> <li>Adjusted hue for dark-theme for better contrast.</li> <li>New usage examples and FAQs.</li> <li>Added <code>gitmoji</code> for commits.</li> </ul> </li> <li> Continuous Integration:<ul> <li>Maintenance Updates:<ul> <li>Added support for new <code>VIDGEAR_LOGFILE</code> environment variable in Travis CI.</li> <li>Added missing CI tests.</li> <li>Added logging for helper functions.</li> </ul> </li> <li>Azure-Pipeline workflow for MacOS envs<ul> <li>Added Azure-Pipeline Workflow for testing MacOS environment.</li> <li>Added codecov support.</li> </ul> </li> <li>GitHub Actions workflow for Linux envs<ul> <li>Added GitHub Action work-flow for testing Linux environment.</li> </ul> </li> <li>New YAML to implement GitHub Action workflow for python 3.6, 3.7, 3,8 &amp; 3.9 matrices.</li> <li>Added Upload coverage to Codecov GitHub Action workflow.</li> <li>New codecov-bash uploader for Azure Pipelines.</li> </ul> </li> <li> Logging:<ul> <li>Added file support<ul> <li>Added <code>VIDGEAR_LOGFILE</code> environment variable to manually add file/dir path.</li> <li>Reworked <code>logger_handler()</code> Helper methods (in asyncio too).</li> <li>Added new formatter and Filehandler for handling logger files.</li> </ul> </li> <li>Added <code>restore_levelnames</code> auxiliary method for restoring logging levelnames.</li> </ul> </li> <li> Added auto version extraction from package <code>version.py</code> in setup.py.</li> </ul> Updates/Improvements <ul> <li> Added missing Lazy-pirate auto-reconnection support for Multi-Servers and Multi-Clients Mode in NetGear API.</li> <li> Added new FFmpeg test path to Bash-Script and updated README broken links.</li> <li> Asset Cleanup:<ul> <li>Removed all third-party javascripts from projects.</li> <li>Linked all third-party javascript directly.</li> <li>Cleaned up necessary code from CSS and JS files.</li> <li>Removed any copyrighted material or links.</li> </ul> </li> <li> Rewritten Docs from scratch:<ul> <li>Improved complete docs formatting.</li> <li>Simplified language for easier understanding.</li> <li>Fixed <code>mkdocstrings</code> showing root headings.</li> <li>Included all APIs methods to <code>mkdocstrings</code> docs.</li> <li>Removed unnecessary information from docs.</li> <li>Corrected Spelling and typos.</li> <li>Fixed context and grammar.</li> <li>Removed <code>motivation.md</code>.</li> <li>Renamed many terms.</li> <li>Fixed hyper-links.</li> <li>Reformatted missing or improper information.</li> <li>Fixed context and spellings in Docs files.</li> <li>Simplified language for easy understanding.</li> <li>Updated image sizes for better visibility.</li> </ul> </li> <li> Bash Script: Updated to Latest OpenCV Binaries version and related changes</li> <li> Docs: Moved version-selector to header and changed default to alias.</li> <li> Docs: Updated <code>deploy_docs.yml</code> for releasing dev, stable, and release versions.</li> <li> Re-implemented overridden material theme.</li> <li> Updated docs with all new additions and examples.</li> <li> CamGear: CI Stream Mode test updated.</li> <li> Updated ReadMe.md badges.</li> <li> Updated CI tests. </li> <li> Updated <code>setup.py</code> with new features.</li> <li> Updated <code>contributing.md</code> and <code>ReadMe.md</code>.</li> <li> Updated OpenCV version to <code>4.5.1-dev</code> in bash scripts</li> <li> Updated <code>changelog.md</code>.</li> <li> Moved WebGear API to Streaming Gears.</li> <li> Bumped Codecov.</li> <li> UI changes to version-select.js</li> <li> Docs: Retitle the versions and <code>mkdocs.yml</code> formatting updated.</li> <li> Docs: Version Selector UI reworked and other minor changes.</li> </ul> Breaking Updates/Changes <ul> <li> <code>y_tube</code> parameter renamed as <code>stream_mode</code> in CamGear API!</li> <li> Removed Travis support and <code>travis.yml</code> deleted.</li> </ul> Bug-fixes <ul> <li> Fixed StreamGear API Limited Segments Bug</li> <li> Fixed Missing links in docs and bump up version.</li> <li> CI: Fixed Appveyor need newer VM image to support Python 3.9.x matrix.</li> <li> ScreenGear BugFix: Fixed Error Handling and updated CI Tests.</li> <li> Fixed improper <code>mkdocs.yml</code> variables.</li> <li> Fixed GStreamer plugin support in bash scripts.</li> <li> Fixed typos in YAMLs and docs.</li> <li> Docs: Fixed Docs Deployer YAML bug for CI envs.</li> <li> Fixed wrong import in YAML.</li> <li> Fixed visible hyperlink on hover in dark-toggle button.</li> <li> Docs: Deployer YAML bug fixed.</li> <li> Docs YAML: issue jimporter/mike#33 patched and fixed <code>fetch-depth=0</code>.</li> <li> Docs: <code>version-select.js</code> bug fixed.</li> <li> Docs: UI Bugs Fixed.</li> <li> CI: Codecov bugfixes.</li> <li> Azure-Pipelines Codecov BugFixes.</li> <li> Fixed <code>version.json</code> not detecting properly in <code>version-select.js</code>.</li> <li> Fixed images not centered inside <code>&lt;figure&gt;</code> tag.</li> <li> Fixed Asset Colors.</li> <li> Fixed failing CI tests.</li> <li> Fixed Several logging bugs.</li> </ul> Pull Requests <ul> <li>PR #164</li> <li>PR #170</li> <li>PR #173</li> <li>PR #181</li> <li>PR #183</li> <li>PR #184 </li> </ul>"},{"location":"changelog/#v019-2020-08-31","title":"v0.1.9 (2020-08-31)","text":"New Features <ul> <li> StreamGear API:<ul> <li>New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats.</li> <li>Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters.</li> <li>API automatically transcodes videos/audio files &amp; real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file.</li> <li>Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1).</li> <li>Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source.</li> <li>Added TQDM progress bar in non-debugged output for visual representation of internal processes.</li> <li>Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams.</li> <li>Several standalone internal checks to ensure robust performance.</li> <li>New <code>terminate()</code> function to terminate StremGear Safely.</li> <li>New StreamGear Dual Modes of Operation:<ul> <li>Implemented Single-Source and Real-time Frames like independent Transcoding Modes.</li> <li>Linked <code>-video_source</code> attribute for activating these modes</li> <li>Single-Source Mode, transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming</li> <li>Real-time Frames Mode, directly transcodes video-frames (as opposed to a entire file), into a sequence of multiple smaller segments for streaming</li> <li>Added separate functions, <code>stream()</code> for Real-time Frame Mode and <code>transcode_source()</code> for Single-Source Mode for easy transcoding.</li> <li>Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear), into StreamGear.  </li> </ul> </li> <li>New StreamGear Parameters:<ul> <li>Developed several new parameters such as:<ul> <li><code>output</code>: handles assets directory</li> <li><code>formats</code>: handles adaptive HTTP streaming format.</li> <li><code>custom_ffmpeg</code>: handles custom FFmpeg location.</li> <li><code>stream_params</code>: handles internal and FFmpeg parameter seamlessly.</li> <li><code>logging</code>: turns logging on or off.</li> </ul> </li> <li>New <code>stream_params</code> parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes:<ul> <li><code>-streams</code> (list of dictionaries) for building additional streams with <code>-resolution</code>, <code>-video_bitrate</code> &amp; <code>-framerate</code> like sub-attributes.</li> <li><code>-audio</code> for specifying external audio.</li> <li><code>-video_source</code> for specifying Single-Source Mode source.</li> <li><code>-input_framerate</code> for handling input framerate in Real-time Frames Mode.</li> <li><code>-bpp</code> attribute for handling bits-per-pixels used to auto-calculate video-bitrate.</li> <li><code>-gop</code> to manually specify GOP length.</li> <li><code>-ffmpeg_download_path</code> to handle custom FFmpeg download path on windows.</li> <li><code>-clear_prev_assets</code> to remove any previous copies of SteamGear Assets.</li> </ul> </li> </ul> </li> <li>New StreamGear docs, MPEG-DASH demo, and recommended DASH players list:<ul> <li>Added new StreamGear docs, usage examples, parameters, references, new FAQs.</li> <li>Added Several StreamGear usage examples w.r.t Mode of Operation.</li> <li>Implemented Clappr based on Shaka-Player, as Demo Player.</li> <li>Added Adaptive-dimensional behavior for Demo-player, purely in css.</li> <li>Hosted StreamGear generated DASH chunks on GitHub and served with <code>raw.githack.com</code>.</li> <li>Introduced variable quality level-selector plugin for Clapper Player.</li> <li>Provide various required javascripts and implemented additional functionality for player in <code>extra.js</code>.</li> <li>Recommended tested Online, Command-line and GUI Adaptive Stream players.</li> <li>Implemented separate FFmpeg installation doc for StreamGear API.</li> <li>Reduced <code>rebufferingGoal</code> for faster response.</li> </ul> </li> <li>New StreamGear CI tests:<ul> <li>Added IO and API initialization CI tests for its Modes.</li> <li>Added various mode Streaming check CI tests.</li> </ul> </li> </ul> </li> <li> NetGear_Async API:<ul> <li>Added new <code>send_terminate_signal</code> internal method.</li> <li>Added <code>WindowsSelectorEventLoopPolicy()</code> for windows 3.8+ envs.</li> <li>Moved Client auto-termination to separate method.</li> <li>Implemented graceful termination with <code>signal</code> API on UNIX machines.</li> <li>Added new <code>timeout</code> attribute for controlling Timeout in Connections.</li> <li>Added missing termination optimizer (<code>linger=0</code>) flag.</li> <li>Several ZMQ Optimizer Flags added to boost performance.</li> </ul> </li> <li> WriteGear API:<ul> <li>Added support for adding duplicate FFmpeg parameters to <code>output_params</code>:<ul> <li>Added new <code>-clones</code> attribute in <code>output_params</code> parameter for handing this behavior..</li> <li>Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified.</li> <li>Built support for <code>zmq.REQ/zmq.REP</code> and <code>zmq.PUB/zmq.SUB</code> patterns in this mode.</li> <li>Added new CI tests debugging this behavior.</li> <li>Updated docs accordingly.</li> </ul> </li> <li>Added support for Networks URLs in Compression Mode:<ul> <li><code>output_filename</code> parameter supports Networks URLs in compression modes only</li> <li>Added automated handling of non path/file Networks URLs as input.</li> <li>Implemented new <code>is_valid_url</code> helper method to easily validate assigned URLs value.</li> <li>Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. </li> <li>WriteGear will throw <code>ValueError</code> if <code>-output_filename</code> is not supported.</li> <li>Added related CI tests and docs.</li> </ul> </li> <li>Added <code>disable_force_termination</code> attribute in WriteGear to disable force-termination.</li> </ul> </li> <li> NetGear API:<ul> <li>Added option to completely disable Native Frame-Compression:<ul> <li>Checks if any Incorrect/Invalid value is assigned on <code>compression_format</code> attribute.</li> <li>Completely disables Native Frame-Compression.</li> <li>Updated docs accordingly.</li> </ul> </li> </ul> </li> <li> CamGear API:<ul> <li>Added new and robust regex for identifying YouTube URLs.</li> <li>Moved <code>youtube_url_validator</code> to Helper.</li> </ul> </li> <li> New <code>helper.py</code> methods: <ul> <li>Added <code>validate_video</code> function to validate video_source.</li> <li>Added <code>extract_time</code> Extract time from give string value.</li> <li>Added <code>get_video_bitrate</code> to calculate video birate from resolution, framerate, bits-per-pixels values.</li> <li>Added <code>delete_safe</code> to safely delete files of given extension.</li> <li>Added <code>validate_audio</code> to validate audio source.</li> <li>Added new Helper CI tests.<ul> <li>Added new <code>check_valid_mpd</code> function to test MPD files validity.</li> <li>Added <code>mpegdash</code> library to CI requirements.</li> </ul> </li> </ul> </li> <li> Deployed New Docs Upgrades:<ul> <li>Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs.</li> <li>Added <code>clappr.min.js</code>, <code>dash-shaka-playback.js</code>, <code>clappr-level-selector.min.js</code> third-party javascripts locally.</li> <li>Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.).</li> <li>Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. </li> <li>Added new <code>pymdownx.keys</code> to replace <code>[Ctrl+C]/[\u2318+C]</code> formats.</li> <li>Added new <code>custom.css</code> stylescripts variables for fluid animations in docs.</li> <li>Overridden announce bar and added donation button. </li> <li>Lossless WEBP compressed all PNG assets for faster loading.</li> <li>Enabled lazy-loading for GIFS and Images for performance.</li> <li>Reimplemented Admonitions contexts and added new ones.</li> <li>Added StreamGear and its different modes Docs Assets.</li> <li>Added patch for images &amp; unicodes for PiP flavored markdown in <code>setup.py</code>.</li> </ul> </li> <li> Added <code>Request Info</code> and <code>Welcome</code> GitHub Apps to automate PR and issue workflow<ul> <li>Added new <code>config.yml</code> for customizations.</li> <li>Added various suitable configurations.</li> </ul> </li> <li> Added new <code>-clones</code> attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API.</li> <li> Added new Video-only and Audio-Only sources in bash script.</li> <li> Added new paths in bash script for storing StreamGear &amp; WriteGear assets temporarily.</li> </ul> Updates/Improvements <ul> <li> Added patch for <code>NotImplementedError</code> in NetGear_Async API on Windows 3.8+ envs.</li> <li> Check for valid <code>output</code> file extension according to <code>format</code> selected in StreamGear.</li> <li> Completed migration to <code>travis.com</code>.</li> <li> Created new <code>temp_write</code> temp directory for WriteGear Assets in bash script.</li> <li> Deleted old Redundant assets and added new ones.</li> <li> Employed <code>isort</code> library to sort and group imports in Vidgear APIs.</li> <li> Enabled exception for <code>list, tuple, int, float</code> in WriteGear API's <code>output_params</code> dict.</li> <li> Enabled missing support for frame-compression in its primary Receive Mode.</li> <li> Enforced pixel formats for streams.</li> <li> Improved check for valid system path detection in WriteGear API.</li> <li> Overrided <code>pytest-asyncio</code> fixture in NetGear_Async API.</li> <li> Quoted Gear Headline for understanding each gear easily. </li> <li> Re-Positioned Gear's banner images in overview for better readability.</li> <li> Reduced redundant try-except blocks in NetGear Async.</li> <li> Reformatted and Simplified Docs context.</li> <li> Reimplemented <code>return_testvideo_path</code> CI function with variable streams.</li> <li> Reimplemented <code>skip_loop</code> in NetGear_Async to fix <code>asyncio.CancelledError</code>.</li> <li> Reimplemented buggy audio handler in StreamGear.</li> <li> Reimplemented images with <code>&lt;figure&gt;</code> and <code>&lt;figurecaption&gt;</code> like tags.</li> <li> Removed Python &lt; 3.8 condition from all CI tests.</li> <li> Removed or Grouped redundant code for increasing codecov.</li> <li> Removed redundant code and simplified algorithmic complexities in Gears.</li> <li> Replaced <code>;nbsp</code> with <code>;thinsp</code> and <code>;emsp</code>.</li> <li> Replaced <code>IOError</code> with more reliable <code>RuntimeError</code> in StreamGear Pipelines.</li> <li> Replaced <code>del</code> with <code>pop</code> in dicts.</li> <li> Replaced all Netgear CI tests with more reliable <code>try-except-final</code> blocks.</li> <li> Replaced simple lists with <code>pymdownx.tasklist</code>.</li> <li> Replaced subprocess <code>call()</code> with <code>run()</code> for better error handling in <code>execute_ffmpeg_cmd</code> function.</li> <li> Resized over-sized docs images. </li> <li> Simplified <code>delete_safe</code> Helper function.</li> <li> Simplified default audio-bitrate logic in StreamGear</li> <li> Updated CI tests and cleared redundant code from NetGear_Async API.</li> <li> Updated CI with new tests and Bumped Codecov.</li> <li> Updated Issue and PR templates.</li> <li> Updated Licenses for new files and shrink images dimensions.</li> <li> Updated Missing Helpful tips and increased logging.</li> <li> Updated PR guidelines for more clarity.</li> <li> Updated WebGear examples addresses from <code>0.0.0.0</code> to <code>localhost</code>.</li> <li> Updated WriteGear and StreamGear CI tests for not supporting temp directory.</li> <li> Updated <code>README.md</code> and <code>changelog.md</code> with new changes.</li> <li> Updated <code>check_output</code> and added <code>force_retrieve_stderr</code> support to <code>**kwargs</code> to extract <code>stderr</code> output even on FFmpeg  error.</li> <li> Updated <code>dicts2args</code> to support internal repeated <code>coreX</code> FFmpeg parameters for StreamGear. </li> <li> Updated <code>mkdocs.yml</code>, <code>changelog.md</code> and <code>README.md</code> with latest changes.</li> <li> Updated <code>validate_audio</code> Helper function will now retrieve audio-bitrate for validation.</li> <li> Updated buggy <code>mpegdash</code> dependency with custom dev fork for Windows machines.</li> <li> Updated core parameters for audio handling.</li> <li> Updated logging for debugging selected eventloops in NetGear_Async API.</li> <li> Updated termination linger to zero at Server's end.</li> </ul> Breaking Updates/Changes <ul> <li> Changed Webgear API default address to <code>localhost</code> for cross-compatibility between different platforms.</li> <li> In Netgear_Async API, <code>source</code> value can now be NoneType for a custom frame-generator at Server-end only.</li> <li> Temp (such as <code>/tmp</code> in linux) is now not a valid directory for WriteGear &amp; StreamGear API outputs.</li> <li> Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to <code>override</code> directory.</li> </ul> Bug-fixes <ul> <li> Added workaround for system path not handle correctly.</li> <li> Fixed Bug: URL Audio format not being handled properly.</li> <li> Fixed Critical Bug in NetGear_Async throwing <code>ValueError</code> with None-type Source.</li> <li> Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode.</li> <li> Fixed Critical external audio handler bug: moved audio-input to input_parameters.</li> <li> Fixed Frozen-threads bug in CI tests.</li> <li> Fixed Mkdocs only accepting Relative paths.</li> <li> Fixed OSError in WriteGear's compression mode.</li> <li> Fixed StreamGear CI bugs for Windows and CI envs.</li> <li> Fixed Typos and Indentation bugs in NetGear API.</li> <li> Fixed ZMQ throwing error on termination if all max-tries exhausted.</li> <li> Fixed <code>NameError</code> bug in NetGear API and CI tests.</li> <li> Fixed <code>TimeoutError</code> bug in NetGear_Async CI tests.</li> <li> Fixed <code>get_valid_ffmpeg_path</code> throwing <code>TypeError</code> with non-string values.</li> <li> Fixed broken links in docs. </li> <li> Fixed critical duplicate logging bug.</li> <li> Fixed default <code>gop</code> value not handle correctly.</li> <li> Fixed handling of incorrect paths detection.</li> <li> Fixed incorrect definitions in NetGear_Async.</li> <li> Fixed left-over attribute bug in WriteGear.</li> <li> Fixed logic and indentation bugs in CI tests.</li> <li> Fixed logic for handling output parameters in WriteGear API.</li> <li> Fixed missing definitions and logic bug in StreamGear.</li> <li> Fixed missing import and incorrect CI definitions. </li> <li> Fixed missing source dimensions from <code>extract_resolutions</code> output in StreamGear API.</li> <li> Fixed missing support for compression parameters in Multi-Clients Mode.</li> <li> Fixed round off error in FPS.</li> <li> Fixed several CI bugs and updated <code>extract_resolutions</code> method.</li> <li> Fixed several bugs from CI Bidirectional Mode tests.</li> <li> Fixed several typos in docs usage examples.</li> <li> Fixed various <code>AttributeError</code> with wrong attribute names and definition in CI Helper functions.</li> <li> Fixed wrong and missing definitions in docs.</li> <li> Fixed wrong logic for extracting OpenCV frames.</li> <li> Fixed wrong type bug in StreamGear API.</li> <li> Fixed wrong type error bug in WriteGear API.</li> <li> Fixed wrong variable assignments bug in WriteGear API.</li> <li> Fixes to CLI tests and missing docs imports.</li> <li> Many minor typos and wrong definitions.</li> </ul> Pull Requests <ul> <li>PR #129</li> <li>PR #130</li> <li>PR #155</li> </ul>"},{"location":"changelog/#v018-2020-06-12","title":"v0.1.8 (2020-06-12)","text":"New Features <ul> <li> NetGear API:<ul> <li>Multiple Clients support:<ul> <li>Implemented support for handling any number of Clients simultaneously with a single Server in this mode.</li> <li>Added new <code>multiclient_mode</code> attribute for enabling this mode easily.</li> <li>Built support for <code>zmq.REQ/zmq.REP</code> and <code>zmq.PUB/zmq.SUB</code> patterns in this mode.</li> <li>Implemented ability to receive data from all Client(s) along with frames with <code>zmq.REQ/zmq.REP</code> pattern only.</li> <li>Updated related CI tests</li> </ul> </li> <li>Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends:<ul> <li>Implemented a algorithm where NetGear rather than doing a blocking receive, will now:<ul> <li>Poll the socket and receive from it only when it's sure a reply has arrived.</li> <li>Attempt to reconnect, if no reply has arrived within a timeout period.</li> <li>Abandon the connection if there is still no reply after several requests.</li> </ul> </li> <li>Implemented its default support for <code>REQ/REP</code> and <code>PAIR</code> messaging patterns internally.</li> <li>Added new <code>max_retries</code> and <code>request_timeout</code>(in seconds) for handling polling.</li> <li>Added <code>DONTWAIT</code> flag for interruption-free data receiving.</li> <li>Both Server and Client can now reconnect even after a premature termination.</li> </ul> </li> <li>Performance Updates:<ul> <li>Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode.</li> <li>Added support for <code>Reducer()</code> function in Helper.py to aid reducing frame-size on-the-go for more performance.</li> <li>Added small delay in <code>recv()</code> function at client's end to reduce system load. </li> <li>Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags.</li> </ul> </li> </ul> </li> <li> Docs: Migration to Mkdocs<ul> <li>Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages.</li> <li>Crafted base mkdocs with third-party elegant &amp; simplistic <code>mkdocs-material</code> theme.</li> <li>Implemented new <code>mkdocs.yml</code> for Mkdocs with relevant data.</li> <li>Added new <code>docs</code> folder to handle markdown pages and its assets.</li> <li>Added new Markdown pages(<code>.md</code>) to docs folder, which are carefully crafted documents - [x] based on previous Wiki's docs, and some completely new additions.</li> <li>Added navigation under tabs for easily accessing each document.</li> <li>New Assets:<ul> <li>Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design.</li> <li>Designed brand new logo and banner for VidGear Documents.</li> <li>Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License.</li> </ul> </li> <li>Added Required Plugins and Extensions:<ul> <li>Added support for all pymarkdown-extensions.</li> <li>Added support for some important <code>admonition</code>, <code>attr_list</code>, <code>codehilite</code>, <code>def_list</code>, <code>footnotes</code>, <code>meta</code>, and <code>toc</code> like Mkdocs extensions.</li> <li>Enabled <code>search</code>, <code>minify</code> and <code>git-revision-date-localized</code> plugins support.</li> <li>Added various VidGear's social links to yaml.</li> <li>Added support for <code>en</code> (English) language.</li> </ul> </li> <li>Auto-Build API Reference with <code>mkdocstrings:</code><ul> <li>Added support for <code>mkdocstrings</code> plugin for auto-building each VidGear's API references.</li> <li>Added python handler for parsing python source-code to <code>mkdocstrings</code>.</li> </ul> </li> <li>Auto-Deploy Docs with GitHub Actions:<ul> <li>Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow.</li> <li>Added new workflow yaml with minimal configuration for automated docs deployment.</li> <li>Added all required  python dependencies and environment for this workflow.</li> <li>Added <code>master</code> branch on Ubuntu machine to build matrix.</li> </ul> </li> </ul> </li> </ul> Updates/Improvements <ul> <li> Added in-built support for bidirectional frames(<code>NDarray</code>) transfer in Bidirectional mode.</li> <li> Added support for User-Defined compression params in Bidirectional frames transfer.</li> <li> Added workaround for <code>address already in use</code> bug at client's end.</li> <li> Unified Bidirectional and Multi-Clients mode for client's return data transmission.</li> <li> Replaced <code>ValueError</code> with more suitable <code>RuntimeError</code>.</li> <li> Updated logging for better readability.</li> <li> Added CI test for Multi-Clients mode.</li> <li> Reformatted and grouped imports in VidGear.</li> <li> Added <code>Reducer</code> Helper function CI test.</li> <li> Added Reliability tests for both Server and Client end.</li> <li> Disabled reliable reconnection for Multi-Clients mode.</li> <li> Replaced <code>os.devnull</code> with suprocess's inbuilt function.</li> <li> Updated README.md, Issue and PR templates with new information and updates.</li> <li> Moved <code>changelog.md</code> to <code>/docs</code> and updated contribution guidelines.</li> <li> Improved source-code docs for compatibility with <code>mkdocstrings</code>.</li> <li> Added additional dependency <code>mkdocs-exclude</code>, for excluding files from Mkdocs builds.</li> <li> Updated license and compressed images/diagrams.</li> <li> Added new CI tests and Bumped Codecov.</li> <li> Changed YouTube video URL for CI tests to Creative Commons(CC) video.</li> <li> Removed redundant code.</li> </ul> Breaking Updates/Changes <ul> <li> VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear.</li> <li> Removed <code>filter</code> attribute from <code>options</code> parameter in NetGear API.</li> <li> Removed <code>force_terminate</code> parameter support from NetGear API.</li> <li> Disabled additional data of datatype <code>numpy.ndarray</code> for Server end in Bidirectional Mode.</li> </ul> Bug-fixes <ul> <li> Fixed <code>'NoneType' object is not subscriptable</code> bug.</li> <li> Fixed bugs related to delayed termination in NetGear API.</li> <li> Reduced default <code>request_timeout</code> value to 4 and also lowered cut-off limit for the same.</li> <li> Removed redundant ZMQ context termination and similar variables.</li> <li> Added missing VidGear installation in workflow.</li> <li> Excluded conflicting assets <code>README.md</code> from Mkdocs builds.</li> <li> Fixed <code>pattern</code> value check bypassed if wrong value is assigned.</li> <li> Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end.</li> <li> Replaced Netgear CI test with more reliable <code>try-except-final</code> blocks.</li> <li> Updated termination linger to zero at Server's end.</li> <li> Fixed <code>NameError</code> bug in NetGear API.</li> <li> Fixed missing support for compression parameters in Multi-Clients Mode.</li> <li> Fixed ZMQ throwing error on termination if all max-tries exhausted.</li> <li> Enabled missing support for frame compression in its primary receive mode.</li> <li> Fixed several bugs from CI Bidirectional Mode tests.</li> <li> Removed or Grouped redundant code for increasing codecov.</li> <li> Fixed Mkdocs only accepting Relative paths.</li> <li> Fixed broken links in docs. </li> <li> Fixed round off error in FPS.</li> <li> Many small typos and bugs fixes.</li> </ul> Pull Requests <ul> <li>PR #129</li> <li>PR #130</li> </ul>"},{"location":"changelog/#v017-2020-04-29","title":"v0.1.7 (2020-04-29)","text":"New Features <ul> <li> WebGear API:<ul> <li>Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time.</li> <li>Implemented a flexible asyncio wrapper around <code>starlette</code> ASGI Application Server.</li> <li>Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc.</li> <li>Added a special internal access to VideoGear API and all its parameters.</li> <li>Implemented a new Auto-Generation Work-flow to generate/download &amp; thereby validate WebGear API data files from its GitHub server automatically.</li> <li>Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily.</li> <li>Added new simple &amp; elegant default Bootstrap Cover Template for WebGear Server.</li> <li>Added <code>__main__.py</code> to directly run WebGear Server through the terminal.</li> <li>Added new gif and related docs for WebGear API.</li> <li>Added and Updated various CI tests for this API.</li> </ul> </li> <li> NetGear_Async API: <ul> <li>Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API.</li> <li>Implemented support for state-of-the-art asyncio event loop <code>uvloop</code> at its backend.</li> <li>Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint.</li> <li>Added exclusive internal wrapper around VideoGear API for this API.</li> <li>Implemented complete server-client handling and options to use variable protocols/patterns for this API.</li> <li>Implemented support for  all four ZeroMQ messaging patterns: i.e <code>zmq.PAIR</code>, <code>zmq.REQ/zmq.REP</code>, <code>zmq.PUB/zmq.SUB</code>, and <code>zmq.PUSH/zmq.PULL</code>.</li> <li>Implemented initial support for <code>tcp</code> and <code>ipc</code> protocols.</li> <li>Added new Coverage CI tests for NetGear_Async Network Gear.</li> <li>Added new Benchmark tests for benchmarking NetGear_Async against NetGear.</li> </ul> </li> <li> Asynchronous Enhancements: <ul> <li>Added <code>asyncio</code> package to for handling asynchronous APIs.</li> <li>Moved WebGear API(webgear.py) to <code>asyncio</code> and created separate asyncio <code>helper.py</code> for it.</li> <li>Various Performance tweaks for Asyncio APIs with concurrency within a single thread.</li> <li>Moved <code>__main__.py</code> to asyncio for easier access to WebGear API through the terminal.</li> <li>Updated <code>setup.py</code> with new dependencies and separated asyncio dependencies.</li> </ul> </li> <li> General Enhancements:<ul> <li>Added new highly-precise Threaded FPS class for accurate benchmarking with <code>time.perf_counter</code> python module.</li> <li>Added a new Gitter community channel.</li> <li>Added a new Reducer function to reduce the frame size on-the-go.</li> <li>Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss)</li> <li>Added a new unified <code>logging handler</code> helper function for vidgear.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Re-implemented and simplified logic for NetGear Async server-end.</li> <li> Added new dependencies for upcoming asyncio updates to <code>setup.py</code>.</li> <li> Added <code>retry</code> function and replaced <code>wget</code> with <code>curl</code> for Linux test envs. </li> <li> Bumped OpenCV to latest <code>4.2.0-dev</code> for Linux test envs.</li> <li> Updated YAML files to reflect new changes to different CI envs.</li> <li> Separated each API logger with a common helper method to avoid multiple copies. </li> <li> Limited Importing OpenCV API version check's scope to <code>helper.py</code> only.</li> <li> Implemented case for incorrect <code>color_space</code> value in ScreenGear API.</li> <li> Removed old conflicting logging formatter with a common method and expanded logging.</li> <li> Improved and added <code>shutdown</code> function for safely stopping frame producer threads in WebGear API.</li> <li> Re-implemented and simplified all CI tests with maximum code-coverage in mind.</li> <li> Replaced old <code>mkdir</code> function with new <code>mkdir_safe</code> helper function for creating directories safely.</li> <li> Updated ReadMe.md with updated diagrams, gifs and information.</li> <li> Improve, structured and Simplified the Contribution Guidelines.</li> <li> Bundled CI requirements in a single command.(Suggested by @cclauss)</li> <li> Replaced line endings CRLF with LF endings.</li> <li> Added dos2unix for Travis OSX envs.</li> <li> Bumped Codecov to maximum. </li> </ul> Breaking Updates/Changes <ul> <li> Dropped support for Python 3.5 and below legacies. (See issue #99)</li> <li> Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments.</li> <li> Implemented PEP-8 Styled Black formatting throughout the source-code.</li> <li> Limited protocols support to <code>tcp</code> and <code>ipc</code> only, in NetGear API.</li> </ul> Bug-fixes <ul> <li> Fixed Major NetGear_Async bug where <code>__address</code> and <code>__port</code> are not set in async mode.(PR by @otter-in-a-suit) </li> <li> Fixed Major PiGear Color-space Conversion logic bug.</li> <li> Workaround for <code>CAP_IMAGES</code> error in YouTube Mode.</li> <li> Replaced incorrect <code>terminate()</code> with <code>join()</code> in PiGear.</li> <li> Removed <code>uvloop</code> for windows as still NOT yet supported.</li> <li> Refactored Asynchronous Package name <code>async</code> to <code>asyncio</code>, since it is used as Keyword in python&gt;=3.7 (raises SyntaxError).</li> <li> Fixed unfinished close of event loops bug in WebGear API.</li> <li> Fixed NameError in helper.py.</li> <li> Added fix for OpenCV installer failure on Linux test envs.</li> <li> Fixed undefined NameError in <code>helper.py</code> context. (@cclauss)</li> <li> Fixed incorrect logic while pulling frames from ScreenGear API.</li> <li> Fixed missing functions in <code>__main__.py</code>.</li> <li> Fixed Typos and definitions in docs.</li> <li> Added missing <code>camera_num</code> parameter to VideoGear.</li> <li> Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs.</li> <li> Removed <code>download_url</code> meta from setup.py.</li> <li> Removed PiGear from CI completely due to hardware emulation limitation.</li> <li> Removed VideoCapture benchmark tests for macOS envs.</li> <li> Removed trivial <code>__main__.py</code> from codecov.</li> <li> Removed several redundant <code>try-catch</code> loops.</li> <li> Renamed <code>youtube_url_validation</code> as <code>youtube_url_validator</code>.</li> <li> Several minor wrong/duplicate variable definitions and various bugs fixed.</li> <li> Fixed, Improved &amp; removed many Redundant CI tests for various APIs.</li> </ul> Pull Requests <ul> <li>PR #88</li> <li>PR #91</li> <li>PR #93</li> <li>PR #95</li> <li>PR #98</li> <li>PR #101</li> <li>PR #114</li> <li>PR #118</li> <li>PR #124</li> </ul> New Contributors <ul> <li>@cclauss</li> <li>@chollinger93</li> </ul>"},{"location":"changelog/#v016-2020-01-01","title":"v0.1.6 (2020-01-01)","text":"New Features <ul> <li> NetGear API:<ul> <li>Added powerful ZMQ Authentication &amp; Data Encryption features for NetGear API:<ul> <li>Added exclusive <code>secure_mode</code> param for enabling it.</li> <li>Added support for two most powerful <code>Stonehouse</code> &amp; <code>Ironhouse</code> ZMQ security mechanisms.</li> <li>Added smart auth-certificates/key generation and validation features.</li> </ul> </li> <li>Implemented Robust Multi-Servers support for NetGear API:<ul> <li>Enables Multiple Servers messaging support with a single client.</li> <li>Added exclusive <code>multiserver_mode</code> param for enabling it.</li> <li>Added support for <code>REQ/REP</code> &amp;  <code>PUB/SUB</code> patterns for this mode.</li> <li>Added ability to send additional data of any datatype along with the frame in realtime in this mode.</li> </ul> </li> <li>Introducing exclusive Bidirectional Mode for bidirectional data transmission:<ul> <li>Added new <code>return_data</code> parameter to <code>recv()</code> function.</li> <li>Added new <code>bidirectional_mode</code> attribute for enabling this mode.</li> <li>Added support for <code>PAIR</code> &amp; <code>REQ/REP</code> patterns for this mode</li> <li>Added support for sending data of any python datatype.</li> <li>Added support for <code>message</code> parameter for non-exclusive primary modes for this mode.</li> </ul> </li> <li>Implemented compression support with on-the-fly flexible frame encoding for the Server-end:<ul> <li>Added initial support for <code>JPEG</code>, <code>PNG</code> &amp; <code>BMP</code> encoding formats .</li> <li>Added exclusive options attribute <code>compression_format</code> &amp; <code>compression_param</code> to tweak this feature.</li> <li>Client-end will now decode frame automatically based on the encoding as well as support decoding flags.</li> </ul> </li> <li>Added <code>force_terminate</code> attribute flag for handling force socket termination at the Server-end if there's latency in the network. </li> <li>Implemented new Publish/Subscribe(<code>zmq.PUB/zmq.SUB</code>) pattern for seamless Live Streaming in NetGear API.</li> </ul> </li> <li> PiGear API:<ul> <li>Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads.</li> <li>PiGear will not exit safely with <code>SystemError</code> if Picamera ribbon cable is pulled out to save resources.</li> <li>Added support for new user-defined <code>HWFAILURE_TIMEOUT</code> options attribute to alter timeout.</li> </ul> </li> <li> VideoGear API: <ul> <li>Added <code>framerate</code> global variable and removed redundant function.</li> <li>Added <code>CROP_N_ZOOM</code> attribute in Videogear API for supporting Crop and Zoom stabilizer feature.</li> </ul> </li> <li> WriteGear API: <ul> <li>Added new <code>execute_ffmpeg_cmd</code> function to pass a custom command to its FFmpeg pipeline.</li> </ul> </li> <li> Stabilizer class: <ul> <li>Added new Crop and Zoom feature.<ul> <li>Added <code>crop_n_zoom</code> param for enabling this feature.</li> </ul> </li> <li>Updated docs.</li> </ul> </li> <li> CI &amp; Tests updates:<ul> <li>Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment.</li> <li>Added full support for Codecov in all CI environments.</li> <li>Updated OpenCV to v4.2.0-pre(master branch). </li> <li>Added various Netgear API tests.</li> <li>Added initial Screengear API test.</li> <li>More test RTSP feeds added with better error handling in CamGear network test.</li> <li>Added tests for ZMQ authentication certificate generation.</li> <li>Added badge and Minor doc updates.</li> </ul> </li> <li> Added VidGear's official native support for MacOS environments.</li> </ul> Updates/Improvements <ul> <li> Replace <code>print</code> logging commands with python's logging module completely.</li> <li> Implemented encapsulation for class functions and variables on all gears.</li> <li> Updated support for screen casting from multiple/all monitors in ScreenGear API.</li> <li> Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant <code>THREADED_QUEUE_MODE</code> param.</li> <li> Updated bash script path to download test dataset in <code>$TMPDIR</code> rather than <code>$HOME</code> directory for downloading testdata.</li> <li> Implemented better error handling of colorspace in various videocapture APIs.</li> <li> Updated bash scripts, Moved FFmpeg static binaries to <code>github.com</code>.</li> <li> Updated bash scripts, Added additional flag to support un-secure apt sources.</li> <li> CamGear API will now throw <code>RuntimeError</code> if source provided is invalid.</li> <li> Updated threaded Queue mode in CamGear API for more robust performance.</li> <li> Added new <code>camera_num</code> to support multiple Picameras.</li> <li> Moved thread exceptions to the main thread and then re-raised.</li> <li> Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses.</li> <li> Added <code>colorlog</code> python module for presentable colored logging.</li> <li> Replaced <code>traceback</code> with <code>sys.exc_info</code>.</li> <li> Overall APIs Code and Docs optimizations.</li> <li> Updated Code Readability and Wiki Docs.</li> <li> Updated ReadMe &amp; Changelog with the latest changes.</li> <li> Updated Travis CI Tests with support for macOS environment.</li> <li> Reformatted &amp; implemented necessary MacOS related changes and dependencies in <code>travis.yml</code>.</li> </ul> Breaking Updates/Changes <ul> <li> Python 2.7 legacy support dropped completely.</li> <li> Source-code Relicensed to Apache 2.0 License.</li> <li> Python 3+ are only supported legacies for installing v0.1.6 and above.</li> <li> Python 2.7 and 3.4 legacies support dropped from CI tests.</li> </ul> Bug-fixes <ul> <li> Reimplemented <code>Pub/Sub</code> pattern for smoother performance on various networks.</li> <li> Fixed Assertion error in CamGear API during colorspace manipulation.</li> <li> Fixed random freezing in <code>Secure Mode</code> and several related performance updates</li> <li> Fixed <code>multiserver_mode</code> not working properly over some networks.</li> <li> Fixed assigned Port address ignored bug (commit 073bca1).</li> <li> Fixed several wrong definition bugs from NetGear API(commit 8f7153c).</li> <li> Fixed unreliable dataset video URL(rehosted file on <code>github.com</code>).</li> <li> Disabled <code>overwrite_cert</code> for client-end in NetGear API.</li> <li> Disabled Universal Python wheel builds in <code>setup.cfg</code>file.</li> <li> Removed duplicate code to import MSS(@BoboTiG) from ScreenGear API.</li> <li> Eliminated unused redundant code blocks from library.</li> <li> Fixed Code indentation in <code>setup.py</code> and updated new release information.</li> <li> Fixed code definitions &amp; Typos.</li> <li> Fixed several bugs related to <code>secure_mode</code> &amp; <code>multiserver_mode</code> Modes.</li> <li> Fixed various macOS environment bugs.</li> </ul> Pull Requests <ul> <li> PR #39</li> <li> PR #42</li> <li> PR #44</li> <li> PR #52</li> <li> PR #55</li> <li> PR #62</li> <li> PR #67</li> <li> PR #72</li> <li> PR #77</li> <li> PR #78</li> <li> PR #82</li> <li> PR #84</li> </ul> New Contributors <ul> <li>@BoboTiG</li> </ul>"},{"location":"changelog/#v015-2019-07-24","title":"v0.1.5 (2019-07-24)","text":"New Features <ul> <li> Added new ScreenGear API, supports Live ScreenCasting.</li> <li> Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network.</li> <li> Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV.</li> <li> Added Option to use API's standalone.</li> <li> Added Option to use VideoGear API as internal wrapper around Stabilizer Class.</li> <li> Added new parameter <code>stabilize</code> to API, to enable or disable Video Stabilization.</li> <li> Added support for <code>**option</code> dict attributes to update VidGear's video stabilizer parameters directly. </li> <li> Added brand new logo and functional block diagram (<code>.svg</code>) in readme.md</li> <li> Added new pictures and GIFs for improving readme.md readability </li> <li> Added new <code>contributing.md</code> and <code>changelog.md</code> for reference.</li> <li> Added <code>collections.deque</code> import in Threaded Queue Mode for performance consideration</li> <li> Added new <code>install_opencv.sh</code> bash scripts for Travis cli, to handle OpenCV installation.</li> <li> Added new Project Issue &amp; PR Templates</li> <li> Added new Sponsor Button(<code>FUNDING.yml</code>)</li> </ul> Updates/Improvements <ul> <li> Updated New dependencies: <code>mss</code>, <code>pyzmq</code> and rejected redundant ones.</li> <li> Revamped and refreshed look for <code>readme.md</code> and added new badges.</li> <li> Updated Releases Documentation completely.</li> <li> Updated CI tests for new changes</li> <li> Updated Code Documentation.</li> <li> Updated bash scripts and removed redundant information</li> <li> Updated <code>Youtube video</code> URL in tests</li> <li> Completely Reformatted and Updated Wiki Docs with new changes.</li> </ul> Breaking Updates/Changes <ul> <li> Implemented experimental Threaded Queue Mode(a.k.a Blocking Mode) for fast, synchronized, error-free multi-threading.</li> <li> Renamed bash script <code>pre-install.sh</code> to <code>prepare_dataset.sh</code> - [x] downloads opensourced test datasets and static FFmpeg binaries for debugging.</li> <li> Changed <code>script</code> folder location to <code>bash/script</code>.</li> <li> <code>Python 3.4</code> removed from Travis CI tests.</li> </ul> Bug-fixes <ul> <li> Temporarily fixed Travis CI bug: Replaced <code>opencv-contrib-python</code> with OpenCV built from scratch as dependency.</li> <li> Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests</li> <li> Fixes** <code>sys.stderr.close()</code> throws ValueError bug: Replaced <code>sys.close()</code> with <code>DEVNULL.close()</code></li> <li> Fixed Youtube Live Stream bug that return <code>NonType</code> frames in CamGear API.</li> <li> Fixed <code>NoneType</code> frames bug in  PiGear class on initialization.</li> <li> Fixed Wrong function definitions</li> <li> Removed <code>/xe2</code> unicode bug from Stabilizer class.</li> <li> Fixed <code>**output_params</code> KeyError bug in WriteGear API</li> <li> Fixed subprocess not closing properly on exit in WriteGear API.</li> <li> Fixed bugs in ScreenGear: Non-negative <code>monitor</code> values</li> <li> Fixed missing import, typos, wrong variable definitions</li> <li> Removed redundant hack from <code>setup.py</code></li> <li> Fixed Minor YouTube playback Test CI Bug </li> <li> Fixed new Twitter Intent</li> <li> Fixed bug in bash script that not working properly due to changes at server end.</li> </ul> Pull Requests <ul> <li> PR #17</li> <li> PR #21</li> <li> PR #22</li> <li> PR #27</li> <li> PR #31</li> <li> PR #32</li> <li> PR #33</li> <li> PR #34</li> </ul>"},{"location":"changelog/#v014-2019-05-11","title":"v0.1.4 (2019-05-11)","text":"New Features <ul> <li> Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer)</li> <li> Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API</li> <li> Added new <code>y_tube</code> to access YouTube Mode in CamGear API.</li> <li> Added flexible Output file Compression control capabilities in compression-mode(WriteGear).</li> <li> Added <code>-output_dimensions</code> special parameter to WriteGear API.</li> <li> Added new <code>helper.py</code> to handle special helper functions.</li> <li> Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms.</li> <li> Added <code>-input_framerate</code> special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear).</li> <li> Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API.</li> <li> Added new <code>framerate</code> class variable for CamGear API, to retrieve input framerate.</li> <li> Added new parameter <code>backend</code> - [x] changes the backend of CamGear's API</li> <li> Added automatic required prerequisites installation ability, when installation from source.</li> <li> Added Travis CI Complete Integration for Linux-based Testing for VidGear.</li> <li> Added and configured <code>travis.yml</code></li> <li> Added Appveyor CI Complete Integration for Windows-based Testing in VidGear.</li> <li> Added and configured new <code>appveyor.yml</code></li> <li> Added new bash script <code>pre-install.sh</code> to download opensourced test datasets and static FFmpeg binaries for debugging.</li> <li> Added several new Tests(including Benchmarking Tests) for each API for testing with <code>pytest</code>.</li> <li> Added license to code docs.</li> <li> Added <code>Say Thank you!</code> badge to <code>Readme.md</code>.</li> </ul> Updates/Improvements <ul> <li> Removed redundant dependencies</li> <li> Updated <code>youtube-dl</code> as a dependency, as required by <code>pafy</code>'s backend.</li> <li> Updated common VideoGear API with new parameter.</li> <li> Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. </li> <li> Improved system previously installed OpenCV detection in setup.py.</li> <li> Updated setup.py with hack to remove bullets from pypi description. </li> <li> Updated Code Documentation</li> <li> Reformatted &amp; Modernized readme.md with new badges.</li> <li> Reformatted and Updated Wiki Docs.</li> </ul> Breaking Updates/Changes <ul> <li> Removed <code>-height</code> and <code>-width</code> parameter from CamGear API.</li> <li> Replaced dependency <code>opencv-python</code> with <code>opencv-contrib-python</code> completely</li> </ul> Bug-fixes <ul> <li> Windows Cross-Platform fix: replaced dependency <code>os</code> with <code>platform</code> in setup.py.</li> <li> Fixed Bug: Arises due to spaces in input <code>**options</code>/<code>**output_param</code> dictionary keys.</li> <li> Fixed several wrong/missing variable &amp; function definitions.</li> <li> Fixed code uneven indentation.</li> <li> Fixed several typos in docs.</li> </ul> Pull Requests <ul> <li> PR #7</li> <li> PR #8</li> <li> PR #10</li> <li> PR #12</li> </ul>"},{"location":"changelog/#v013-2019-04-07","title":"v0.1.3 (2019-04-07)","text":"Bug-fixes <ul> <li> Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class</li> <li> Several Fixes for backend <code>picamera</code> API handling during frame capture(PiGear)</li> <li> Fixed missing frame variable initialization.</li> <li> Fixed minor typos</li> </ul> Pull Requests <ul> <li> PR #6</li> <li> PR #5</li> </ul>"},{"location":"changelog/#v012-2019-03-27","title":"v0.1.2 (2019-03-27)","text":"New Features <ul> <li> Added easy Source manipulation feature in CamGear API, to control features like <code>resolution, brightness, framerate etc.</code></li> <li> Added new <code>**option</code> parameter to CamGear API, provides the flexibility to manipulate input stream directly.</li> <li> Added new parameters for Camgear API for time delay and logging.</li> <li> Added new Logo to readme.md</li> <li> Added new Wiki Documentation.</li> </ul> Updates/Improvements <ul> <li> Reformatted readme.md.</li> <li> Updated Wiki Docs with new changes.</li> </ul> Bug-fixes <ul> <li> Improved Error Handling in CamGear &amp; PiGear API.</li> <li> Fixed minor typos in docs.</li> </ul> Pull Requests <ul> <li> PR #4</li> </ul>"},{"location":"changelog/#v011-2019-03-24","title":"v0.1.1 (2019-03-24)","text":"New Features <ul> <li> Release ViGear binaries on the Python Package Index (PyPI)</li> <li> Added new and configured <code>setup.py</code> &amp; <code>setup.cfg</code></li> </ul> Bug-fixes <ul> <li> Fixed PEP bugs: added and configured properly <code>__init__.py</code> in each folder </li> <li> Fixed PEP bugs: improved code Indentation</li> <li> Fixed wrong imports: replaced <code>distutils.core</code> with <code>setuptools</code></li> <li> Fixed readme.md</li> </ul>"},{"location":"changelog/#v010-2019-03-17","title":"v0.1.0 (2019-03-17)","text":"New Features <ul> <li> Initial Release</li> <li> Converted my <code>imutils</code> PR into Python Project.</li> <li> Renamed conventions and reformatted complete source-code from scratch.</li> <li> Added support for both python 2.7 and 3 legacies</li> <li> Added new multi-threaded CamGear, PiGear, and VideoGear APIs</li> <li> Added multi-platform compatibility</li> <li> Added robust &amp; flexible control over the source in PiGear API.</li> </ul>"},{"location":"contribution/","title":"Contribution Overview","text":""},{"location":"contribution/#contribution-overview","title":"Contribution Overview","text":"<p>Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features!</p> <p>Contribution Opportunities </p> <p>If you're looking for something to work on, check for the PR WELCOMED  labeled issues on our GitHub Repository.</p> <p> </p>"},{"location":"contribution/#submission-guidelines","title":"Submission Guidelines","text":"<ul> <li>Submitting an Issue Guidelines \u27b6</li> <li>Submitting Pull Request(PR) Guidelines \u27b6</li> </ul>"},{"location":"contribution/#submission-contexts","title":"Submission Contexts","text":""},{"location":"contribution/#got-a-question-or-problem","title":"Got a question or problem?","text":"<p>For quick questions, please refrain from opening an issue, instead read our FAQ &amp; Troubleshooting section or you can reach us on Gitter community channel.</p>"},{"location":"contribution/#found-a-typo","title":"Found a typo?","text":"<p>There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time. </p>"},{"location":"contribution/#found-a-bug","title":"Found a bug?","text":"<p>If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6.</p>"},{"location":"contribution/#request-for-a-featureimprovement","title":"Request for a feature/improvement?","text":"Subscribe to Github Repository <p>You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6</p> <p>You can request our GitHub Repository for a new feature/improvement based on the type of request:</p> <p>Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community.</p> <ul> <li> <p>Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! </p> </li> <li> <p>Minor Feature Requests:  Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.</p> </li> </ul> <p> </p>"},{"location":"gears/","title":"Introduction","text":""},{"location":"gears/#introduction","title":"Introduction","text":"Gears: generalized workflow"},{"location":"gears/#gears-what-are-these","title":"Gears , What are these?","text":"<p>VidGear is built on Standalone APIs - also known as Gears , each with some unique functionality. Each Gears is designed exclusively to handle/control/process different data-specific &amp; device-specific video streams, network streams, and media encoders/decoders. </p> <p>Gears allows users to work with an inherently optimized, easy-to-use, extensible, and exposed API Framework on top of many state-of-the-art libraries, while silently delivering robust error handling and unmatched real-time performance.</p>"},{"location":"gears/#gears-classification","title":"Gears Classification","text":"<p>These Gears can be classified as follows:</p>"},{"location":"gears/#a-videocapture-gears","title":"A. VideoCapture Gears","text":"<p>Basic Function: Retrieves <code>numpy.ndarray</code> frames from various sources.</p> <ul> <li>CamGear: Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs.</li> <li>PiGear: Multi-Threaded API targeting various Camera Modules and (limited) USB cameras on Raspberry Pis .</li> <li>ScreenGear: High-performance API targeting rapid Screencasting Capabilities.</li> <li>VideoGear: Common Video-Capture API with internal Video Stabilizer wrapper. </li> </ul>"},{"location":"gears/#b-videowriter-gears","title":"B. VideoWriter Gears","text":"<p>Basic Function: Writes <code>numpy.ndarray</code> frames to a video file or network stream.</p> <ul> <li>WriteGear: Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.</li> </ul>"},{"location":"gears/#c-streaming-gears","title":"C. Streaming Gears","text":"<p>Basic Function: Transcodes/Broadcasts files and <code>numpy.ndarray</code> frames for streaming.</p> <p>You can also use WriteGear for  streaming with traditional protocols such as RTMP, RTSP/RTP.</p> <ul> <li> <p>StreamGear: Handles Transcoding of High-Quality, Dynamic &amp; Adaptive Streaming Formats.</p> </li> <li> <p>Asynchronous I/O Streaming Gear:</p> <ul> <li> <p>WebGear: ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network.</p> </li> <li> <p>WebGear_RTC: Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.</p> </li> </ul> </li> </ul>"},{"location":"gears/#d-network-gears","title":"D. Network Gears","text":"<p>Basic Function: Sends/Receives data and <code>numpy.ndarray</code> frames over connected networks.</p> <ul> <li> <p>NetGear: Handles High-Performance Video-Frames &amp; Data Transfer between interconnecting systems over the network.</p> </li> <li> <p>Asynchronous I/O Network Gear:</p> <ul> <li>NetGear_Async: Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.</li> </ul> </li> </ul> <p> </p>"},{"location":"help/","title":"Helping VidGear","text":""},{"location":"help/#helping-vidgear","title":"Helping VidGear","text":"<p>Liked VidGear? Would you like to help VidGear, other users, and the author?</p> <p>There are many simple ways to help us:</p> <p> </p>"},{"location":"help/#star-vidgear-on-github","title":"Star VidGear on GitHub","text":"<p>You can star  VidGear on GitHub: </p> <p>It helps us a lot by making it easier for others to find &amp; trust this library. Thanks!</p> <p> </p>"},{"location":"help/#help-others-with-issues-on-github","title":"Help others with issues on GitHub","text":"<p>You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: </p> <p> </p>"},{"location":"help/#watch-the-github-repository","title":"Watch the GitHub repository","text":"<p>You can watch \ud83d\udc40 VidGear Activities on GitHub: </p> <p>When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request.</p> <p>You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.</p> <p> </p>"},{"location":"help/#helping-author","title":"Helping Author","text":"<p>Donations help keep VidGear's development alive and motivate me (as author). </p> <p>It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference </p> <p></p> <p>Thanks a million! </p> <p> </p>"},{"location":"help/#connect-with-author","title":"Connect with Author","text":"<p>You can connect with me, the author \ud83d\udc4b:</p> <p></p> <ul> <li>Follow author on GitHub: </li> <li>Get in touch with author on Linkedin: </li> </ul> <p> </p>"},{"location":"installation/","title":"Installation Overview","text":""},{"location":"installation/#installation-overview","title":"Installation Overview","text":""},{"location":"installation/#supported-systems","title":"Supported Systems","text":"<p>VidGear is well-tested and supported on the following systems(but not limited to), with python 3.8+ and pip installed:</p> <ul> <li>Any  Linux distro released in 2016 or later</li> <li> Windows 7 or later</li> <li> MacOS 10.12.6 (Sierra) or later</li> </ul> <p> </p>"},{"location":"installation/#supported-python-legacies","title":"Supported Python legacies","text":"<p>Depreciation Notice</p> <p>Python-3.7 legacies support has been dropped from Vidgear.</p> <p> Python 3.8+ are only supported legacies for installing Vidgear <code>v0.3.1</code> and above.</p> <p> </p>"},{"location":"installation/#installation-methods","title":"Installation methods","text":"<ul> <li>Install using pip (recommended)</li> <li>Install from source</li> </ul>"},{"location":"license/","title":"License","text":""},{"location":"license/#license","title":"License","text":"<p>This library is released under the Apache 2.0 License.</p>"},{"location":"license/#copyright-notice","title":"Copyright Notice","text":"<pre><code>Copyright (c) 2019 Abhishek Thakur(@abhiTronix) &lt;abhi.una12@gmail.com&gt;\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"switch_from_cv/","title":"Switching from OpenCV","text":""},{"location":"switch_from_cv/#switching-from-opencv-library","title":"Switching from OpenCV Library","text":"<p>Switching OpenCV with VidGear APIs is fairly painless process, and will just require changing a few lines in your python script. </p> <p>This document is intended to software developers who want to migrate their python code from OpenCV Library to VidGear APIs.</p> <p>Prior knowledge of Python or OpenCV won't be covered in this guide. Proficiency with OpenCV-Python (Python API for OpenCV) is a must in order understand this document.</p> <p>If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6</p> <p> </p>"},{"location":"switch_from_cv/#why-vidgear-is-better-than-opencv","title":"Why VidGear is better than OpenCV?","text":"<p>Learn more about OpenCV here \u27b6</p> <p>VidGear employs OpenCV at its backend and enhances its existing capabilities even further by introducing many new state-of-the-art functionalities such as:</p> <ul> <li> Accelerated Multi-Threaded Performance.</li> <li> Out-of-the-box support for OpenCV APIs.</li> <li> Real-time Stabilization ready.</li> <li> Lossless hardware enabled video encoding and transcoding.</li> <li> Inherited multi-backend support for various video sources and devices.</li> <li> Screen-casting, Multi-bitrate network-streaming, and way much more \u27b6</li> </ul> <p>Vidgear offers all this at once while maintaining the same standard OpenCV-Python (Python API for OpenCV) coding syntax for all of its APIs, thereby making it even easier to implement complex real-time OpenCV applications in python code without changing things much.</p> <p> </p>"},{"location":"switch_from_cv/#switching-the-videocapture-apis","title":"Switching the VideoCapture APIs","text":"<p>Let's compare a bare-minimum python code for extracting frames out of any Webcam/USB-camera (connected at index 0), between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side:</p> <p>CamGear API share the same syntax as other VideoCapture APIs, thereby you can easily switch to any of those APIs in a similar manner.</p> OpenCV VideoCapture ClassVidGear's CamGear API <pre><code># import required libraries\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n      break\n\n\n    # {do something with the frame here}\n\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>and both syntax almost looks the same, easy, isn't it?</p> <p> </p>"},{"location":"switch_from_cv/#differences","title":"Differences","text":"<p>Let's breakdown a few noteworthy difference in both syntaxes:</p> Task OpenCV VideoCapture Class VidGear's CamGear API Initiating <code>stream = cv2.VideoCapture(0)</code> <code>stream = CamGear(source=0).start()</code> Reading frames <code>(grabbed, frame) = stream.read()</code> <code>frame = stream.read()</code> Checking empty frame <code>if not grabbed:</code> <code>if frame is None:</code> Terminating <code>stream.release()</code> <code>stream.stop()</code> <p>Now checkout other VideoCapture Gears \u27b6</p> <p> </p> <p> </p>"},{"location":"switch_from_cv/#switching-the-videowriter-api","title":"Switching the VideoWriter API","text":"<p>Let's extend previous bare-minimum python code and save those extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear (with FFmpeg backend), compared side-to-side:</p> <p>WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6</p> OpenCV VideoWriter ClassVidGear's WriteGear API <pre><code># import required libraries\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n\n# Define the codec and create VideoWriter object with suitable output \n# filename for e.g. `Output.avi`\nfourcc = cv2.VideoWriter_fourcc(*'XVID') \nwriter = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480)) \n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n      break\n\n\n    # {do something with the frame here}\n\n\n    # write frame to writer\n    writer.write(frame)\n\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close writer\nwriter.release() \n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n\n# Define WriteGear Object with suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output = 'Output.mp4') \n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if None-type\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p>Noticed WriteGear's coding syntax looks similar but less complex?</p> <p> </p>"},{"location":"switch_from_cv/#differences_1","title":"Differences","text":"<p>Let's breakdown a few noteworthy difference in both syntaxes:</p> Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating <code>writer = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))</code> <code>writer = WriteGear(output='Output.mp4')</code> Writing frames <code>writer.write(frame)</code> <code>writer.write(frame)</code> Terminating <code>writer.release()</code> <code>writer.close()</code> <p>Now checkout more about WriteGear API here \u27b6</p> <p> </p>"},{"location":"bonus/TQM/","title":"Threaded Queue Mode","text":""},{"location":"bonus/TQM/#threaded-queue-mode","title":"Threaded Queue Mode","text":""},{"location":"bonus/TQM/#overview","title":"Overview","text":"Threaded-Queue-Mode: generalized timing diagram <p>Threaded Queue Mode is designed exclusively for VidGear's Videocapture Gears (namely CamGear, VideoGear) and few Network Gears (such as NetGear(Client's end)) for achieving high-performance, asynchronous, error-free video-frames handling. </p> <p>Threaded-Queue-Mode is enabled by default, but can be disabled, only if extremely necessary.</p> <p>Threaded-Queue-Mode is NOT required and thereby automatically disabled for Live feed such as Camera Devices/Modules, since .</p> <p> </p>"},{"location":"bonus/TQM/#what-does-threaded-queue-mode-exactly-do","title":"What does Threaded-Queue-Mode exactly do?","text":"<p>Threaded-Queue-Mode helps VidGear do the Threaded Video-Processing tasks in highly optimized, well-organized, and most competent way possible: </p>"},{"location":"bonus/TQM/#a-enables-multi-threading","title":"A. Enables Multi-Threading","text":"<p>In case you don't already know, OpenCV's' <code>read()</code> is a Blocking I/O function for reading and decoding the next video-frame, and consumes much of the I/O bound memory depending upon our video source properties &amp; system hardware. This essentially means, the corresponding thread that reads data from it, is continuously blocked from retrieving the next frame. As a result, our python program appears slow and sluggish even without any type of computationally expensive image processing operations. This problem is far more severe on low memory SBCs like Raspberry Pis.</p> <p>In Threaded-Queue-Mode, VidGear creates several Python Threads within one process to offload the frame-decoding task to a different thread. Thereby,  VidGear is able to execute different Video I/O-bounded operations at the same time by overlapping there waiting times. Moreover,  threads are managed by operating system itself and is capable of distributing them between available CPU cores efficiently. In this way, Threaded-Queue-Mode keeps on processing frames faster in the background without affecting by sluggishness in our main python program thread.</p>"},{"location":"bonus/TQM/#b-utilizes-fixed-size-queues","title":"B. Utilizes Fixed-Size Queues","text":"<p>Although Multi-threading is fast, easy, and efficient, it can lead to some serious undesired effects like frame-skipping, Global Interpreter Lock, race conditions, etc. This is because there is no isolation whatsoever in python threads, and in case there is any crash it will cause the whole process to crash. That's not all, the memory of the process is shared by different threads and that may result in random process crashes due to unwanted race conditions.</p> <p>These problems are avoided in Threaded-Queue-Mode by utilizing Thread-Safe, Memory-Efficient, and Fixed-Size <code>Queues</code> (with approximately same O(1) performance in both directions), that isolates the frame-decoding thread from other parallel threads and provide synchronized access to incoming frames without any obstruction. </p>"},{"location":"bonus/TQM/#c-accelerates-frame-processing","title":"C. Accelerates Frame Processing","text":"<p>With queues, VidGear always maintains a fixed-length frames buffer in the memory and blocks the thread temporarily if the queue is full to avoid possible frame drops or otherwise pops out the frames synchronously without any obstructions. This significantly accelerates frame processing rate (and therefore our overall video processing pipeline) comes from dramatically reducing latency \u2014 since we don\u2019t have to wait for the <code>read()</code> method to finish reading and decoding a frame; instead, there is always a pre-decoded frame ready for us to process.</p> <p> </p>"},{"location":"bonus/TQM/#what-are-the-advantages-of-threaded-queue-mode","title":"What are the advantages of Threaded-Queue-Mode?","text":"<ul> <li> <p> Enables Blocking, Sequential and Threaded LIFO Frame Handling.</p> </li> <li> <p> Sequentially adds and releases frames from <code>queues</code> and handles the overflow.</p> </li> <li> <p> Utilizes thread-safe, memory efficient <code>queues</code> that appends and pops frames with same O(1) performance from either side.</p> </li> <li> <p> Faster frame access due to buffered frames in the <code>queue</code>.</p> </li> <li> <p> Provides isolation for source thread and prevents GIL.</p> </li> </ul> <p> </p>"},{"location":"bonus/TQM/#manually-disabling-threaded-queue-mode","title":"Manually disabling Threaded-Queue-Mode","text":"<p>To manually disable Threaded-Queue-Mode, VidGear provides <code>THREADED_QUEUE_MODE</code> boolean attribute for <code>options</code> dictionary parameter in respective VideoCapture APIs:  </p> <p>Important Warnings</p> <ul> <li> <p>Disabling Threaded-Queue-Mode does NOT disables Multi-Threading.</p> </li> <li> <p><code>THREADED_QUEUE_MODE</code> attribute does NOT work with Live feed, such as Camera Devices/Modules.</p> </li> <li> <p><code>THREADED_QUEUE_MODE</code> attribute is NOT supported by ScreenGear &amp; NetGear APIs, as Threaded Queue Mode is essential for their core operations.</p> </li> </ul> <p>Disabling Threaded-Queue-Mode may lead to Random Intermittent Bugs that can be quite difficult to discover. More insight can be found here \u27b6</p> <p><code>THREADED_QUEUE_MODE</code> (boolean): This attribute can be used to override Threaded-Queue-Mode mode to manually disable it:</p> <pre><code>options = {'THREADED_QUEUE_MODE': False} # to disable Threaded Queue Mode. \n</code></pre> <p>and you can pass it to <code>options</code> dictionary parameter of the respective API.</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/","title":"Colorspace Manipulation","text":""},{"location":"bonus/colorspace_manipulation/#colorspace-manipulation-for-videocapture-gears","title":"Colorspace Manipulation for VideoCapture Gears","text":""},{"location":"bonus/colorspace_manipulation/#source-colorspace-manipulation","title":"Source ColorSpace manipulation","text":"<p>All VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and some Streaming Gears (namely WebGear, WebGear_RTC) and Network Gears (Client's end) - provides exclusive internal support for Source Color Space manipulation. </p> <p>There are two ways to alter source colorspace:</p>"},{"location":"bonus/colorspace_manipulation/#using-colorspace-parameter","title":"Using <code>colorspace</code> parameter","text":"<p>Primarily, the safest way is by <code>colorspace</code> (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, <code>colorspace</code> parameter value CANNOT be changed/altered at runtime. </p> <p>All possible values for this parameter are discussed below \u27b6</p>"},{"location":"bonus/colorspace_manipulation/#using-color_space-global-variable","title":"Using <code>color_space</code> global variable","text":"<p>Alternatively, a more direct approach is by using <code>color_space</code> (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with <code>colorspace</code> parameter easily. </p> <p> </p> <p>Supported Colorspace Conversions</p> <p>Any conversion from default Source colorspace (i.e. BGR in case of OpenCV), to any other colorspace and vice-versa (use <code>None</code> to revert), is supported.</p> <p>Important Information</p> <ul> <li> <p>Using <code>color_space</code> global variable is NOT Supported in VideoGear API, calling it will result in <code>AttribueError</code>.</p> </li> <li> <p>Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. <code>BGR</code>).</p> </li> <li> <p>Using <code>color_space</code> global variable with Threaded Queue Mode may have minor lag, User discretion is advised.</p> </li> </ul> <p>Tip</p> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#supported-colorspace-parameter-values","title":"Supported <code>colorspace</code> parameter values","text":"<p>All supported string values for <code>colorspace</code> parameter are as follows:</p> <p>You can check all OpenCV Colorspace Conversion Codes here \u27b6.</p> Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR) <p> </p>"},{"location":"bonus/colorspace_manipulation/#usage-examples","title":"Usage examples","text":""},{"location":"bonus/colorspace_manipulation/#using-camgear-with-direct-colorspace-manipulation","title":"Using CamGear with Direct Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#using-pigear-with-direct-colorspace-manipulation","title":"Using PiGear with Direct Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#using-videogear-with-colorspace-manipulation","title":"Using VideoGear with Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#using-screengear-with-direct-colorspace-manipulation","title":"Using ScreenGear with Direct Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/reference/camgear/","title":"API References","text":"<p>CamGear API usage examples can be found here \u27b6</p> <p>CamGear API parameters are explained here \u27b6</p> <p>CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rtsp, rtmp, mms, etc. It also supports Gstreamer's RAW pipelines.</p> <p>CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters. It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.</p> <p>CamGear internally implements <code>yt_dlp</code> backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Dailymotion, Twitch, and many more \u27b6</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>class CamGear:\n    \"\"\"\n    CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested),\n    any network stream URL such as http(s), rtp, rtsp, rtmp, mms, etc. It also supports Gstreamer's RAW pipelines.\n\n    CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters.\n    It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.\n\n    CamGear internally implements `yt_dlp` backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Dailymotion,\n    Twitch, and [many more \u27b6](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites)\n    \"\"\"\n\n    def __init__(\n        self,\n        source=0,\n        stream_mode=False,\n        backend=0,\n        colorspace=None,\n        logging=False,\n        time_delay=0,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the CamGear class.\n\n        Parameters:\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Source Tweak Parameters.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # initialize global\n        self.ytv_metadata = {}\n\n        # check if Stream-Mode is ON (True)\n        if stream_mode:\n            # TODO: check GStreamer backend support\n            # gst_support = check_gstreamer_support(logging=self.__logging)\n            # handle special Stream Mode parameters\n            stream_resolution = get_supported_resolution(\n                options.pop(\"STREAM_RESOLUTION\", \"best\"), logging=self.__logging\n            )\n            # handle Stream-Mode\n            if not (yt_dlp is None):\n                # extract user-defined params\n                yt_stream_params = options.pop(\"STREAM_PARAMS\", {})\n                if isinstance(yt_stream_params, dict):\n                    yt_stream_params = {\n                        str(k).strip(): v for k, v in yt_stream_params.items()\n                    }\n                else:\n                    yt_stream_params = {}\n                try:\n                    # Validate source for Yt_dlp backend\n                    logger.info(\n                        \"Verifying Streaming URL using yt-dlp backend. Please wait...\"\n                    )\n                    # initialize YT_backend\n                    ytbackend = YT_backend(\n                        source_url=source, logging=self.__logging, **yt_stream_params\n                    )\n                    if ytbackend:\n                        # save video metadata\n                        self.ytv_metadata = ytbackend.meta_data\n                        # handle live-streams\n                        # Throw warning for livestreams\n                        ytbackend.is_livestream and logger.warning(\n                            \"Livestream URL detected. It is strongly recommended to use the GStreamer backend (`backend=cv2.CAP_GSTREAMER`) with these URLs.\"\n                        )\n                        # check whether stream-resolution was specified and available\n                        if not (stream_resolution in ytbackend.streams.keys()):\n                            logger.warning(\n                                \"Specified stream-resolution `{}` is not available. Reverting to `best`!\".format(\n                                    stream_resolution\n                                )\n                            )\n                            # revert to best\n                            stream_resolution = \"best\"\n                        else:\n                            self.__logging and logger.debug(\n                                \"Using `{}` resolution for streaming.\".format(\n                                    stream_resolution\n                                )\n                            )\n                        # extract stream URL as source using stream-resolution\n                        source = ytbackend.streams[stream_resolution]\n                        # log progress\n                        self.__logging and logger.debug(\n                            \"YouTube source ID: `{}`, Title: `{}`, Quality: `{}`\".format(\n                                self.ytv_metadata[\"id\"],\n                                self.ytv_metadata[\"title\"],\n                                stream_resolution,\n                            )\n                        )\n                except Exception as e:\n                    # raise error if something went wrong\n                    raise ValueError(\n                        \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\"\n                    )\n            else:\n                # raise import errors\n                import_dependency_safe(\"yt_dlp\")\n\n        # assigns special parameter to global variable and clear\n        # Threaded Queue Mode\n        self.__threaded_queue_mode = options.pop(\"THREADED_QUEUE_MODE\", True)\n        if not isinstance(self.__threaded_queue_mode, bool):\n            # reset improper values\n            self.__threaded_queue_mode = True\n        # Thread Timeout\n        self.__thread_timeout = options.pop(\"THREAD_TIMEOUT\", None)\n        if self.__thread_timeout and isinstance(self.__thread_timeout, (int, float)):\n            # set values\n            self.__thread_timeout = float(self.__thread_timeout)\n        else:\n            # defaults to 5mins timeout\n            self.__thread_timeout = None\n\n        self.__queue = None\n        # initialize queue for video files only\n        if self.__threaded_queue_mode and isinstance(source, str):\n            # define queue and assign it to global var\n            self.__queue = queue.Queue(maxsize=96)  # max bufferlen 96 to check overflow\n            # log it\n            self.__logging and logger.debug(\n                \"Enabling Threaded Queue Mode for the current video source!\"\n            )\n        else:\n            # otherwise disable it\n            self.__threaded_queue_mode = False\n            # log it\n            self.__logging and logger.warning(\n                \"Threaded Queue Mode is disabled for the current video source!\"\n            )\n\n        self.__thread_timeout and logger.info(\n            \"Setting Video-Thread Timeout to {}s.\".format(self.__thread_timeout)\n        )\n\n        # stream variable initialization\n        self.stream = None\n\n        if backend and isinstance(backend, int):\n            # add backend if specified and initialize the camera stream\n            if check_CV_version() == 3:\n                # Different OpenCV 3.4.x statement\n                self.stream = cv2.VideoCapture(source + backend)\n            else:\n                # Two parameters are available since OpenCV 4+ (master branch)\n                self.stream = cv2.VideoCapture(source, backend)\n            logger.info(\"Setting backend `{}` for this source.\".format(backend))\n        else:\n            # initialize the camera stream\n            self.stream = cv2.VideoCapture(source)\n\n        # initializing colorspace variable\n        self.color_space = None\n\n        # apply attributes to source if specified\n        options = {str(k).strip(): v for k, v in options.items()}\n        for key, value in options.items():\n            property = capPropId(key)\n            not (property is None) and self.stream.set(property, value)\n\n        # handle colorspace value\n        if not (colorspace is None):\n            self.color_space = capPropId(colorspace.strip())\n            self.__logging and not (self.color_space is None) and logger.debug(\n                \"Enabling `{}` colorspace for this video stream!\".format(\n                    colorspace.strip()\n                )\n            )\n\n        # initialize and assign frame-rate variable\n        self.framerate = 0.0\n        _fps = self.stream.get(cv2.CAP_PROP_FPS)\n        if _fps &gt; 1.0:\n            self.framerate = _fps\n\n        # applying time delay to warm-up webcam only if specified\n        time_delay and isinstance(time_delay, (int, float)) and time.sleep(time_delay)\n\n        # frame variable initialization\n        (grabbed, self.frame) = self.stream.read()\n\n        # check if valid stream\n        if grabbed:\n            # render colorspace if defined\n            if not (self.color_space is None):\n                self.frame = cv2.cvtColor(self.frame, self.color_space)\n\n            # initialize and append to queue\n            self.__threaded_queue_mode and self.__queue.put(self.frame)\n        else:\n            raise RuntimeError(\n                \"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\"\n            )\n\n        # thread initialization\n        self.__thread = None\n\n        # initialize termination flag event\n        self.__terminate = Event()\n\n        # initialize stream read flag event\n        self.__stream_read = Event()\n\n    def start(self):\n        \"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon.\n\n        **Returns:** A reference to the CamGear class object.\n        \"\"\"\n\n        self.__thread = Thread(target=self.__update, name=\"CamGear\", args=())\n        self.__thread.daemon = True\n        self.__thread.start()\n        return self\n\n    def __update(self):\n        \"\"\"\n        A **Threaded Frames Extractor**, that keep iterating frames from OpenCV's VideoCapture API to a internal monitored queue,\n        until the thread is terminated, or frames runs out.\n        \"\"\"\n\n        # keep iterating infinitely\n        # until the thread is terminated\n        # or frames runs out\n        # if the thread indicator variable is set, stop the thread\n        while not self.__terminate.is_set():\n            # stream not read yet\n            self.__stream_read.clear()\n\n            # otherwise, read the next frame from the stream\n            (grabbed, frame) = self.stream.read()\n\n            # stream read completed\n            self.__stream_read.set()\n\n            # check for valid frame if received\n            if not grabbed:\n                # no frames received, then safely exit\n                if self.__threaded_queue_mode:\n                    if self.__queue.empty():\n                        break\n                    else:\n                        continue\n                else:\n                    break\n\n            # apply colorspace to frames if valid\n            if not (self.color_space is None):\n                # apply colorspace to frames\n                color_frame = None\n                try:\n                    color_frame = cv2.cvtColor(frame, self.color_space)\n                except Exception as e:\n                    # Catch if any error occurred\n                    color_frame = None\n                    self.color_space = None\n                    self.__logging and logger.exception(str(e))\n                    logger.warning(\"Assigned colorspace value is invalid. Discarding!\")\n                self.frame = color_frame if not (color_frame is None) else frame\n            else:\n                self.frame = frame\n\n            # append to queue\n            self.__threaded_queue_mode and self.__queue.put(self.frame)\n\n        # signal queue we're done\n        self.__threaded_queue_mode and self.__queue.put(None)\n        self.__threaded_queue_mode = False\n\n        # indicate immediate termination\n        self.__terminate.set()\n        self.__stream_read.set()\n\n        # release resources\n        self.stream.release()\n\n    def read(self):\n        \"\"\"\n        Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory,\n        and blocks the thread if the queue is full.\n\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n        while self.__threaded_queue_mode and not self.__terminate.is_set():\n            return self.__queue.get(timeout=self.__thread_timeout)\n        # return current frame\n        # only after stream is read\n        return (\n            self.frame\n            if not self.__terminate.is_set()  # check if already terminated\n            and self.__stream_read.wait(timeout=self.__thread_timeout)  # wait for it\n            else None\n        )\n\n    def stop(self):\n        \"\"\"\n        Safely terminates the thread, and release the multi-threaded resources.\n        \"\"\"\n        self.__logging and logger.debug(\"Terminating processes.\")\n        # terminate Threaded queue mode separately\n        self.__threaded_queue_mode = False\n\n        # indicate that the thread\n        # should be terminated immediately\n        self.__stream_read.set()\n        self.__terminate.set()\n\n        # wait until stream resources are released (producer thread might be still grabbing frame)\n        if self.__thread is not None:\n            if not (self.__queue is None):\n                while not self.__queue.empty():\n                    try:\n                        self.__queue.get_nowait()\n                    except queue.Empty:\n                        continue\n                    self.__queue.task_done()\n            self.__thread.join()\n</code></pre> <p> </p>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.__init__","title":"<code>__init__(self, source=0, stream_mode=False, backend=0, colorspace=None, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the CamGear class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>0</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive Stream Mode for handling streaming URLs.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Source Tweak Parameters.</p> <code>{}</code> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def __init__(\n    self,\n    source=0,\n    stream_mode=False,\n    backend=0,\n    colorspace=None,\n    logging=False,\n    time_delay=0,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the CamGear class.\n\n    Parameters:\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Source Tweak Parameters.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # initialize global\n    self.ytv_metadata = {}\n\n    # check if Stream-Mode is ON (True)\n    if stream_mode:\n        # TODO: check GStreamer backend support\n        # gst_support = check_gstreamer_support(logging=self.__logging)\n        # handle special Stream Mode parameters\n        stream_resolution = get_supported_resolution(\n            options.pop(\"STREAM_RESOLUTION\", \"best\"), logging=self.__logging\n        )\n        # handle Stream-Mode\n        if not (yt_dlp is None):\n            # extract user-defined params\n            yt_stream_params = options.pop(\"STREAM_PARAMS\", {})\n            if isinstance(yt_stream_params, dict):\n                yt_stream_params = {\n                    str(k).strip(): v for k, v in yt_stream_params.items()\n                }\n            else:\n                yt_stream_params = {}\n            try:\n                # Validate source for Yt_dlp backend\n                logger.info(\n                    \"Verifying Streaming URL using yt-dlp backend. Please wait...\"\n                )\n                # initialize YT_backend\n                ytbackend = YT_backend(\n                    source_url=source, logging=self.__logging, **yt_stream_params\n                )\n                if ytbackend:\n                    # save video metadata\n                    self.ytv_metadata = ytbackend.meta_data\n                    # handle live-streams\n                    # Throw warning for livestreams\n                    ytbackend.is_livestream and logger.warning(\n                        \"Livestream URL detected. It is strongly recommended to use the GStreamer backend (`backend=cv2.CAP_GSTREAMER`) with these URLs.\"\n                    )\n                    # check whether stream-resolution was specified and available\n                    if not (stream_resolution in ytbackend.streams.keys()):\n                        logger.warning(\n                            \"Specified stream-resolution `{}` is not available. Reverting to `best`!\".format(\n                                stream_resolution\n                            )\n                        )\n                        # revert to best\n                        stream_resolution = \"best\"\n                    else:\n                        self.__logging and logger.debug(\n                            \"Using `{}` resolution for streaming.\".format(\n                                stream_resolution\n                            )\n                        )\n                    # extract stream URL as source using stream-resolution\n                    source = ytbackend.streams[stream_resolution]\n                    # log progress\n                    self.__logging and logger.debug(\n                        \"YouTube source ID: `{}`, Title: `{}`, Quality: `{}`\".format(\n                            self.ytv_metadata[\"id\"],\n                            self.ytv_metadata[\"title\"],\n                            stream_resolution,\n                        )\n                    )\n            except Exception as e:\n                # raise error if something went wrong\n                raise ValueError(\n                    \"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\"\n                )\n        else:\n            # raise import errors\n            import_dependency_safe(\"yt_dlp\")\n\n    # assigns special parameter to global variable and clear\n    # Threaded Queue Mode\n    self.__threaded_queue_mode = options.pop(\"THREADED_QUEUE_MODE\", True)\n    if not isinstance(self.__threaded_queue_mode, bool):\n        # reset improper values\n        self.__threaded_queue_mode = True\n    # Thread Timeout\n    self.__thread_timeout = options.pop(\"THREAD_TIMEOUT\", None)\n    if self.__thread_timeout and isinstance(self.__thread_timeout, (int, float)):\n        # set values\n        self.__thread_timeout = float(self.__thread_timeout)\n    else:\n        # defaults to 5mins timeout\n        self.__thread_timeout = None\n\n    self.__queue = None\n    # initialize queue for video files only\n    if self.__threaded_queue_mode and isinstance(source, str):\n        # define queue and assign it to global var\n        self.__queue = queue.Queue(maxsize=96)  # max bufferlen 96 to check overflow\n        # log it\n        self.__logging and logger.debug(\n            \"Enabling Threaded Queue Mode for the current video source!\"\n        )\n    else:\n        # otherwise disable it\n        self.__threaded_queue_mode = False\n        # log it\n        self.__logging and logger.warning(\n            \"Threaded Queue Mode is disabled for the current video source!\"\n        )\n\n    self.__thread_timeout and logger.info(\n        \"Setting Video-Thread Timeout to {}s.\".format(self.__thread_timeout)\n    )\n\n    # stream variable initialization\n    self.stream = None\n\n    if backend and isinstance(backend, int):\n        # add backend if specified and initialize the camera stream\n        if check_CV_version() == 3:\n            # Different OpenCV 3.4.x statement\n            self.stream = cv2.VideoCapture(source + backend)\n        else:\n            # Two parameters are available since OpenCV 4+ (master branch)\n            self.stream = cv2.VideoCapture(source, backend)\n        logger.info(\"Setting backend `{}` for this source.\".format(backend))\n    else:\n        # initialize the camera stream\n        self.stream = cv2.VideoCapture(source)\n\n    # initializing colorspace variable\n    self.color_space = None\n\n    # apply attributes to source if specified\n    options = {str(k).strip(): v for k, v in options.items()}\n    for key, value in options.items():\n        property = capPropId(key)\n        not (property is None) and self.stream.set(property, value)\n\n    # handle colorspace value\n    if not (colorspace is None):\n        self.color_space = capPropId(colorspace.strip())\n        self.__logging and not (self.color_space is None) and logger.debug(\n            \"Enabling `{}` colorspace for this video stream!\".format(\n                colorspace.strip()\n            )\n        )\n\n    # initialize and assign frame-rate variable\n    self.framerate = 0.0\n    _fps = self.stream.get(cv2.CAP_PROP_FPS)\n    if _fps &gt; 1.0:\n        self.framerate = _fps\n\n    # applying time delay to warm-up webcam only if specified\n    time_delay and isinstance(time_delay, (int, float)) and time.sleep(time_delay)\n\n    # frame variable initialization\n    (grabbed, self.frame) = self.stream.read()\n\n    # check if valid stream\n    if grabbed:\n        # render colorspace if defined\n        if not (self.color_space is None):\n            self.frame = cv2.cvtColor(self.frame, self.color_space)\n\n        # initialize and append to queue\n        self.__threaded_queue_mode and self.__queue.put(self.frame)\n    else:\n        raise RuntimeError(\n            \"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\"\n        )\n\n    # thread initialization\n    self.__thread = None\n\n    # initialize termination flag event\n    self.__terminate = Event()\n\n    # initialize stream read flag event\n    self.__stream_read = Event()\n</code></pre>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def read(self):\n    \"\"\"\n    Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory,\n    and blocks the thread if the queue is full.\n\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n    while self.__threaded_queue_mode and not self.__terminate.is_set():\n        return self.__queue.get(timeout=self.__thread_timeout)\n    # return current frame\n    # only after stream is read\n    return (\n        self.frame\n        if not self.__terminate.is_set()  # check if already terminated\n        and self.__stream_read.wait(timeout=self.__thread_timeout)  # wait for it\n        else None\n    )\n</code></pre>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon.</p> <p>Returns: A reference to the CamGear class object.</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def start(self):\n    \"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon.\n\n    **Returns:** A reference to the CamGear class object.\n    \"\"\"\n\n    self.__thread = Thread(target=self.__update, name=\"CamGear\", args=())\n    self.__thread.daemon = True\n    self.__thread.start()\n    return self\n</code></pre>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the multi-threaded resources.</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def stop(self):\n    \"\"\"\n    Safely terminates the thread, and release the multi-threaded resources.\n    \"\"\"\n    self.__logging and logger.debug(\"Terminating processes.\")\n    # terminate Threaded queue mode separately\n    self.__threaded_queue_mode = False\n\n    # indicate that the thread\n    # should be terminated immediately\n    self.__stream_read.set()\n    self.__terminate.set()\n\n    # wait until stream resources are released (producer thread might be still grabbing frame)\n    if self.__thread is not None:\n        if not (self.__queue is None):\n            while not self.__queue.empty():\n                try:\n                    self.__queue.get_nowait()\n                except queue.Empty:\n                    continue\n                self.__queue.task_done()\n        self.__thread.join()\n</code></pre>"},{"location":"bonus/reference/helper/","title":"Helper Methods","text":""},{"location":"bonus/reference/helper/#vidgear.gears.helper.logger_handler--logger_handler","title":"logger_handler","text":"<p>Returns the logger handler</p> <p>Returns: A logger handler</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def logger_handler():\n    \"\"\"\n    ## logger_handler\n\n    Returns the logger handler\n\n    **Returns:** A logger handler\n    \"\"\"\n    # logging formatter\n    formatter = ColoredFormatter(\n        \"{green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message}\",\n        datefmt=\"%H:%M:%S\",\n        reset=True,\n        log_colors={\n            \"INFO\": \"bold_cyan\",\n            \"DEBUG\": \"bold_yellow\",\n            \"WARNING\": \"bold_red,fg_thin_yellow\",\n            \"ERROR\": \"bold_red\",\n            \"CRITICAL\": \"bold_red,bg_white\",\n        },\n        style=\"{\",\n    )\n    # check if VIDGEAR_LOGFILE defined\n    file_mode = os.environ.get(\"VIDGEAR_LOGFILE\", False)\n    # define handler\n    handler = log.StreamHandler()\n    if file_mode and isinstance(file_mode, str):\n        file_path = os.path.abspath(file_mode)\n        if (os.name == \"nt\" or os.access in os.supports_effective_ids) and os.access(\n            os.path.dirname(file_path), os.W_OK\n        ):\n            file_path = (\n                os.path.join(file_path, \"vidgear.log\")\n                if os.path.isdir(file_path)\n                else file_path\n            )\n            handler = log.FileHandler(file_path, mode=\"a\")\n            formatter = log.Formatter(\n                \"{asctime} :: {name} :: {levelname} :: {message}\",\n                datefmt=\"%H:%M:%S\",\n                style=\"{\",\n            )\n\n    handler.setFormatter(formatter)\n    return handler\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_CV_version--check_cv_version","title":"check_CV_version","text":"<p>Returns: OpenCV's version first bit</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_CV_version():\n    \"\"\"\n    ## check_CV_version\n\n    **Returns:** OpenCV's version first bit\n    \"\"\"\n    if parse_version(cv2.__version__) &gt;= parse_version(\"4\"):\n        return 4\n    else:\n        return 3\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_gstreamer_support--check_gstreamer_support","title":"check_gstreamer_support","text":"<p>Checks whether OpenCV is compiled with Gstreamer(<code>&gt;=1.0.0</code>) support.</p> <p>Parameters:</p> Name Type Description Default <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A Boolean value</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_gstreamer_support(logging=False):\n    \"\"\"\n    ## check_gstreamer_support\n\n    Checks whether OpenCV is compiled with Gstreamer(`&gt;=1.0.0`) support.\n\n    Parameters:\n        logging (bool): enables logging for its operations\n\n    **Returns:** A Boolean value\n    \"\"\"\n    raw = cv2.getBuildInformation()\n    gst = [\n        x.strip()\n        for x in raw.split(\"\\n\")\n        if x and re.search(r\"GStreamer[,-:]+\\s*(?:YES|NO)\", x)\n    ]\n    if gst and \"YES\" in gst[0]:\n        version = re.search(r\"(\\d+\\.)?(\\d+\\.)?(\\*|\\d+)\", gst[0])\n        logging and logger.debug(\"Found GStreamer version:{}\".format(version[0]))\n        return version[0] &gt;= \"1.0.0\"\n    else:\n        logger.warning(\"GStreamer not found!\")\n        return False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_resolution--get_supported_resolution","title":"get_supported_resolution","text":"<p>Parameters:</p> Name Type Description Default <code>value</code> <code>string</code> <p>value to be validated</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: Valid stream resolution</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_supported_resolution(value, logging=False):\n    \"\"\"\n    ## get_supported_resolution\n\n    Parameters:\n        value (string): value to be validated\n        logging (bool): enables logging for its operations\n\n    **Returns:** Valid stream resolution\n    \"\"\"\n    # default to best\n    stream_resolution = \"best\"\n    supported_stream_qualities = [\n        \"144p\",\n        \"240p\",\n        \"360p\",\n        \"480p\",\n        \"720p\",\n        \"1080p\",\n        \"1440p\",\n        \"2160p\",\n        \"4320p\",\n        \"worst\",\n        \"best\",\n    ]\n    if isinstance(value, str):\n        if value.strip().lower() in supported_stream_qualities:\n            stream_resolution = value.strip().lower()\n            logging and logger.debug(\n                \"Selecting `{}` resolution for streams.\".format(stream_resolution)\n            )\n        else:\n            logger.warning(\n                \"Specified stream-resolution `{}` is not supported. Reverting to `best`!\".format(\n                    value\n                )\n            )\n    else:\n        logger.warning(\n            \"Specified stream-resolution `{}` is Invalid. Reverting to `best`!\".format(\n                value\n            )\n        )\n    return stream_resolution\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dimensions_to_resolutions--dimensions_to_resolutions","title":"dimensions_to_resolutions","text":"<p>Parameters:</p> Name Type Description Default <code>value</code> <code>list</code> <p>list of dimensions (e.g. <code>640x360</code>)</p> required <p>Returns: list of resolutions (e.g. <code>360p</code>)</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def dimensions_to_resolutions(value):\n    \"\"\"\n    ## dimensions_to_resolutions\n\n    Parameters:\n        value (list): list of dimensions (e.g. `640x360`)\n\n    **Returns:** list of resolutions (e.g. `360p`)\n    \"\"\"\n    supported_resolutions = {\n        \"256x144\": \"144p\",\n        \"426x240\": \"240p\",\n        \"640x360\": \"360p\",\n        \"854x480\": \"480p\",\n        \"1280x720\": \"720p\",\n        \"1920x1080\": \"1080p\",\n        \"2560x1440\": \"1440p\",\n        \"3840x2160\": \"2160p\",\n        \"7680x4320\": \"4320p\",\n    }\n    return (\n        list(map(supported_resolutions.get, value, value))\n        if isinstance(value, list)\n        else []\n    )\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.mkdir_safe--mkdir_safe","title":"mkdir_safe","text":"<p>Safely creates directory at given path.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>string</code> <p>path to the directory</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def mkdir_safe(dir_path, logging=False):\n    \"\"\"\n    ## mkdir_safe\n\n    Safely creates directory at given path.\n\n    Parameters:\n        dir_path (string): path to the directory\n        logging (bool): enables logging for its operations\n\n    \"\"\"\n    try:\n        os.makedirs(dir_path)\n        logging and logger.debug(\"Created directory at `{}`\".format(dir_path))\n    except (OSError, IOError) as e:\n        if e.errno != errno.EACCES and e.errno != errno.EEXIST:\n            raise\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_ext_safe--delete_ext_safe","title":"delete_ext_safe","text":"<p>Safely deletes files with given extensions at given path.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>string</code> <p>path to the directory</p> required <code>extensions</code> <code>list</code> <p>list of extensions to be deleted</p> <code>[]</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def delete_ext_safe(dir_path, extensions=[], logging=False):\n    \"\"\"\n    ## delete_ext_safe\n\n    Safely deletes files with given extensions at given path.\n\n    Parameters:\n        dir_path (string): path to the directory\n        extensions (list): list of extensions to be deleted\n        logging (bool): enables logging for its operations\n\n    \"\"\"\n    if not extensions or not os.path.exists(dir_path):\n        logger.warning(\"Invalid input provided for deleting!\")\n        return\n\n    logger.critical(\"Clearing Assets at `{}`!\".format(dir_path))\n\n    for ext in extensions:\n        if len(ext) == 2:\n            files_ext = [\n                os.path.join(dir_path, f)\n                for f in os.listdir(dir_path)\n                if f.startswith(ext[0]) and f.endswith(ext[1])\n            ]\n        else:\n            files_ext = [\n                os.path.join(dir_path, f)\n                for f in os.listdir(dir_path)\n                if f.endswith(ext)\n            ]\n        for file in files_ext:\n            delete_file_safe(file)\n            logging and logger.debug(\"Deleted file: `{}`\".format(file))\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.capPropId--cappropid","title":"capPropId","text":"<p>Retrieves the OpenCV property's Integer(Actual) value from string.</p> <p>Parameters:</p> Name Type Description Default <code>property</code> <code>string</code> <p>inputs OpenCV property as string.</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>True</code> <p>Returns: Resultant integer value.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def capPropId(property, logging=True):\n    \"\"\"\n    ## capPropId\n\n    Retrieves the OpenCV property's Integer(Actual) value from string.\n\n    Parameters:\n        property (string): inputs OpenCV property as string.\n        logging (bool): enables logging for its operations\n\n    **Returns:** Resultant integer value.\n    \"\"\"\n    integer_value = 0\n    try:\n        integer_value = getattr(cv2, property)\n    except Exception as e:\n        logging and logger.exception(str(e))\n        logger.critical(\"`{}` is not a valid OpenCV property!\".format(property))\n        return None\n    return integer_value\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.reducer--reducer","title":"reducer","text":"<p>Reduces frame size by given percentage</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>percentage</code> <code>int/float</code> <p>inputs size-reduction percentage.</p> <code>0</code> <code>interpolation</code> <code>int</code> <p>Change resize interpolation.</p> <code>4</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def reducer(frame=None, percentage=0, interpolation=cv2.INTER_LANCZOS4):\n    \"\"\"\n    ## reducer\n\n    Reduces frame size by given percentage\n\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        percentage (int/float): inputs size-reduction percentage.\n        interpolation (int): Change resize interpolation.\n\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n    # check if frame is valid\n    if frame is None:\n        raise ValueError(\"[Helper:ERROR] :: Input frame cannot be NoneType!\")\n\n    # check if valid reduction percentage is given\n    if not (percentage &gt; 0 and percentage &lt; 90):\n        raise ValueError(\n            \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\"\n        )\n\n    if not (isinstance(interpolation, int)):\n        raise ValueError(\n            \"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\"\n        )\n\n    # grab the frame size\n    (height, width) = frame.shape[:2]\n\n    # calculate the ratio of the width from percentage\n    reduction = ((100 - percentage) / 100) * width\n    ratio = reduction / float(width)\n    # construct the dimensions\n    dimensions = (int(reduction), int(height * ratio))\n\n    # return the resized frame\n    return cv2.resize(frame, dimensions, interpolation=interpolation)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.create_blank_frame--create_blank_frame","title":"create_blank_frame","text":"<p>Create blank frames of given frame size with text</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>text</code> <code>str</code> <p>Text to be written on frame.</p> <code>''</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def create_blank_frame(frame=None, text=\"\", logging=False):\n    \"\"\"\n    ## create_blank_frame\n\n    Create blank frames of given frame size with text\n\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        text (str): Text to be written on frame.\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n    # check if frame is valid\n    if frame is None or not (isinstance(frame, np.ndarray)):\n        raise ValueError(\"[Helper:ERROR] :: Input frame is invalid!\")\n    # grab the frame size\n    (height, width) = frame.shape[:2]\n    # create blank frame\n    blank_frame = np.zeros(frame.shape, frame.dtype)\n    # setup text\n    if text and isinstance(text, str):\n        logging and logger.debug(\"Adding text: {}\".format(text))\n        # setup font\n        font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n        # get boundary of this text\n        fontScale = min(height, width) / (25 / 0.25)\n        textsize = cv2.getTextSize(text, font, fontScale, 5)[0]\n        # get coords based on boundary\n        textX = (width - textsize[0]) // 2\n        textY = (height + textsize[1]) // 2\n        # put text\n        cv2.putText(\n            blank_frame, text, (textX, textY), font, fontScale, (125, 125, 125), 6\n        )\n\n    # return frame\n    return blank_frame\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dict2Args--dict2args","title":"dict2Args","text":"<p>Converts dictionary attributes to list(args)</p> <p>Parameters:</p> Name Type Description Default <code>param_dict</code> <code>dict</code> <p>Parameters dictionary</p> required <p>Returns: Arguments list</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def dict2Args(param_dict):\n    \"\"\"\n    ## dict2Args\n\n    Converts dictionary attributes to list(args)\n\n    Parameters:\n        param_dict (dict): Parameters dictionary\n\n    **Returns:** Arguments list\n    \"\"\"\n    args = []\n    for key in param_dict.keys():\n        if key in [\"-clones\"] or key.startswith(\"-core\"):\n            if isinstance(param_dict[key], list):\n                args.extend(param_dict[key])\n            else:\n                logger.warning(\n                    \"{} with invalid datatype:`{}`, Skipped!\".format(\n                        \"Core parameter\" if key.startswith(\"-core\") else \"Clone\",\n                        param_dict[key],\n                    )\n                )\n        else:\n            args.append(key)\n            args.append(str(param_dict[key]))\n    return args\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","title":"get_valid_ffmpeg_path","text":"<p>Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.</p> <p>Parameters:</p> Name Type Description Default <code>custom_ffmpeg</code> <code>string</code> <p>path to custom FFmpeg executables</p> <code>''</code> <code>is_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>ffmpeg_download_path</code> <code>string</code> <p>FFmpeg static binaries download location (Windows only)</p> <code>''</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_valid_ffmpeg_path(\n    custom_ffmpeg=\"\", is_windows=False, ffmpeg_download_path=\"\", logging=False\n):\n    \"\"\"\n    ## get_valid_ffmpeg_path\n\n    Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.\n\n    Parameters:\n        custom_ffmpeg (string): path to custom FFmpeg executables\n        is_windows (boolean): is running on Windows OS?\n        ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_\n        logging (bool): enables logging for its operations\n\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\n    final_path = \"\"\n    if is_windows:\n        # checks if current os is windows\n        if custom_ffmpeg:\n            # if custom FFmpeg path is given assign to local variable\n            final_path += custom_ffmpeg\n        else:\n            # otherwise auto-download them\n            try:\n                if not (ffmpeg_download_path):\n                    # otherwise save to Temp Directory\n                    import tempfile\n\n                    ffmpeg_download_path = tempfile.gettempdir()\n\n                logging and logger.debug(\n                    \"FFmpeg Windows Download Path: {}\".format(ffmpeg_download_path)\n                )\n\n                # download Binaries\n                os_bit = (\n                    (\"win64\" if platform.machine().endswith(\"64\") else \"win32\")\n                    if is_windows\n                    else \"\"\n                )\n                _path = download_ffmpeg_binaries(\n                    path=ffmpeg_download_path, os_windows=is_windows, os_bit=os_bit\n                )\n                # assign to local variable\n                final_path += _path\n\n            except Exception as e:\n                # log if any error occurred\n                logger.exception(str(e))\n                logger.error(\n                    \"Error in downloading FFmpeg binaries, Check your network and Try again!\"\n                )\n                return False\n\n        if os.path.isfile(final_path):\n            # check if valid FFmpeg file exist\n            pass\n        elif os.path.isfile(os.path.join(final_path, \"ffmpeg.exe\")):\n            # check if FFmpeg directory exists, if does, then check for valid file\n            final_path = os.path.join(final_path, \"ffmpeg.exe\")\n        else:\n            # else return False\n            logging and logger.debug(\n                \"No valid FFmpeg executables found at Custom FFmpeg path!\"\n            )\n            return False\n    else:\n        # otherwise perform test for Unix\n        if custom_ffmpeg:\n            # if custom FFmpeg path is given assign to local variable\n            if os.path.isfile(custom_ffmpeg):\n                # check if valid FFmpeg file exist\n                final_path += custom_ffmpeg\n            elif os.path.isfile(os.path.join(custom_ffmpeg, \"ffmpeg\")):\n                # check if FFmpeg directory exists, if does, then check for valid file\n                final_path = os.path.join(custom_ffmpeg, \"ffmpeg\")\n            else:\n                # else return False\n                logging and logger.debug(\n                    \"No valid FFmpeg executables found at Custom FFmpeg path!\"\n                )\n                return False\n        else:\n            # otherwise assign ffmpeg binaries from system\n            final_path += \"ffmpeg\"\n\n    logging and logger.debug(\"Final FFmpeg Path: {}\".format(final_path))\n\n    # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed\n    return final_path if validate_ffmpeg(final_path, logging=logging) else False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.download_ffmpeg_binaries--download_ffmpeg_binaries","title":"download_ffmpeg_binaries","text":"<p>Generates FFmpeg Static Binaries for windows(if not available)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for downloading custom FFmpeg executables</p> required <code>os_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>os_bit</code> <code>string</code> <p>32-bit or 64-bit OS?</p> <code>''</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def download_ffmpeg_binaries(path, os_windows=False, os_bit=\"\"):\n    \"\"\"\n    ## download_ffmpeg_binaries\n\n    Generates FFmpeg Static Binaries for windows(if not available)\n\n    Parameters:\n        path (string): path for downloading custom FFmpeg executables\n        os_windows (boolean): is running on Windows OS?\n        os_bit (string): 32-bit or 64-bit OS?\n\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\n    final_path = \"\"\n    if os_windows and os_bit:\n        # initialize with available FFmpeg Static Binaries GitHub Server\n        file_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static-{}-gpl.zip\".format(\n            os_bit\n        )\n\n        file_name = os.path.join(\n            os.path.abspath(path), \"ffmpeg-static-{}-gpl.zip\".format(os_bit)\n        )\n        file_path = os.path.join(\n            os.path.abspath(path),\n            \"ffmpeg-static-{}-gpl/bin/ffmpeg.exe\".format(os_bit),\n        )\n        base_path, _ = os.path.split(file_name)  # extract file base path\n        # check if file already exists\n        if os.path.isfile(file_path):\n            final_path += file_path  # skip download if does\n        else:\n            # import libs\n            import zipfile\n\n            # check if given path has write access\n            assert os.access(path, os.W_OK), (\n                \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \"\n                + path\n            )\n            # remove leftovers if exists\n            os.path.isfile(file_name) and delete_file_safe(file_name)\n            # download and write file to the given path\n            with open(file_name, \"wb\") as f:\n                logger.debug(\n                    \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\"\n                )\n                # create session\n                with requests.Session() as http:\n                    # setup retry strategy\n                    retries = Retry(\n                        total=3,\n                        backoff_factor=1,\n                        status_forcelist=[429, 500, 502, 503, 504],\n                    )\n                    # Mount it for https usage\n                    adapter = TimeoutHTTPAdapter(timeout=2.0, max_retries=retries)\n                    http.mount(\"https://\", adapter)\n                    response = http.get(file_url, stream=True)\n                    response.raise_for_status()\n                    total_length = (\n                        response.headers.get(\"content-length\")\n                        if \"content-length\" in response.headers\n                        else len(response.content)\n                    )\n                    assert not (\n                        total_length is None\n                    ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\"\n                    bar = tqdm(total=int(total_length), unit=\"B\", unit_scale=True)\n                    for data in response.iter_content(chunk_size=4096):\n                        f.write(data)\n                        len(data) &gt; 0 and bar.update(len(data))\n                    bar.close()\n            logger.debug(\"Extracting executables.\")\n            with zipfile.ZipFile(file_name, \"r\") as zip_ref:\n                zip_fname, _ = os.path.split(zip_ref.infolist()[0].filename)\n                zip_ref.extractall(base_path)\n            # perform cleaning\n            delete_file_safe(file_name)\n            logger.debug(\"FFmpeg binaries for Windows configured successfully!\")\n            final_path += file_path\n    # return final path\n    return final_path\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_ffmpeg--validate_ffmpeg","title":"validate_ffmpeg","text":"<p>Validate FFmeg Binaries. returns <code>True</code> if tests are passed.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_ffmpeg(path, logging=False):\n    \"\"\"\n    ## validate_ffmpeg\n\n    Validate FFmeg Binaries. returns `True` if tests are passed.\n\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        logging (bool): enables logging for its operations\n\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n    try:\n        # get the FFmpeg version\n        version = check_output([path, \"-version\"])\n        firstline = version.split(b\"\\n\")[0]\n        version = firstline.split(b\" \")[2].strip()\n        # log if test are passed\n        logging and logger.info(\"FFmpeg validity Test Passed!\")\n        logging and logger.debug(\n            \"Found valid FFmpeg Version: `{}` installed on this system\".format(version)\n        )\n    except Exception as e:\n        # log if test are failed\n        logging and logger.exception(str(e))\n        logger.error(\"FFmpeg validity Test Failed!\")\n        return False\n    return True\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_output--check_output","title":"check_output","text":"<p>Returns stdin output from subprocess module</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_output(*args, **kwargs):\n    \"\"\"\n    ## check_output\n\n    Returns stdin output from subprocess module\n    \"\"\"\n    # import libs\n    import subprocess as sp\n\n    # workaround for python bug: https://bugs.python.org/issue37380\n    if platform.system() == \"Windows\":\n        # see comment https://bugs.python.org/msg370334\n        sp._cleanup = lambda: None\n\n    # handle additional params\n    retrieve_stderr = kwargs.pop(\"force_retrieve_stderr\", False)\n\n    # execute command in subprocess\n    process = sp.Popen(\n        stdout=sp.PIPE,\n        stderr=sp.DEVNULL if not (retrieve_stderr) else sp.PIPE,\n        *args,\n        **kwargs,\n    )\n    output, stderr = process.communicate()\n    retcode = process.poll()\n\n    # handle return code\n    if retcode and not (retrieve_stderr):\n        cmd = kwargs.get(\"args\")\n        if cmd is None:\n            cmd = args[0]\n        error = sp.CalledProcessError(retcode, cmd)\n        error.output = output\n        raise error\n\n    return output if not (retrieve_stderr) else stderr\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.generate_auth_certificates--generate_auth_certificates","title":"generate_auth_certificates","text":"<p>Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for generating CURVE key-pairs</p> required <code>overwrite</code> <code>boolean</code> <p>overwrite existing key-pairs or not?</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid CURVE key-pairs path as string.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def generate_auth_certificates(path, overwrite=False, logging=False):\n    \"\"\"\n    ## generate_auth_certificates\n\n    Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode.\n\n    Parameters:\n        path (string): path for generating CURVE key-pairs\n        overwrite (boolean): overwrite existing key-pairs or not?\n        logging (bool): enables logging for its operations\n\n    **Returns:** A valid CURVE key-pairs path as string.\n    \"\"\"\n    # import necessary lib\n    import zmq.auth\n\n    # check if path corresponds to vidgear only\n    if os.path.basename(path) != \".vidgear\":\n        path = os.path.join(path, \".vidgear\")\n\n    # generate keys dir\n    keys_dir = os.path.join(path, \"keys\")\n    mkdir_safe(keys_dir, logging=logging)\n\n    # generate separate public and private key dirs\n    public_keys_dir = os.path.join(keys_dir, \"public_keys\")\n    secret_keys_dir = os.path.join(keys_dir, \"private_keys\")\n\n    # check if overwriting is allowed\n    if overwrite:\n        # delete previous certificates\n        for dirs in [public_keys_dir, secret_keys_dir]:\n            if os.path.exists(dirs):\n                shutil.rmtree(dirs)\n            mkdir_safe(dirs, logging=logging)\n\n        # generate new keys\n        server_public_file, server_secret_file = zmq.auth.create_certificates(\n            keys_dir, \"server\"\n        )\n        client_public_file, client_secret_file = zmq.auth.create_certificates(\n            keys_dir, \"client\"\n        )\n\n        # move keys to their appropriate directory respectively\n        for key_file in os.listdir(keys_dir):\n            if key_file.endswith(\".key\"):\n                shutil.move(os.path.join(keys_dir, key_file), public_keys_dir)\n            elif key_file.endswith(\".key_secret\"):\n                shutil.move(os.path.join(keys_dir, key_file), secret_keys_dir)\n            else:\n                # clean redundant keys if present\n                redundant_key = os.path.join(keys_dir, key_file)\n                if os.path.isfile(redundant_key):\n                    delete_file_safe(redundant_key)\n    else:\n        # otherwise validate available keys\n        status_public_keys = validate_auth_keys(public_keys_dir, \".key\")\n        status_private_keys = validate_auth_keys(secret_keys_dir, \".key_secret\")\n\n        # check if all valid keys are found\n        if status_private_keys and status_public_keys:\n            return (keys_dir, secret_keys_dir, public_keys_dir)\n\n        # check if valid public keys are found\n        if not (status_public_keys):\n            mkdir_safe(public_keys_dir, logging=logging)\n\n        # check if valid private keys are found\n        if not (status_private_keys):\n            mkdir_safe(secret_keys_dir, logging=logging)\n\n        # generate new keys\n        server_public_file, server_secret_file = zmq.auth.create_certificates(\n            keys_dir, \"server\"\n        )\n        client_public_file, client_secret_file = zmq.auth.create_certificates(\n            keys_dir, \"client\"\n        )\n\n        # move keys to their appropriate directory respectively\n        for key_file in os.listdir(keys_dir):\n            if key_file.endswith(\".key\") and not (status_public_keys):\n                shutil.move(\n                    os.path.join(keys_dir, key_file), os.path.join(public_keys_dir, \".\")\n                )\n            elif key_file.endswith(\".key_secret\") and not (status_private_keys):\n                shutil.move(\n                    os.path.join(keys_dir, key_file), os.path.join(secret_keys_dir, \".\")\n                )\n            else:\n                # clean redundant keys if present\n                redundant_key = os.path.join(keys_dir, key_file)\n                if os.path.isfile(redundant_key):\n                    delete_file_safe(redundant_key)\n\n    # validate newly generated keys\n    status_public_keys = validate_auth_keys(public_keys_dir, \".key\")\n    status_private_keys = validate_auth_keys(secret_keys_dir, \".key_secret\")\n\n    # raise error is validation test fails\n    if not (status_private_keys) or not (status_public_keys):\n        raise RuntimeError(\n            \"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at `{}`!\".format(\n                keys_dir\n            )\n        )\n\n    # finally return valid key paths\n    return (keys_dir, secret_keys_dir, public_keys_dir)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_audio--validate_audio","title":"validate_audio","text":"<p>Validates audio by retrieving audio-bitrate from file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>source</code> <code>string/list</code> <p>source to be validated.</p> <code>None</code> <p>Returns: A string value, confirming whether audio is present, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_audio(path, source=None):\n    \"\"\"\n    ## validate_audio\n\n    Validates audio by retrieving audio-bitrate from file.\n\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        source (string/list): source to be validated.\n\n    **Returns:** A string value, confirming whether audio is present, or not?.\n    \"\"\"\n    if source is None or not (source):\n        logger.warning(\"Audio input source is empty!\")\n        return \"\"\n\n    # create ffmpeg command\n    cmd = [path, \"-hide_banner\"] + (\n        source if isinstance(source, list) else [\"-i\", source]\n    )\n    # extract metadata\n    metadata = check_output(cmd, force_retrieve_stderr=True)\n    # extract bitrate\n    audio_bitrate_meta = [\n        line.strip()\n        for line in metadata.decode(\"utf-8\").split(\"\\n\")\n        if \"Audio:\" in line\n    ]\n    audio_bitrate = (\n        re.findall(r\"([0-9]+)\\s(kb|mb|gb)\\/s\", audio_bitrate_meta[0])[-1]\n        if audio_bitrate_meta\n        else \"\"\n    )\n    # extract samplerate\n    audio_samplerate_metadata = [\n        line.strip()\n        for line in metadata.decode(\"utf-8\").split(\"\\n\")\n        if all(x in line for x in [\"Audio:\", \"Hz\"])\n    ]\n    audio_samplerate = (\n        re.findall(r\"[0-9]+\\sHz\", audio_samplerate_metadata[0])[0]\n        if audio_samplerate_metadata\n        else \"\"\n    )\n    # format into actual readable bitrate value\n    if audio_bitrate:\n        # return bitrate directly\n        return \"{}{}\".format(int(audio_bitrate[0].strip()), audio_bitrate[1].strip()[0])\n    elif audio_samplerate:\n        # convert samplerate to bitrate first\n        sample_rate_value = int(audio_samplerate.split(\" \")[0])\n        channels_value = 1 if \"mono\" in audio_samplerate_metadata[0] else 2\n        bit_depth_value = re.findall(\n            r\"(u|s|f)([0-9]+)(le|be)\", audio_samplerate_metadata[0]\n        )[0][1]\n        return (\n            (\n                str(\n                    get_audio_bitrate(\n                        sample_rate_value, channels_value, int(bit_depth_value)\n                    )\n                )\n                + \"k\"\n            )\n            if bit_depth_value\n            else \"\"\n        )\n    else:\n        return \"\"\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.extract_time--extract_time","title":"extract_time","text":"<p>Extract time from give string value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>string</code> <p>string value.</p> required <p>Returns: Time (in seconds) as integer.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def extract_time(value):\n    \"\"\"\n    ## extract_time\n\n    Extract time from give string value.\n\n    Parameters:\n        value (string): string value.\n\n    **Returns:** Time _(in seconds)_ as integer.\n    \"\"\"\n    if not (value):\n        logger.warning(\"Value is empty!\")\n        return 0\n    else:\n        stripped_data = value.strip()\n        t_duration = re.findall(r\"\\d{2}:\\d{2}:\\d{2}(?:\\.\\d{2})?\", stripped_data)\n        return (\n            sum(\n                float(x) * 60**i\n                for i, x in enumerate(reversed(t_duration[0].split(\":\")))\n            )\n            if t_duration\n            else 0\n        )\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_video--validate_video","title":"validate_video","text":"<p>Validates video by retrieving resolution/size and framerate from file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>video_path</code> <code>string</code> <p>absolute path to Video.</p> <code>None</code> <p>Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float).</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_video(path, video_path=None, logging=False):\n    \"\"\"\n    ## validate_video\n\n    Validates video by retrieving resolution/size and framerate from file.\n\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        video_path (string): absolute path to Video.\n\n    **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_.\n    \"\"\"\n    if video_path is None or not (video_path):\n        logger.warning(\"Video path is empty!\")\n        return None\n\n    # extract metadata\n    metadata = check_output(\n        [path, \"-hide_banner\", \"-i\", video_path], force_retrieve_stderr=True\n    )\n    # clean and search\n    stripped_data = [x.decode(\"utf-8\").strip() for x in metadata.split(b\"\\n\")]\n    logging and logger.debug(stripped_data)\n    result = {}\n    for data in stripped_data:\n        output_a = re.findall(r\"([1-9]\\d+)x([1-9]\\d+)\", data)\n        output_b = re.findall(r\"\\d+(?:\\.\\d+)?\\sfps\", data)\n        if len(result) == 2:\n            break\n        if output_b and not \"framerate\" in result:\n            result[\"framerate\"] = re.findall(r\"[\\d\\.\\d]+\", output_b[0])[0]\n        if output_a and not \"resolution\" in result:\n            result[\"resolution\"] = output_a[-1]\n\n    # return values\n    return result if (len(result) == 2) else None\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.is_valid_url--is_valid_url","title":"is_valid_url","text":"<p>Checks URL validity by testing its scheme against FFmpeg's supported protocols</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>url</code> <code>string</code> <p>URL to be validated</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def is_valid_url(path, url=None, logging=False):\n    \"\"\"\n    ## is_valid_url\n\n    Checks URL validity by testing its scheme against\n    FFmpeg's supported protocols\n\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        url (string): URL to be validated\n        logging (bool): enables logging for its operations\n\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n    if url is None or not (url):\n        logger.warning(\"URL is empty!\")\n        return False\n    # extract URL scheme\n    extracted_scheme_url = url.split(\"://\", 1)[0]\n    # extract all FFmpeg supported protocols\n    protocols = check_output([path, \"-hide_banner\", \"-protocols\"])\n    splitted = [x.decode(\"utf-8\").strip() for x in protocols.split(b\"\\n\")]\n    supported_protocols = splitted[splitted.index(\"Output:\") + 1 : len(splitted) - 1]\n    # rtsp is a demuxer somehow\n    supported_protocols += [\"rtsp\"] if \"rtsp\" in get_supported_demuxers(path) else []\n    # Test and return result whether scheme is supported\n    if extracted_scheme_url and extracted_scheme_url in supported_protocols:\n        logging and logger.debug(\n            \"URL scheme `{}` is supported by FFmpeg.\".format(extracted_scheme_url)\n        )\n        return True\n    else:\n        logger.warning(\n            \"URL scheme `{}` isn't supported by FFmpeg!\".format(extracted_scheme_url)\n        )\n        return False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.import_dependency_safe--import_dependency_safe","title":"import_dependency_safe","text":"<p>Imports specified dependency safely. By default(<code>error = raise</code>), if a dependency is missing, an ImportError with a meaningful message will be raised. Otherwise if <code>error = log</code> a warning will be logged and on <code>error = silent</code> everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>string</code> <p>name of dependency to be imported.</p> required <code>error</code> <code>string</code> <p>raise or Log or silence ImportError. Possible values are <code>\"raise\"</code>, <code>\"log\"</code> and <code>silent</code>. Default is <code>\"raise\"</code>.</p> <code>'raise'</code> <code>pkg_name</code> <code>string</code> <p>(Optional) package name of dependency(if different <code>pip</code> name). Otherwise <code>name</code> will be used.</p> <code>None</code> <code>min_version</code> <code>string</code> <p>(Optional) required minimum version of the dependency to be imported.</p> <code>None</code> <code>custom_message</code> <code>string</code> <p>(Optional) custom Import error message to be raised or logged.</p> <code>None</code> <p>Returns: The imported module, when found and the version is correct(if specified). Otherwise <code>None</code>.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def import_dependency_safe(\n    name,\n    error=\"raise\",\n    pkg_name=None,\n    min_version=None,\n    custom_message=None,\n):\n    \"\"\"\n    ## import_dependency_safe\n\n    Imports specified dependency safely. By default(`error = raise`), if a dependency is missing,\n    an ImportError with a meaningful message will be raised. Otherwise if `error = log` a warning\n    will be logged and on `error = silent` everything will be quit. But If a dependency is present,\n    but older than specified, an error is raised if specified.\n\n    Parameters:\n        name (string): name of dependency to be imported.\n        error (string): raise or Log or silence ImportError. Possible values are `\"raise\"`, `\"log\"` and `silent`. Default is `\"raise\"`.\n        pkg_name (string): (Optional) package name of dependency(if different `pip` name). Otherwise `name` will be used.\n        min_version (string): (Optional) required minimum version of the dependency to be imported.\n        custom_message (string): (Optional) custom Import error message to be raised or logged.\n\n    **Returns:** The imported module, when found and the version is correct(if specified). Otherwise `None`.\n    \"\"\"\n    # check specified parameters\n    sub_class = \"\"\n    if not name or not isinstance(name, str):\n        return None\n    else:\n        # extract name in case of relative import\n        name = name.strip()\n        if name.startswith(\"from\"):\n            name = name.split(\" \")\n            name, sub_class = (name[1].strip(), name[-1].strip())\n\n    assert error in [\n        \"raise\",\n        \"log\",\n        \"silent\",\n    ], \"[Vidgear:ERROR] :: Invalid value at `error` parameter.\"\n\n    # specify package name of dependency(if defined). Otherwise use name\n    install_name = pkg_name if not (pkg_name is None) else name\n\n    # create message\n    msg = (\n        custom_message\n        if not (custom_message is None)\n        else \"Failed to find required dependency '{}'. Install it with  `pip install {}` command.\".format(\n            name, install_name\n        )\n    )\n    # try importing dependency\n    try:\n        module = importlib.import_module(name)\n        module = getattr(module, sub_class) if sub_class else module\n    except Exception as e:\n        if error == \"raise\":\n            if isinstance(e, ModuleNotFoundError):\n                # raise message\n                raise ModuleNotFoundError(msg) from None\n            else:\n                # raise error+message\n                raise ImportError(msg) from e\n        elif error == \"log\":\n            logger.error(msg, exc_info=sys.exc_info())\n            return None\n        else:\n            return None\n\n    # check if minimum required version\n    if not (min_version) is None:\n        # Handle submodules\n        parent_module = name.split(\".\")[0]\n        if parent_module != name:\n            # grab parent module\n            module_to_get = sys.modules[parent_module]\n        else:\n            module_to_get = module\n        # extract version\n        version = get_module_version(module_to_get)\n        # verify\n        if parse_version(version) &lt; parse_version(min_version):\n            # create message\n            msg = \"\"\"Unsupported version '{}' found. Vidgear requires '{}' dependency installed with version '{}' or greater. \n            Update it with  `pip install -U {}` command.\"\"\".format(\n                parent_module, min_version, version, install_name\n            )\n            # handle errors.\n            if error == \"silent\":\n                return None\n            else:\n                # raise\n                raise ImportError(msg)\n\n    return module\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_video_bitrate--get_video_bitrate","title":"get_video_bitrate","text":"<p>Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>video-width</p> required <code>height</code> <code>int</code> <p>video-height</p> required <code>fps</code> <code>float</code> <p>video-framerate</p> required <code>bpp</code> <code>float</code> <p>bit-per-pixels value</p> required <p>Returns: Video bitrate (in Kbps) as integer.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_video_bitrate(width, height, fps, bpp):\n    \"\"\"\n    ## get_video_bitrate\n\n    Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values\n\n    Parameters:\n        width (int): video-width\n        height (int): video-height\n        fps (float): video-framerate\n        bpp (float): bit-per-pixels value\n\n    **Returns:** Video bitrate _(in Kbps)_ as integer.\n    \"\"\"\n    return round((width * height * bpp * fps) / 1000)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_WriteAccess--check_writeaccess","title":"check_WriteAccess","text":"<p>Checks whether given path directory has Write-Access.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of directory</p> required <code>is_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether Write-Access available, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_WriteAccess(path, is_windows=False, logging=False):\n    \"\"\"\n    ## check_WriteAccess\n\n    Checks whether given path directory has Write-Access.\n\n    Parameters:\n        path (string): absolute path of directory\n        is_windows (boolean): is running on Windows OS?\n        logging (bool): enables logging for its operations\n\n    **Returns:** A boolean value, confirming whether Write-Access available, or not?.\n    \"\"\"\n    # check if path exists\n    dirpath = Path(path)\n    try:\n        if not (dirpath.exists() and dirpath.is_dir()):\n            logger.warning(\n                \"Specified directory `{}` doesn't exists or valid.\".format(path)\n            )\n            return False\n        else:\n            path = dirpath.resolve()\n    except:\n        return False\n    # check filepath on *nix systems\n    if not is_windows:\n        uid = os.geteuid()\n        gid = os.getegid()\n        s = os.stat(path)\n        mode = s[stat.ST_MODE]\n        return (\n            ((s[stat.ST_UID] == uid) and (mode &amp; stat.S_IWUSR))\n            or ((s[stat.ST_GID] == gid) and (mode &amp; stat.S_IWGRP))\n            or (mode &amp; stat.S_IWOTH)\n        )\n    # otherwise, check filepath on windows\n    else:\n        write_accessible = False\n        temp_fname = os.path.join(path, \"temp.tmp\")\n        try:\n            fd = os.open(temp_fname, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)\n            os.close(fd)\n            write_accessible = True\n        except Exception as e:\n            if isinstance(e, PermissionError):\n                logger.error(\n                    \"You don't have adequate access rights to use `{}` directory!\".format(\n                        path\n                    )\n                )\n            logging and logger.exception(str(e))\n        finally:\n            delete_file_safe(temp_fname)\n        return write_accessible\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_open_port--check_open_port","title":"check_open_port","text":"<p>Checks whether specified port open at given IP address.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>string</code> <p>given IP address.</p> required <code>port</code> <code>int</code> <p>check if port is open at given address.</p> <code>22</code> <p>Returns: A boolean value, confirming whether given port is open at given IP address.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_open_port(address, port=22):\n    \"\"\"\n    ## check_open_port\n\n    Checks whether specified port open at given IP address.\n\n    Parameters:\n        address (string): given IP address.\n        port (int): check if port is open at given address.\n\n    **Returns:** A boolean value, confirming whether given port is open at given IP address.\n    \"\"\"\n    if not address:\n        return False\n    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:\n        if sock.connect_ex((address, port)) == 0:\n            return True\n        else:\n            return False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_file_safe--delete_ext_safe","title":"delete_ext_safe","text":"<p>Safely deletes files at given path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>string</code> <p>path to the file</p> required Source code in <code>vidgear/gears/helper.py</code> <pre><code>def delete_file_safe(file_path):\n    \"\"\"\n    ## delete_ext_safe\n\n    Safely deletes files at given path.\n\n    Parameters:\n        file_path (string): path to the file\n    \"\"\"\n    try:\n        dfile = Path(file_path)\n        dfile.unlink(missing_ok=True)\n    except Exception as e:\n        logger.exception(str(e))\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_demuxers--get_supported_demuxers","title":"get_supported_demuxers","text":"<p>Find and returns FFmpeg's supported demuxers</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported demuxers.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_supported_demuxers(path):\n    \"\"\"\n    ## get_supported_demuxers\n\n    Find and returns FFmpeg's supported demuxers\n\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n\n    **Returns:** List of supported demuxers.\n    \"\"\"\n    demuxers = check_output([path, \"-hide_banner\", \"-demuxers\"])\n    splitted = [x.decode(\"utf-8\").strip() for x in demuxers.split(b\"\\n\")]\n    split_index = [idx for idx, s in enumerate(splitted) if \"--\" in s][0]\n    supported_demuxers = splitted[split_index + 1 : len(splitted) - 1]\n    # compile regex\n    finder = re.compile(r\"\\s\\s[a-z0-9_,-]+\\s+\")\n    # find all outputs\n    outputs = finder.findall(\"\\n\".join(supported_demuxers))\n    # return output findings\n    return [o.strip() for o in outputs]\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_vencoders--get_supported_vencoders","title":"get_supported_vencoders","text":"<p>Find and returns FFmpeg's supported video encoders</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported encoders.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_supported_vencoders(path):\n    \"\"\"\n    ## get_supported_vencoders\n\n    Find and returns FFmpeg's supported video encoders\n\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n\n    **Returns:** List of supported encoders.\n    \"\"\"\n    encoders = check_output([path, \"-hide_banner\", \"-encoders\"])\n    splitted = encoders.split(b\"\\n\")\n    # extract video encoders\n    supported_vencoders = [\n        x.decode(\"utf-8\").strip()\n        for x in splitted[2 : len(splitted) - 1]\n        if x.decode(\"utf-8\").strip().startswith(\"V\")\n    ]\n    # compile regex\n    finder = re.compile(r\"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\")\n    # find all outputs\n    outputs = finder.findall(\"\\n\".join(supported_vencoders))\n    # return output findings\n    return [[s for s in o.split(\" \")][-1] for o in outputs]\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_auth_keys--validate_auth_keys","title":"validate_auth_keys","text":"<p>Validates, and also maintains generated ZMQ CURVE Key-pairs.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path of generated CURVE key-pairs</p> required <code>extension</code> <code>string</code> <p>type of key-pair to be validated</p> required <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_auth_keys(path, extension):\n    \"\"\"\n    ## validate_auth_keys\n\n    Validates, and also maintains generated ZMQ CURVE Key-pairs.\n\n    Parameters:\n        path (string): path of generated CURVE key-pairs\n        extension (string): type of key-pair to be validated\n\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n    # check for valid path\n    if not (os.path.exists(path)):\n        return False\n\n    # check if directory empty\n    if not (os.listdir(path)):\n        return False\n\n    keys_buffer = []  # stores auth-keys\n\n    # loop over auth-keys\n    for key_file in os.listdir(path):\n        key = os.path.splitext(key_file)\n        # check if valid key is generated\n        if key and (key[0] in [\"server\", \"client\"]) and (key[1] == extension):\n            keys_buffer.append(key_file)  # store it\n\n    # remove invalid keys if found\n    len(keys_buffer) == 1 and delete_file_safe(os.path.join(path, keys_buffer[0]))\n\n    # return results\n    return True if (len(keys_buffer) == 2) else False\n</code></pre>"},{"location":"bonus/reference/helper_async/","title":"Helper Methods","text":""},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.reducer--reducer","title":"reducer","text":"<p>Asynchronous method that reduces frame size by given percentage.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>percentage</code> <code>int/float</code> <p>inputs size-reduction percentage.</p> <code>0</code> <code>interpolation</code> <code>int</code> <p>Change resize interpolation.</p> <code>4</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>async def reducer(frame=None, percentage=0, interpolation=cv2.INTER_LANCZOS4):\n    \"\"\"\n    ## reducer\n\n    Asynchronous method that reduces frame size by given percentage.\n\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        percentage (int/float): inputs size-reduction percentage.\n        interpolation (int): Change resize interpolation.\n\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n    # check if frame is valid\n    if frame is None:\n        raise ValueError(\"[Helper:ERROR] :: Input frame cannot be NoneType!\")\n\n    # check if valid reduction percentage is given\n    if not (percentage &gt; 0 and percentage &lt; 90):\n        raise ValueError(\n            \"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\"\n        )\n\n    if not (isinstance(interpolation, int)):\n        raise ValueError(\n            \"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\"\n        )\n\n    # grab the frame size\n    (height, width) = frame.shape[:2]\n\n    # calculate the ratio of the width from percentage\n    reduction = ((100 - percentage) / 100) * width\n    ratio = reduction / float(width)\n    # construct the dimensions\n    dimensions = (int(reduction), int(height * ratio))\n\n    # return the resized frame\n    return cv2.resize(frame, dimensions, interpolation=interpolation)\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.create_blank_frame--create_blank_frame","title":"create_blank_frame","text":"<p>Create blank frames of given frame size with text</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>text</code> <code>str</code> <p>Text to be written on frame.</p> <code>''</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def create_blank_frame(frame=None, text=\"\", logging=False):\n    \"\"\"\n    ## create_blank_frame\n\n    Create blank frames of given frame size with text\n\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        text (str): Text to be written on frame.\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n    # check if frame is valid\n    if frame is None or not (isinstance(frame, np.ndarray)):\n        raise ValueError(\"[Helper:ERROR] :: Input frame is invalid!\")\n    # grab the frame size\n    (height, width) = frame.shape[:2]\n    # create blank frame\n    blank_frame = np.zeros(frame.shape, frame.dtype)\n    # setup text\n    if text and isinstance(text, str):\n        if logging:\n            logger.debug(\"Adding text: {}\".format(text))\n        # setup font\n        font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n        # get boundary of this text\n        fontScale = min(height, width) / (25 / 0.25)\n        textsize = cv2.getTextSize(text, font, fontScale, 5)[0]\n        # get coords based on boundary\n        textX = (width - textsize[0]) // 2\n        textY = (height + textsize[1]) // 2\n        # put text\n        cv2.putText(\n            blank_frame, text, (textX, textY), font, fontScale, (125, 125, 125), 6\n        )\n\n    # return frame\n    return blank_frame\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.generate_webdata--generate_webdata","title":"generate_webdata","text":"<p>Auto-Generates, and Auto-validates default data for WebGear and WebGear_RTC APIs.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for generating data</p> required <code>c_name</code> <code>string</code> <p>class name that is generating files</p> <code>'webgear'</code> <code>overwrite_default</code> <code>boolean</code> <p>overwrite existing data or not?</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid data path as string.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def generate_webdata(path, c_name=\"webgear\", overwrite_default=False, logging=False):\n    \"\"\"\n    ## generate_webdata\n\n    Auto-Generates, and Auto-validates default data for WebGear and WebGear_RTC APIs.\n\n    Parameters:\n        path (string): path for generating data\n        c_name (string): class name that is generating files\n        overwrite_default (boolean): overwrite existing data or not?\n        logging (bool): enables logging for its operations\n\n    **Returns:** A valid data path as string.\n    \"\"\"\n    # check if path corresponds to vidgear only\n    if os.path.basename(path) != \".vidgear\":\n        path = os.path.join(path, \".vidgear\")\n\n    # generate parent directory\n    path = os.path.join(path, c_name)\n    mkdir_safe(path, logging=logging)\n\n    # self-generate dirs\n    template_dir = os.path.join(path, \"templates\")  # generates HTML templates dir\n    static_dir = os.path.join(path, \"static\")  # generates static dir\n    # generate js &amp; css static and favicon img subdirs\n    js_static_dir = os.path.join(static_dir, \"js\")\n    css_static_dir = os.path.join(static_dir, \"css\")\n    favicon_dir = os.path.join(static_dir, \"img\")\n\n    mkdir_safe(static_dir, logging=logging)\n    mkdir_safe(template_dir, logging=logging)\n    mkdir_safe(js_static_dir, logging=logging)\n    mkdir_safe(css_static_dir, logging=logging)\n    mkdir_safe(favicon_dir, logging=logging)\n\n    # check if overwriting is enabled\n    if overwrite_default or not validate_webdata(\n        template_dir, [\"index.html\", \"404.html\", \"500.html\"]\n    ):\n        logger.critical(\n            \"Overwriting existing {} data-files with default data-files from the server!\".format(\n                c_name.capitalize()\n            )\n            if overwrite_default\n            else \"Failed to detect critical {} data-files: index.html, 404.html &amp; 500.html!\".format(\n                c_name.capitalize()\n            )\n        )\n        # download default files\n        logging and logger.info(\n            \"Downloading default data-files from the Gitlab Server: {}\".format(\n                \"https://gitlab.com/abhiTronix/vidgear-vitals\"\n            )\n        )\n        download_webdata(\n            template_dir,\n            c_name=c_name,\n            files=[\"index.html\", \"404.html\", \"500.html\", \"base.html\"],\n            logging=logging,\n        )\n        download_webdata(\n            css_static_dir, c_name=c_name, files=[\"custom.css\"], logging=logging\n        )\n        download_webdata(\n            js_static_dir,\n            c_name=c_name,\n            files=[\"custom.js\"],\n            logging=logging,\n        )\n        download_webdata(\n            favicon_dir, c_name=c_name, files=[\"favicon-32x32.png\"], logging=logging\n        )\n    else:\n        # validate important data-files\n        if logging:\n            logger.debug(\"Found valid WebGear data-files successfully.\")\n\n    return path\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.download_webdata--download_webdata","title":"download_webdata","text":"<p>Downloads given list of files for WebGear and WebGear_RTC APIs(if not available) from GitHub/Gitlab Servers, and also Validates them.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for downloading data</p> required <code>c_name</code> <code>string</code> <p>class name that is generating files</p> <code>'webgear'</code> <code>files</code> <code>list</code> <p>list of files to be downloaded</p> <code>[]</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid path as string.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def download_webdata(path, c_name=\"webgear\", files=[], logging=False):\n    \"\"\"\n    ## download_webdata\n\n    Downloads given list of files for WebGear and WebGear_RTC APIs(if not available) from GitHub/Gitlab Servers,\n    and also Validates them.\n\n    Parameters:\n        path (string): path for downloading data\n        c_name (string): class name that is generating files\n        files (list): list of files to be downloaded\n        logging (bool): enables logging for its operations\n\n    **Returns:** A valid path as string.\n    \"\"\"\n    basename = os.path.basename(path)\n    if logging:\n        logger.debug(\"Downloading {} data-files at `{}`\".format(basename, path))\n\n    # list all registered urls\n    reg_urls = [\n        \"https://gitlab.com/abhiTronix/vidgear-vitals/-/raw/main\",\n        \"https://raw.githubusercontent.com/abhiTronix/vidgear-vitals/main\",\n    ]\n\n    # create session\n    with requests.Session() as http:\n        for url in reg_urls:\n            try:\n                for file in files:\n                    # get filename\n                    file_name = os.path.join(path, file)\n                    # get URL\n                    file_url = \"{}/{}{}/{}/{}\".format(\n                        url,\n                        c_name,\n                        \"/static\" if basename != \"templates\" else \"\",\n                        basename,\n                        file,\n                    )\n                    # download and write file to the given path\n                    logging and logger.debug(\n                        \"Downloading {} data-file: {}.\".format(basename, file)\n                    )\n\n                    with open(file_name, \"wb\") as f:\n                        # setup retry strategy\n                        retries = Retry(\n                            total=3,\n                            backoff_factor=1,\n                            status_forcelist=[429, 500, 502, 503, 504],\n                        )\n                        # Mount it for https usage\n                        adapter = TimeoutHTTPAdapter(timeout=2.0, max_retries=retries)\n                        http.mount(\"https://\", adapter)\n                        response = http.get(file_url, stream=True)\n                        response.raise_for_status()\n                        total_length = (\n                            response.headers.get(\"content-length\")\n                            if \"content-length\" in response.headers\n                            else len(response.content)\n                        )\n                        assert not (\n                            total_length is None\n                        ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\"\n                        bar = tqdm(total=int(total_length), unit=\"B\", unit_scale=True)\n                        for data in response.iter_content(chunk_size=256):\n                            f.write(data)\n                            if len(data) &gt; 0:\n                                bar.update(len(data))\n                        bar.close()\n            except AssertionError as e:\n                # raise if connection error\n                raise e\n            except Exception as e:\n                # log error\n                logger.exception(str(e))\n                # log event if necessary\n                url != reg_urls[1] and logger.error(\n                    \"Download failed for Gitlab Server! Retrying from GitHub Server: {}\".format(\n                        url, \"https://github.com/abhiTronix/vidgear-vitals\"\n                    )\n                )\n            else:\n                # break otherwise\n                break\n\n    if logging:\n        logger.debug(\"Verifying downloaded data:\")\n    if validate_webdata(path, files=files, logging=logging):\n        if logging:\n            logger.info(\"Successful!\")\n        return path\n    else:\n        raise RuntimeError(\n            \"[Helper:ERROR] :: Failed to download required {} data-files at: {}, Check your Internet connectivity!\".format(\n                basename, path\n            )\n        )\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.validate_webdata--validate_auth_keys","title":"validate_auth_keys","text":"<p>Validates, and also maintains downloaded list of files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path of downloaded files</p> required <code>files</code> <code>list</code> <p>list of files to be validated</p> <code>[]</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A  boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def validate_webdata(path, files=[], logging=False):\n    \"\"\"\n    ## validate_auth_keys\n\n    Validates, and also maintains downloaded list of files.\n\n    Parameters:\n        path (string): path of downloaded files\n        files (list): list of files to be validated\n        logging (bool): enables logging for its operations\n\n    **Returns:** A  boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n    # check if valid path or directory empty\n    if not (os.path.exists(path)) or not (os.listdir(path)):\n        return False\n\n    files_buffer = []\n    # loop over files\n    for file in os.listdir(path):\n        if file in files:\n            files_buffer.append(file)  # store them\n\n    # return results\n    if len(files_buffer) &lt; len(files):\n        if logging:\n            logger.warning(\n                \"`{}` file(s) missing from data-files!\".format(\n                    \" ,\".join(list(set(files_buffer) ^ set(files)))\n                )\n            )\n        return False\n    else:\n        return True\n</code></pre>"},{"location":"bonus/reference/netgear/","title":"API References","text":"<p>NetGear API usage examples can be found here \u27b6</p> <p>NetGear API parameters are explained here \u27b6</p> <p>NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time.</p> <p>NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker.</p> <p>NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time.</p> <p>Info</p> <p>NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns (i.e. <code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) at both Server and Client ends, where its API instead of doing a blocking receive, will:</p> <ul> <li>Poll the socket and receive from it only when it's sure a reply has arrived.</li> <li>Attempt to reconnect, if no reply has arrived within a timeout period.</li> <li>Abandon the connection if there is still no reply after several requests.</li> </ul> <p>NetGear as of now seamlessly supports three ZeroMQ messaging patterns:</p> <ul> <li><code>zmq.PAIR</code> (ZMQ Pair Pattern)</li> <li><code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern)</li> <li><code>zmq.PUB/zmq.SUB</code> (ZMQ Publish/Subscribe Pattern)</li> </ul> <p>whereas the supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> Modes of Operation <ul> <li> <p>Primary Modes</p> <p>NetGear API primarily has two modes of operations:</p> <ul> <li> <p>Send Mode: which employs <code>send()</code> function to send video frames over the network in real-time.</p> </li> <li> <p>Receive Mode: which employs <code>recv()</code> function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns.</p> </li> </ul> </li> <li> <p>Exclusive Modes</p> <p>In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes:</p> <ul> <li> <p>Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once, thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time.</p> </li> <li> <p>Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once, thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time.</p> </li> <li> <p>Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames.</p> </li> <li> <p>Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network.</p> </li> </ul> </li> </ul> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>class NetGear:\n    \"\"\"\n    NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time.\n\n    NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library\n    that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker.\n\n    NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending\n    it and decoding it on the client's end automatically in real-time.\n\n    !!! info\n        NetGear API now internally implements robust *Lazy Pirate pattern* (auto-reconnection) for its synchronous messaging patterns _(i.e. `zmq.PAIR` &amp; `zmq.REQ/zmq.REP`)_\n        at both Server and Client ends, where its API instead of doing a blocking receive, will:\n\n        * Poll the socket and receive from it only when it's sure a reply has arrived.\n        * Attempt to reconnect, if no reply has arrived within a timeout period.\n        * Abandon the connection if there is still no reply after several requests.\n\n    NetGear as of now seamlessly supports three ZeroMQ messaging patterns:\n\n    - `zmq.PAIR` _(ZMQ Pair Pattern)_\n    - `zmq.REQ/zmq.REP` _(ZMQ Request/Reply Pattern)_\n    - `zmq.PUB/zmq.SUB` _(ZMQ Publish/Subscribe Pattern)_\n\n    _whereas the supported protocol are: `tcp` and `ipc`_.\n\n    ??? tip \"Modes of Operation\"\n\n        * **Primary Modes**\n\n            NetGear API primarily has two modes of operations:\n\n            * **Send Mode:** _which employs `send()` function to send video frames over the network in real-time._\n\n            * **Receive Mode:** _which employs `recv()` function to receive frames, sent over the network with *Send Mode* in real-time. The mode sends back confirmation when the\n            frame is received successfully in few patterns._\n\n        * **Exclusive Modes**\n\n            In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes:\n\n            * **Multi-Servers Mode:** _In this exclusive mode, NetGear API robustly **handles multiple servers at once**, thereby providing seamless access to frames and unidirectional\n            data transfer from multiple Servers/Publishers across the network in real-time._\n\n            * **Multi-Clients Mode:** _In this exclusive mode, NetGear API robustly **handles multiple clients at once**, thereby providing seamless access to frames and unidirectional\n            data transfer to multiple Client/Consumers across the network in real-time._\n\n            * **Bidirectional Mode:** _This exclusive mode **provides seamless support for bidirectional data transmission between between Server and Client along with video frames**._\n\n            * **Secure Mode:** _In this exclusive mode, NetGear API **provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers** that enables strong encryption on\n            data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication\n            for distributed systems over the network._\n    \"\"\"\n\n    def __init__(\n        self,\n        address=None,\n        port=None,\n        protocol=None,\n        pattern=0,\n        receive_mode=False,\n        logging=False,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the NetGear class.\n\n        Parameters:\n            address (str): sets the valid network address of the Server/Client.\n            port (str): sets the valid Network Port of the Server/Client.\n            protocol (str): sets the valid messaging protocol between Server/Client.\n            pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n            receive_mode (bool): select the Netgear's Mode of operation.\n            logging (bool): enables/disables logging.\n            options (dict): provides the flexibility to alter various NetGear internal properties.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # raise error(s) for critical Class imports\n        import_dependency_safe(\n            \"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n        )\n        import_dependency_safe(\n            \"simplejpeg\" if simplejpeg is None else \"\", error=\"log\", min_version=\"1.6.1\"\n        )\n\n        # define valid messaging patterns =&gt; `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB)\n        valid_messaging_patterns = {\n            0: (zmq.PAIR, zmq.PAIR),\n            1: (zmq.REQ, zmq.REP),\n            2: (zmq.PUB, zmq.SUB),\n        }\n\n        # Handle messaging pattern\n        msg_pattern = None\n        # check whether user-defined messaging pattern is valid\n        if isinstance(pattern, int) and pattern in valid_messaging_patterns.keys():\n            # assign value\n            msg_pattern = valid_messaging_patterns[pattern]\n        else:\n            # otherwise default to 0:`zmq.PAIR`\n            pattern = 0\n            msg_pattern = valid_messaging_patterns[pattern]\n            self.__logging and logger.warning(\n                \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\"\n            )\n        # assign pattern to global parameter for further use\n        self.__pattern = pattern\n\n        # Handle messaging protocol\n        if protocol is None or not (protocol in [\"tcp\", \"ipc\"]):\n            # else default to `tcp` protocol\n            protocol = \"tcp\"\n            # log it\n            self.__logging and logger.warning(\n                \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\"\n            )\n\n        # Handle connection params\n\n        self.__msg_flag = 0  # handles connection flags\n        self.__msg_copy = False  # handles whether to copy data\n        self.__msg_track = False  # handles whether to track packets\n\n        # Handle NetGear's internal exclusive modes and params\n\n        # define Secure Mode\n        self.__z_auth = None\n\n        # define SSH Tunneling Mode\n        self.__ssh_tunnel_mode = None  # handles ssh_tunneling mode state\n        self.__ssh_tunnel_pwd = None\n        self.__ssh_tunnel_keyfile = None\n        self.__paramiko_present = False if paramiko is None else True\n\n        # define Multi-Server mode\n        self.__multiserver_mode = False  # handles multi-server mode state\n\n        # define Multi-Client mode\n        self.__multiclient_mode = False  # handles multi-client mode state\n\n        # define Bidirectional mode\n        self.__bi_mode = False  # handles Bidirectional mode state\n\n        # define Secure mode\n        valid_security_mech = {0: \"Grasslands\", 1: \"StoneHouse\", 2: \"IronHouse\"}\n        self.__secure_mode = 0  # handles ZMQ security layer status\n        auth_cert_dir = \"\"  # handles valid ZMQ certificates dir\n        self.__auth_publickeys_dir = \"\"  # handles valid ZMQ public certificates dir\n        self.__auth_secretkeys_dir = \"\"  # handles valid ZMQ private certificates dir\n        overwrite_cert = False  # checks if certificates overwriting allowed\n        custom_cert_location = \"\"  # handles custom ZMQ certificates path\n\n        # define frame-compression handler\n        self.__jpeg_compression = (\n            True if not (simplejpeg is None) else False\n        )  # enabled by default for all connections if simplejpeg is installed\n        self.__jpeg_compression_quality = 90  # 90% quality\n        self.__jpeg_compression_fastdct = True  # fastest DCT on by default\n        self.__jpeg_compression_fastupsample = False  # fastupsample off by default\n        self.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\n\n        # defines frame compression on return data\n        self.__ex_compression_params = None\n\n        # define receiver return data handler\n        self.__return_data = None\n\n        # generate 8-digit random system id\n        self.__id = \"\".join(\n            secrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n        )\n\n        # define termination flag\n        self.__terminate = False\n\n        # additional settings for reliability\n        if pattern &lt; 2:\n            # define zmq poller for reliable transmission\n            self.__poll = zmq.Poller()\n            # define max retries\n            self.__max_retries = 3\n            # request timeout\n            self.__request_timeout = 4000  # 4 secs\n        else:\n            # subscriber timeout\n            self.__subscriber_timeout = None\n\n        # Handle user-defined options dictionary values\n        # reformat dictionary\n        options = {str(k).strip(): v for k, v in options.items()}\n\n        # loop over dictionary key &amp; values and assign to global variables if valid\n        for key, value in options.items():\n            # handle multi-server mode\n            if key == \"multiserver_mode\" and isinstance(value, bool):\n                # check if valid pattern assigned\n                if pattern &gt; 0:\n                    # activate Multi-server mode\n                    self.__multiserver_mode = value\n                else:\n                    # otherwise disable it and raise error\n                    self.__multiserver_mode = False\n                    logger.critical(\"Multi-Server Mode is disabled!\")\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\".format(\n                            pattern\n                        )\n                    )\n\n            # handle multi-client mode\n            elif key == \"multiclient_mode\" and isinstance(value, bool):\n                # check if valid pattern assigned\n                if pattern &gt; 0:\n                    # activate Multi-client mode\n                    self.__multiclient_mode = value\n                else:\n                    # otherwise disable it and raise error\n                    self.__multiclient_mode = False\n                    logger.critical(\"Multi-Client Mode is disabled!\")\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\".format(\n                            pattern\n                        )\n                    )\n\n            # handle bidirectional mode\n            elif key == \"bidirectional_mode\" and isinstance(value, bool):\n                # check if pattern is valid\n                if pattern &lt; 2:\n                    # activate Bidirectional mode if specified\n                    self.__bi_mode = value\n                else:\n                    # otherwise disable it and raise error\n                    self.__bi_mode = False\n                    logger.warning(\"Bidirectional data transmission is disabled!\")\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\n                            pattern\n                        )\n                    )\n\n            # handle secure mode\n            elif (\n                key == \"secure_mode\"\n                and isinstance(value, int)\n                and (value in valid_security_mech)\n            ):\n                self.__secure_mode = value\n\n            elif key == \"custom_cert_location\" and isinstance(value, str):\n                # verify custom auth certificates path for secure mode\n                custom_cert_location = os.path.abspath(value)\n                assert os.path.isdir(\n                    custom_cert_location\n                ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\"\n                assert check_WriteAccess(\n                    custom_cert_location,\n                    is_windows=True if os.name == \"nt\" else False,\n                    logging=self.__logging,\n                ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to '{}' directory!\".format(\n                    value\n                )\n            elif key == \"overwrite_cert\" and isinstance(value, bool):\n                # enable/disable auth certificate overwriting in secure mode\n                overwrite_cert = value\n\n            # handle ssh-tunneling mode\n            elif key == \"ssh_tunnel_mode\" and isinstance(value, str):\n                # enable SSH Tunneling Mode\n                self.__ssh_tunnel_mode = value.strip()\n            elif key == \"ssh_tunnel_pwd\" and isinstance(value, str):\n                # add valid SSH Tunneling password\n                self.__ssh_tunnel_pwd = value\n            elif key == \"ssh_tunnel_keyfile\" and isinstance(value, str):\n                # add valid SSH Tunneling key-file\n                self.__ssh_tunnel_keyfile = value if os.path.isfile(value) else None\n                if self.__ssh_tunnel_keyfile is None:\n                    logger.warning(\n                        \"Discarded invalid or non-existential SSH Tunnel Key-file at {}!\".format(\n                            value\n                        )\n                    )\n\n            # handle jpeg compression\n            elif (\n                key == \"jpeg_compression\"\n                and not (simplejpeg is None)\n                and isinstance(value, (bool, str))\n            ):\n                if isinstance(value, str) and value.strip().upper() in [\n                    \"RGB\",\n                    \"BGR\",\n                    \"RGBX\",\n                    \"BGRX\",\n                    \"XBGR\",\n                    \"XRGB\",\n                    \"GRAY\",\n                    \"RGBA\",\n                    \"BGRA\",\n                    \"ABGR\",\n                    \"ARGB\",\n                    \"CMYK\",\n                ]:\n                    # set encoding colorspace\n                    self.__jpeg_compression_colorspace = value.strip().upper()\n                    # enable frame-compression encoding value\n                    self.__jpeg_compression = True\n                else:\n                    # enable frame-compression encoding value\n                    self.__jpeg_compression = value\n            elif key == \"jpeg_compression_quality\" and isinstance(value, (int, float)):\n                # set valid jpeg quality\n                if value &gt;= 10 and value &lt;= 100:\n                    self.__jpeg_compression_quality = int(value)\n                else:\n                    logger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\n            elif key == \"jpeg_compression_fastdct\" and isinstance(value, bool):\n                # enable jpeg fastdct\n                self.__jpeg_compression_fastdct = value\n            elif key == \"jpeg_compression_fastupsample\" and isinstance(value, bool):\n                # enable jpeg  fastupsample\n                self.__jpeg_compression_fastupsample = value\n\n            # assign maximum retries in synchronous patterns\n            elif key == \"max_retries\" and isinstance(value, int) and pattern &lt; 2:\n                if value &gt;= 0:\n                    self.__max_retries = value\n                else:\n                    logger.warning(\"Invalid `max_retries` value skipped!\")\n\n            # assign request timeout in synchronous patterns\n            elif key == \"request_timeout\" and isinstance(value, int) and pattern &lt; 2:\n                if value &gt;= 4:\n                    self.__request_timeout = value * 1000  # covert to milliseconds\n                else:\n                    logger.warning(\"Invalid `request_timeout` value skipped!\")\n\n            # assign subscriber timeout\n            elif (\n                key == \"subscriber_timeout\" and isinstance(value, int) and pattern == 2\n            ):\n                if value &gt; 0:\n                    self.__subscriber_timeout = value * 1000  # covert to milliseconds\n                else:\n                    logger.warning(\"Invalid `request_timeout` value skipped!\")\n\n            # handle ZMQ flags\n            elif key == \"flag\" and isinstance(value, int):\n                self.__msg_flag = value\n                self.__msg_flag and logger.warning(\n                    \"The flag optional value is set to `1` (NOBLOCK) for this run. This might cause NetGear to not terminate gracefully.\"\n                )\n            elif key == \"copy\" and isinstance(value, bool):\n                self.__msg_copy = value\n            elif key == \"track\" and isinstance(value, bool):\n                self.__msg_track = value\n                self.__msg_copy and self.__msg_track and logger.info(\n                    \"The `track` optional value will be ignored for this run because `copy=True` is also defined.\"\n                )\n            else:\n                pass\n\n        # Handle ssh tunneling if enabled\n        if not (self.__ssh_tunnel_mode is None):\n            # SSH Tunnel Mode only available for server mode\n            if receive_mode:\n                logger.error(\"SSH Tunneling cannot be enabled for Client-end!\")\n            else:\n                # check if SSH tunneling possible\n                ssh_address = self.__ssh_tunnel_mode\n                ssh_address, ssh_port = (\n                    ssh_address.split(\":\")\n                    if \":\" in ssh_address\n                    else [ssh_address, \"22\"]\n                )  # default to port 22\n                if \"47\" in ssh_port:\n                    self.__ssh_tunnel_mode = self.__ssh_tunnel_mode.replace(\n                        \":47\", \"\"\n                    )  # port-47 is reserved for testing\n                else:\n                    # extract ip for validation\n                    ssh_user, ssh_ip = (\n                        ssh_address.split(\"@\")\n                        if \"@\" in ssh_address\n                        else [\"\", ssh_address]\n                    )\n                    # validate ip specified port\n                    assert check_open_port(\n                        ssh_ip, port=int(ssh_port)\n                    ), \"[NetGear:ERROR] :: Host `{}` is not available for SSH Tunneling at port-{}!\".format(\n                        ssh_address, ssh_port\n                    )\n\n        # Handle multiple exclusive modes if enabled\n        if self.__multiclient_mode and self.__multiserver_mode:\n            raise ValueError(\n                \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\"\n            )\n        elif self.__multiserver_mode or self.__multiclient_mode:\n            # check if Bidirectional Mode also enabled\n            if self.__bi_mode:\n                # log it\n                self.__logging and logger.debug(\n                    \"Bidirectional Data Transmission is also enabled for this connection!\"\n                )\n            # check if SSH Tunneling Mode also enabled\n            if self.__ssh_tunnel_mode:\n                # raise error\n                raise ValueError(\n                    \"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\".format(\n                        \"Multi-Server\" if self.__multiserver_mode else \"Multi-Client\"\n                    )\n                )\n        elif self.__bi_mode:\n            # log Bidirectional mode activation\n            self.__logging and logger.debug(\n                \"Bidirectional Data Transmission is enabled for this connection!\"\n            )\n        elif self.__ssh_tunnel_mode:\n            # log Bidirectional mode activation\n            self.__logging and logger.debug(\n                \"SSH Tunneling is enabled for host:`{}` with `{}` back-end.\".format(\n                    self.__ssh_tunnel_mode,\n                    \"paramiko\" if self.__paramiko_present else \"pexpect\",\n                )\n            )\n\n        # On Windows, NetGear requires the ``WindowsSelectorEventLoop`` but Python 3.8 and above,\n        # defaults to an ``ProactorEventLoop`` loop that is not compatible with it. Thereby,\n        # we had to set it manually.\n        platform.system() == \"Windows\" and asyncio.set_event_loop_policy(\n            asyncio.WindowsSelectorEventLoopPolicy()\n        )\n\n        # define ZMQ messaging context instance\n        self.__msg_context = zmq.Context.instance()\n\n        # initialize and assign receive mode to global variable\n        self.__receive_mode = receive_mode\n\n        # Handle Secure mode\n        if self.__secure_mode &gt; 0:\n            # activate and log if overwriting is enabled\n            if receive_mode:\n                overwrite_cert = False\n                overwrite_cert and logger.warning(\n                    \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\"\n                )\n            else:\n                overwrite_cert and self.__logging and logger.info(\n                    \"Overwriting ZMQ Authentication certificates over previous ones!\"\n                )\n\n            # Validate certificate generation paths\n            # Start threaded authenticator for this context\n            try:\n                # check if custom certificates path is specified\n                if custom_cert_location:\n                    (\n                        auth_cert_dir,\n                        self.__auth_secretkeys_dir,\n                        self.__auth_publickeys_dir,\n                    ) = generate_auth_certificates(\n                        custom_cert_location, overwrite=overwrite_cert, logging=logging\n                    )\n                else:\n                    # otherwise auto-generate suitable path\n                    (\n                        auth_cert_dir,\n                        self.__auth_secretkeys_dir,\n                        self.__auth_publickeys_dir,\n                    ) = generate_auth_certificates(\n                        os.path.join(expanduser(\"~\"), \".vidgear\"),\n                        overwrite=overwrite_cert,\n                        logging=logging,\n                    )\n                # log it\n                self.__logging and logger.debug(\n                    \"`{}` is the default location for storing ZMQ authentication certificates/keys.\".format(\n                        auth_cert_dir\n                    )\n                )\n\n                # start an authenticator for this context\n                self.__z_auth = ThreadAuthenticator(self.__msg_context)\n                self.__z_auth.start()\n                self.__z_auth.allow(str(address))  # allow current address\n\n                # check if `IronHouse` is activated\n                if self.__secure_mode == 2:\n                    # tell authenticator to use the certificate from given valid dir\n                    self.__z_auth.configure_curve(\n                        domain=\"*\", location=self.__auth_publickeys_dir\n                    )\n                else:\n                    # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated\n                    self.__z_auth.configure_curve(\n                        domain=\"*\", location=auth.CURVE_ALLOW_ANY\n                    )\n            except zmq.ZMQError as e:\n                if \"Address in use\" in str(e):\n                    logger.info(\"ZMQ Authenticator already running.\")\n                else:\n                    # catch if any error occurred and disable Secure mode\n                    logger.exception(str(e))\n                    self.__secure_mode = 0\n                    logger.error(\n                        \"ZMQ Security Mechanism is disabled for this connection due to errors!\"\n                    )\n\n        # check whether `receive_mode` is enabled\n        if self.__receive_mode:\n            # define connection address\n            address = \"*\" if address is None else address\n\n            # check if multiserver_mode is enabled\n            if self.__multiserver_mode:\n                # check if unique server port address list/tuple is assigned or not in multiserver_mode\n                if port is None or not isinstance(port, (tuple, list)):\n                    # raise error if not\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\"\n                    )\n                else:\n                    # otherwise log it\n                    logger.debug(\n                        \"Enabling Multi-Server Mode at PORTS: {}!\".format(port)\n                    )\n                # create port address buffer for keeping track of connected client's port(s)\n                self.__port_buffer = []\n            # check if multiclient_mode is enabled\n            elif self.__multiclient_mode:\n                # check if unique server port address is assigned or not in multiclient_mode\n                if port is None:\n                    # raise error if not\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Client-end. For more information refer VidGear docs.\"\n                    )\n                else:\n                    # otherwise log it\n                    logger.debug(\n                        \"Enabling Multi-Client Mode at PORT: {} on this device!\".format(\n                            port\n                        )\n                    )\n                # assign value to global variable\n                self.__port = port\n            else:\n                # otherwise assign local port address if None\n                port = \"5555\" if port is None else port\n\n            try:\n                # define thread-safe messaging socket\n                self.__msg_socket = self.__msg_context.socket(msg_pattern[1])\n\n                # define pub-sub flag\n                self.__pattern == 2 and self.__msg_socket.set_hwm(1)\n\n                # enable specified secure mode for the socket\n                if self.__secure_mode &gt; 0:\n                    # load server key\n                    server_secret_file = os.path.join(\n                        self.__auth_secretkeys_dir, \"server.key_secret\"\n                    )\n                    server_public, server_secret = auth.load_certificate(\n                        server_secret_file\n                    )\n                    # load  all CURVE keys\n                    self.__msg_socket.curve_secretkey = server_secret\n                    self.__msg_socket.curve_publickey = server_public\n                    # enable CURVE connection for this socket\n                    self.__msg_socket.curve_server = True\n\n                # define exclusive socket options for `patterns=2`\n                if self.__pattern == 2:\n                    self.__msg_socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n                    self.__subscriber_timeout and self.__msg_socket.setsockopt(\n                        zmq.RCVTIMEO, self.__subscriber_timeout\n                    )\n                    self.__subscriber_timeout and self.__msg_socket.setsockopt(\n                        zmq.LINGER, 0\n                    )\n\n                # if multiserver_mode is enabled, then assign port addresses to zmq socket\n                if self.__multiserver_mode:\n                    # bind socket to given server protocol, address and ports\n                    for pt in port:\n                        self.__msg_socket.bind(\n                            protocol + \"://\" + str(address) + \":\" + str(pt)\n                        )\n                else:\n                    # bind socket to given protocol, address and port normally\n                    self.__msg_socket.bind(\n                        protocol + \"://\" + str(address) + \":\" + str(port)\n                    )\n\n                # additional settings\n                if pattern &lt; 2:\n                    if self.__multiserver_mode:\n                        self.__connection_address = []\n                        for pt in port:\n                            self.__connection_address.append(\n                                protocol + \"://\" + str(address) + \":\" + str(pt)\n                            )\n                    else:\n                        self.__connection_address = (\n                            protocol + \"://\" + str(address) + \":\" + str(port)\n                        )\n                    self.__msg_pattern = msg_pattern[1]\n                    self.__poll.register(self.__msg_socket, zmq.POLLIN)\n                    self.__logging and logger.debug(\n                        \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\n                            self.__max_retries, self.__request_timeout / 1000\n                        )\n                    )\n                else:\n                    self.__logging and self.__subscriber_timeout and logger.debug(\n                        \"Timeout: {} secs is enabled for this system.\".format(\n                            self.__subscriber_timeout / 1000\n                        )\n                    )\n\n            except Exception as e:\n                # otherwise log and raise error\n                logger.exception(str(e))\n                # Handle Secure Mode\n                self.__secure_mode and logger.critical(\n                    \"Failed to activate Secure Mode: `{}` for this connection!\".format(\n                        valid_security_mech[self.__secure_mode]\n                    )\n                )\n                # raise errors for exclusive modes\n                if self.__multiserver_mode or self.__multiclient_mode:\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n                            (\n                                \"Multi-Server\"\n                                if self.__multiserver_mode\n                                else \"Multi-Client\"\n                            ),\n                            (protocol + \"://\" + str(address) + \":\" + str(port)),\n                            pattern,\n                        )\n                    )\n                else:\n                    self.__bi_mode and logger.critical(\n                        \"Failed to activate Bidirectional Mode for this connection!\"\n                    )\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n                            (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                        )\n                    )\n\n            # Handle threaded queue mode\n            self.__logging and logger.debug(\n                \"Threaded Queue Mode is enabled by default for this connection.\"\n            )\n\n            # define deque and assign it to global var\n            self.__queue = deque(maxlen=96)  # max len 96 to check overflow\n\n            # initialize and start threaded recv_handler\n            self.__thread = Thread(target=self.__recv_handler, name=\"NetGear\", args=())\n            self.__thread.daemon = True\n            self.__thread.start()\n\n            if self.__logging:\n                # finally log progress\n                logger.debug(\n                    \"Successfully Binded to address: {} with pattern: {}.\".format(\n                        (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                    )\n                )\n                self.__jpeg_compression and logger.debug(\n                    \"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\n                        self.__jpeg_compression_colorspace,\n                        self.__jpeg_compression_quality,\n                        (\"enabled\" if self.__jpeg_compression_fastdct else \"disabled\"),\n                        (\n                            \"enabled\"\n                            if self.__jpeg_compression_fastupsample\n                            else \"disabled\"\n                        ),\n                    )\n                )\n                self.__secure_mode and logger.debug(\n                    \"Successfully enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\n                        valid_security_mech[self.__secure_mode]\n                    )\n                )\n                logger.debug(\"Multi-threaded Receive Mode is successfully enabled.\")\n                logger.debug(\"Unique System ID is {}.\".format(self.__id))\n                logger.debug(\"Receive Mode is now activated.\")\n\n        else:\n            # otherwise default to `Send Mode`\n            # define connection address\n            address = \"localhost\" if address is None else address\n\n            # check if multiserver_mode is enabled\n            if self.__multiserver_mode:\n                # check if unique server port address is assigned or not in multiserver_mode\n                if port is None:\n                    # raise error if not\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Server-end. For more information refer VidGear docs.\"\n                    )\n                else:\n                    # otherwise log it\n                    logger.debug(\n                        \"Enabling Multi-Server Mode at PORT: {} on this device!\".format(\n                            port\n                        )\n                    )\n                # assign value to global variable\n                self.__port = port\n            # check if multiclient_mode is enabled\n            elif self.__multiclient_mode:\n                # check if unique client port address list/tuple is assigned or not in multiclient_mode\n                if port is None or not isinstance(port, (tuple, list)):\n                    # raise error if not\n                    raise ValueError(\n                        \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\"\n                    )\n                else:\n                    # otherwise log it\n                    logger.debug(\n                        \"Enabling Multi-Client Mode at PORTS: {}!\".format(port)\n                    )\n                # create port address buffer for keeping track of connected client ports\n                self.__port_buffer = []\n            else:\n                # otherwise assign local port address if None\n                port = \"5555\" if port is None else port\n\n            try:\n                # define thread-safe messaging socket\n                self.__msg_socket = self.__msg_context.socket(msg_pattern[0])\n\n                # if req/rep pattern, define additional flags\n                if self.__pattern == 1:\n                    self.__msg_socket.REQ_RELAXED = True\n                    self.__msg_socket.REQ_CORRELATE = True\n\n                # if pub/sub pattern, define additional optimizer\n                if self.__pattern == 2:\n                    self.__msg_socket.set_hwm(1)\n\n                # enable specified secure mode for the socket\n                if self.__secure_mode &gt; 0:\n                    # load client key\n                    client_secret_file = os.path.join(\n                        self.__auth_secretkeys_dir, \"client.key_secret\"\n                    )\n                    client_public, client_secret = auth.load_certificate(\n                        client_secret_file\n                    )\n                    # load  all CURVE keys\n                    self.__msg_socket.curve_secretkey = client_secret\n                    self.__msg_socket.curve_publickey = client_public\n                    # load server key\n                    server_public_file = os.path.join(\n                        self.__auth_publickeys_dir, \"server.key\"\n                    )\n                    server_public, _ = auth.load_certificate(server_public_file)\n                    # inject public key to make a CURVE connection.\n                    self.__msg_socket.curve_serverkey = server_public\n\n                # check if multi-client_mode is enabled\n                if self.__multiclient_mode:\n                    # bind socket to given server protocol, address and ports\n                    for pt in port:\n                        self.__msg_socket.connect(\n                            protocol + \"://\" + str(address) + \":\" + str(pt)\n                        )\n                else:\n                    # handle SSH tunneling if enabled\n                    if self.__ssh_tunnel_mode:\n                        # establish tunnel connection\n                        ssh.tunnel_connection(\n                            self.__msg_socket,\n                            protocol + \"://\" + str(address) + \":\" + str(port),\n                            self.__ssh_tunnel_mode,\n                            keyfile=self.__ssh_tunnel_keyfile,\n                            password=self.__ssh_tunnel_pwd,\n                            paramiko=self.__paramiko_present,\n                        )\n                    else:\n                        # connect socket to given protocol, address and port\n                        self.__msg_socket.connect(\n                            protocol + \"://\" + str(address) + \":\" + str(port)\n                        )\n\n                # additional settings\n                if pattern &lt; 2:\n                    if self.__multiclient_mode:\n                        self.__connection_address = []\n                        for pt in port:\n                            self.__connection_address.append(\n                                protocol + \"://\" + str(address) + \":\" + str(pt)\n                            )\n                    else:\n                        self.__connection_address = (\n                            protocol + \"://\" + str(address) + \":\" + str(port)\n                        )\n                    self.__msg_pattern = msg_pattern[0]\n                    self.__poll.register(self.__msg_socket, zmq.POLLIN)\n\n                    self.__logging and logger.debug(\n                        \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\n                            self.__max_retries, self.__request_timeout / 1000\n                        )\n                    )\n\n            except Exception as e:\n                # otherwise log and raise error\n                logger.exception(str(e))\n                # Handle Secure Mode\n                self.__secure_mode and logger.critical(\n                    \"Failed to activate Secure Mode: `{}` for this connection!\".format(\n                        valid_security_mech[self.__secure_mode]\n                    )\n                )\n                # raise errors for exclusive modes\n                if self.__multiserver_mode or self.__multiclient_mode:\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n                            (\n                                \"Multi-Server\"\n                                if self.__multiserver_mode\n                                else \"Multi-Client\"\n                            ),\n                            (protocol + \"://\" + str(address) + \":\" + str(port)),\n                            pattern,\n                        )\n                    )\n                else:\n                    self.__bi_mode and logger.critical(\n                        \"Failed to activate Bidirectional Mode for this connection!\"\n                    )\n                    self.__ssh_tunnel_mode and logger.critical(\n                        \"Failed to initiate SSH Tunneling Mode for this server with `{}` back-end!\".format(\n                            \"paramiko\" if self.__paramiko_present else \"pexpect\"\n                        )\n                    )\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n                            (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                        )\n                    )\n\n            if self.__logging:\n                # finally log progress\n                logger.debug(\n                    \"Successfully connected to address: {} with pattern: {}.\".format(\n                        (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                    )\n                )\n                self.__jpeg_compression and logger.debug(\n                    \"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\n                        self.__jpeg_compression_colorspace,\n                        self.__jpeg_compression_quality,\n                        (\"enabled\" if self.__jpeg_compression_fastdct else \"disabled\"),\n                        (\n                            \"enabled\"\n                            if self.__jpeg_compression_fastupsample\n                            else \"disabled\"\n                        ),\n                    )\n                )\n                self.__secure_mode and logger.debug(\n                    \"Enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\n                        valid_security_mech[self.__secure_mode]\n                    )\n                )\n                logger.debug(\"Unique System ID is {}.\".format(self.__id))\n                logger.debug(\n                    \"Send Mode is successfully activated and ready to send data.\"\n                )\n\n    def __recv_handler(self):\n        \"\"\"\n        A threaded receiver handler, that keep iterating data from ZMQ socket to a internally monitored deque,\n        until the thread is terminated, or socket disconnects.\n        \"\"\"\n        # initialize variables\n        frame = None\n        msg_json = None\n\n        # keep looping infinitely until the thread is terminated\n        while not self.__terminate:\n            # check queue buffer for overflow\n            if len(self.__queue) &gt;= 96:\n                # stop iterating if overflowing occurs\n                time.sleep(0.000001)\n                continue\n\n            if self.__pattern &lt; 2:\n                socks = dict(self.__poll.poll(self.__request_timeout * 3))\n                if socks.get(self.__msg_socket) == zmq.POLLIN:\n                    msg_json = self.__msg_socket.recv_json(\n                        flags=self.__msg_flag | zmq.DONTWAIT\n                    )\n                else:\n                    logger.critical(\"No response from Server(s), Reconnecting again...\")\n                    self.__msg_socket.close(linger=0)\n                    self.__poll.unregister(self.__msg_socket)\n                    self.__max_retries -= 1\n\n                    if not (self.__max_retries):\n                        if self.__multiserver_mode:\n                            logger.error(\"All Servers seems to be offline, Abandoning!\")\n                        else:\n                            logger.error(\"Server seems to be offline, Abandoning!\")\n                        self.__terminate = True\n                        continue\n\n                    # Create new connection\n                    try:\n                        self.__msg_socket = self.__msg_context.socket(\n                            self.__msg_pattern\n                        )\n                        if isinstance(self.__connection_address, list):\n                            for _connection in self.__connection_address:\n                                self.__msg_socket.bind(_connection)\n                        else:\n                            self.__msg_socket.bind(self.__connection_address)\n                    except Exception as e:\n                        logger.exception(str(e))\n                        self.__terminate = True\n                        raise RuntimeError(\"API failed to restart the Client-end!\")\n                    self.__poll.register(self.__msg_socket, zmq.POLLIN)\n\n                    continue\n            else:\n                try:\n                    msg_json = self.__msg_socket.recv_json(flags=self.__msg_flag)\n                except zmq.ZMQError as e:\n                    if e.errno == zmq.EAGAIN:\n                        logger.critical(\"Connection Timeout. Exiting!\")\n                        self.__terminate = True\n                        self.__queue.append(None)\n                        break\n\n            # check if terminate_flag` received\n            if msg_json and msg_json[\"terminate_flag\"]:\n                # if multiserver_mode is enabled\n                if self.__multiserver_mode:\n                    # check and remove from which ports signal is received\n                    if msg_json[\"port\"] in self.__port_buffer:\n                        # if pattern is 1, then send back server the info about termination\n                        if self.__pattern == 1:\n                            self.__msg_socket.send_string(\n                                \"Termination signal successfully received at client!\"\n                            )\n                        self.__port_buffer.remove(msg_json[\"port\"])\n                        self.__logging and logger.warning(\n                            \"Termination signal received from Server at port: {}!\".format(\n                                msg_json[\"port\"]\n                            )\n                        )\n                    # if termination signal received from all servers then exit client.\n                    if not self.__port_buffer:\n                        logger.critical(\n                            \"Termination signal received from all Servers!!!\"\n                        )\n                        self.__terminate = True  # termination\n                else:\n                    # if pattern is 1, then send back server the info about termination\n                    if self.__pattern == 1:\n                        self.__msg_socket.send_string(\n                            \"Termination signal successfully received at Client's end!\"\n                        )\n                    # termination\n                    self.__terminate = True\n                    # notify client\n                    self.__logging and logger.critical(\n                        \"Termination signal received from server!\"\n                    )\n                continue\n\n            try:\n                msg_data = self.__msg_socket.recv(\n                    flags=self.__msg_flag | zmq.DONTWAIT,\n                    copy=self.__msg_copy,\n                    track=self.__msg_track,\n                )\n            except zmq.ZMQError as e:\n                logger.critical(\"Socket Session Expired. Exiting!\")\n                self.__terminate = True\n                self.__queue.append(None)\n                break\n\n            # handle data transfer in synchronous modes.\n            if self.__pattern &lt; 2:\n                if self.__bi_mode or self.__multiclient_mode:\n                    # check if we are returning `ndarray` frames\n                    if not (self.__return_data is None) and isinstance(\n                        self.__return_data, np.ndarray\n                    ):\n                        # handle return data for compression\n                        return_data = np.copy(self.__return_data)\n\n                        # check whether exit_flag is False\n                        if not (return_data.flags[\"C_CONTIGUOUS\"]):\n                            # check whether the incoming frame is contiguous\n                            return_data = np.ascontiguousarray(\n                                return_data, dtype=return_data.dtype\n                            )\n\n                        # handle jpeg-compression encoding\n                        if self.__jpeg_compression:\n                            if self.__jpeg_compression_colorspace == \"GRAY\":\n                                if return_data.ndim == 2:\n                                    # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                                    return_data = return_data[:, :, np.newaxis]\n                                return_data = simplejpeg.encode_jpeg(\n                                    return_data,\n                                    quality=self.__jpeg_compression_quality,\n                                    colorspace=self.__jpeg_compression_colorspace,\n                                    fastdct=self.__jpeg_compression_fastdct,\n                                )\n                            else:\n                                return_data = simplejpeg.encode_jpeg(\n                                    return_data,\n                                    quality=self.__jpeg_compression_quality,\n                                    colorspace=self.__jpeg_compression_colorspace,\n                                    colorsubsampling=\"422\",\n                                    fastdct=self.__jpeg_compression_fastdct,\n                                )\n\n                        return_dict = (\n                            dict(port=self.__port)\n                            if self.__multiclient_mode\n                            else dict()\n                        )\n\n                        return_dict.update(\n                            dict(\n                                return_type=(type(self.__return_data).__name__),\n                                compression=(\n                                    {\n                                        \"dct\": self.__jpeg_compression_fastdct,\n                                        \"ups\": self.__jpeg_compression_fastupsample,\n                                        \"colorspace\": self.__jpeg_compression_colorspace,\n                                    }\n                                    if self.__jpeg_compression\n                                    else False\n                                ),\n                                array_dtype=(\n                                    str(self.__return_data.dtype)\n                                    if not (self.__jpeg_compression)\n                                    else \"\"\n                                ),\n                                array_shape=(\n                                    self.__return_data.shape\n                                    if not (self.__jpeg_compression)\n                                    else \"\"\n                                ),\n                                data=None,\n                            )\n                        )\n\n                        # send the json dict\n                        self.__msg_socket.send_json(\n                            return_dict, self.__msg_flag | zmq.SNDMORE\n                        )\n                        # send the array with correct flags\n                        self.__msg_socket.send(\n                            return_data,\n                            flags=self.__msg_flag,\n                            copy=self.__msg_copy,\n                            track=self.__msg_track,\n                        )\n                    else:\n                        return_dict = (\n                            dict(port=self.__port)\n                            if self.__multiclient_mode\n                            else dict()\n                        )\n                        return_dict.update(\n                            dict(\n                                return_type=(type(self.__return_data).__name__),\n                                data=self.__return_data,\n                            )\n                        )\n                        self.__msg_socket.send_json(return_dict, self.__msg_flag)\n                else:\n                    # send confirmation message to server\n                    self.__msg_socket.send_string(\n                        \"Data received on device: {} !\".format(self.__id)\n                    )\n            else:\n                # else raise warning\n                if self.__return_data:\n                    logger.warning(\"`return_data` is disabled for this pattern!\")\n\n            # check if encoding was enabled\n            if msg_json[\"compression\"]:\n                # decode JPEG frame\n                frame = simplejpeg.decode_jpeg(\n                    msg_data,\n                    colorspace=msg_json[\"compression\"][\"colorspace\"],\n                    fastdct=self.__jpeg_compression_fastdct\n                    or msg_json[\"compression\"][\"dct\"],\n                    fastupsample=self.__jpeg_compression_fastupsample\n                    or msg_json[\"compression\"][\"ups\"],\n                )\n                # check if valid frame returned\n                if frame is None:\n                    self.__terminate = True\n                    # otherwise raise error and exit\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Received compressed JPEG frame decoding failed\"\n                    )\n                if msg_json[\"compression\"][\"colorspace\"] == \"GRAY\" and frame.ndim == 3:\n                    # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                    frame = np.squeeze(frame, axis=2)\n            else:\n                # recover and reshape frame from buffer\n                frame_buffer = np.frombuffer(msg_data, dtype=msg_json[\"dtype\"])\n                frame = frame_buffer.reshape(msg_json[\"shape\"])\n\n            # check if multiserver_mode\n            if self.__multiserver_mode:\n                # save the unique port addresses\n                if not msg_json[\"port\"] in self.__port_buffer:\n                    self.__port_buffer.append(msg_json[\"port\"])\n                # extract if any message from server and display it\n                if msg_json[\"message\"]:\n                    self.__queue.append((msg_json[\"port\"], msg_json[\"message\"], frame))\n                else:\n                    # append recovered unique port and frame to queue\n                    self.__queue.append((msg_json[\"port\"], frame))\n            # extract if any message from server if Bidirectional Mode is enabled\n            elif self.__bi_mode:\n                if msg_json[\"message\"]:\n                    # append grouped frame and data to queue\n                    self.__queue.append((msg_json[\"message\"], frame))\n                else:\n                    self.__queue.append((None, frame))\n            else:\n                # otherwise append recovered frame to queue\n                self.__queue.append(frame)\n\n    def recv(self, return_data=None):\n        \"\"\"\n        A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a\n        fixed-length frame buffer in the memory, and blocks the thread if the deque is full.\n\n        Parameters:\n            return_data (any): inputs return data _(of any datatype)_, for sending back to Server.\n\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n        # check whether `receive mode` is activated\n        if not (self.__receive_mode):\n            # raise value error and exit\n            self.__terminate = True\n            raise ValueError(\n                \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\"\n            )\n\n        # handle Bidirectional return data\n        if (self.__bi_mode or self.__multiclient_mode) and not (return_data is None):\n            self.__return_data = return_data\n\n        # check whether or not termination flag is enabled\n        while not self.__terminate:\n            try:\n                # check if queue is empty\n                if len(self.__queue) &gt; 0:\n                    return self.__queue.popleft()\n                else:\n                    time.sleep(0.00001)\n                    continue\n            except KeyboardInterrupt:\n                self.__terminate = True\n                break\n        # otherwise return NoneType\n        return None\n\n    def send(self, frame, message=None):\n        \"\"\"\n        A Server end method, that sends the data and frames over the network to Client(s).\n\n        Parameters:\n            frame (numpy.ndarray): inputs numpy array(frame).\n            message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s).\n\n        **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type.\n\n        \"\"\"\n        # check whether `receive_mode` is disabled\n        if self.__receive_mode:\n            # raise value error and exit\n            self.__terminate = True\n            raise ValueError(\n                \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\"\n            )\n\n        if not (message is None) and isinstance(message, np.ndarray):\n            logger.warning(\n                \"Skipped unsupported `message` of datatype: {}!\".format(\n                    type(message).__name__\n                )\n            )\n            message = None\n\n        # define exit_flag and assign value\n        exit_flag = True if (frame is None or self.__terminate) else False\n\n        # check whether exit_flag is False\n        if not (exit_flag) and not (frame.flags[\"C_CONTIGUOUS\"]):\n            # check whether the incoming frame is contiguous\n            frame = np.ascontiguousarray(frame, dtype=frame.dtype)\n\n        # handle JPEG compression encoding\n        if self.__jpeg_compression:\n            if self.__jpeg_compression_colorspace == \"GRAY\":\n                if frame.ndim == 2:\n                    # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                    frame = np.expand_dims(frame, axis=2)\n                frame = simplejpeg.encode_jpeg(\n                    frame,\n                    quality=self.__jpeg_compression_quality,\n                    colorspace=self.__jpeg_compression_colorspace,\n                    fastdct=self.__jpeg_compression_fastdct,\n                )\n            else:\n                frame = simplejpeg.encode_jpeg(\n                    frame,\n                    quality=self.__jpeg_compression_quality,\n                    colorspace=self.__jpeg_compression_colorspace,\n                    colorsubsampling=\"422\",\n                    fastdct=self.__jpeg_compression_fastdct,\n                )\n\n        # check if multiserver_mode is activated and assign values with unique port\n        msg_dict = dict(port=self.__port) if self.__multiserver_mode else dict()\n\n        # prepare the exclusive json dict\n        msg_dict.update(\n            dict(\n                terminate_flag=exit_flag,\n                compression=(\n                    {\n                        \"dct\": self.__jpeg_compression_fastdct,\n                        \"ups\": self.__jpeg_compression_fastupsample,\n                        \"colorspace\": self.__jpeg_compression_colorspace,\n                    }\n                    if self.__jpeg_compression\n                    else False\n                ),\n                message=message,\n                pattern=str(self.__pattern),\n                dtype=str(frame.dtype) if not (self.__jpeg_compression) else \"\",\n                shape=frame.shape if not (self.__jpeg_compression) else \"\",\n            )\n        )\n\n        # send the json dict\n        self.__msg_socket.send_json(msg_dict, self.__msg_flag | zmq.SNDMORE)\n        # send the frame array with correct flags\n        self.__msg_socket.send(\n            frame, flags=self.__msg_flag, copy=self.__msg_copy, track=self.__msg_track\n        )\n\n        # check if synchronous patterns, then wait for confirmation\n        if self.__pattern &lt; 2:\n            # check if Bidirectional data transmission is enabled\n            if self.__bi_mode or self.__multiclient_mode:\n                # handles return data\n                recvd_data = None\n\n                socks = dict(self.__poll.poll(self.__request_timeout))\n                if socks.get(self.__msg_socket) == zmq.POLLIN:\n                    # handle return data\n                    recv_json = self.__msg_socket.recv_json(flags=self.__msg_flag)\n                else:\n                    logger.critical(\"No response from Client, Reconnecting again...\")\n                    # Socket is confused. Close and remove it.\n                    self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                    self.__msg_socket.close()\n                    self.__poll.unregister(self.__msg_socket)\n                    self.__max_retries -= 1\n\n                    if not (self.__max_retries):\n                        if self.__multiclient_mode:\n                            logger.error(\n                                \"All Clients failed to respond on multiple attempts.\"\n                            )\n                        else:\n                            logger.error(\n                                \"Client failed to respond on multiple attempts.\"\n                            )\n                        self.__terminate = True\n                        raise RuntimeError(\n                            \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\"\n                        )\n\n                    # Create new connection\n                    self.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\n                    if isinstance(self.__connection_address, list):\n                        for _connection in self.__connection_address:\n                            self.__msg_socket.connect(_connection)\n                    else:\n                        # handle SSH tunneling if enabled\n                        if self.__ssh_tunnel_mode:\n                            # establish tunnel connection\n                            ssh.tunnel_connection(\n                                self.__msg_socket,\n                                self.__connection_address,\n                                self.__ssh_tunnel_mode,\n                                keyfile=self.__ssh_tunnel_keyfile,\n                                password=self.__ssh_tunnel_pwd,\n                                paramiko=self.__paramiko_present,\n                            )\n                        else:\n                            # connect normally\n                            self.__msg_socket.connect(self.__connection_address)\n                    self.__poll.register(self.__msg_socket, zmq.POLLIN)\n                    # return None for mean-time\n                    return None\n\n                # save the unique port addresses\n                if (\n                    self.__multiclient_mode\n                    and not recv_json[\"port\"] in self.__port_buffer\n                ):\n                    self.__port_buffer.append(recv_json[\"port\"])\n\n                if recv_json[\"return_type\"] == \"ndarray\":\n                    recv_array = self.__msg_socket.recv(\n                        flags=self.__msg_flag,\n                        copy=self.__msg_copy,\n                        track=self.__msg_track,\n                    )\n                    # check if encoding was enabled\n                    if recv_json[\"compression\"]:\n                        # decode JPEG frame\n                        recvd_data = simplejpeg.decode_jpeg(\n                            recv_array,\n                            colorspace=recv_json[\"compression\"][\"colorspace\"],\n                            fastdct=self.__jpeg_compression_fastdct\n                            or recv_json[\"compression\"][\"dct\"],\n                            fastupsample=self.__jpeg_compression_fastupsample\n                            or recv_json[\"compression\"][\"ups\"],\n                        )\n                        # check if valid frame returned\n                        if recvd_data is None:\n                            self.__terminate = True\n                            # otherwise raise error and exit\n                            raise RuntimeError(\n                                \"[NetGear:ERROR] :: Received compressed frame `{}` decoding failed with flag: {}.\".format(\n                                    recv_json[\"compression\"],\n                                    self.__ex_compression_params,\n                                )\n                            )\n\n                        if (\n                            recv_json[\"compression\"][\"colorspace\"] == \"GRAY\"\n                            and recvd_data.ndim == 3\n                        ):\n                            # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                            recvd_data = np.squeeze(recvd_data, axis=2)\n                    else:\n                        recvd_data = np.frombuffer(\n                            recv_array, dtype=recv_json[\"array_dtype\"]\n                        ).reshape(recv_json[\"array_shape\"])\n                else:\n                    recvd_data = recv_json[\"data\"]\n\n                return (\n                    (recv_json[\"port\"], recvd_data)\n                    if self.__multiclient_mode\n                    else recvd_data\n                )\n            else:\n                # otherwise log normally\n                socks = dict(self.__poll.poll(self.__request_timeout))\n                if socks.get(self.__msg_socket) == zmq.POLLIN:\n                    recv_confirmation = self.__msg_socket.recv()\n                else:\n                    logger.critical(\"No response from Client, Reconnecting again...\")\n                    # Socket is confused. Close and remove it.\n                    self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                    self.__msg_socket.close()\n                    self.__poll.unregister(self.__msg_socket)\n                    self.__max_retries -= 1\n\n                    if not (self.__max_retries):\n                        logger.error(\"Client failed to respond on repeated attempts.\")\n                        self.__terminate = True\n                        raise RuntimeError(\n                            \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\"\n                        )\n\n                    # Create new connection\n                    self.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\n                    # handle SSH tunneling if enabled\n                    if self.__ssh_tunnel_mode:\n                        # establish tunnel connection\n                        ssh.tunnel_connection(\n                            self.__msg_socket,\n                            self.__connection_address,\n                            self.__ssh_tunnel_mode,\n                            keyfile=self.__ssh_tunnel_keyfile,\n                            password=self.__ssh_tunnel_pwd,\n                            paramiko=self.__paramiko_present,\n                        )\n                    else:\n                        # connect normally\n                        self.__msg_socket.connect(self.__connection_address)\n                    self.__poll.register(self.__msg_socket, zmq.POLLIN)\n                    return None\n\n                # log confirmation\n                self.__logging and logger.debug(recv_confirmation)\n\n    def close(self, kill=False):\n        \"\"\"\n        Safely terminates the threads, and NetGear resources.\n\n        Parameters:\n            kill (bool): Kills ZMQ context instead of graceful exiting in receive mode.\n        \"\"\"\n        # log it\n        self.__logging and logger.debug(\n            \"Terminating various {} Processes.\".format(\n                \"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n            )\n        )\n        #  whether `receive_mode` is enabled or not\n        if self.__receive_mode:\n            # check whether queue mode is empty\n            if not (self.__queue is None) and self.__queue:\n                self.__queue.clear()\n            # call immediate termination\n            self.__terminate = True\n            # properly close the socket\n            self.__logging and logger.debug(\"Terminating. Please wait...\")\n            # Handle Secure Mode Thread\n            if self.__z_auth:\n                self.__logging and logger.debug(\"Terminating Authenticator Thread.\")\n                self.__z_auth.stop()\n                while self.__z_auth.is_alive():\n                    pass\n            # wait until stream resources are released\n            # (producer thread might be still grabbing frame)\n            if self.__thread is not None:\n                self.__logging and logger.debug(\"Terminating Main Thread.\")\n                # properly handle thread exit\n                if self.__thread.is_alive() and kill:\n                    # force close if still alive\n                    logger.warning(\"Thread still running...Killing it forcefully!\")\n                    self.__msg_context.destroy()\n                    self.__thread.join()\n                else:\n                    self.__msg_socket.close(linger=0)\n                    self.__thread.join()\n                self.__thread = None\n            self.__logging and logger.debug(\"Terminated Successfully!\")\n        else:\n            # indicate that process should be terminated\n            self.__terminate = True\n            # log if kill enabled\n            kill and logger.warning(\n                \"`kill` parmeter is only available in the receive mode.\"\n            )\n            # Handle Secure Mode Thread\n            if self.__z_auth:\n                self.__logging and logger.debug(\"Terminating Authenticator Thread.\")\n                self.__z_auth.stop()\n                while self.__z_auth.is_alive():\n                    pass\n            # check if all attempts of reconnecting failed, then skip to closure\n            if (self.__pattern &lt; 2 and not self.__max_retries) or (\n                self.__multiclient_mode and not self.__port_buffer\n            ):\n                try:\n                    # properly close the socket\n                    self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                    self.__msg_socket.close()\n                except ZMQError:\n                    pass\n                finally:\n                    # exit\n                    return\n\n            if self.__multiserver_mode:\n                # check if multiserver_mode\n                # send termination flag to client with its unique port\n                term_dict = dict(terminate_flag=True, port=self.__port)\n            else:\n                # otherwise send termination flag to client\n                term_dict = dict(terminate_flag=True)\n\n            try:\n                if self.__multiclient_mode:\n                    for _ in self.__port_buffer:\n                        self.__msg_socket.send_json(term_dict)\n                else:\n                    self.__msg_socket.send_json(term_dict)\n\n                # check for confirmation if available within 1/5 timeout\n                if self.__pattern &lt; 2:\n                    self.__logging and logger.debug(\"Terminating. Please wait...\")\n                    if self.__msg_socket.poll(self.__request_timeout // 5, zmq.POLLIN):\n                        self.__msg_socket.recv()\n            except Exception as e:\n                if not isinstance(e, ZMQError):\n                    logger.exception(str(e))\n            finally:\n                # properly close the socket\n                self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                self.__msg_socket.close()\n                self.__logging and logger.debug(\"Terminated Successfully!\")\n</code></pre> <p> </p>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.__init__","title":"<code>__init__(self, address=None, port=None, protocol=None, pattern=0, receive_mode=False, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the NetGear class.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>sets the valid network address of the Server/Client.</p> <code>None</code> <code>port</code> <code>str</code> <p>sets the valid Network Port of the Server/Client.</p> <code>None</code> <code>protocol</code> <code>str</code> <p>sets the valid messaging protocol between Server/Client.</p> <code>None</code> <code>pattern</code> <code>int</code> <p>sets the supported messaging pattern(flow of communication) between Server/Client</p> <code>0</code> <code>receive_mode</code> <code>bool</code> <p>select the Netgear's Mode of operation.</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>options</code> <code>dict</code> <p>provides the flexibility to alter various NetGear internal properties.</p> <code>{}</code> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def __init__(\n    self,\n    address=None,\n    port=None,\n    protocol=None,\n    pattern=0,\n    receive_mode=False,\n    logging=False,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the NetGear class.\n\n    Parameters:\n        address (str): sets the valid network address of the Server/Client.\n        port (str): sets the valid Network Port of the Server/Client.\n        protocol (str): sets the valid messaging protocol between Server/Client.\n        pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n        receive_mode (bool): select the Netgear's Mode of operation.\n        logging (bool): enables/disables logging.\n        options (dict): provides the flexibility to alter various NetGear internal properties.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # raise error(s) for critical Class imports\n    import_dependency_safe(\n        \"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n    )\n    import_dependency_safe(\n        \"simplejpeg\" if simplejpeg is None else \"\", error=\"log\", min_version=\"1.6.1\"\n    )\n\n    # define valid messaging patterns =&gt; `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB)\n    valid_messaging_patterns = {\n        0: (zmq.PAIR, zmq.PAIR),\n        1: (zmq.REQ, zmq.REP),\n        2: (zmq.PUB, zmq.SUB),\n    }\n\n    # Handle messaging pattern\n    msg_pattern = None\n    # check whether user-defined messaging pattern is valid\n    if isinstance(pattern, int) and pattern in valid_messaging_patterns.keys():\n        # assign value\n        msg_pattern = valid_messaging_patterns[pattern]\n    else:\n        # otherwise default to 0:`zmq.PAIR`\n        pattern = 0\n        msg_pattern = valid_messaging_patterns[pattern]\n        self.__logging and logger.warning(\n            \"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\"\n        )\n    # assign pattern to global parameter for further use\n    self.__pattern = pattern\n\n    # Handle messaging protocol\n    if protocol is None or not (protocol in [\"tcp\", \"ipc\"]):\n        # else default to `tcp` protocol\n        protocol = \"tcp\"\n        # log it\n        self.__logging and logger.warning(\n            \"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\"\n        )\n\n    # Handle connection params\n\n    self.__msg_flag = 0  # handles connection flags\n    self.__msg_copy = False  # handles whether to copy data\n    self.__msg_track = False  # handles whether to track packets\n\n    # Handle NetGear's internal exclusive modes and params\n\n    # define Secure Mode\n    self.__z_auth = None\n\n    # define SSH Tunneling Mode\n    self.__ssh_tunnel_mode = None  # handles ssh_tunneling mode state\n    self.__ssh_tunnel_pwd = None\n    self.__ssh_tunnel_keyfile = None\n    self.__paramiko_present = False if paramiko is None else True\n\n    # define Multi-Server mode\n    self.__multiserver_mode = False  # handles multi-server mode state\n\n    # define Multi-Client mode\n    self.__multiclient_mode = False  # handles multi-client mode state\n\n    # define Bidirectional mode\n    self.__bi_mode = False  # handles Bidirectional mode state\n\n    # define Secure mode\n    valid_security_mech = {0: \"Grasslands\", 1: \"StoneHouse\", 2: \"IronHouse\"}\n    self.__secure_mode = 0  # handles ZMQ security layer status\n    auth_cert_dir = \"\"  # handles valid ZMQ certificates dir\n    self.__auth_publickeys_dir = \"\"  # handles valid ZMQ public certificates dir\n    self.__auth_secretkeys_dir = \"\"  # handles valid ZMQ private certificates dir\n    overwrite_cert = False  # checks if certificates overwriting allowed\n    custom_cert_location = \"\"  # handles custom ZMQ certificates path\n\n    # define frame-compression handler\n    self.__jpeg_compression = (\n        True if not (simplejpeg is None) else False\n    )  # enabled by default for all connections if simplejpeg is installed\n    self.__jpeg_compression_quality = 90  # 90% quality\n    self.__jpeg_compression_fastdct = True  # fastest DCT on by default\n    self.__jpeg_compression_fastupsample = False  # fastupsample off by default\n    self.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\n\n    # defines frame compression on return data\n    self.__ex_compression_params = None\n\n    # define receiver return data handler\n    self.__return_data = None\n\n    # generate 8-digit random system id\n    self.__id = \"\".join(\n        secrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n    )\n\n    # define termination flag\n    self.__terminate = False\n\n    # additional settings for reliability\n    if pattern &lt; 2:\n        # define zmq poller for reliable transmission\n        self.__poll = zmq.Poller()\n        # define max retries\n        self.__max_retries = 3\n        # request timeout\n        self.__request_timeout = 4000  # 4 secs\n    else:\n        # subscriber timeout\n        self.__subscriber_timeout = None\n\n    # Handle user-defined options dictionary values\n    # reformat dictionary\n    options = {str(k).strip(): v for k, v in options.items()}\n\n    # loop over dictionary key &amp; values and assign to global variables if valid\n    for key, value in options.items():\n        # handle multi-server mode\n        if key == \"multiserver_mode\" and isinstance(value, bool):\n            # check if valid pattern assigned\n            if pattern &gt; 0:\n                # activate Multi-server mode\n                self.__multiserver_mode = value\n            else:\n                # otherwise disable it and raise error\n                self.__multiserver_mode = False\n                logger.critical(\"Multi-Server Mode is disabled!\")\n                raise ValueError(\n                    \"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\".format(\n                        pattern\n                    )\n                )\n\n        # handle multi-client mode\n        elif key == \"multiclient_mode\" and isinstance(value, bool):\n            # check if valid pattern assigned\n            if pattern &gt; 0:\n                # activate Multi-client mode\n                self.__multiclient_mode = value\n            else:\n                # otherwise disable it and raise error\n                self.__multiclient_mode = False\n                logger.critical(\"Multi-Client Mode is disabled!\")\n                raise ValueError(\n                    \"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\".format(\n                        pattern\n                    )\n                )\n\n        # handle bidirectional mode\n        elif key == \"bidirectional_mode\" and isinstance(value, bool):\n            # check if pattern is valid\n            if pattern &lt; 2:\n                # activate Bidirectional mode if specified\n                self.__bi_mode = value\n            else:\n                # otherwise disable it and raise error\n                self.__bi_mode = False\n                logger.warning(\"Bidirectional data transmission is disabled!\")\n                raise ValueError(\n                    \"[NetGear:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\n                        pattern\n                    )\n                )\n\n        # handle secure mode\n        elif (\n            key == \"secure_mode\"\n            and isinstance(value, int)\n            and (value in valid_security_mech)\n        ):\n            self.__secure_mode = value\n\n        elif key == \"custom_cert_location\" and isinstance(value, str):\n            # verify custom auth certificates path for secure mode\n            custom_cert_location = os.path.abspath(value)\n            assert os.path.isdir(\n                custom_cert_location\n            ), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\"\n            assert check_WriteAccess(\n                custom_cert_location,\n                is_windows=True if os.name == \"nt\" else False,\n                logging=self.__logging,\n            ), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to '{}' directory!\".format(\n                value\n            )\n        elif key == \"overwrite_cert\" and isinstance(value, bool):\n            # enable/disable auth certificate overwriting in secure mode\n            overwrite_cert = value\n\n        # handle ssh-tunneling mode\n        elif key == \"ssh_tunnel_mode\" and isinstance(value, str):\n            # enable SSH Tunneling Mode\n            self.__ssh_tunnel_mode = value.strip()\n        elif key == \"ssh_tunnel_pwd\" and isinstance(value, str):\n            # add valid SSH Tunneling password\n            self.__ssh_tunnel_pwd = value\n        elif key == \"ssh_tunnel_keyfile\" and isinstance(value, str):\n            # add valid SSH Tunneling key-file\n            self.__ssh_tunnel_keyfile = value if os.path.isfile(value) else None\n            if self.__ssh_tunnel_keyfile is None:\n                logger.warning(\n                    \"Discarded invalid or non-existential SSH Tunnel Key-file at {}!\".format(\n                        value\n                    )\n                )\n\n        # handle jpeg compression\n        elif (\n            key == \"jpeg_compression\"\n            and not (simplejpeg is None)\n            and isinstance(value, (bool, str))\n        ):\n            if isinstance(value, str) and value.strip().upper() in [\n                \"RGB\",\n                \"BGR\",\n                \"RGBX\",\n                \"BGRX\",\n                \"XBGR\",\n                \"XRGB\",\n                \"GRAY\",\n                \"RGBA\",\n                \"BGRA\",\n                \"ABGR\",\n                \"ARGB\",\n                \"CMYK\",\n            ]:\n                # set encoding colorspace\n                self.__jpeg_compression_colorspace = value.strip().upper()\n                # enable frame-compression encoding value\n                self.__jpeg_compression = True\n            else:\n                # enable frame-compression encoding value\n                self.__jpeg_compression = value\n        elif key == \"jpeg_compression_quality\" and isinstance(value, (int, float)):\n            # set valid jpeg quality\n            if value &gt;= 10 and value &lt;= 100:\n                self.__jpeg_compression_quality = int(value)\n            else:\n                logger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\n        elif key == \"jpeg_compression_fastdct\" and isinstance(value, bool):\n            # enable jpeg fastdct\n            self.__jpeg_compression_fastdct = value\n        elif key == \"jpeg_compression_fastupsample\" and isinstance(value, bool):\n            # enable jpeg  fastupsample\n            self.__jpeg_compression_fastupsample = value\n\n        # assign maximum retries in synchronous patterns\n        elif key == \"max_retries\" and isinstance(value, int) and pattern &lt; 2:\n            if value &gt;= 0:\n                self.__max_retries = value\n            else:\n                logger.warning(\"Invalid `max_retries` value skipped!\")\n\n        # assign request timeout in synchronous patterns\n        elif key == \"request_timeout\" and isinstance(value, int) and pattern &lt; 2:\n            if value &gt;= 4:\n                self.__request_timeout = value * 1000  # covert to milliseconds\n            else:\n                logger.warning(\"Invalid `request_timeout` value skipped!\")\n\n        # assign subscriber timeout\n        elif (\n            key == \"subscriber_timeout\" and isinstance(value, int) and pattern == 2\n        ):\n            if value &gt; 0:\n                self.__subscriber_timeout = value * 1000  # covert to milliseconds\n            else:\n                logger.warning(\"Invalid `request_timeout` value skipped!\")\n\n        # handle ZMQ flags\n        elif key == \"flag\" and isinstance(value, int):\n            self.__msg_flag = value\n            self.__msg_flag and logger.warning(\n                \"The flag optional value is set to `1` (NOBLOCK) for this run. This might cause NetGear to not terminate gracefully.\"\n            )\n        elif key == \"copy\" and isinstance(value, bool):\n            self.__msg_copy = value\n        elif key == \"track\" and isinstance(value, bool):\n            self.__msg_track = value\n            self.__msg_copy and self.__msg_track and logger.info(\n                \"The `track` optional value will be ignored for this run because `copy=True` is also defined.\"\n            )\n        else:\n            pass\n\n    # Handle ssh tunneling if enabled\n    if not (self.__ssh_tunnel_mode is None):\n        # SSH Tunnel Mode only available for server mode\n        if receive_mode:\n            logger.error(\"SSH Tunneling cannot be enabled for Client-end!\")\n        else:\n            # check if SSH tunneling possible\n            ssh_address = self.__ssh_tunnel_mode\n            ssh_address, ssh_port = (\n                ssh_address.split(\":\")\n                if \":\" in ssh_address\n                else [ssh_address, \"22\"]\n            )  # default to port 22\n            if \"47\" in ssh_port:\n                self.__ssh_tunnel_mode = self.__ssh_tunnel_mode.replace(\n                    \":47\", \"\"\n                )  # port-47 is reserved for testing\n            else:\n                # extract ip for validation\n                ssh_user, ssh_ip = (\n                    ssh_address.split(\"@\")\n                    if \"@\" in ssh_address\n                    else [\"\", ssh_address]\n                )\n                # validate ip specified port\n                assert check_open_port(\n                    ssh_ip, port=int(ssh_port)\n                ), \"[NetGear:ERROR] :: Host `{}` is not available for SSH Tunneling at port-{}!\".format(\n                    ssh_address, ssh_port\n                )\n\n    # Handle multiple exclusive modes if enabled\n    if self.__multiclient_mode and self.__multiserver_mode:\n        raise ValueError(\n            \"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\"\n        )\n    elif self.__multiserver_mode or self.__multiclient_mode:\n        # check if Bidirectional Mode also enabled\n        if self.__bi_mode:\n            # log it\n            self.__logging and logger.debug(\n                \"Bidirectional Data Transmission is also enabled for this connection!\"\n            )\n        # check if SSH Tunneling Mode also enabled\n        if self.__ssh_tunnel_mode:\n            # raise error\n            raise ValueError(\n                \"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\".format(\n                    \"Multi-Server\" if self.__multiserver_mode else \"Multi-Client\"\n                )\n            )\n    elif self.__bi_mode:\n        # log Bidirectional mode activation\n        self.__logging and logger.debug(\n            \"Bidirectional Data Transmission is enabled for this connection!\"\n        )\n    elif self.__ssh_tunnel_mode:\n        # log Bidirectional mode activation\n        self.__logging and logger.debug(\n            \"SSH Tunneling is enabled for host:`{}` with `{}` back-end.\".format(\n                self.__ssh_tunnel_mode,\n                \"paramiko\" if self.__paramiko_present else \"pexpect\",\n            )\n        )\n\n    # On Windows, NetGear requires the ``WindowsSelectorEventLoop`` but Python 3.8 and above,\n    # defaults to an ``ProactorEventLoop`` loop that is not compatible with it. Thereby,\n    # we had to set it manually.\n    platform.system() == \"Windows\" and asyncio.set_event_loop_policy(\n        asyncio.WindowsSelectorEventLoopPolicy()\n    )\n\n    # define ZMQ messaging context instance\n    self.__msg_context = zmq.Context.instance()\n\n    # initialize and assign receive mode to global variable\n    self.__receive_mode = receive_mode\n\n    # Handle Secure mode\n    if self.__secure_mode &gt; 0:\n        # activate and log if overwriting is enabled\n        if receive_mode:\n            overwrite_cert = False\n            overwrite_cert and logger.warning(\n                \"Overwriting ZMQ Authentication certificates is disabled for Client's end!\"\n            )\n        else:\n            overwrite_cert and self.__logging and logger.info(\n                \"Overwriting ZMQ Authentication certificates over previous ones!\"\n            )\n\n        # Validate certificate generation paths\n        # Start threaded authenticator for this context\n        try:\n            # check if custom certificates path is specified\n            if custom_cert_location:\n                (\n                    auth_cert_dir,\n                    self.__auth_secretkeys_dir,\n                    self.__auth_publickeys_dir,\n                ) = generate_auth_certificates(\n                    custom_cert_location, overwrite=overwrite_cert, logging=logging\n                )\n            else:\n                # otherwise auto-generate suitable path\n                (\n                    auth_cert_dir,\n                    self.__auth_secretkeys_dir,\n                    self.__auth_publickeys_dir,\n                ) = generate_auth_certificates(\n                    os.path.join(expanduser(\"~\"), \".vidgear\"),\n                    overwrite=overwrite_cert,\n                    logging=logging,\n                )\n            # log it\n            self.__logging and logger.debug(\n                \"`{}` is the default location for storing ZMQ authentication certificates/keys.\".format(\n                    auth_cert_dir\n                )\n            )\n\n            # start an authenticator for this context\n            self.__z_auth = ThreadAuthenticator(self.__msg_context)\n            self.__z_auth.start()\n            self.__z_auth.allow(str(address))  # allow current address\n\n            # check if `IronHouse` is activated\n            if self.__secure_mode == 2:\n                # tell authenticator to use the certificate from given valid dir\n                self.__z_auth.configure_curve(\n                    domain=\"*\", location=self.__auth_publickeys_dir\n                )\n            else:\n                # otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated\n                self.__z_auth.configure_curve(\n                    domain=\"*\", location=auth.CURVE_ALLOW_ANY\n                )\n        except zmq.ZMQError as e:\n            if \"Address in use\" in str(e):\n                logger.info(\"ZMQ Authenticator already running.\")\n            else:\n                # catch if any error occurred and disable Secure mode\n                logger.exception(str(e))\n                self.__secure_mode = 0\n                logger.error(\n                    \"ZMQ Security Mechanism is disabled for this connection due to errors!\"\n                )\n\n    # check whether `receive_mode` is enabled\n    if self.__receive_mode:\n        # define connection address\n        address = \"*\" if address is None else address\n\n        # check if multiserver_mode is enabled\n        if self.__multiserver_mode:\n            # check if unique server port address list/tuple is assigned or not in multiserver_mode\n            if port is None or not isinstance(port, (tuple, list)):\n                # raise error if not\n                raise ValueError(\n                    \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\"\n                )\n            else:\n                # otherwise log it\n                logger.debug(\n                    \"Enabling Multi-Server Mode at PORTS: {}!\".format(port)\n                )\n            # create port address buffer for keeping track of connected client's port(s)\n            self.__port_buffer = []\n        # check if multiclient_mode is enabled\n        elif self.__multiclient_mode:\n            # check if unique server port address is assigned or not in multiclient_mode\n            if port is None:\n                # raise error if not\n                raise ValueError(\n                    \"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Client-end. For more information refer VidGear docs.\"\n                )\n            else:\n                # otherwise log it\n                logger.debug(\n                    \"Enabling Multi-Client Mode at PORT: {} on this device!\".format(\n                        port\n                    )\n                )\n            # assign value to global variable\n            self.__port = port\n        else:\n            # otherwise assign local port address if None\n            port = \"5555\" if port is None else port\n\n        try:\n            # define thread-safe messaging socket\n            self.__msg_socket = self.__msg_context.socket(msg_pattern[1])\n\n            # define pub-sub flag\n            self.__pattern == 2 and self.__msg_socket.set_hwm(1)\n\n            # enable specified secure mode for the socket\n            if self.__secure_mode &gt; 0:\n                # load server key\n                server_secret_file = os.path.join(\n                    self.__auth_secretkeys_dir, \"server.key_secret\"\n                )\n                server_public, server_secret = auth.load_certificate(\n                    server_secret_file\n                )\n                # load  all CURVE keys\n                self.__msg_socket.curve_secretkey = server_secret\n                self.__msg_socket.curve_publickey = server_public\n                # enable CURVE connection for this socket\n                self.__msg_socket.curve_server = True\n\n            # define exclusive socket options for `patterns=2`\n            if self.__pattern == 2:\n                self.__msg_socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n                self.__subscriber_timeout and self.__msg_socket.setsockopt(\n                    zmq.RCVTIMEO, self.__subscriber_timeout\n                )\n                self.__subscriber_timeout and self.__msg_socket.setsockopt(\n                    zmq.LINGER, 0\n                )\n\n            # if multiserver_mode is enabled, then assign port addresses to zmq socket\n            if self.__multiserver_mode:\n                # bind socket to given server protocol, address and ports\n                for pt in port:\n                    self.__msg_socket.bind(\n                        protocol + \"://\" + str(address) + \":\" + str(pt)\n                    )\n            else:\n                # bind socket to given protocol, address and port normally\n                self.__msg_socket.bind(\n                    protocol + \"://\" + str(address) + \":\" + str(port)\n                )\n\n            # additional settings\n            if pattern &lt; 2:\n                if self.__multiserver_mode:\n                    self.__connection_address = []\n                    for pt in port:\n                        self.__connection_address.append(\n                            protocol + \"://\" + str(address) + \":\" + str(pt)\n                        )\n                else:\n                    self.__connection_address = (\n                        protocol + \"://\" + str(address) + \":\" + str(port)\n                    )\n                self.__msg_pattern = msg_pattern[1]\n                self.__poll.register(self.__msg_socket, zmq.POLLIN)\n                self.__logging and logger.debug(\n                    \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\n                        self.__max_retries, self.__request_timeout / 1000\n                    )\n                )\n            else:\n                self.__logging and self.__subscriber_timeout and logger.debug(\n                    \"Timeout: {} secs is enabled for this system.\".format(\n                        self.__subscriber_timeout / 1000\n                    )\n                )\n\n        except Exception as e:\n            # otherwise log and raise error\n            logger.exception(str(e))\n            # Handle Secure Mode\n            self.__secure_mode and logger.critical(\n                \"Failed to activate Secure Mode: `{}` for this connection!\".format(\n                    valid_security_mech[self.__secure_mode]\n                )\n            )\n            # raise errors for exclusive modes\n            if self.__multiserver_mode or self.__multiclient_mode:\n                raise RuntimeError(\n                    \"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n                        (\n                            \"Multi-Server\"\n                            if self.__multiserver_mode\n                            else \"Multi-Client\"\n                        ),\n                        (protocol + \"://\" + str(address) + \":\" + str(port)),\n                        pattern,\n                    )\n                )\n            else:\n                self.__bi_mode and logger.critical(\n                    \"Failed to activate Bidirectional Mode for this connection!\"\n                )\n                raise RuntimeError(\n                    \"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n                        (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                    )\n                )\n\n        # Handle threaded queue mode\n        self.__logging and logger.debug(\n            \"Threaded Queue Mode is enabled by default for this connection.\"\n        )\n\n        # define deque and assign it to global var\n        self.__queue = deque(maxlen=96)  # max len 96 to check overflow\n\n        # initialize and start threaded recv_handler\n        self.__thread = Thread(target=self.__recv_handler, name=\"NetGear\", args=())\n        self.__thread.daemon = True\n        self.__thread.start()\n\n        if self.__logging:\n            # finally log progress\n            logger.debug(\n                \"Successfully Binded to address: {} with pattern: {}.\".format(\n                    (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                )\n            )\n            self.__jpeg_compression and logger.debug(\n                \"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\n                    self.__jpeg_compression_colorspace,\n                    self.__jpeg_compression_quality,\n                    (\"enabled\" if self.__jpeg_compression_fastdct else \"disabled\"),\n                    (\n                        \"enabled\"\n                        if self.__jpeg_compression_fastupsample\n                        else \"disabled\"\n                    ),\n                )\n            )\n            self.__secure_mode and logger.debug(\n                \"Successfully enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\n                    valid_security_mech[self.__secure_mode]\n                )\n            )\n            logger.debug(\"Multi-threaded Receive Mode is successfully enabled.\")\n            logger.debug(\"Unique System ID is {}.\".format(self.__id))\n            logger.debug(\"Receive Mode is now activated.\")\n\n    else:\n        # otherwise default to `Send Mode`\n        # define connection address\n        address = \"localhost\" if address is None else address\n\n        # check if multiserver_mode is enabled\n        if self.__multiserver_mode:\n            # check if unique server port address is assigned or not in multiserver_mode\n            if port is None:\n                # raise error if not\n                raise ValueError(\n                    \"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Server-end. For more information refer VidGear docs.\"\n                )\n            else:\n                # otherwise log it\n                logger.debug(\n                    \"Enabling Multi-Server Mode at PORT: {} on this device!\".format(\n                        port\n                    )\n                )\n            # assign value to global variable\n            self.__port = port\n        # check if multiclient_mode is enabled\n        elif self.__multiclient_mode:\n            # check if unique client port address list/tuple is assigned or not in multiclient_mode\n            if port is None or not isinstance(port, (tuple, list)):\n                # raise error if not\n                raise ValueError(\n                    \"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\"\n                )\n            else:\n                # otherwise log it\n                logger.debug(\n                    \"Enabling Multi-Client Mode at PORTS: {}!\".format(port)\n                )\n            # create port address buffer for keeping track of connected client ports\n            self.__port_buffer = []\n        else:\n            # otherwise assign local port address if None\n            port = \"5555\" if port is None else port\n\n        try:\n            # define thread-safe messaging socket\n            self.__msg_socket = self.__msg_context.socket(msg_pattern[0])\n\n            # if req/rep pattern, define additional flags\n            if self.__pattern == 1:\n                self.__msg_socket.REQ_RELAXED = True\n                self.__msg_socket.REQ_CORRELATE = True\n\n            # if pub/sub pattern, define additional optimizer\n            if self.__pattern == 2:\n                self.__msg_socket.set_hwm(1)\n\n            # enable specified secure mode for the socket\n            if self.__secure_mode &gt; 0:\n                # load client key\n                client_secret_file = os.path.join(\n                    self.__auth_secretkeys_dir, \"client.key_secret\"\n                )\n                client_public, client_secret = auth.load_certificate(\n                    client_secret_file\n                )\n                # load  all CURVE keys\n                self.__msg_socket.curve_secretkey = client_secret\n                self.__msg_socket.curve_publickey = client_public\n                # load server key\n                server_public_file = os.path.join(\n                    self.__auth_publickeys_dir, \"server.key\"\n                )\n                server_public, _ = auth.load_certificate(server_public_file)\n                # inject public key to make a CURVE connection.\n                self.__msg_socket.curve_serverkey = server_public\n\n            # check if multi-client_mode is enabled\n            if self.__multiclient_mode:\n                # bind socket to given server protocol, address and ports\n                for pt in port:\n                    self.__msg_socket.connect(\n                        protocol + \"://\" + str(address) + \":\" + str(pt)\n                    )\n            else:\n                # handle SSH tunneling if enabled\n                if self.__ssh_tunnel_mode:\n                    # establish tunnel connection\n                    ssh.tunnel_connection(\n                        self.__msg_socket,\n                        protocol + \"://\" + str(address) + \":\" + str(port),\n                        self.__ssh_tunnel_mode,\n                        keyfile=self.__ssh_tunnel_keyfile,\n                        password=self.__ssh_tunnel_pwd,\n                        paramiko=self.__paramiko_present,\n                    )\n                else:\n                    # connect socket to given protocol, address and port\n                    self.__msg_socket.connect(\n                        protocol + \"://\" + str(address) + \":\" + str(port)\n                    )\n\n            # additional settings\n            if pattern &lt; 2:\n                if self.__multiclient_mode:\n                    self.__connection_address = []\n                    for pt in port:\n                        self.__connection_address.append(\n                            protocol + \"://\" + str(address) + \":\" + str(pt)\n                        )\n                else:\n                    self.__connection_address = (\n                        protocol + \"://\" + str(address) + \":\" + str(port)\n                    )\n                self.__msg_pattern = msg_pattern[0]\n                self.__poll.register(self.__msg_socket, zmq.POLLIN)\n\n                self.__logging and logger.debug(\n                    \"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\n                        self.__max_retries, self.__request_timeout / 1000\n                    )\n                )\n\n        except Exception as e:\n            # otherwise log and raise error\n            logger.exception(str(e))\n            # Handle Secure Mode\n            self.__secure_mode and logger.critical(\n                \"Failed to activate Secure Mode: `{}` for this connection!\".format(\n                    valid_security_mech[self.__secure_mode]\n                )\n            )\n            # raise errors for exclusive modes\n            if self.__multiserver_mode or self.__multiclient_mode:\n                raise RuntimeError(\n                    \"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n                        (\n                            \"Multi-Server\"\n                            if self.__multiserver_mode\n                            else \"Multi-Client\"\n                        ),\n                        (protocol + \"://\" + str(address) + \":\" + str(port)),\n                        pattern,\n                    )\n                )\n            else:\n                self.__bi_mode and logger.critical(\n                    \"Failed to activate Bidirectional Mode for this connection!\"\n                )\n                self.__ssh_tunnel_mode and logger.critical(\n                    \"Failed to initiate SSH Tunneling Mode for this server with `{}` back-end!\".format(\n                        \"paramiko\" if self.__paramiko_present else \"pexpect\"\n                    )\n                )\n                raise RuntimeError(\n                    \"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n                        (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                    )\n                )\n\n        if self.__logging:\n            # finally log progress\n            logger.debug(\n                \"Successfully connected to address: {} with pattern: {}.\".format(\n                    (protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n                )\n            )\n            self.__jpeg_compression and logger.debug(\n                \"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\n                    self.__jpeg_compression_colorspace,\n                    self.__jpeg_compression_quality,\n                    (\"enabled\" if self.__jpeg_compression_fastdct else \"disabled\"),\n                    (\n                        \"enabled\"\n                        if self.__jpeg_compression_fastupsample\n                        else \"disabled\"\n                    ),\n                )\n            )\n            self.__secure_mode and logger.debug(\n                \"Enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\n                    valid_security_mech[self.__secure_mode]\n                )\n            )\n            logger.debug(\"Unique System ID is {}.\".format(self.__id))\n            logger.debug(\n                \"Send Mode is successfully activated and ready to send data.\"\n            )\n</code></pre>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.close","title":"<code>close(self, kill=False)</code>","text":"<p>Safely terminates the threads, and NetGear resources.</p> <p>Parameters:</p> Name Type Description Default <code>kill</code> <code>bool</code> <p>Kills ZMQ context instead of graceful exiting in receive mode.</p> <code>False</code> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def close(self, kill=False):\n    \"\"\"\n    Safely terminates the threads, and NetGear resources.\n\n    Parameters:\n        kill (bool): Kills ZMQ context instead of graceful exiting in receive mode.\n    \"\"\"\n    # log it\n    self.__logging and logger.debug(\n        \"Terminating various {} Processes.\".format(\n            \"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n        )\n    )\n    #  whether `receive_mode` is enabled or not\n    if self.__receive_mode:\n        # check whether queue mode is empty\n        if not (self.__queue is None) and self.__queue:\n            self.__queue.clear()\n        # call immediate termination\n        self.__terminate = True\n        # properly close the socket\n        self.__logging and logger.debug(\"Terminating. Please wait...\")\n        # Handle Secure Mode Thread\n        if self.__z_auth:\n            self.__logging and logger.debug(\"Terminating Authenticator Thread.\")\n            self.__z_auth.stop()\n            while self.__z_auth.is_alive():\n                pass\n        # wait until stream resources are released\n        # (producer thread might be still grabbing frame)\n        if self.__thread is not None:\n            self.__logging and logger.debug(\"Terminating Main Thread.\")\n            # properly handle thread exit\n            if self.__thread.is_alive() and kill:\n                # force close if still alive\n                logger.warning(\"Thread still running...Killing it forcefully!\")\n                self.__msg_context.destroy()\n                self.__thread.join()\n            else:\n                self.__msg_socket.close(linger=0)\n                self.__thread.join()\n            self.__thread = None\n        self.__logging and logger.debug(\"Terminated Successfully!\")\n    else:\n        # indicate that process should be terminated\n        self.__terminate = True\n        # log if kill enabled\n        kill and logger.warning(\n            \"`kill` parmeter is only available in the receive mode.\"\n        )\n        # Handle Secure Mode Thread\n        if self.__z_auth:\n            self.__logging and logger.debug(\"Terminating Authenticator Thread.\")\n            self.__z_auth.stop()\n            while self.__z_auth.is_alive():\n                pass\n        # check if all attempts of reconnecting failed, then skip to closure\n        if (self.__pattern &lt; 2 and not self.__max_retries) or (\n            self.__multiclient_mode and not self.__port_buffer\n        ):\n            try:\n                # properly close the socket\n                self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                self.__msg_socket.close()\n            except ZMQError:\n                pass\n            finally:\n                # exit\n                return\n\n        if self.__multiserver_mode:\n            # check if multiserver_mode\n            # send termination flag to client with its unique port\n            term_dict = dict(terminate_flag=True, port=self.__port)\n        else:\n            # otherwise send termination flag to client\n            term_dict = dict(terminate_flag=True)\n\n        try:\n            if self.__multiclient_mode:\n                for _ in self.__port_buffer:\n                    self.__msg_socket.send_json(term_dict)\n            else:\n                self.__msg_socket.send_json(term_dict)\n\n            # check for confirmation if available within 1/5 timeout\n            if self.__pattern &lt; 2:\n                self.__logging and logger.debug(\"Terminating. Please wait...\")\n                if self.__msg_socket.poll(self.__request_timeout // 5, zmq.POLLIN):\n                    self.__msg_socket.recv()\n        except Exception as e:\n            if not isinstance(e, ZMQError):\n                logger.exception(str(e))\n        finally:\n            # properly close the socket\n            self.__msg_socket.setsockopt(zmq.LINGER, 0)\n            self.__msg_socket.close()\n            self.__logging and logger.debug(\"Terminated Successfully!\")\n</code></pre>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.recv","title":"<code>recv(self, return_data=None)</code>","text":"<p>A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Parameters:</p> Name Type Description Default <code>return_data</code> <code>any</code> <p>inputs return data (of any datatype), for sending back to Server.</p> <code>None</code> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def recv(self, return_data=None):\n    \"\"\"\n    A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a\n    fixed-length frame buffer in the memory, and blocks the thread if the deque is full.\n\n    Parameters:\n        return_data (any): inputs return data _(of any datatype)_, for sending back to Server.\n\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n    # check whether `receive mode` is activated\n    if not (self.__receive_mode):\n        # raise value error and exit\n        self.__terminate = True\n        raise ValueError(\n            \"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\"\n        )\n\n    # handle Bidirectional return data\n    if (self.__bi_mode or self.__multiclient_mode) and not (return_data is None):\n        self.__return_data = return_data\n\n    # check whether or not termination flag is enabled\n    while not self.__terminate:\n        try:\n            # check if queue is empty\n            if len(self.__queue) &gt; 0:\n                return self.__queue.popleft()\n            else:\n                time.sleep(0.00001)\n                continue\n        except KeyboardInterrupt:\n            self.__terminate = True\n            break\n    # otherwise return NoneType\n    return None\n</code></pre>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.send","title":"<code>send(self, frame, message=None)</code>","text":"<p>A Server end method, that sends the data and frames over the network to Client(s).</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> required <code>message</code> <code>any</code> <p>input for sending additional data (of any datatype except <code>numpy.ndarray</code>) to Client(s).</p> <code>None</code> <p>Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type.</p> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def send(self, frame, message=None):\n    \"\"\"\n    A Server end method, that sends the data and frames over the network to Client(s).\n\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s).\n\n    **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type.\n\n    \"\"\"\n    # check whether `receive_mode` is disabled\n    if self.__receive_mode:\n        # raise value error and exit\n        self.__terminate = True\n        raise ValueError(\n            \"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\"\n        )\n\n    if not (message is None) and isinstance(message, np.ndarray):\n        logger.warning(\n            \"Skipped unsupported `message` of datatype: {}!\".format(\n                type(message).__name__\n            )\n        )\n        message = None\n\n    # define exit_flag and assign value\n    exit_flag = True if (frame is None or self.__terminate) else False\n\n    # check whether exit_flag is False\n    if not (exit_flag) and not (frame.flags[\"C_CONTIGUOUS\"]):\n        # check whether the incoming frame is contiguous\n        frame = np.ascontiguousarray(frame, dtype=frame.dtype)\n\n    # handle JPEG compression encoding\n    if self.__jpeg_compression:\n        if self.__jpeg_compression_colorspace == \"GRAY\":\n            if frame.ndim == 2:\n                # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                frame = np.expand_dims(frame, axis=2)\n            frame = simplejpeg.encode_jpeg(\n                frame,\n                quality=self.__jpeg_compression_quality,\n                colorspace=self.__jpeg_compression_colorspace,\n                fastdct=self.__jpeg_compression_fastdct,\n            )\n        else:\n            frame = simplejpeg.encode_jpeg(\n                frame,\n                quality=self.__jpeg_compression_quality,\n                colorspace=self.__jpeg_compression_colorspace,\n                colorsubsampling=\"422\",\n                fastdct=self.__jpeg_compression_fastdct,\n            )\n\n    # check if multiserver_mode is activated and assign values with unique port\n    msg_dict = dict(port=self.__port) if self.__multiserver_mode else dict()\n\n    # prepare the exclusive json dict\n    msg_dict.update(\n        dict(\n            terminate_flag=exit_flag,\n            compression=(\n                {\n                    \"dct\": self.__jpeg_compression_fastdct,\n                    \"ups\": self.__jpeg_compression_fastupsample,\n                    \"colorspace\": self.__jpeg_compression_colorspace,\n                }\n                if self.__jpeg_compression\n                else False\n            ),\n            message=message,\n            pattern=str(self.__pattern),\n            dtype=str(frame.dtype) if not (self.__jpeg_compression) else \"\",\n            shape=frame.shape if not (self.__jpeg_compression) else \"\",\n        )\n    )\n\n    # send the json dict\n    self.__msg_socket.send_json(msg_dict, self.__msg_flag | zmq.SNDMORE)\n    # send the frame array with correct flags\n    self.__msg_socket.send(\n        frame, flags=self.__msg_flag, copy=self.__msg_copy, track=self.__msg_track\n    )\n\n    # check if synchronous patterns, then wait for confirmation\n    if self.__pattern &lt; 2:\n        # check if Bidirectional data transmission is enabled\n        if self.__bi_mode or self.__multiclient_mode:\n            # handles return data\n            recvd_data = None\n\n            socks = dict(self.__poll.poll(self.__request_timeout))\n            if socks.get(self.__msg_socket) == zmq.POLLIN:\n                # handle return data\n                recv_json = self.__msg_socket.recv_json(flags=self.__msg_flag)\n            else:\n                logger.critical(\"No response from Client, Reconnecting again...\")\n                # Socket is confused. Close and remove it.\n                self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                self.__msg_socket.close()\n                self.__poll.unregister(self.__msg_socket)\n                self.__max_retries -= 1\n\n                if not (self.__max_retries):\n                    if self.__multiclient_mode:\n                        logger.error(\n                            \"All Clients failed to respond on multiple attempts.\"\n                        )\n                    else:\n                        logger.error(\n                            \"Client failed to respond on multiple attempts.\"\n                        )\n                    self.__terminate = True\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\"\n                    )\n\n                # Create new connection\n                self.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\n                if isinstance(self.__connection_address, list):\n                    for _connection in self.__connection_address:\n                        self.__msg_socket.connect(_connection)\n                else:\n                    # handle SSH tunneling if enabled\n                    if self.__ssh_tunnel_mode:\n                        # establish tunnel connection\n                        ssh.tunnel_connection(\n                            self.__msg_socket,\n                            self.__connection_address,\n                            self.__ssh_tunnel_mode,\n                            keyfile=self.__ssh_tunnel_keyfile,\n                            password=self.__ssh_tunnel_pwd,\n                            paramiko=self.__paramiko_present,\n                        )\n                    else:\n                        # connect normally\n                        self.__msg_socket.connect(self.__connection_address)\n                self.__poll.register(self.__msg_socket, zmq.POLLIN)\n                # return None for mean-time\n                return None\n\n            # save the unique port addresses\n            if (\n                self.__multiclient_mode\n                and not recv_json[\"port\"] in self.__port_buffer\n            ):\n                self.__port_buffer.append(recv_json[\"port\"])\n\n            if recv_json[\"return_type\"] == \"ndarray\":\n                recv_array = self.__msg_socket.recv(\n                    flags=self.__msg_flag,\n                    copy=self.__msg_copy,\n                    track=self.__msg_track,\n                )\n                # check if encoding was enabled\n                if recv_json[\"compression\"]:\n                    # decode JPEG frame\n                    recvd_data = simplejpeg.decode_jpeg(\n                        recv_array,\n                        colorspace=recv_json[\"compression\"][\"colorspace\"],\n                        fastdct=self.__jpeg_compression_fastdct\n                        or recv_json[\"compression\"][\"dct\"],\n                        fastupsample=self.__jpeg_compression_fastupsample\n                        or recv_json[\"compression\"][\"ups\"],\n                    )\n                    # check if valid frame returned\n                    if recvd_data is None:\n                        self.__terminate = True\n                        # otherwise raise error and exit\n                        raise RuntimeError(\n                            \"[NetGear:ERROR] :: Received compressed frame `{}` decoding failed with flag: {}.\".format(\n                                recv_json[\"compression\"],\n                                self.__ex_compression_params,\n                            )\n                        )\n\n                    if (\n                        recv_json[\"compression\"][\"colorspace\"] == \"GRAY\"\n                        and recvd_data.ndim == 3\n                    ):\n                        # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                        recvd_data = np.squeeze(recvd_data, axis=2)\n                else:\n                    recvd_data = np.frombuffer(\n                        recv_array, dtype=recv_json[\"array_dtype\"]\n                    ).reshape(recv_json[\"array_shape\"])\n            else:\n                recvd_data = recv_json[\"data\"]\n\n            return (\n                (recv_json[\"port\"], recvd_data)\n                if self.__multiclient_mode\n                else recvd_data\n            )\n        else:\n            # otherwise log normally\n            socks = dict(self.__poll.poll(self.__request_timeout))\n            if socks.get(self.__msg_socket) == zmq.POLLIN:\n                recv_confirmation = self.__msg_socket.recv()\n            else:\n                logger.critical(\"No response from Client, Reconnecting again...\")\n                # Socket is confused. Close and remove it.\n                self.__msg_socket.setsockopt(zmq.LINGER, 0)\n                self.__msg_socket.close()\n                self.__poll.unregister(self.__msg_socket)\n                self.__max_retries -= 1\n\n                if not (self.__max_retries):\n                    logger.error(\"Client failed to respond on repeated attempts.\")\n                    self.__terminate = True\n                    raise RuntimeError(\n                        \"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\"\n                    )\n\n                # Create new connection\n                self.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\n                # handle SSH tunneling if enabled\n                if self.__ssh_tunnel_mode:\n                    # establish tunnel connection\n                    ssh.tunnel_connection(\n                        self.__msg_socket,\n                        self.__connection_address,\n                        self.__ssh_tunnel_mode,\n                        keyfile=self.__ssh_tunnel_keyfile,\n                        password=self.__ssh_tunnel_pwd,\n                        paramiko=self.__paramiko_present,\n                    )\n                else:\n                    # connect normally\n                    self.__msg_socket.connect(self.__connection_address)\n                self.__poll.register(self.__msg_socket, zmq.POLLIN)\n                return None\n\n            # log confirmation\n            self.__logging and logger.debug(recv_confirmation)\n</code></pre>"},{"location":"bonus/reference/netgear_async/","title":"API References","text":"<p>NetGear_Async API usage examples can be found here \u27b6</p> <p>NetGear_Async API parameters are explained here \u27b6</p> <p>NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes.</p> <p>NetGear_Async is built on <code>zmq.asyncio</code>, and powered by a high-performance asyncio event loop called uvloop to achieve unwatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system.</p> <p>NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define  our custom Server as source to transform frames easily before sending them across the network.</p> <p>NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code.</p> <p>In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> <p>NetGear_Async as of now supports four ZeroMQ messaging patterns:</p> <ul> <li><code>zmq.PAIR</code> (ZMQ Pair Pattern)</li> <li><code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern)</li> <li><code>zmq.PUB/zmq.SUB</code> (ZMQ Publish/Subscribe Pattern)</li> <li><code>zmq.PUSH/zmq.PULL</code> (ZMQ Push/Pull Pattern)</li> </ul> <p>Whereas supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>class NetGear_Async:\n    \"\"\"\n    NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various\n    options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes.\n\n    NetGear_Async is built on `zmq.asyncio`, and powered by a high-performance asyncio event loop called uvloop to achieve unwatchable high-speed and lag-free video streaming\n    over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your\n    system.\n\n    NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define\n     our custom Server as source to transform frames easily before sending them across the network.\n\n    NetGear_Async now supports additional **bidirectional data transmission** between receiver(client) and sender(server) while transferring frames.\n    Users can easily build complex applications such as like _Real-Time Video Chat_ in just few lines of code.\n\n    In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby\n    granting it exclusive power for transferring frames incoming from any source to the network.\n\n    NetGear_Async as of now supports four ZeroMQ messaging patterns:\n\n    - `zmq.PAIR` _(ZMQ Pair Pattern)_\n    - `zmq.REQ/zmq.REP` _(ZMQ Request/Reply Pattern)_\n    - `zmq.PUB/zmq.SUB` _(ZMQ Publish/Subscribe Pattern)_\n    - `zmq.PUSH/zmq.PULL` _(ZMQ Push/Pull Pattern)_\n\n    Whereas supported protocol are: `tcp` and `ipc`.\n    \"\"\"\n\n    def __init__(\n        self,\n        # NetGear_Async parameters\n        address=None,\n        port=None,\n        protocol=\"tcp\",\n        pattern=0,\n        receive_mode=False,\n        timeout=0.0,\n        # Videogear parameters\n        enablePiCamera=False,\n        stabilize=False,\n        source=None,\n        camera_num=0,\n        stream_mode=False,\n        backend=0,\n        colorspace=None,\n        resolution=(640, 480),\n        framerate=25,\n        time_delay=0,\n        # common parameters\n        logging=False,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the NetGear_Async class.\n\n        Parameters:\n            address (str): sets the valid network address of the Server/Client.\n            port (str): sets the valid Network Port of the Server/Client.\n            protocol (str): sets the valid messaging protocol between Server/Client.\n            pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n            receive_mode (bool): select the NetGear_Async's Mode of operation.\n            timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`.\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # raise error(s) for critical Class imports\n        import_dependency_safe(\n            \"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n        )\n        import_dependency_safe(\"msgpack\" if msgpack is None else \"\")\n        import_dependency_safe(\"msgpack_numpy\" if m is None else \"\")\n\n        # define valid messaging patterns =&gt; `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL)\n        valid_messaging_patterns = {\n            0: (zmq.PAIR, zmq.PAIR),\n            1: (zmq.REQ, zmq.REP),\n            2: (zmq.PUB, zmq.SUB),\n            3: (zmq.PUSH, zmq.PULL),\n        }\n\n        # check whether user-defined messaging pattern is valid\n        if isinstance(pattern, int) and pattern in valid_messaging_patterns:\n            # assign value\n            self.__msg_pattern = pattern\n            self.__pattern = valid_messaging_patterns[pattern]\n        else:\n            # otherwise default to 0:`zmq.PAIR`\n            self.__msg_pattern = 0\n            self.__pattern = valid_messaging_patterns[self.__msg_pattern]\n            self.__logging and logger.warning(\n                \"Invalid pattern {pattern}. Defaulting to `zmq.PAIR`!\".format(\n                    pattern=pattern\n                )\n            )\n\n        # check  whether user-defined messaging protocol is valid\n        if isinstance(protocol, str) and protocol in [\"tcp\", \"ipc\"]:\n            # assign value\n            self.__protocol = protocol\n        else:\n            # else default to `tcp` protocol\n            self.__protocol = \"tcp\"\n            self.__logging and logger.warning(\"Invalid protocol. Defaulting to `tcp`!\")\n\n        # initialize Termination flag\n        self.__terminate = False\n        # initialize and assign `Receive Mode`\n        self.__receive_mode = receive_mode\n        # initialize stream handler\n        self.__stream = None\n        # initialize Messaging Socket\n        self.__msg_socket = None\n        # initialize NetGear_Async's configuration dictionary\n        self.config = {}\n        # asyncio queue handler\n        self.__queue = None\n        # define Bidirectional mode\n        self.__bi_mode = False  # handles Bidirectional mode state\n\n        # assign timeout for Receiver end\n        if timeout and isinstance(timeout, (int, float)):\n            self.__timeout = float(timeout)\n        else:\n            self.__timeout = 15.0\n\n        # generate 8-digit random system id\n        self.__id = \"\".join(\n            secrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n        )\n\n        # Handle user-defined options dictionary values\n        # reformat dictionary\n        options = {str(k).strip(): v for k, v in options.items()}\n        # handle bidirectional mode\n        if \"bidirectional_mode\" in options:\n            value = options[\"bidirectional_mode\"]\n            # also check if pattern and source is valid\n            if isinstance(value, bool) and pattern &lt; 2 and source is None:\n                # activate Bidirectional mode if specified\n                self.__bi_mode = value\n            else:\n                # otherwise disable it\n                self.__bi_mode = False\n                logger.warning(\"Bidirectional data transmission is disabled!\")\n            # handle errors and logging\n            if pattern &gt;= 2:\n                # raise error\n                raise ValueError(\n                    \"[NetGear_Async:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\n                        pattern\n                    )\n                )\n            elif not (source is None):\n                raise ValueError(\n                    \"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\n                        pattern\n                    )\n                )\n            elif isinstance(value, bool) and self.__logging:\n                # log Bidirectional mode activation\n                logger.debug(\n                    \"Bidirectional Data Transmission is {} for this connection!\".format(\n                        \"enabled\" if value else \"disabled\"\n                    )\n                )\n            else:\n                logger.error(\"`bidirectional_mode` value is invalid!\")\n            # clean\n            del options[\"bidirectional_mode\"]\n\n        # Setup and assign event loop policy\n        if platform.system() == \"Windows\":\n            # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, but Python 3.8 and above,\n            # defaults to an ``ProactorEventLoop`` loop that is not compatible with it. Thereby,\n            # we had to set it manually.\n            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n        else:\n            if not (uvloop is None):\n                # Latest uvloop eventloop is only available for UNIX machines.\n                asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n            else:\n                # log if not present\n                import_dependency_safe(\"uvloop\", error=\"log\")\n\n        # Retrieve event loop and assign it\n        try:\n            self.loop = asyncio.get_running_loop()\n        except RuntimeError:\n            # otherwise create one\n            logger.critical(\"No running event loop found. Creating a new one.\")\n            self.loop = asyncio.new_event_loop()\n\n        # log eventloop for debugging\n        self.__logging and logger.info(\n            \"Using ``{}`` event loop for this process.\".format(\n                self.loop.__class__.__name__\n            )\n        )\n\n        # define messaging asynchronous Context\n        self.__msg_context = zmq.asyncio.Context()\n\n        # check whether `Receive Mode` is enabled\n        if receive_mode:\n            # assign local IP address if None\n            if address is None:\n                self.__address = \"*\"  # define address\n            else:\n                self.__address = address\n            # assign default port address if None\n            if port is None:\n                self.__port = \"5555\"\n            else:\n                self.__port = port\n        else:\n            # Handle video source\n            if source is None:\n                self.config = {\"generator\": None}\n                self.__logging and logger.warning(\"Given source is of NoneType!\")\n            else:\n                # define stream with necessary params\n                self.__stream = VideoGear(\n                    enablePiCamera=enablePiCamera,\n                    stabilize=stabilize,\n                    source=source,\n                    camera_num=camera_num,\n                    stream_mode=stream_mode,\n                    backend=backend,\n                    colorspace=colorspace,\n                    resolution=resolution,\n                    framerate=framerate,\n                    logging=logging,\n                    time_delay=time_delay,\n                    **options\n                )\n                # define default frame generator in configuration\n                self.config = {\"generator\": self.__frame_generator()}\n            # assign local ip address if None\n            if address is None:\n                self.__address = \"localhost\"\n            else:\n                self.__address = address\n            # assign default port address if None\n            if port is None:\n                self.__port = \"5555\"\n            else:\n                self.__port = port\n            # add server task handler\n            self.task = None\n\n        # create asyncio queue if bidirectional mode activated\n        self.__queue = asyncio.Queue() if self.__bi_mode else None\n\n    def launch(self):\n        \"\"\"\n        Launches an asynchronous generators and loop executors for respective task.\n        \"\"\"\n        # check if receive mode enabled\n        if self.__receive_mode:\n            self.__logging and logger.debug(\n                \"Launching NetGear_Async asynchronous generator!\"\n            )\n            # run loop executor for Receiver asynchronous generator\n            self.loop.run_in_executor(None, self.recv_generator)\n        else:\n            # Otherwise launch Server handler\n            self.__logging and logger.debug(\n                \"Creating NetGear_Async asynchronous server handler!\"\n            )\n            # create task for Server Handler\n            self.task = self.loop.create_task(self.__server_handler())\n        # return instance\n        return self\n\n    async def __server_handler(self):\n        \"\"\"\n        Handles various Server-end processes/tasks.\n        \"\"\"\n        # validate assigned frame generator in NetGear_Async configuration\n        if isinstance(self.config, dict) and \"generator\" in self.config:\n            # check if its  assigned value is a asynchronous generator\n            if self.config[\"generator\"] is None or not inspect.isasyncgen(\n                self.config[\"generator\"]\n            ):\n                # otherwise raise error\n                raise ValueError(\n                    \"[NetGear_Async:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\"\n                )\n        else:\n            # raise error if validation fails\n            raise RuntimeError(\n                \"[NetGear_Async:ERROR] :: Assigned NetGear_Async configuration is invalid!\"\n            )\n\n        # define our messaging socket\n        self.__msg_socket = self.__msg_context.socket(self.__pattern[0])\n\n        # if req/rep pattern, define additional flags\n        if self.__msg_pattern == 1:\n            self.__msg_socket.REQ_RELAXED = True\n            self.__msg_socket.REQ_CORRELATE = True\n\n        # if pub/sub pattern, define additional optimizer\n        if self.__msg_pattern == 2:\n            self.__msg_socket.set_hwm(1)\n\n        # try connecting socket to assigned protocol, address and port\n        try:\n            self.__msg_socket.connect(\n                self.__protocol + \"://\" + str(self.__address) + \":\" + str(self.__port)\n            )\n            # finally log if successful\n            self.__logging and logger.debug(\n                \"Successfully connected to address: {} with pattern: {}.\".format(\n                    (\n                        self.__protocol\n                        + \"://\"\n                        + str(self.__address)\n                        + \":\"\n                        + str(self.__port)\n                    ),\n                    self.__msg_pattern,\n                )\n            )\n            logger.critical(\n                \"Send Mode is successfully activated and ready to send data!\"\n            )\n        except Exception as e:\n            # log ad raise error if failed\n            logger.exception(str(e))\n            if self.__bi_mode:\n                logger.error(\n                    \"Failed to activate Bidirectional Mode for this connection!\"\n                )\n            raise ValueError(\n                \"[NetGear_Async:ERROR] :: Failed to connect address: {} and pattern: {}!\".format(\n                    (\n                        self.__protocol\n                        + \"://\"\n                        + str(self.__address)\n                        + \":\"\n                        + str(self.__port)\n                    ),\n                    self.__msg_pattern,\n                )\n            )\n\n        # loop over our Asynchronous frame generator\n        async for dataframe in self.config[\"generator\"]:\n            # extract data if bidirectional mode\n            if self.__bi_mode and len(dataframe) == 2:\n                (data, frame) = dataframe\n                if not (data is None) and isinstance(data, np.ndarray):\n                    logger.warning(\n                        \"Skipped unsupported `data` of datatype: {}!\".format(\n                            type(data).__name__\n                        )\n                    )\n                    data = None\n                assert isinstance(\n                    frame, np.ndarray\n                ), \"[NetGear_Async:ERROR] :: Invalid data received from server end!\"\n            elif self.__bi_mode:\n                # raise error for invalid data\n                raise ValueError(\n                    \"[NetGear_Async:ERROR] :: Send Mode only accepts tuple(data, frame) as input in Bidirectional Mode. \\\n                    Kindly refer vidgear docs!\"\n                )\n            else:\n                # otherwise just make a copy of frame\n                frame = np.copy(dataframe)\n                data = None\n\n            # check if retrieved frame is `CONTIGUOUS`\n            if not (frame.flags[\"C_CONTIGUOUS\"]):\n                # otherwise make it\n                frame = np.ascontiguousarray(frame, dtype=frame.dtype)\n\n            # create data dict\n            data_dict = dict(\n                terminate=False,\n                bi_mode=self.__bi_mode,\n                data=data if not (data is None) else \"\",\n            )\n            # encode it\n            data_enc = msgpack.packb(data_dict)\n            # send the encoded data with correct flags\n            await self.__msg_socket.send(data_enc, flags=zmq.SNDMORE)\n\n            # encode frame\n            frame_enc = msgpack.packb(frame, default=m.encode)\n            # send the encoded frame\n            await self.__msg_socket.send_multipart([frame_enc])\n\n            # check if bidirectional patterns used\n            if self.__msg_pattern &lt; 2:\n                # handle bidirectional data transfer if enabled\n                if self.__bi_mode:\n                    # get receiver encoded message withing timeout limit\n                    recvdmsg_encoded = await asyncio.wait_for(\n                        self.__msg_socket.recv(), timeout=self.__timeout\n                    )\n                    # retrieve receiver data from encoded message\n                    recvd_data = msgpack.unpackb(recvdmsg_encoded, use_list=False)\n                    # check message type\n                    if recvd_data[\"return_type\"] == \"ndarray\":  # numpy.ndarray\n                        # get encoded frame from receiver\n                        recvdframe_encoded = await asyncio.wait_for(\n                            self.__msg_socket.recv_multipart(), timeout=self.__timeout\n                        )\n                        # retrieve frame and put in queue\n                        await self.__queue.put(\n                            msgpack.unpackb(\n                                recvdframe_encoded[0],\n                                use_list=False,\n                                object_hook=m.decode,\n                            )\n                        )\n                    else:\n                        # otherwise put data directly in queue\n                        await self.__queue.put(\n                            recvd_data[\"return_data\"]\n                            if recvd_data[\"return_data\"]\n                            else None\n                        )\n                else:\n                    # otherwise log received confirmation\n                    recv_confirmation = await asyncio.wait_for(\n                        self.__msg_socket.recv(), timeout=self.__timeout\n                    )\n                    self.__logging and logger.debug(recv_confirmation)\n\n    async def recv_generator(self):\n        \"\"\"\n        A default Asynchronous Frame Generator for NetGear_Async's Receiver-end.\n        \"\"\"\n        # check whether `receive mode` is activated\n        if not (self.__receive_mode):\n            # raise Value error and exit\n            self.__terminate = True\n            raise ValueError(\n                \"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\"\n            )\n\n        # initialize and define messaging socket\n        self.__msg_socket = self.__msg_context.socket(self.__pattern[1])\n\n        # define exclusive socket options for patterns\n        if self.__msg_pattern == 2:\n            self.__msg_socket.set_hwm(1)\n            self.__msg_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\n        try:\n            # bind socket to the assigned protocol, address and port\n            self.__msg_socket.bind(\n                self.__protocol + \"://\" + str(self.__address) + \":\" + str(self.__port)\n            )\n            # finally log progress\n            self.__logging and logger.debug(\n                \"Successfully binded to address: {} with pattern: {}.\".format(\n                    (\n                        self.__protocol\n                        + \"://\"\n                        + str(self.__address)\n                        + \":\"\n                        + str(self.__port)\n                    ),\n                    self.__msg_pattern,\n                )\n            )\n            logger.critical(\"Receive Mode is activated successfully!\")\n        except Exception as e:\n            logger.exception(str(e))\n            raise RuntimeError(\n                \"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{}!\".format(\n                    (\n                        self.__protocol\n                        + \"://\"\n                        + str(self.__address)\n                        + \":\"\n                        + str(self.__port)\n                    ),\n                    self.__msg_pattern,\n                    \" and Bidirectional Mode enabled\" if self.__bi_mode else \"\",\n                )\n            )\n\n        # loop until terminated\n        while not self.__terminate:\n            # get encoded data message from server withing timeout limit\n            datamsg_encoded = await asyncio.wait_for(\n                self.__msg_socket.recv(), timeout=self.__timeout\n            )\n            # retrieve data from message\n            data = msgpack.unpackb(datamsg_encoded, use_list=False)\n            # terminate if exit` flag received from server\n            if data[\"terminate\"]:\n                # send confirmation message to server if bidirectional patterns\n                if self.__msg_pattern &lt; 2:\n                    # create termination confirmation message\n                    return_dict = dict(\n                        terminated=\"Client-`{}` successfully terminated!\".format(\n                            self.__id\n                        ),\n                    )\n                    # encode message\n                    retdata_enc = msgpack.packb(return_dict)\n                    # send message back to server\n                    await self.__msg_socket.send(retdata_enc)\n                self.__logging and logger.info(\n                    \"Termination signal received from server!\"\n                )\n                # break loop and terminate\n                self.__terminate = True\n                break\n            # get encoded frame message from server withing timeout limit\n            framemsg_encoded = await asyncio.wait_for(\n                self.__msg_socket.recv_multipart(), timeout=self.__timeout\n            )\n            # retrieve frame from message\n            frame = msgpack.unpackb(\n                framemsg_encoded[0], use_list=False, object_hook=m.decode\n            )\n\n            # check if bidirectional patterns\n            if self.__msg_pattern &lt; 2:\n                # handle bidirectional data transfer if enabled\n                if self.__bi_mode and data[\"bi_mode\"]:\n                    # handle empty queue\n                    if not self.__queue.empty():\n                        return_data = await self.__queue.get()\n                        self.__queue.task_done()\n                    else:\n                        return_data = None\n                    # check if we are returning `ndarray` frames\n                    if not (return_data is None) and isinstance(\n                        return_data, np.ndarray\n                    ):\n                        # check whether the incoming frame is contiguous\n                        if not (return_data.flags[\"C_CONTIGUOUS\"]):\n                            return_data = np.ascontiguousarray(\n                                return_data, dtype=return_data.dtype\n                            )\n\n                        # create return type dict without data\n                        rettype_dict = dict(\n                            return_type=(type(return_data).__name__),\n                            return_data=None,\n                        )\n                        # encode it\n                        rettype_enc = msgpack.packb(rettype_dict)\n                        # send it to server with correct flags\n                        await self.__msg_socket.send(rettype_enc, flags=zmq.SNDMORE)\n\n                        # encode return ndarray data\n                        retframe_enc = msgpack.packb(return_data, default=m.encode)\n                        # send it over network to server\n                        await self.__msg_socket.send_multipart([retframe_enc])\n                    else:\n                        # otherwise create type and data dict\n                        return_dict = dict(\n                            return_type=(type(return_data).__name__),\n                            return_data=(\n                                return_data if not (return_data is None) else \"\"\n                            ),\n                        )\n                        # encode it\n                        retdata_enc = msgpack.packb(return_dict)\n                        # send it over network to server\n                        await self.__msg_socket.send(retdata_enc)\n                elif self.__bi_mode or data[\"bi_mode\"]:\n                    # raise error if bidirectional mode is disabled at server or client but not both\n                    raise RuntimeError(\n                        \"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\".format(\n                            \"client\" if self.__bi_mode else \"server\"\n                        )\n                    )\n                else:\n                    # otherwise just send confirmation message to server\n                    await self.__msg_socket.send(\n                        bytes(\n                            \"Data received on client: {} !\".format(self.__id), \"utf-8\"\n                        )\n                    )\n            # yield received tuple(data-frame) if bidirectional mode or else just frame\n            if self.__bi_mode:\n                yield (data[\"data\"], frame) if data[\"data\"] else (None, frame)\n            else:\n                yield frame\n            # sleep for sometime\n            await asyncio.sleep(0)\n\n    async def __frame_generator(self):\n        \"\"\"\n        Returns a default frame-generator for NetGear_Async's Server Handler.\n        \"\"\"\n        # start stream\n        self.__stream.start()\n        # loop over stream until its terminated\n        while not self.__terminate:\n            # read frames\n            frame = self.__stream.read()\n            # break if NoneType\n            if frame is None:\n                break\n            # yield frame\n            yield frame\n            # sleep for sometime\n            await asyncio.sleep(0)\n\n    async def transceive_data(self, data=None):\n        \"\"\"\n        Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_.\n\n        Parameters:\n            data (any): inputs data _(of any datatype)_ for sending back to Server.\n        \"\"\"\n        recvd_data = None\n        if not self.__terminate:\n            if self.__bi_mode:\n                if self.__receive_mode:\n                    await self.__queue.put(data)\n                else:\n                    if not self.__queue.empty():\n                        recvd_data = await self.__queue.get()\n                        self.__queue.task_done()\n            else:\n                logger.error(\n                    \"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\"\n                )\n        return recvd_data\n\n    async def __terminate_connection(self, disable_confirmation=False):\n        \"\"\"\n        Internal asyncio method to safely terminate ZMQ connection and queues\n\n        Parameters:\n            disable_confirmation (boolean): Force disable termination confirmation from client in bidirectional patterns.\n        \"\"\"\n        # log termination\n        self.__logging and logger.debug(\n            \"Terminating various {} Processes. Please wait.\".format(\n                \"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n            )\n        )\n\n        # check whether `receive_mode` is enabled or not\n        if self.__receive_mode:\n            # indicate that process should be terminated\n            self.__terminate = True\n        else:\n            # indicate that process should be terminated\n            self.__terminate = True\n            # terminate stream\n            if not (self.__stream is None):\n                self.__stream.stop()\n            # signal `exit` flag for termination!\n            data_dict = dict(terminate=True)\n            data_enc = msgpack.packb(data_dict)\n            await self.__msg_socket.send(data_enc)\n            # check if bidirectional patterns\n            if self.__msg_pattern &lt; 2 and not disable_confirmation:\n                # then receive and log confirmation\n                recv_confirmation = await self.__msg_socket.recv()\n                recvd_conf = msgpack.unpackb(recv_confirmation, use_list=False)\n                self.__logging and \"terminated\" in recvd_conf and logger.debug(\n                    recvd_conf[\"terminated\"]\n                )\n        # close socket\n        self.__msg_socket.setsockopt(zmq.LINGER, 0)\n        self.__msg_socket.close()\n        # handle asyncio queues in bidirectional mode\n        if self.__bi_mode:\n            # empty queue if not\n            while not self.__queue.empty():\n                try:\n                    self.__queue.get_nowait()\n                except asyncio.QueueEmpty:\n                    continue\n                self.__queue.task_done()\n            # join queues\n            await self.__queue.join()\n\n        logger.critical(\n            \"{} successfully terminated!\".format(\n                \"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n            )\n        )\n\n    def close(self, skip_loop=False):\n        \"\"\"\n        Terminates all NetGear_Async Asynchronous processes gracefully.\n\n        Parameters:\n            skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest).\n        \"\"\"\n        # close event loop if specified\n        if not (skip_loop):\n            # close connection gracefully\n            self.loop.run_until_complete(self.__terminate_connection())\n            self.loop.close()\n        else:\n            # otherwise create a task\n            asyncio.ensure_future(\n                self.__terminate_connection(disable_confirmation=True)\n            )\n</code></pre> <p> </p>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.__init__","title":"<code>__init__(self, address=None, port=None, protocol='tcp', pattern=0, receive_mode=False, timeout=0.0, enablePiCamera=False, stabilize=False, source=None, camera_num=0, stream_mode=False, backend=0, colorspace=None, resolution=(640, 480), framerate=25, time_delay=0, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the NetGear_Async class.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>sets the valid network address of the Server/Client.</p> <code>None</code> <code>port</code> <code>str</code> <p>sets the valid Network Port of the Server/Client.</p> <code>None</code> <code>protocol</code> <code>str</code> <p>sets the valid messaging protocol between Server/Client.</p> <code>'tcp'</code> <code>pattern</code> <code>int</code> <p>sets the supported messaging pattern(flow of communication) between Server/Client</p> <code>0</code> <code>receive_mode</code> <code>bool</code> <p>select the NetGear_Async's Mode of operation.</p> <code>False</code> <code>timeout</code> <code>int/float</code> <p>controls the maximum waiting time(in sec) after which Client throws <code>TimeoutError</code>.</p> <code>0.0</code> <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>25</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>None</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>def __init__(\n    self,\n    # NetGear_Async parameters\n    address=None,\n    port=None,\n    protocol=\"tcp\",\n    pattern=0,\n    receive_mode=False,\n    timeout=0.0,\n    # Videogear parameters\n    enablePiCamera=False,\n    stabilize=False,\n    source=None,\n    camera_num=0,\n    stream_mode=False,\n    backend=0,\n    colorspace=None,\n    resolution=(640, 480),\n    framerate=25,\n    time_delay=0,\n    # common parameters\n    logging=False,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the NetGear_Async class.\n\n    Parameters:\n        address (str): sets the valid network address of the Server/Client.\n        port (str): sets the valid Network Port of the Server/Client.\n        protocol (str): sets the valid messaging protocol between Server/Client.\n        pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n        receive_mode (bool): select the NetGear_Async's Mode of operation.\n        timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`.\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # raise error(s) for critical Class imports\n    import_dependency_safe(\n        \"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n    )\n    import_dependency_safe(\"msgpack\" if msgpack is None else \"\")\n    import_dependency_safe(\"msgpack_numpy\" if m is None else \"\")\n\n    # define valid messaging patterns =&gt; `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL)\n    valid_messaging_patterns = {\n        0: (zmq.PAIR, zmq.PAIR),\n        1: (zmq.REQ, zmq.REP),\n        2: (zmq.PUB, zmq.SUB),\n        3: (zmq.PUSH, zmq.PULL),\n    }\n\n    # check whether user-defined messaging pattern is valid\n    if isinstance(pattern, int) and pattern in valid_messaging_patterns:\n        # assign value\n        self.__msg_pattern = pattern\n        self.__pattern = valid_messaging_patterns[pattern]\n    else:\n        # otherwise default to 0:`zmq.PAIR`\n        self.__msg_pattern = 0\n        self.__pattern = valid_messaging_patterns[self.__msg_pattern]\n        self.__logging and logger.warning(\n            \"Invalid pattern {pattern}. Defaulting to `zmq.PAIR`!\".format(\n                pattern=pattern\n            )\n        )\n\n    # check  whether user-defined messaging protocol is valid\n    if isinstance(protocol, str) and protocol in [\"tcp\", \"ipc\"]:\n        # assign value\n        self.__protocol = protocol\n    else:\n        # else default to `tcp` protocol\n        self.__protocol = \"tcp\"\n        self.__logging and logger.warning(\"Invalid protocol. Defaulting to `tcp`!\")\n\n    # initialize Termination flag\n    self.__terminate = False\n    # initialize and assign `Receive Mode`\n    self.__receive_mode = receive_mode\n    # initialize stream handler\n    self.__stream = None\n    # initialize Messaging Socket\n    self.__msg_socket = None\n    # initialize NetGear_Async's configuration dictionary\n    self.config = {}\n    # asyncio queue handler\n    self.__queue = None\n    # define Bidirectional mode\n    self.__bi_mode = False  # handles Bidirectional mode state\n\n    # assign timeout for Receiver end\n    if timeout and isinstance(timeout, (int, float)):\n        self.__timeout = float(timeout)\n    else:\n        self.__timeout = 15.0\n\n    # generate 8-digit random system id\n    self.__id = \"\".join(\n        secrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n    )\n\n    # Handle user-defined options dictionary values\n    # reformat dictionary\n    options = {str(k).strip(): v for k, v in options.items()}\n    # handle bidirectional mode\n    if \"bidirectional_mode\" in options:\n        value = options[\"bidirectional_mode\"]\n        # also check if pattern and source is valid\n        if isinstance(value, bool) and pattern &lt; 2 and source is None:\n            # activate Bidirectional mode if specified\n            self.__bi_mode = value\n        else:\n            # otherwise disable it\n            self.__bi_mode = False\n            logger.warning(\"Bidirectional data transmission is disabled!\")\n        # handle errors and logging\n        if pattern &gt;= 2:\n            # raise error\n            raise ValueError(\n                \"[NetGear_Async:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\n                    pattern\n                )\n            )\n        elif not (source is None):\n            raise ValueError(\n                \"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\n                    pattern\n                )\n            )\n        elif isinstance(value, bool) and self.__logging:\n            # log Bidirectional mode activation\n            logger.debug(\n                \"Bidirectional Data Transmission is {} for this connection!\".format(\n                    \"enabled\" if value else \"disabled\"\n                )\n            )\n        else:\n            logger.error(\"`bidirectional_mode` value is invalid!\")\n        # clean\n        del options[\"bidirectional_mode\"]\n\n    # Setup and assign event loop policy\n    if platform.system() == \"Windows\":\n        # On Windows, VidGear requires the ``WindowsSelectorEventLoop``, but Python 3.8 and above,\n        # defaults to an ``ProactorEventLoop`` loop that is not compatible with it. Thereby,\n        # we had to set it manually.\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n    else:\n        if not (uvloop is None):\n            # Latest uvloop eventloop is only available for UNIX machines.\n            asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n        else:\n            # log if not present\n            import_dependency_safe(\"uvloop\", error=\"log\")\n\n    # Retrieve event loop and assign it\n    try:\n        self.loop = asyncio.get_running_loop()\n    except RuntimeError:\n        # otherwise create one\n        logger.critical(\"No running event loop found. Creating a new one.\")\n        self.loop = asyncio.new_event_loop()\n\n    # log eventloop for debugging\n    self.__logging and logger.info(\n        \"Using ``{}`` event loop for this process.\".format(\n            self.loop.__class__.__name__\n        )\n    )\n\n    # define messaging asynchronous Context\n    self.__msg_context = zmq.asyncio.Context()\n\n    # check whether `Receive Mode` is enabled\n    if receive_mode:\n        # assign local IP address if None\n        if address is None:\n            self.__address = \"*\"  # define address\n        else:\n            self.__address = address\n        # assign default port address if None\n        if port is None:\n            self.__port = \"5555\"\n        else:\n            self.__port = port\n    else:\n        # Handle video source\n        if source is None:\n            self.config = {\"generator\": None}\n            self.__logging and logger.warning(\"Given source is of NoneType!\")\n        else:\n            # define stream with necessary params\n            self.__stream = VideoGear(\n                enablePiCamera=enablePiCamera,\n                stabilize=stabilize,\n                source=source,\n                camera_num=camera_num,\n                stream_mode=stream_mode,\n                backend=backend,\n                colorspace=colorspace,\n                resolution=resolution,\n                framerate=framerate,\n                logging=logging,\n                time_delay=time_delay,\n                **options\n            )\n            # define default frame generator in configuration\n            self.config = {\"generator\": self.__frame_generator()}\n        # assign local ip address if None\n        if address is None:\n            self.__address = \"localhost\"\n        else:\n            self.__address = address\n        # assign default port address if None\n        if port is None:\n            self.__port = \"5555\"\n        else:\n            self.__port = port\n        # add server task handler\n        self.task = None\n\n    # create asyncio queue if bidirectional mode activated\n    self.__queue = asyncio.Queue() if self.__bi_mode else None\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.close","title":"<code>close(self, skip_loop=False)</code>","text":"<p>Terminates all NetGear_Async Asynchronous processes gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>skip_loop</code> <code>Boolean</code> <p>(optional)used only if don't want to close eventloop(required in pytest).</p> <code>False</code> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>def close(self, skip_loop=False):\n    \"\"\"\n    Terminates all NetGear_Async Asynchronous processes gracefully.\n\n    Parameters:\n        skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest).\n    \"\"\"\n    # close event loop if specified\n    if not (skip_loop):\n        # close connection gracefully\n        self.loop.run_until_complete(self.__terminate_connection())\n        self.loop.close()\n    else:\n        # otherwise create a task\n        asyncio.ensure_future(\n            self.__terminate_connection(disable_confirmation=True)\n        )\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.launch","title":"<code>launch(self)</code>","text":"<p>Launches an asynchronous generators and loop executors for respective task.</p> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>def launch(self):\n    \"\"\"\n    Launches an asynchronous generators and loop executors for respective task.\n    \"\"\"\n    # check if receive mode enabled\n    if self.__receive_mode:\n        self.__logging and logger.debug(\n            \"Launching NetGear_Async asynchronous generator!\"\n        )\n        # run loop executor for Receiver asynchronous generator\n        self.loop.run_in_executor(None, self.recv_generator)\n    else:\n        # Otherwise launch Server handler\n        self.__logging and logger.debug(\n            \"Creating NetGear_Async asynchronous server handler!\"\n        )\n        # create task for Server Handler\n        self.task = self.loop.create_task(self.__server_handler())\n    # return instance\n    return self\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.recv_generator","title":"<code>recv_generator(self)</code>","text":"<p>A default Asynchronous Frame Generator for NetGear_Async's Receiver-end.</p> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>async def recv_generator(self):\n    \"\"\"\n    A default Asynchronous Frame Generator for NetGear_Async's Receiver-end.\n    \"\"\"\n    # check whether `receive mode` is activated\n    if not (self.__receive_mode):\n        # raise Value error and exit\n        self.__terminate = True\n        raise ValueError(\n            \"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\"\n        )\n\n    # initialize and define messaging socket\n    self.__msg_socket = self.__msg_context.socket(self.__pattern[1])\n\n    # define exclusive socket options for patterns\n    if self.__msg_pattern == 2:\n        self.__msg_socket.set_hwm(1)\n        self.__msg_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\n\n    try:\n        # bind socket to the assigned protocol, address and port\n        self.__msg_socket.bind(\n            self.__protocol + \"://\" + str(self.__address) + \":\" + str(self.__port)\n        )\n        # finally log progress\n        self.__logging and logger.debug(\n            \"Successfully binded to address: {} with pattern: {}.\".format(\n                (\n                    self.__protocol\n                    + \"://\"\n                    + str(self.__address)\n                    + \":\"\n                    + str(self.__port)\n                ),\n                self.__msg_pattern,\n            )\n        )\n        logger.critical(\"Receive Mode is activated successfully!\")\n    except Exception as e:\n        logger.exception(str(e))\n        raise RuntimeError(\n            \"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{}!\".format(\n                (\n                    self.__protocol\n                    + \"://\"\n                    + str(self.__address)\n                    + \":\"\n                    + str(self.__port)\n                ),\n                self.__msg_pattern,\n                \" and Bidirectional Mode enabled\" if self.__bi_mode else \"\",\n            )\n        )\n\n    # loop until terminated\n    while not self.__terminate:\n        # get encoded data message from server withing timeout limit\n        datamsg_encoded = await asyncio.wait_for(\n            self.__msg_socket.recv(), timeout=self.__timeout\n        )\n        # retrieve data from message\n        data = msgpack.unpackb(datamsg_encoded, use_list=False)\n        # terminate if exit` flag received from server\n        if data[\"terminate\"]:\n            # send confirmation message to server if bidirectional patterns\n            if self.__msg_pattern &lt; 2:\n                # create termination confirmation message\n                return_dict = dict(\n                    terminated=\"Client-`{}` successfully terminated!\".format(\n                        self.__id\n                    ),\n                )\n                # encode message\n                retdata_enc = msgpack.packb(return_dict)\n                # send message back to server\n                await self.__msg_socket.send(retdata_enc)\n            self.__logging and logger.info(\n                \"Termination signal received from server!\"\n            )\n            # break loop and terminate\n            self.__terminate = True\n            break\n        # get encoded frame message from server withing timeout limit\n        framemsg_encoded = await asyncio.wait_for(\n            self.__msg_socket.recv_multipart(), timeout=self.__timeout\n        )\n        # retrieve frame from message\n        frame = msgpack.unpackb(\n            framemsg_encoded[0], use_list=False, object_hook=m.decode\n        )\n\n        # check if bidirectional patterns\n        if self.__msg_pattern &lt; 2:\n            # handle bidirectional data transfer if enabled\n            if self.__bi_mode and data[\"bi_mode\"]:\n                # handle empty queue\n                if not self.__queue.empty():\n                    return_data = await self.__queue.get()\n                    self.__queue.task_done()\n                else:\n                    return_data = None\n                # check if we are returning `ndarray` frames\n                if not (return_data is None) and isinstance(\n                    return_data, np.ndarray\n                ):\n                    # check whether the incoming frame is contiguous\n                    if not (return_data.flags[\"C_CONTIGUOUS\"]):\n                        return_data = np.ascontiguousarray(\n                            return_data, dtype=return_data.dtype\n                        )\n\n                    # create return type dict without data\n                    rettype_dict = dict(\n                        return_type=(type(return_data).__name__),\n                        return_data=None,\n                    )\n                    # encode it\n                    rettype_enc = msgpack.packb(rettype_dict)\n                    # send it to server with correct flags\n                    await self.__msg_socket.send(rettype_enc, flags=zmq.SNDMORE)\n\n                    # encode return ndarray data\n                    retframe_enc = msgpack.packb(return_data, default=m.encode)\n                    # send it over network to server\n                    await self.__msg_socket.send_multipart([retframe_enc])\n                else:\n                    # otherwise create type and data dict\n                    return_dict = dict(\n                        return_type=(type(return_data).__name__),\n                        return_data=(\n                            return_data if not (return_data is None) else \"\"\n                        ),\n                    )\n                    # encode it\n                    retdata_enc = msgpack.packb(return_dict)\n                    # send it over network to server\n                    await self.__msg_socket.send(retdata_enc)\n            elif self.__bi_mode or data[\"bi_mode\"]:\n                # raise error if bidirectional mode is disabled at server or client but not both\n                raise RuntimeError(\n                    \"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\".format(\n                        \"client\" if self.__bi_mode else \"server\"\n                    )\n                )\n            else:\n                # otherwise just send confirmation message to server\n                await self.__msg_socket.send(\n                    bytes(\n                        \"Data received on client: {} !\".format(self.__id), \"utf-8\"\n                    )\n                )\n        # yield received tuple(data-frame) if bidirectional mode or else just frame\n        if self.__bi_mode:\n            yield (data[\"data\"], frame) if data[\"data\"] else (None, frame)\n        else:\n            yield frame\n        # sleep for sometime\n        await asyncio.sleep(0)\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.transceive_data","title":"<code>transceive_data(self, data=None)</code>  <code>async</code>","text":"<p>Bidirectional Mode exclusive method to Transmit data (in Receive mode) and Receive data (in Send mode).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>any</code> <p>inputs data (of any datatype) for sending back to Server.</p> <code>None</code> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>async def transceive_data(self, data=None):\n    \"\"\"\n    Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_.\n\n    Parameters:\n        data (any): inputs data _(of any datatype)_ for sending back to Server.\n    \"\"\"\n    recvd_data = None\n    if not self.__terminate:\n        if self.__bi_mode:\n            if self.__receive_mode:\n                await self.__queue.put(data)\n            else:\n                if not self.__queue.empty():\n                    recvd_data = await self.__queue.get()\n                    self.__queue.task_done()\n        else:\n            logger.error(\n                \"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\"\n            )\n    return recvd_data\n</code></pre>"},{"location":"bonus/reference/pigear/","title":"API References","text":"<p>PiGear API usage examples can be found here \u27b6</p> <p>PiGear API parameters are explained here \u27b6</p> <p>PiGear implements a seamless and robust wrapper around the picamera2 python library, simplifying integration with minimal code changes and ensuring a smooth transition for developers already familiar with the Picamera2 API. PiGear leverages the <code>libcamera</code> API under the hood with multi-threading, providing high-performance , enhanced control and functionality for Raspberry Pi camera modules.</p> <p>PiGear handles common configuration parameters and non-standard settings for various camera types, simplifying the integration process. PiGear currently supports picamera2 API parameters such as <code>sensor</code>, <code>controls</code>, <code>transform</code>, and <code>stride</code>, with internal type and sanity checks for robust performance.</p> <p>While primarily focused on Raspberry Pi camera modules, PiGear also provides basic functionality for USB webcams only with Picamera2 API, along with the ability to accurately differentiate between USB and Raspberry Pi cameras using metadata.</p> Backward compatibility with <code>picamera</code> library <p>PiGear seamlessly switches to the legacy picamera library if the <code>picamera2</code> library is unavailable, ensuring seamless backward compatibility. For this, PiGear also provides a flexible multi-threaded framework around complete <code>picamera</code> API, allowing developers to effortlessly exploit a wide range of parameters, such as <code>brightness</code>, <code>saturation</code>, <code>sensor_mode</code>, <code>iso</code>, <code>exposure</code>, and more.</p> <p>Furthermore, PiGear supports the use of multiple camera modules, including those found on Raspberry Pi Compute Module IO boards and USB cameras (only with Picamera2 API).</p> Threaded Internal Timer  <p>PiGear ensures proper resource release during the termination of the API, preventing potential issues or resource leaks. PiGear API internally implements a Threaded Internal Timer that silently keeps active track of any frozen-threads or hardware-failures and exits safely if any do occur. This means that if you're running the PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into a possible kernel panic, the API will exit safely to save resources.</p> <p>Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>class PiGear:\n    \"\"\"\n    PiGear implements a seamless and robust wrapper around the [picamera2](https://github.com/raspberrypi/picamera2) python library, simplifying integration with minimal code changes and ensuring a\n    smooth transition for developers already familiar with the Picamera2 API. PiGear leverages the `libcamera` API under the hood with multi-threading, providing high-performance :fire:, enhanced\n    control and functionality for Raspberry Pi camera modules.\n\n    PiGear handles common configuration parameters and non-standard settings for various camera types, simplifying the integration process. PiGear currently supports picamera2 API parameters such as\n    `sensor`, `controls`, `transform`, and `stride`, with internal type and sanity checks for robust performance.\n\n    While primarily focused on Raspberry Pi camera modules, PiGear also provides basic functionality for USB webcams only with Picamera2 API, along with the ability to accurately differentiate between\n    USB and Raspberry Pi cameras using metadata.\n\n    ???+ info \"Backward compatibility with `picamera` library\"\n        PiGear seamlessly switches to the legacy [picamera](https://picamera.readthedocs.io/en/release-1.13/index.html) library if the `picamera2` library is unavailable, ensuring seamless backward\n        compatibility. For this, PiGear also provides a flexible multi-threaded framework around complete `picamera` API, allowing developers to effortlessly exploit a wide range of parameters, such\n        as `brightness`, `saturation`, `sensor_mode`, `iso`, `exposure`, and more.\n\n    Furthermore, PiGear supports the use of multiple camera modules, including those found on Raspberry Pi Compute Module IO boards and USB cameras _(only with Picamera2 API)_.\n\n    ??? new \"Threaded Internal Timer :material-camera-timer:\"\n        PiGear ensures proper resource release during the termination of the API, preventing potential issues or resource leaks. PiGear API internally implements a\n        ==Threaded Internal Timer== that silently keeps active track of any frozen-threads or hardware-failures and exits safely if any do occur. This means that if\n        you're running the PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into a possible kernel panic,\n        the API will exit safely to save resources.\n\n    !!! failure \"Make sure to [enable Raspberry Pi hardware-specific settings](https://picamera.readthedocs.io/en/release-1.13/quickstart.html) prior using this API, otherwise nothing will work.\"\n    \"\"\"\n\n    def __init__(\n        self,\n        camera_num=0,\n        resolution=(640, 480),\n        framerate=30,\n        colorspace=None,\n        logging=False,\n        time_delay=0,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the PiGear class.\n\n        Parameters:\n            camera_num (int): selects the camera module index which will be used as source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source..\n            framerate (int/float): sets the framerate of the source.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Source Tweak Parameters.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # raise error(s) for critical Class imports\n        global picamera, picamera2\n        if picamera2:\n            # log if picamera2\n            self.__logging and logger.info(\"picamera2 API is currently being accessed.\")\n        elif picamera:\n            # switch to picamera otherwise\n            logger.critical(\n                \"picamera2 library not installed on this system. Defaulting to legacy picamera API.\"\n            )\n        else:\n            # raise error if none\n            import_dependency_safe(\"picamera\")\n\n        assert (\n            isinstance(framerate, (int, float)) and framerate &gt; 0.0\n        ), \"[PiGear:ERROR] :: Input framerate value `{}` is a Invalid! Kindly read docs.\".format(\n            framerate\n        )\n        assert (\n            isinstance(resolution, (tuple, list)) and len(resolution) == 2\n        ), \"[PiGear:ERROR] :: Input resolution value `{}` is a Invalid! Kindly read docs.\".format(\n            resolution\n        )\n        if not (isinstance(camera_num, int) and camera_num &gt;= 0):\n            camera_num = 0\n            logger.warning(\n                \"Input camera_num value `{}` is invalid, Defaulting to index 0!\"\n            )\n\n        # reformat dict\n        options = {str(k).strip(): v for k, v in options.items()}\n\n        # check if legacy picamera backend is enforced\n        enforce_legacy_picamera = options.pop(\"enforce_legacy_picamera\", False)\n        if isinstance(enforce_legacy_picamera, bool) and enforce_legacy_picamera:\n            # check if picamera library is available.\n            if picamera:\n                logger.critical(\n                    \"Enforcing legacy picamera API for this run. picamera2 API access will be disabled!\"\n                )\n                # disable picamera2\n                picamera2 = None\n            else:\n                # raise error otherwise\n                logger.error(\n                    \"`picamera` is unavailable or unsupported on this system, `enforce_legacy_picamera` will be discarded!\"\n                )\n                import_dependency_safe(\"picamera\")\n\n        if picamera2:\n            # handle logging\n            not (self.__logging) and not os.getenv(\n                \"LIBCAMERA_LOG_LEVELS\", False\n            ) and logger.info(\n                \"Kindly set `LIBCAMERA_LOG_LEVELS=2` environment variable to disable common libcamera API messages.\"\n            )\n            # collect metadata\n            cameras_metadata = Picamera2.global_camera_info()\n            # initialize the picamera stream at given index\n            self.__camera = Picamera2(camera_num=camera_num)\n            # extract metadata for current camera\n            camera_metadata = [x for x in cameras_metadata if x[\"Num\"] == camera_num][0]\n            # check connected camera is USB or I2C\n            self.__camera_is_usb = True if \"usb\" in camera_metadata[\"Id\"] else False\n            # handle framerate control\n            if not self.__camera_is_usb:\n                self.__camera.set_controls({\"FrameRate\": framerate})\n            else:\n                logger.warning(\n                    \"USB camera detected. Setting input framerate is NOT supported with Picamera2 API!\"\n                )\n            # log\n            self.__logging and logger.debug(\n                \"Activating Picamera2 API for `{}` camera at index: {} with resolution: {} &amp; framerate: {}\".format(\n                    camera_metadata[\"Model\"],\n                    camera_num,\n                    resolution if not self.__camera_is_usb else \"default\",\n                    framerate,\n                )\n            )\n        else:\n            # initialize the picamera stream at given index\n            self.__camera = PiCamera(camera_num=camera_num)\n            self.__camera.resolution = tuple(resolution)\n            self.__camera.framerate = framerate\n            self.__logging and logger.debug(\n                \"Activating Picamera API at index: {} with resolution: {} &amp; framerate: {}\".format(\n                    camera_num, resolution, framerate\n                )\n            )\n\n        # initialize framerate (Read-only) variable\n        self.framerate = framerate\n\n        # initializing colorspace variable\n        self.color_space = None\n\n        # define timeout variable default value(handles hardware failures)\n        self.__failure_timeout = options.pop(\"HWFAILURE_TIMEOUT\", 2.0)\n        if isinstance(self.__failure_timeout, (int, float)):\n            if not (10.0 &gt; self.__failure_timeout &gt; 1.0):\n                raise ValueError(\n                    \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\"\n                )\n            self.__logging and logger.debug(\n                \"Setting HW Failure Timeout: {} seconds\".format(self.__failure_timeout)\n            )\n        else:\n            # reset improper values\n            self.__failure_timeout = 2.0\n\n        try:\n            if picamera2:\n                # define common supported picamera2 config parameters\n                valid_config_options = [\n                    \"auto_align_output_size\",  # internal\n                    \"enable_verbose_logs\",  # internal\n                    \"format\",\n                    \"sensor\",\n                ]\n\n                # define non-USB supported picamera2 config parameters\n                non_usb_options = [\n                    \"controls\",  # not-supported on USB\n                    \"transform\",  # not-working on USB\n                    \"buffer_count\",  # not-supported on USB\n                    \"queue\",  # not-supported on USB\n                ]  # Less are supported (will be changed in future)\n\n                # filter parameter supported with non-USB cameras only\n                if self.__camera_is_usb:\n                    unsupported_config_keys = set(list(options.keys())).intersection(\n                        set(non_usb_options)\n                    )\n                    unsupported_config_keys and logger.warning(\n                        \"Setting parameters: `{}` for USB camera is NOT supported with Picamera2 API!\".format(\n                            \"`, `\".join(unsupported_config_keys)\n                        )\n                    )\n                else:\n                    valid_config_options += non_usb_options\n\n                # log all invalid keys\n                invalid_config_keys = set(list(options.keys())) - set(\n                    valid_config_options\n                )\n                invalid_config_keys and logger.warning(\n                    \"Discarding invalid options NOT supported by Picamera2 API for current Camera Sensor: `{}`\".format(\n                        \"`, `\".join(invalid_config_keys)\n                    )\n                )\n                # delete all unsupported options\n                options = {\n                    x: y for x, y in options.items() if x in valid_config_options\n                }\n\n                # setting size, already defined\n                options.update({\"size\": tuple(resolution)})\n\n                # set 24-bit, BGR format by default\n                if not \"format\" in options:\n                    # auto defaults for USB cameras\n                    not self.__camera_is_usb and options.update({\"format\": \"RGB888\"})\n                elif self.__camera_is_usb:\n                    # check the supported formats, if USB camera\n                    avail_formats = [\n                        mode[\"format\"] for mode in self.__camera.sensor_modes\n                    ]\n                    # handle unsupported formats\n                    if not options[\"format\"] in avail_formats:\n                        logger.warning(\n                            \"Discarding `format={}`. `{}` are the only available formats for USB camera in use!\".format(\n                                options[\"format\"], \"`, `\".join(avail_formats)\n                            )\n                        )\n                        del options[\"format\"]\n                    else:\n                        # `colorspace` parameter must define with  `format` optional parameter\n                        # unless format is MPEG (tested)\n                        (\n                            not (colorspace is None) or options[\"format\"] == \"MPEG\"\n                        ) and logger.warning(\n                            \"Custom Output frames `format={}` detected. It is advised to define `colorspace` parameter or handle this format manually in your code!\".format(\n                                options[\"format\"]\n                            )\n                        )\n                else:\n                    # `colorspace` parameter must define with  `format` optional parameter\n                    # unless format is either BGR or BGRA\n                    (\n                        not (colorspace is None)\n                        or options[\"format\"]\n                        in [\n                            \"RGB888\",\n                            \"XRGB8888\",\n                        ]\n                    ) and logger.warning(\n                        \"Custom Output frames `format={}` detected. It is advised to define `colorspace` parameter or handle this format manually in your code!\".format(\n                            options[\"format\"]\n                        )\n                    )\n\n                # enable verbose logging mode (handled by Picamera2 API)\n                verbose = options.pop(\"enable_verbose_logs\", False)\n                if self.__logging and isinstance(verbose, bool) and verbose:\n                    self.__camera.set_logging(Picamera2.DEBUG)\n                else:\n                    # setup logging\n                    self.__camera.set_logging(Picamera2.WARNING)\n\n                # handle transformations, if specified\n                transform = options.pop(\"transform\", Transform())\n                if not isinstance(transform, Transform):\n                    logger.warning(\"`transform` value is of invalid type, Discarding!\")\n                    transform = Transform()\n\n                # handle sensor configurations, if specified\n                sensor = options.pop(\"sensor\", {})\n                if isinstance(sensor, dict):\n                    # extract all valid sensor keys\n                    valid_sensor = [\"output_size\", \"bit_depth\"]\n                    # log all invalid keys\n                    invalid_sensor_keys = set(list(sensor)) - set(valid_sensor)\n                    invalid_sensor_keys and logger.warning(\n                        \"Discarding sensor properties NOT supported by current Camera Sensor: `{}`. Only supported are: (`{}`)\".format(\n                            \"`, `\".join(invalid_sensor_keys),\n                            \"`, `\".join(valid_sensor),\n                        )\n                    )\n                    # delete all unsupported control keys\n                    sensor = {x: y for x, y in sensor.items() if x in valid_sensor}\n                    # remove size if output size is defined\n                    if \"output_size\" in sensor:\n                        del options[\"size\"]\n                        logger.critical(\n                            \"Overriding output frame size with `output_size={}!\".format(\n                                sensor[\"output_size\"]\n                            )\n                        )\n                else:\n                    logger.warning(\"`sensor` value is of invalid type, Discarding!\")\n                    sensor = {}\n\n                # handle controls, if specified\n                controls = options.pop(\"controls\", {})\n                if isinstance(controls, dict):\n                    # extract all valid control keys\n                    valid_controls = self.__camera.camera_controls\n                    # remove any fps controls, assigned already\n                    valid_controls.pop(\"FrameDuration\", None)\n                    valid_controls.pop(\"FrameDurationLimits\", None)\n                    # log all invalid keys\n                    invalid_control_keys = set(list(controls.keys())) - set(\n                        list(valid_controls.keys())\n                    )\n                    invalid_control_keys and logger.warning(\n                        \"Discarding control properties NOT supported by current Camera Sensor: `{}`. Only supported are: (`{}`)\".format(\n                            \"`, `\".join(invalid_control_keys),\n                            \"`, `\".join(list(valid_controls.keys())),\n                        )\n                    )\n                    # delete all unsupported control keys\n                    controls = {\n                        x: y for x, y in controls.items() if x in valid_controls.keys()\n                    }\n                else:\n                    logger.warning(\"`controls` value is of invalid type, Discarding!\")\n                    controls = {}\n\n                # handle buffer_count, if specified\n                buffer_count = options.pop(\"buffer_count\", 4)\n                if (\n                    not isinstance(buffer_count, int) or buffer_count &lt; 1\n                ):  # must be greater than 1\n                    logger.warning(\n                        \"`buffer_count` value is of invalid type, Discarding!\"\n                    )\n                    # `create_preview_configuration` requests 4 sets of buffers\n                    buffer_count = 4\n\n                # handle queue, if specified\n                queue = options.pop(\"queue\", True)\n                if not isinstance(queue, bool):\n                    logger.warning(\"`queue` value is of invalid type, Discarding!\")\n                    queue = True\n\n                # check if auto-align camera configuration is specified\n                auto_align_output_size = options.pop(\"auto_align_output_size\", False)\n\n                # create default configuration for camera\n                config = self.__camera.create_preview_configuration(\n                    main=options,\n                    transform=transform,\n                    sensor=sensor,\n                    controls=controls,\n                    buffer_count=buffer_count,\n                    queue=queue,\n                )\n\n                # auto-align camera configuration, if specified\n                if isinstance(auto_align_output_size, bool) and auto_align_output_size:\n                    self.__logging and logger.debug(\n                        \"Re-aligning Output frames to optimal size supported by current Camera Sensor.\"\n                    )\n                    self.__camera.align_configuration(config)\n\n                # configure camera\n                self.__camera.configure(config)\n                self.__logging and logger.debug(\n                    \"Setting Picamera2 API Parameters: `{}`, controls: `{}`, sensor: `{}`, buffer_count: `{}`, and queue: `{}`.\".format(\n                        self.__camera.camera_configuration()[\"main\"],\n                        controls,\n                        sensor,\n                        buffer_count,\n                        queue,\n                    )\n                )\n            else:\n                # apply attributes to source if specified\n                for key, value in options.items():\n                    self.__logging and logger.debug(\n                        \"Setting {} API Parameter for Picamera: `{}`\".format(key, value)\n                    )\n                    setattr(self.__camera, key, value)\n        except Exception as e:\n            # Catch if any error occurred\n            logger.exception(str(e))\n\n        # separately handle colorspace value to int conversion\n        if not (colorspace is None):\n            self.color_space = capPropId(colorspace.strip())\n            if self.__logging and not (self.color_space is None):\n                logger.debug(\n                    \"Enabling `{}` colorspace for this video stream!\".format(\n                        colorspace.strip()\n                    )\n                )\n\n        # enable rgb capture array thread and capture stream\n        if not picamera2:\n            self.__rawCapture = PiRGBArray(self.__camera, size=resolution)\n            self.stream = self.__camera.capture_continuous(\n                self.__rawCapture, format=\"bgr\", use_video_port=True\n            )\n\n        # initialize frame variable\n        # with captured frame\n        try:\n            if picamera2:\n                # start camera thread\n                self.__camera.start()\n                # capture frame array\n                self.frame = self.__camera.capture_array(\"main\")\n                # assign camera as stream for setting\n                # parameters after starting the camera\n                self.stream = self.__camera\n            else:\n                # capture frame array from stream\n                stream = next(self.stream)\n                self.frame = stream.array\n                self.__rawCapture.seek(0)\n                self.__rawCapture.truncate()\n            # render colorspace if defined\n            if not (self.frame is None) and not (self.color_space is None):\n                self.frame = cv2.cvtColor(self.frame, self.color_space)\n        except Exception as e:\n            logger.exception(str(e))\n            raise RuntimeError(\"[PiGear:ERROR] :: Camera Module failed to initialize!\")\n\n        # applying time delay to warm-up picamera only if specified\n        if time_delay and isinstance(time_delay, (int, float)):\n            time.sleep(time_delay)\n\n        # thread initialization\n        self.__thread = None\n\n        # timer thread initialization(Keeps check on frozen thread)\n        self.__timer = None\n        self.__t_elapsed = 0.0  # records time taken by thread\n\n        # catching thread exceptions\n        self.__exceptions = None\n\n        # initialize termination flag\n        self.__terminate = False\n\n    def start(self):\n        \"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon\n\n        **Returns:** A reference to the PiGear class object.\n        \"\"\"\n        # Start frame producer thread\n        self.__thread = Thread(target=self.__update, name=\"PiGear\", args=())\n        self.__thread.daemon = True\n        self.__thread.start()\n\n        # Start internal timer thread\n        self.__timer = Thread(target=self.__timeit, name=\"PiTimer\", args=())\n        self.__timer.daemon = True\n        self.__timer.start()\n\n        return self\n\n    def __timeit(self):\n        \"\"\"\n        Threaded Internal Timer that keep checks on thread execution timing\n        \"\"\"\n        # assign current time\n        self.__t_elapsed = time.time()\n\n        # loop until terminated\n        while not (self.__terminate):\n            # check for frozen thread\n            if time.time() - self.__t_elapsed &gt; self.__failure_timeout:\n                # log failure\n                self.__logging and logger.critical(\"Camera Module Disconnected!\")\n                # prepare for clean exit\n                self.__exceptions = True\n                self.__terminate = True  # self-terminate\n\n    def __update(self):\n        \"\"\"\n        A **Threaded Frames Extractor**, that keep iterating frames from PiCamera API to a internal monitored deque,\n        until the thread is terminated, or frames runs out.\n        \"\"\"\n        # keep looping infinitely until the thread is terminated\n        while not (self.__terminate):\n            if not picamera2:\n                try:\n                    # Try to iterate next frame from generator\n                    stream = next(self.stream)\n                except Exception:\n                    # catch and save any exceptions\n                    self.__exceptions = sys.exc_info()\n                    break  # exit\n\n            # __update timer\n            self.__t_elapsed = time.time()\n\n            # grab the frame from the stream\n            if picamera2:\n                frame = self.__camera.capture_array(\"main\")\n            else:\n                frame = stream.array\n                # clear the stream in preparation\n                # for the next frame\n                self.__rawCapture.seek(0)\n                self.__rawCapture.truncate()\n\n            # apply colorspace if specified\n            if not (self.color_space is None):\n                # apply colorspace to frames\n                color_frame = None\n                try:\n                    color_frame = cv2.cvtColor(frame, self.color_space)\n                except Exception as e:\n                    # Catch if any error occurred\n                    color_frame = None\n                    self.color_space = None\n                    self.__logging and logger.exception(str(e))\n                    logger.warning(\"Assigned colorspace value is invalid. Discarding!\")\n                self.frame = color_frame if not (color_frame is None) else frame\n            else:\n                self.frame = frame\n\n        # terminate processes\n        if not (self.__terminate):\n            self.__terminate = True\n\n        # release resources\n        if picamera2:\n            self.__camera.stop()\n        else:\n            self.__rawCapture.close()\n            self.__camera.close()\n\n    def read(self):\n        \"\"\"\n        Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n        and blocks the thread if the deque is full.\n\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n        # check if there are any thread exceptions\n        if not (self.__exceptions is None):\n            if isinstance(self.__exceptions, bool):\n                # clear frame\n                self.frame = None\n                # notify user about hardware failure\n                raise SystemError(\n                    \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\"\n                )\n            else:\n                # clear frame\n                self.frame = None\n                # re-raise error for debugging\n                error_msg = (\n                    \"[PiGear:ERROR] :: Camera Module API failure occurred: {}\".format(\n                        self.__exceptions[1]\n                    )\n                )\n                raise RuntimeError(error_msg).with_traceback(self.__exceptions[2])\n        # return the frame\n        return self.frame\n\n    def stop(self):\n        \"\"\"\n        Safely terminates the thread, and release the multi-threaded resources.\n        \"\"\"\n        # log termination\n        self.__logging and logger.debug(\"Terminating PiGear Processes.\")\n\n        # make sure that the threads should be terminated\n        self.__terminate = True\n\n        # stop timer thread\n        if not (self.__timer is None):\n            self.__timer.join()\n            self.__timer = None\n\n        # handle camera thread\n        if not (self.__thread is None):\n            # check if hardware failure occurred\n            if not (self.__exceptions is None) and isinstance(self.__exceptions, bool):\n                if picamera2:\n                    # release picamera2 resources\n                    self.__camera.stop()\n                else:\n                    # force release picamera resources\n                    self.__rawCapture.close()\n                    self.__camera.close()\n            # properly handle thread exit\n            # wait if still process is still\n            # processing some information\n            self.__thread.join()\n            # remove any threads\n            self.__thread = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.__init__","title":"<code>__init__(self, camera_num=0, resolution=(640, 480), framerate=30, colorspace=None, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the PiGear class.</p> <p>Parameters:</p> Name Type Description Default <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the source..</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the source.</p> <code>30</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Source Tweak Parameters.</p> <code>{}</code> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def __init__(\n    self,\n    camera_num=0,\n    resolution=(640, 480),\n    framerate=30,\n    colorspace=None,\n    logging=False,\n    time_delay=0,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the PiGear class.\n\n    Parameters:\n        camera_num (int): selects the camera module index which will be used as source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source..\n        framerate (int/float): sets the framerate of the source.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Source Tweak Parameters.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # raise error(s) for critical Class imports\n    global picamera, picamera2\n    if picamera2:\n        # log if picamera2\n        self.__logging and logger.info(\"picamera2 API is currently being accessed.\")\n    elif picamera:\n        # switch to picamera otherwise\n        logger.critical(\n            \"picamera2 library not installed on this system. Defaulting to legacy picamera API.\"\n        )\n    else:\n        # raise error if none\n        import_dependency_safe(\"picamera\")\n\n    assert (\n        isinstance(framerate, (int, float)) and framerate &gt; 0.0\n    ), \"[PiGear:ERROR] :: Input framerate value `{}` is a Invalid! Kindly read docs.\".format(\n        framerate\n    )\n    assert (\n        isinstance(resolution, (tuple, list)) and len(resolution) == 2\n    ), \"[PiGear:ERROR] :: Input resolution value `{}` is a Invalid! Kindly read docs.\".format(\n        resolution\n    )\n    if not (isinstance(camera_num, int) and camera_num &gt;= 0):\n        camera_num = 0\n        logger.warning(\n            \"Input camera_num value `{}` is invalid, Defaulting to index 0!\"\n        )\n\n    # reformat dict\n    options = {str(k).strip(): v for k, v in options.items()}\n\n    # check if legacy picamera backend is enforced\n    enforce_legacy_picamera = options.pop(\"enforce_legacy_picamera\", False)\n    if isinstance(enforce_legacy_picamera, bool) and enforce_legacy_picamera:\n        # check if picamera library is available.\n        if picamera:\n            logger.critical(\n                \"Enforcing legacy picamera API for this run. picamera2 API access will be disabled!\"\n            )\n            # disable picamera2\n            picamera2 = None\n        else:\n            # raise error otherwise\n            logger.error(\n                \"`picamera` is unavailable or unsupported on this system, `enforce_legacy_picamera` will be discarded!\"\n            )\n            import_dependency_safe(\"picamera\")\n\n    if picamera2:\n        # handle logging\n        not (self.__logging) and not os.getenv(\n            \"LIBCAMERA_LOG_LEVELS\", False\n        ) and logger.info(\n            \"Kindly set `LIBCAMERA_LOG_LEVELS=2` environment variable to disable common libcamera API messages.\"\n        )\n        # collect metadata\n        cameras_metadata = Picamera2.global_camera_info()\n        # initialize the picamera stream at given index\n        self.__camera = Picamera2(camera_num=camera_num)\n        # extract metadata for current camera\n        camera_metadata = [x for x in cameras_metadata if x[\"Num\"] == camera_num][0]\n        # check connected camera is USB or I2C\n        self.__camera_is_usb = True if \"usb\" in camera_metadata[\"Id\"] else False\n        # handle framerate control\n        if not self.__camera_is_usb:\n            self.__camera.set_controls({\"FrameRate\": framerate})\n        else:\n            logger.warning(\n                \"USB camera detected. Setting input framerate is NOT supported with Picamera2 API!\"\n            )\n        # log\n        self.__logging and logger.debug(\n            \"Activating Picamera2 API for `{}` camera at index: {} with resolution: {} &amp; framerate: {}\".format(\n                camera_metadata[\"Model\"],\n                camera_num,\n                resolution if not self.__camera_is_usb else \"default\",\n                framerate,\n            )\n        )\n    else:\n        # initialize the picamera stream at given index\n        self.__camera = PiCamera(camera_num=camera_num)\n        self.__camera.resolution = tuple(resolution)\n        self.__camera.framerate = framerate\n        self.__logging and logger.debug(\n            \"Activating Picamera API at index: {} with resolution: {} &amp; framerate: {}\".format(\n                camera_num, resolution, framerate\n            )\n        )\n\n    # initialize framerate (Read-only) variable\n    self.framerate = framerate\n\n    # initializing colorspace variable\n    self.color_space = None\n\n    # define timeout variable default value(handles hardware failures)\n    self.__failure_timeout = options.pop(\"HWFAILURE_TIMEOUT\", 2.0)\n    if isinstance(self.__failure_timeout, (int, float)):\n        if not (10.0 &gt; self.__failure_timeout &gt; 1.0):\n            raise ValueError(\n                \"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\"\n            )\n        self.__logging and logger.debug(\n            \"Setting HW Failure Timeout: {} seconds\".format(self.__failure_timeout)\n        )\n    else:\n        # reset improper values\n        self.__failure_timeout = 2.0\n\n    try:\n        if picamera2:\n            # define common supported picamera2 config parameters\n            valid_config_options = [\n                \"auto_align_output_size\",  # internal\n                \"enable_verbose_logs\",  # internal\n                \"format\",\n                \"sensor\",\n            ]\n\n            # define non-USB supported picamera2 config parameters\n            non_usb_options = [\n                \"controls\",  # not-supported on USB\n                \"transform\",  # not-working on USB\n                \"buffer_count\",  # not-supported on USB\n                \"queue\",  # not-supported on USB\n            ]  # Less are supported (will be changed in future)\n\n            # filter parameter supported with non-USB cameras only\n            if self.__camera_is_usb:\n                unsupported_config_keys = set(list(options.keys())).intersection(\n                    set(non_usb_options)\n                )\n                unsupported_config_keys and logger.warning(\n                    \"Setting parameters: `{}` for USB camera is NOT supported with Picamera2 API!\".format(\n                        \"`, `\".join(unsupported_config_keys)\n                    )\n                )\n            else:\n                valid_config_options += non_usb_options\n\n            # log all invalid keys\n            invalid_config_keys = set(list(options.keys())) - set(\n                valid_config_options\n            )\n            invalid_config_keys and logger.warning(\n                \"Discarding invalid options NOT supported by Picamera2 API for current Camera Sensor: `{}`\".format(\n                    \"`, `\".join(invalid_config_keys)\n                )\n            )\n            # delete all unsupported options\n            options = {\n                x: y for x, y in options.items() if x in valid_config_options\n            }\n\n            # setting size, already defined\n            options.update({\"size\": tuple(resolution)})\n\n            # set 24-bit, BGR format by default\n            if not \"format\" in options:\n                # auto defaults for USB cameras\n                not self.__camera_is_usb and options.update({\"format\": \"RGB888\"})\n            elif self.__camera_is_usb:\n                # check the supported formats, if USB camera\n                avail_formats = [\n                    mode[\"format\"] for mode in self.__camera.sensor_modes\n                ]\n                # handle unsupported formats\n                if not options[\"format\"] in avail_formats:\n                    logger.warning(\n                        \"Discarding `format={}`. `{}` are the only available formats for USB camera in use!\".format(\n                            options[\"format\"], \"`, `\".join(avail_formats)\n                        )\n                    )\n                    del options[\"format\"]\n                else:\n                    # `colorspace` parameter must define with  `format` optional parameter\n                    # unless format is MPEG (tested)\n                    (\n                        not (colorspace is None) or options[\"format\"] == \"MPEG\"\n                    ) and logger.warning(\n                        \"Custom Output frames `format={}` detected. It is advised to define `colorspace` parameter or handle this format manually in your code!\".format(\n                            options[\"format\"]\n                        )\n                    )\n            else:\n                # `colorspace` parameter must define with  `format` optional parameter\n                # unless format is either BGR or BGRA\n                (\n                    not (colorspace is None)\n                    or options[\"format\"]\n                    in [\n                        \"RGB888\",\n                        \"XRGB8888\",\n                    ]\n                ) and logger.warning(\n                    \"Custom Output frames `format={}` detected. It is advised to define `colorspace` parameter or handle this format manually in your code!\".format(\n                        options[\"format\"]\n                    )\n                )\n\n            # enable verbose logging mode (handled by Picamera2 API)\n            verbose = options.pop(\"enable_verbose_logs\", False)\n            if self.__logging and isinstance(verbose, bool) and verbose:\n                self.__camera.set_logging(Picamera2.DEBUG)\n            else:\n                # setup logging\n                self.__camera.set_logging(Picamera2.WARNING)\n\n            # handle transformations, if specified\n            transform = options.pop(\"transform\", Transform())\n            if not isinstance(transform, Transform):\n                logger.warning(\"`transform` value is of invalid type, Discarding!\")\n                transform = Transform()\n\n            # handle sensor configurations, if specified\n            sensor = options.pop(\"sensor\", {})\n            if isinstance(sensor, dict):\n                # extract all valid sensor keys\n                valid_sensor = [\"output_size\", \"bit_depth\"]\n                # log all invalid keys\n                invalid_sensor_keys = set(list(sensor)) - set(valid_sensor)\n                invalid_sensor_keys and logger.warning(\n                    \"Discarding sensor properties NOT supported by current Camera Sensor: `{}`. Only supported are: (`{}`)\".format(\n                        \"`, `\".join(invalid_sensor_keys),\n                        \"`, `\".join(valid_sensor),\n                    )\n                )\n                # delete all unsupported control keys\n                sensor = {x: y for x, y in sensor.items() if x in valid_sensor}\n                # remove size if output size is defined\n                if \"output_size\" in sensor:\n                    del options[\"size\"]\n                    logger.critical(\n                        \"Overriding output frame size with `output_size={}!\".format(\n                            sensor[\"output_size\"]\n                        )\n                    )\n            else:\n                logger.warning(\"`sensor` value is of invalid type, Discarding!\")\n                sensor = {}\n\n            # handle controls, if specified\n            controls = options.pop(\"controls\", {})\n            if isinstance(controls, dict):\n                # extract all valid control keys\n                valid_controls = self.__camera.camera_controls\n                # remove any fps controls, assigned already\n                valid_controls.pop(\"FrameDuration\", None)\n                valid_controls.pop(\"FrameDurationLimits\", None)\n                # log all invalid keys\n                invalid_control_keys = set(list(controls.keys())) - set(\n                    list(valid_controls.keys())\n                )\n                invalid_control_keys and logger.warning(\n                    \"Discarding control properties NOT supported by current Camera Sensor: `{}`. Only supported are: (`{}`)\".format(\n                        \"`, `\".join(invalid_control_keys),\n                        \"`, `\".join(list(valid_controls.keys())),\n                    )\n                )\n                # delete all unsupported control keys\n                controls = {\n                    x: y for x, y in controls.items() if x in valid_controls.keys()\n                }\n            else:\n                logger.warning(\"`controls` value is of invalid type, Discarding!\")\n                controls = {}\n\n            # handle buffer_count, if specified\n            buffer_count = options.pop(\"buffer_count\", 4)\n            if (\n                not isinstance(buffer_count, int) or buffer_count &lt; 1\n            ):  # must be greater than 1\n                logger.warning(\n                    \"`buffer_count` value is of invalid type, Discarding!\"\n                )\n                # `create_preview_configuration` requests 4 sets of buffers\n                buffer_count = 4\n\n            # handle queue, if specified\n            queue = options.pop(\"queue\", True)\n            if not isinstance(queue, bool):\n                logger.warning(\"`queue` value is of invalid type, Discarding!\")\n                queue = True\n\n            # check if auto-align camera configuration is specified\n            auto_align_output_size = options.pop(\"auto_align_output_size\", False)\n\n            # create default configuration for camera\n            config = self.__camera.create_preview_configuration(\n                main=options,\n                transform=transform,\n                sensor=sensor,\n                controls=controls,\n                buffer_count=buffer_count,\n                queue=queue,\n            )\n\n            # auto-align camera configuration, if specified\n            if isinstance(auto_align_output_size, bool) and auto_align_output_size:\n                self.__logging and logger.debug(\n                    \"Re-aligning Output frames to optimal size supported by current Camera Sensor.\"\n                )\n                self.__camera.align_configuration(config)\n\n            # configure camera\n            self.__camera.configure(config)\n            self.__logging and logger.debug(\n                \"Setting Picamera2 API Parameters: `{}`, controls: `{}`, sensor: `{}`, buffer_count: `{}`, and queue: `{}`.\".format(\n                    self.__camera.camera_configuration()[\"main\"],\n                    controls,\n                    sensor,\n                    buffer_count,\n                    queue,\n                )\n            )\n        else:\n            # apply attributes to source if specified\n            for key, value in options.items():\n                self.__logging and logger.debug(\n                    \"Setting {} API Parameter for Picamera: `{}`\".format(key, value)\n                )\n                setattr(self.__camera, key, value)\n    except Exception as e:\n        # Catch if any error occurred\n        logger.exception(str(e))\n\n    # separately handle colorspace value to int conversion\n    if not (colorspace is None):\n        self.color_space = capPropId(colorspace.strip())\n        if self.__logging and not (self.color_space is None):\n            logger.debug(\n                \"Enabling `{}` colorspace for this video stream!\".format(\n                    colorspace.strip()\n                )\n            )\n\n    # enable rgb capture array thread and capture stream\n    if not picamera2:\n        self.__rawCapture = PiRGBArray(self.__camera, size=resolution)\n        self.stream = self.__camera.capture_continuous(\n            self.__rawCapture, format=\"bgr\", use_video_port=True\n        )\n\n    # initialize frame variable\n    # with captured frame\n    try:\n        if picamera2:\n            # start camera thread\n            self.__camera.start()\n            # capture frame array\n            self.frame = self.__camera.capture_array(\"main\")\n            # assign camera as stream for setting\n            # parameters after starting the camera\n            self.stream = self.__camera\n        else:\n            # capture frame array from stream\n            stream = next(self.stream)\n            self.frame = stream.array\n            self.__rawCapture.seek(0)\n            self.__rawCapture.truncate()\n        # render colorspace if defined\n        if not (self.frame is None) and not (self.color_space is None):\n            self.frame = cv2.cvtColor(self.frame, self.color_space)\n    except Exception as e:\n        logger.exception(str(e))\n        raise RuntimeError(\"[PiGear:ERROR] :: Camera Module failed to initialize!\")\n\n    # applying time delay to warm-up picamera only if specified\n    if time_delay and isinstance(time_delay, (int, float)):\n        time.sleep(time_delay)\n\n    # thread initialization\n    self.__thread = None\n\n    # timer thread initialization(Keeps check on frozen thread)\n    self.__timer = None\n    self.__t_elapsed = 0.0  # records time taken by thread\n\n    # catching thread exceptions\n    self.__exceptions = None\n\n    # initialize termination flag\n    self.__terminate = False\n</code></pre>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def read(self):\n    \"\"\"\n    Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n    and blocks the thread if the deque is full.\n\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n    # check if there are any thread exceptions\n    if not (self.__exceptions is None):\n        if isinstance(self.__exceptions, bool):\n            # clear frame\n            self.frame = None\n            # notify user about hardware failure\n            raise SystemError(\n                \"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\"\n            )\n        else:\n            # clear frame\n            self.frame = None\n            # re-raise error for debugging\n            error_msg = (\n                \"[PiGear:ERROR] :: Camera Module API failure occurred: {}\".format(\n                    self.__exceptions[1]\n                )\n            )\n            raise RuntimeError(error_msg).with_traceback(self.__exceptions[2])\n    # return the frame\n    return self.frame\n</code></pre>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon</p> <p>Returns: A reference to the PiGear class object.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def start(self):\n    \"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon\n\n    **Returns:** A reference to the PiGear class object.\n    \"\"\"\n    # Start frame producer thread\n    self.__thread = Thread(target=self.__update, name=\"PiGear\", args=())\n    self.__thread.daemon = True\n    self.__thread.start()\n\n    # Start internal timer thread\n    self.__timer = Thread(target=self.__timeit, name=\"PiTimer\", args=())\n    self.__timer.daemon = True\n    self.__timer.start()\n\n    return self\n</code></pre>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the multi-threaded resources.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def stop(self):\n    \"\"\"\n    Safely terminates the thread, and release the multi-threaded resources.\n    \"\"\"\n    # log termination\n    self.__logging and logger.debug(\"Terminating PiGear Processes.\")\n\n    # make sure that the threads should be terminated\n    self.__terminate = True\n\n    # stop timer thread\n    if not (self.__timer is None):\n        self.__timer.join()\n        self.__timer = None\n\n    # handle camera thread\n    if not (self.__thread is None):\n        # check if hardware failure occurred\n        if not (self.__exceptions is None) and isinstance(self.__exceptions, bool):\n            if picamera2:\n                # release picamera2 resources\n                self.__camera.stop()\n            else:\n                # force release picamera resources\n                self.__rawCapture.close()\n                self.__camera.close()\n        # properly handle thread exit\n        # wait if still process is still\n        # processing some information\n        self.__thread.join()\n        # remove any threads\n        self.__thread = None\n</code></pre>"},{"location":"bonus/reference/screengear/","title":"API References","text":"<p>ScreenGear API usage examples can be found here \u27b6</p> <p>ScreenGear API parameters are explained here \u27b6</p> <p>ScreenGear is designed exclusively for targeting rapid Screencasting Capabilities, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends.</p> <p>ScreenGear API implements a multi-threaded wrapper around dxcam, pyscreenshot, python-mss python library, and also flexibly supports its internal parameter.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>class ScreenGear:\n    \"\"\"\n    ScreenGear is designed exclusively for targeting rapid Screencasting Capabilities, which means it can\n    grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen,\n    at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple\n    monitors as well as supports multiple backends.\n\n    ScreenGear API implements a multi-threaded wrapper around dxcam, pyscreenshot, python-mss python library,\n    and also flexibly supports its internal parameter.\n    \"\"\"\n\n    def __init__(\n        self, monitor=None, backend=None, colorspace=None, logging=False, **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the ScreenGear class.\n\n        Parameters:\n            monitor (int): enables `mss` backend and sets the index of the monitor screen.\n            backend (str): select suitable backend for extracting frames.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            options (dict): provides the flexibility to easily alter backend library parameters. Such as, manually set the dimensions of capture screen area etc.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # create instances for the user-defined monitor\n        self.__monitor_instance = None\n        self.__backend = None\n\n        # validate monitor instance\n        assert (\n            monitor is None or monitor and isinstance(monitor, (int, tuple))\n        ), \"[ScreenGear:ERROR] :: Invalid `monitor` value detected!\"\n\n        # initialize backend\n        if backend and monitor is None:\n            self.__backend = backend.lower().strip()\n        else:\n            # enforce `dxcam` for Windows machines if undefined (or monitor is defined)\n            self.__backend = (\n                \"dxcam\" if platform.system() == \"Windows\" and dxcam else None\n            )\n\n        # initiate screen dimension handler\n        screen_dims = {}\n        # reformat proper mss dict and assign to screen dimension handler\n        screen_dims = {\n            k.strip(): v\n            for k, v in options.items()\n            if k.strip() in [\"top\", \"left\", \"width\", \"height\"]\n        }\n        # check whether user-defined dimensions are provided\n        if screen_dims and len(screen_dims) == 4:\n            key_order = (\n                (\"top\", \"left\", \"width\", \"height\")\n                if self.__backend != \"dxcam\"\n                else (\"left\", \"top\", \"width\", \"height\")\n            )\n            screen_dims = OrderedDict((k, screen_dims[k]) for k in key_order)\n            self.__logging and logger.debug(\n                \"Setting Capture-Area dimensions: {}\".format(json.dumps(screen_dims))\n            )\n        else:\n            screen_dims.clear()\n\n        # handle backends\n        if self.__backend == \"dxcam\":\n            # get target fps in case of DXcam\n            self.__target_fps = options.pop(\"dxcam_target_fps\", 0)\n            if self.__target_fps and isinstance(self.__target_fps, (int, float)):\n                # set values\n                self.__target_fps = int(self.__target_fps)\n                self.__logging and logger.debug(\n                    \"Setting Target FPS: {}\".format(self.__target_fps)\n                )\n            else:\n                # defaults to 0fps\n                self.__target_fps = 0\n            # check if platform is windows\n            assert (\n                platform.system() == \"Windows\"\n            ), \"`dxcam` backend is only available for Windows Machines.\"\n            # verify monitor values if tuple\n            assert (\n                monitor is None\n                or isinstance(monitor, int)\n                or (\n                    isinstance(monitor, tuple)\n                    and len(monitor) == 2\n                    and all(isinstance(x, int) for x in monitor)\n                )\n            ), \"For dxcam` backend, monitor` tuple value must be format `int` or `(int, int)` only.\"\n            # raise error(s) for critical Class imports\n            import_dependency_safe(\"dxcam\" if dxcam is None else \"\")\n            if monitor is None:\n                self.__capture_object = dxcam.create(\n                    region=tuple(screen_dims.values()) if screen_dims else None\n                )\n            else:\n                self.__capture_object = (\n                    dxcam.create(\n                        device_idx=monitor[0],\n                        output_idx=monitor[1],\n                        region=tuple(screen_dims.values()) if screen_dims else None,\n                    )\n                    if isinstance(monitor, tuple)\n                    else dxcam.create(\n                        device_idx=monitor,\n                        region=tuple(screen_dims.values()) if screen_dims else None,\n                    )\n                )\n        else:\n            if monitor is None:\n                # raise error(s) for critical Class imports\n                import_dependency_safe(\"pyscreenshot\" if pysct is None else \"\")\n                # reset backend if not provided\n                self.__backend = \"pil\" if self.__backend is None else self.__backend\n                # check if valid backend\n                assert (\n                    self.__backend in pysct.backends()\n                ), \"Unsupported backend {} provided!\".format(backend)\n                # create capture object\n                self.__capture_object = pysct\n            else:\n                # monitor value must be integer\n                assert monitor and isinstance(\n                    monitor, int\n                ), \"[ScreenGear:ERROR] :: Invalid `monitor` value must be integer with mss backend.\"\n                # raise error(s) for critical Class imports\n                import_dependency_safe(\n                    \"from mss import mss\" if mss is None else \"\", pkg_name=\"mss\"\n                )\n                # create capture object\n                self.__capture_object = mss()\n                self.__backend and logger.warning(\n                    \"Backends are disabled for Monitor Indexing(monitor&gt;=0)!\"\n                )\n                self.__monitor_instance = self.__capture_object.monitors[monitor]\n\n        # log backend\n        self.__backend and self.__logging and logger.debug(\n            \"Setting Backend: {}\".format(self.__backend.upper())\n        )\n\n        # assigns special parameter to global variable and clear\n        # separately handle colorspace value to int conversion\n        if colorspace:\n            self.color_space = capPropId(colorspace.strip())\n            self.__logging and not (self.color_space is None) and logger.debug(\n                \"Enabling `{}` colorspace for this video stream!\".format(\n                    colorspace.strip()\n                )\n            )\n        else:\n            self.color_space = None\n\n        # initialize mss capture instance\n        self.__mss_capture_instance = None\n        try:\n            if self.__backend == \"dxcam\":\n                # extract global frame from instance\n                self.frame = self.__capture_object.grab()\n            else:\n                if self.__monitor_instance is None:\n                    if screen_dims:\n                        self.__mss_capture_instance = tuple(screen_dims.values())\n                    # extract global frame from instance\n                    self.frame = np.asanyarray(\n                        self.__capture_object.grab(\n                            bbox=self.__mss_capture_instance,\n                            childprocess=False,\n                            backend=self.__backend,\n                        )\n                    )\n                else:\n                    if screen_dims:\n                        self.__mss_capture_instance = {\n                            \"top\": self.__monitor_instance[\"top\"] + screen_dims[\"top\"],\n                            \"left\": self.__monitor_instance[\"left\"]\n                            + screen_dims[\"left\"],\n                            \"width\": screen_dims[\"width\"],\n                            \"height\": screen_dims[\"height\"],\n                            \"mon\": monitor,\n                        }\n                    else:\n                        self.__mss_capture_instance = (\n                            self.__monitor_instance  # otherwise create instance from monitor\n                        )\n                    # extract global frame from instance\n                    self.frame = np.asanyarray(\n                        self.__capture_object.grab(self.__mss_capture_instance)\n                    )\n            # convert to bgr frame if applicable\n            self.frame = (\n                self.frame[:, :, ::-1]\n                if self.__backend == \"dxcam\" or not (pysct is None)\n                else self.frame\n            )\n            # render colorspace if defined\n            if not (self.frame is None) and not (self.color_space is None):\n                self.frame = cv2.cvtColor(self.frame, self.color_space)\n        except Exception as e:\n            if isinstance(e, ScreenShotError):\n                # otherwise catch and log errors\n                self.__logging and logger.exception(\n                    self.__capture_object.get_error_details()\n                )\n                raise ValueError(\n                    \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\"\n                )\n            else:\n                raise SystemError(\n                    \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\"\n                )\n        # thread initialization\n        self.__thread = None\n        # initialize termination flag\n        self.__terminate = Event()\n\n    def start(self):\n        \"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon\n\n        **Returns:** A reference to the ScreenGear class object.\n        \"\"\"\n        self.__thread = Thread(target=self.__update, name=\"ScreenGear\", args=())\n        self.__thread.daemon = True\n        self.__thread.start()\n        if self.__backend == \"dxcam\":\n            self.__capture_object.start(\n                target_fps=self.__target_fps,\n                video_mode=True,\n            )\n            self.__logging and self.__target_fps and logger.debug(\n                \"Targeting FPS: {}\".format(self.__target_fps)\n            )\n        return self\n\n    def __update(self):\n        \"\"\"\n        A **Threaded Frames Extractor**, that keep iterating frames from `mss` API to a internal monitored deque,\n        until the thread is terminated, or frames runs out.\n        \"\"\"\n        # initialize frame variable\n        frame = None\n        # keep looping infinitely until the thread is terminated\n        while not self.__terminate.is_set():\n            try:\n                if self.__backend == \"dxcam\":\n                    # extract global frame from instance\n                    frame = self.__capture_object.get_latest_frame()\n                else:\n                    if self.__monitor_instance:\n                        frame = np.asanyarray(\n                            self.__capture_object.grab(self.__mss_capture_instance)\n                        )\n                    else:\n                        frame = np.asanyarray(\n                            self.__capture_object.grab(\n                                bbox=self.__mss_capture_instance,\n                                childprocess=False,\n                                backend=self.__backend,\n                            )\n                        )\n                # check if valid frame\n                assert not (\n                    frame is None or np.shape(frame) == ()\n                ), \"[ScreenGear:ERROR] :: Failed to retrieve valid frame!\"\n                # convert to bgr frame if applicable\n                frame = (\n                    frame[:, :, ::-1]\n                    if self.__backend == \"dxcam\" or not (pysct is None)\n                    else frame\n                )\n            except Exception as e:\n                if isinstance(e, ScreenShotError):\n                    raise RuntimeError(self.__capture_object.get_error_details())\n                else:\n                    logger.exception(str(e))\n                self.__terminate.set()\n                continue\n\n            if not (self.color_space is None):\n                # apply colorspace to frames\n                color_frame = None\n                try:\n                    color_frame = cv2.cvtColor(frame, self.color_space)\n                except Exception as e:\n                    # Catch if any error occurred\n                    color_frame = None\n                    self.color_space = None\n                    self.__logging and logger.exception(str(e))\n                    logger.warning(\"Assigned colorspace value is invalid. Discarding!\")\n                self.frame = color_frame if not (color_frame is None) else frame\n            else:\n                self.frame = frame\n\n        # indicate immediate termination\n        self.__terminate.set()\n\n        # finally release mss resources\n        if self.__monitor_instance:\n            self.__capture_object.close()\n        if self.__backend == \"dxcam\":\n            self.__capture_object.stop()\n            del self.__capture_object\n\n    def read(self):\n        \"\"\"\n        Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n        and blocks the thread if the deque is full.\n\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n        # return the frame\n        return self.frame\n\n    def stop(self):\n        \"\"\"\n        Safely terminates the thread, and release the resources.\n        \"\"\"\n        self.__logging and logger.debug(\"Terminating ScreenGear Processes.\")\n\n        # indicate that the thread should be terminate\n        self.__terminate.set()\n\n        # wait until stream resources are released (producer thread might be still grabbing frame)\n        not (self.__thread is None) and self.__thread.join()\n</code></pre> <p> </p>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.__init__","title":"<code>__init__(self, monitor=None, backend=None, colorspace=None, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the ScreenGear class.</p> <p>Parameters:</p> Name Type Description Default <code>monitor</code> <code>int</code> <p>enables <code>mss</code> backend and sets the index of the monitor screen.</p> <code>None</code> <code>backend</code> <code>str</code> <p>select suitable backend for extracting frames.</p> <code>None</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>options</code> <code>dict</code> <p>provides the flexibility to easily alter backend library parameters. Such as, manually set the dimensions of capture screen area etc.</p> <code>{}</code> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def __init__(\n    self, monitor=None, backend=None, colorspace=None, logging=False, **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the ScreenGear class.\n\n    Parameters:\n        monitor (int): enables `mss` backend and sets the index of the monitor screen.\n        backend (str): select suitable backend for extracting frames.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        options (dict): provides the flexibility to easily alter backend library parameters. Such as, manually set the dimensions of capture screen area etc.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # create instances for the user-defined monitor\n    self.__monitor_instance = None\n    self.__backend = None\n\n    # validate monitor instance\n    assert (\n        monitor is None or monitor and isinstance(monitor, (int, tuple))\n    ), \"[ScreenGear:ERROR] :: Invalid `monitor` value detected!\"\n\n    # initialize backend\n    if backend and monitor is None:\n        self.__backend = backend.lower().strip()\n    else:\n        # enforce `dxcam` for Windows machines if undefined (or monitor is defined)\n        self.__backend = (\n            \"dxcam\" if platform.system() == \"Windows\" and dxcam else None\n        )\n\n    # initiate screen dimension handler\n    screen_dims = {}\n    # reformat proper mss dict and assign to screen dimension handler\n    screen_dims = {\n        k.strip(): v\n        for k, v in options.items()\n        if k.strip() in [\"top\", \"left\", \"width\", \"height\"]\n    }\n    # check whether user-defined dimensions are provided\n    if screen_dims and len(screen_dims) == 4:\n        key_order = (\n            (\"top\", \"left\", \"width\", \"height\")\n            if self.__backend != \"dxcam\"\n            else (\"left\", \"top\", \"width\", \"height\")\n        )\n        screen_dims = OrderedDict((k, screen_dims[k]) for k in key_order)\n        self.__logging and logger.debug(\n            \"Setting Capture-Area dimensions: {}\".format(json.dumps(screen_dims))\n        )\n    else:\n        screen_dims.clear()\n\n    # handle backends\n    if self.__backend == \"dxcam\":\n        # get target fps in case of DXcam\n        self.__target_fps = options.pop(\"dxcam_target_fps\", 0)\n        if self.__target_fps and isinstance(self.__target_fps, (int, float)):\n            # set values\n            self.__target_fps = int(self.__target_fps)\n            self.__logging and logger.debug(\n                \"Setting Target FPS: {}\".format(self.__target_fps)\n            )\n        else:\n            # defaults to 0fps\n            self.__target_fps = 0\n        # check if platform is windows\n        assert (\n            platform.system() == \"Windows\"\n        ), \"`dxcam` backend is only available for Windows Machines.\"\n        # verify monitor values if tuple\n        assert (\n            monitor is None\n            or isinstance(monitor, int)\n            or (\n                isinstance(monitor, tuple)\n                and len(monitor) == 2\n                and all(isinstance(x, int) for x in monitor)\n            )\n        ), \"For dxcam` backend, monitor` tuple value must be format `int` or `(int, int)` only.\"\n        # raise error(s) for critical Class imports\n        import_dependency_safe(\"dxcam\" if dxcam is None else \"\")\n        if monitor is None:\n            self.__capture_object = dxcam.create(\n                region=tuple(screen_dims.values()) if screen_dims else None\n            )\n        else:\n            self.__capture_object = (\n                dxcam.create(\n                    device_idx=monitor[0],\n                    output_idx=monitor[1],\n                    region=tuple(screen_dims.values()) if screen_dims else None,\n                )\n                if isinstance(monitor, tuple)\n                else dxcam.create(\n                    device_idx=monitor,\n                    region=tuple(screen_dims.values()) if screen_dims else None,\n                )\n            )\n    else:\n        if monitor is None:\n            # raise error(s) for critical Class imports\n            import_dependency_safe(\"pyscreenshot\" if pysct is None else \"\")\n            # reset backend if not provided\n            self.__backend = \"pil\" if self.__backend is None else self.__backend\n            # check if valid backend\n            assert (\n                self.__backend in pysct.backends()\n            ), \"Unsupported backend {} provided!\".format(backend)\n            # create capture object\n            self.__capture_object = pysct\n        else:\n            # monitor value must be integer\n            assert monitor and isinstance(\n                monitor, int\n            ), \"[ScreenGear:ERROR] :: Invalid `monitor` value must be integer with mss backend.\"\n            # raise error(s) for critical Class imports\n            import_dependency_safe(\n                \"from mss import mss\" if mss is None else \"\", pkg_name=\"mss\"\n            )\n            # create capture object\n            self.__capture_object = mss()\n            self.__backend and logger.warning(\n                \"Backends are disabled for Monitor Indexing(monitor&gt;=0)!\"\n            )\n            self.__monitor_instance = self.__capture_object.monitors[monitor]\n\n    # log backend\n    self.__backend and self.__logging and logger.debug(\n        \"Setting Backend: {}\".format(self.__backend.upper())\n    )\n\n    # assigns special parameter to global variable and clear\n    # separately handle colorspace value to int conversion\n    if colorspace:\n        self.color_space = capPropId(colorspace.strip())\n        self.__logging and not (self.color_space is None) and logger.debug(\n            \"Enabling `{}` colorspace for this video stream!\".format(\n                colorspace.strip()\n            )\n        )\n    else:\n        self.color_space = None\n\n    # initialize mss capture instance\n    self.__mss_capture_instance = None\n    try:\n        if self.__backend == \"dxcam\":\n            # extract global frame from instance\n            self.frame = self.__capture_object.grab()\n        else:\n            if self.__monitor_instance is None:\n                if screen_dims:\n                    self.__mss_capture_instance = tuple(screen_dims.values())\n                # extract global frame from instance\n                self.frame = np.asanyarray(\n                    self.__capture_object.grab(\n                        bbox=self.__mss_capture_instance,\n                        childprocess=False,\n                        backend=self.__backend,\n                    )\n                )\n            else:\n                if screen_dims:\n                    self.__mss_capture_instance = {\n                        \"top\": self.__monitor_instance[\"top\"] + screen_dims[\"top\"],\n                        \"left\": self.__monitor_instance[\"left\"]\n                        + screen_dims[\"left\"],\n                        \"width\": screen_dims[\"width\"],\n                        \"height\": screen_dims[\"height\"],\n                        \"mon\": monitor,\n                    }\n                else:\n                    self.__mss_capture_instance = (\n                        self.__monitor_instance  # otherwise create instance from monitor\n                    )\n                # extract global frame from instance\n                self.frame = np.asanyarray(\n                    self.__capture_object.grab(self.__mss_capture_instance)\n                )\n        # convert to bgr frame if applicable\n        self.frame = (\n            self.frame[:, :, ::-1]\n            if self.__backend == \"dxcam\" or not (pysct is None)\n            else self.frame\n        )\n        # render colorspace if defined\n        if not (self.frame is None) and not (self.color_space is None):\n            self.frame = cv2.cvtColor(self.frame, self.color_space)\n    except Exception as e:\n        if isinstance(e, ScreenShotError):\n            # otherwise catch and log errors\n            self.__logging and logger.exception(\n                self.__capture_object.get_error_details()\n            )\n            raise ValueError(\n                \"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\"\n            )\n        else:\n            raise SystemError(\n                \"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\"\n            )\n    # thread initialization\n    self.__thread = None\n    # initialize termination flag\n    self.__terminate = Event()\n</code></pre>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def read(self):\n    \"\"\"\n    Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n    and blocks the thread if the deque is full.\n\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n    # return the frame\n    return self.frame\n</code></pre>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon</p> <p>Returns: A reference to the ScreenGear class object.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def start(self):\n    \"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon\n\n    **Returns:** A reference to the ScreenGear class object.\n    \"\"\"\n    self.__thread = Thread(target=self.__update, name=\"ScreenGear\", args=())\n    self.__thread.daemon = True\n    self.__thread.start()\n    if self.__backend == \"dxcam\":\n        self.__capture_object.start(\n            target_fps=self.__target_fps,\n            video_mode=True,\n        )\n        self.__logging and self.__target_fps and logger.debug(\n            \"Targeting FPS: {}\".format(self.__target_fps)\n        )\n    return self\n</code></pre>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the resources.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def stop(self):\n    \"\"\"\n    Safely terminates the thread, and release the resources.\n    \"\"\"\n    self.__logging and logger.debug(\"Terminating ScreenGear Processes.\")\n\n    # indicate that the thread should be terminate\n    self.__terminate.set()\n\n    # wait until stream resources are released (producer thread might be still grabbing frame)\n    not (self.__thread is None) and self.__thread.join()\n</code></pre>"},{"location":"bonus/reference/stabilizer/","title":"API References","text":"<p>Stabilizer API usage examples can be found here \u27b6</p> <p>Stabilizer API parameters are explained here \u27b6</p> <p>This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements.</p> <p>The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free &amp; ultra-fast frame handling.</p> Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>class Stabilizer:\n    \"\"\"\n    This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense\n    of little to no additional computational requirements.\n\n    The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses\n    these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies\n    heavily on **Threaded Queue mode** for error-free &amp; ultra-fast frame handling.\n    \"\"\"\n\n    def __init__(\n        self,\n        smoothing_radius=25,\n        border_type=\"black\",\n        border_size=0,\n        crop_n_zoom=False,\n        logging=False,\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the Stabilizer class.\n\n        Parameters:\n            smoothing_radius (int): alter averaging window size.\n            border_type (str): changes the extended border type.\n            border_size (int): enables and set the value for extended border size to reduce the black borders.\n            crop_n_zoom (bool): enables cropping and zooming of frames(to original size) to reduce the black borders.\n            logging (bool): enables/disables logging.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # initialize deques for handling input frames and its indexes\n        self.__frame_queue = deque(maxlen=smoothing_radius)\n        self.__frame_queue_indexes = deque(maxlen=smoothing_radius)\n\n        # define and create Adaptive histogram equalization (AHE) object for optimizations\n        self.__clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n\n        # initialize global vars\n        self.__smoothing_radius = smoothing_radius  # averaging window, handles the quality of stabilization at expense of latency and sudden panning\n        self.__smoothed_path = None  # handles the smoothed path with box filter\n        self.__path = None  # handles path i.e cumulative sum of previous_2_current transformations along a axis\n        self.__transforms = []  # handles previous_2_current transformations [dx,dy,da]\n        self.__frame_transforms_smoothed = None  # handles smoothed array of previous_2_current transformations w.r.t to frames\n        self.__previous_gray = None  # handles previous gray frame\n        self.__previous_keypoints = (\n            None  # handles previous detect_GFTTed keypoints w.r.t previous gray frame\n        )\n        self.__frame_height, self.frame_width = (\n            0,\n            0,\n        )  # handles width and height of input frames\n        self.__crop_n_zoom = 0  # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable.\n\n        # if check if crop_n_zoom defined\n        if crop_n_zoom and border_size:\n            self.__crop_n_zoom = border_size  # crops and zoom frame to original size\n            self.__border_size = 0  # zero out border size\n            self.__frame_size = None  # handles frame size for zooming\n            self.__logging and logger.debug(\n                \"Setting Cropping margin {} pixels\".format(border_size)\n            )\n        else:\n            # Add output borders to frame\n            self.__border_size = border_size\n            self.__logging and border_size and logger.debug(\n                \"Setting Border size {} pixels\".format(border_size)\n            )\n\n        # define valid border modes\n        border_modes = {\n            \"black\": cv2.BORDER_CONSTANT,\n            \"reflect\": cv2.BORDER_REFLECT,\n            \"reflect_101\": cv2.BORDER_REFLECT_101,\n            \"replicate\": cv2.BORDER_REPLICATE,\n            \"wrap\": cv2.BORDER_WRAP,\n        }\n        # choose valid border_mode from border_type\n        if border_type in [\"black\", \"reflect\", \"reflect_101\", \"replicate\", \"wrap\"]:\n            if not crop_n_zoom:\n                # initialize global border mode variable\n                self.__border_mode = border_modes[border_type]\n                self.__logging and border_type != \"black\" and logger.info(\n                    \"Setting Border type: {}\".format(border_type)\n                )\n            else:\n                # log and reset to default\n                self.__logging and border_type != \"black\" and logger.debug(\n                    \"Setting border type is disabled if cropping is enabled!\"\n                )\n                self.__border_mode = border_modes[\"black\"]\n        else:\n            # otherwise log if not\n            self.__logging and logger.debug(\"Invalid input border type!\")\n            self.__border_mode = border_modes[\"black\"]  # reset to default mode\n\n        # define OpenCV version\n        self.__cv2_version = check_CV_version()\n\n        # retrieve best interpolation\n        self.__interpolation = retrieve_best_interpolation(\n            [\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n        )\n\n        # define normalized box filter\n        self.__box_filter = np.ones(smoothing_radius) / smoothing_radius\n\n    def stabilize(self, frame):\n        \"\"\"\n        This method takes an unstabilized video frame, and returns a stabilized one.\n\n        Parameters:\n            frame (numpy.ndarray): inputs unstabilized video frames.\n        \"\"\"\n        # check if frame is None\n        if frame is None:\n            # return if it does\n            return\n\n        # save frame size for zooming\n        if self.__crop_n_zoom and self.__frame_size == None:\n            self.__frame_size = frame.shape[:2]\n\n        # initiate transformations capturing\n        if not self.__frame_queue:\n            # for first frame\n            previous_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to gray\n            previous_gray = self.__clahe.apply(previous_gray)  # optimize gray frame\n            self.__previous_keypoints = cv2.goodFeaturesToTrack(\n                previous_gray,\n                maxCorners=200,\n                qualityLevel=0.05,\n                minDistance=30.0,\n                blockSize=3,\n                mask=None,\n                useHarrisDetector=False,\n                k=0.04,\n            )  # track features using GFTT\n            self.__frame_height, self.frame_width = frame.shape[\n                :2\n            ]  # save input frame height and width\n            self.__frame_queue.append(frame)  # save frame to deque\n            self.__frame_queue_indexes.append(0)  # save frame index to deque\n            self.__previous_gray = previous_gray[\n                :\n            ]  # save gray frame clone for further processing\n\n        elif self.__frame_queue_indexes[-1] &lt; self.__smoothing_radius - 1:\n            # for rest of frames\n            self.__frame_queue.append(frame)  # save frame to deque\n            self.__frame_queue_indexes.append(\n                self.__frame_queue_indexes[-1] + 1\n            )  # save frame index\n            self.__generate_transformations()  # generate transformations\n        else:\n            # start applying transformations\n            self.__frame_queue.append(frame)  # save frame to deque\n            self.__frame_queue_indexes.append(\n                self.__frame_queue_indexes[-1] + 1\n            )  # save frame index\n            self.__generate_transformations()  # generate transformations\n            # calculate smooth path once transformation capturing is completed\n            for i in range(3):\n                # apply normalized box filter to the path\n                self.__smoothed_path[:, i] = self.__box_filter_convolve(\n                    (self.__path[:, i]), window_size=self.__smoothing_radius\n                )\n            # calculate deviation of path from smoothed path\n            deviation = self.__smoothed_path - self.__path\n            # save smoothed transformation\n            self.__frame_transforms_smoothed = self.frame_transform + deviation\n            # return transformation applied stabilized frame\n            return self.__apply_transformations()\n\n    def __generate_transformations(self):\n        \"\"\"\n        An internal method that generate previous-to-current transformations [dx,dy,da].\n        \"\"\"\n        frame_gray = cv2.cvtColor(\n            self.__frame_queue[-1], cv2.COLOR_BGR2GRAY\n        )  # retrieve current frame and convert to gray\n        frame_gray = self.__clahe.apply(frame_gray)  # optimize it\n\n        transformation = None\n        try:\n            # calculate optical flow using Lucas-Kanade differential method\n            curr_kps, status, error = cv2.calcOpticalFlowPyrLK(\n                self.__previous_gray, frame_gray, self.__previous_keypoints, None\n            )\n\n            # select only valid key-points\n            valid_curr_kps = curr_kps[status == 1]  # current\n            valid_previous_keypoints = self.__previous_keypoints[\n                status == 1\n            ]  # previous\n\n            # calculate optimal affine transformation between previous_2_current key-points\n            if self.__cv2_version == 3:\n                # backward compatibility with OpenCV3\n                transformation = cv2.estimateRigidTransform(\n                    valid_previous_keypoints, valid_curr_kps, False\n                )\n            else:\n                transformation = cv2.estimateAffinePartial2D(\n                    valid_previous_keypoints, valid_curr_kps\n                )[0]\n        except cv2.error as e:\n            # catch any OpenCV assertion errors and warn user\n            logger.warning(\"Video-Frame is too dark to generate any transformations!\")\n            transformation = None\n\n        # check if transformation is not None\n        if not (transformation is None):\n            # previous_2_current translation in x direction\n            dx = transformation[0, 2]\n            # previous_2_current translation in y direction\n            dy = transformation[1, 2]\n            # previous_2_current rotation in angle\n            da = np.arctan2(transformation[1, 0], transformation[0, 0])\n        else:\n            # otherwise zero it\n            dx = dy = da = 0\n\n        # save this transformation\n        self.__transforms.append([dx, dy, da])\n\n        # calculate path from cumulative transformations sum\n        self.frame_transform = np.array(self.__transforms, dtype=\"float32\")\n        self.__path = np.cumsum(self.frame_transform, axis=0)\n        # create smoothed path from a copy of path\n        self.__smoothed_path = np.copy(self.__path)\n\n        # re-calculate and save GFTT key-points for current gray frame\n        self.__previous_keypoints = cv2.goodFeaturesToTrack(\n            frame_gray,\n            maxCorners=200,\n            qualityLevel=0.05,\n            minDistance=30.0,\n            blockSize=3,\n            mask=None,\n            useHarrisDetector=False,\n            k=0.04,\n        )\n        # save this gray frame for further processing\n        self.__previous_gray = frame_gray[:]\n\n    def __box_filter_convolve(self, path, window_size):\n        \"\"\"\n        An internal method that applies *normalized linear box filter* to path w.r.t averaging window\n\n        Parameters:\n\n        * path (numpy.ndarray): a cumulative sum of transformations\n        * window_size (int): averaging window size\n        \"\"\"\n        # pad path to size of averaging window\n        path_padded = np.pad(path, (window_size, window_size), \"median\")\n        # apply linear box filter to path\n        path_smoothed = np.convolve(path_padded, self.__box_filter, mode=\"same\")\n        # crop the smoothed path to original path\n        path_smoothed = path_smoothed[window_size:-window_size]\n        # assert if cropping is completed\n        assert path.shape == path_smoothed.shape\n        # return smoothed path\n        return path_smoothed\n\n    def __apply_transformations(self):\n        \"\"\"\n        An internal method that applies affine transformation to the given frame\n        from previously calculated transformations\n        \"\"\"\n        # extract frame and its index from deque\n        queue_frame = self.__frame_queue.popleft()\n        queue_frame_index = self.__frame_queue_indexes.popleft()\n\n        # create border around extracted frame w.r.t border_size\n        bordered_frame = cv2.copyMakeBorder(\n            queue_frame,\n            top=self.__border_size,\n            bottom=self.__border_size,\n            left=self.__border_size,\n            right=self.__border_size,\n            borderType=self.__border_mode,\n            value=[0, 0, 0],\n        )\n        alpha_bordered_frame = cv2.cvtColor(\n            bordered_frame, cv2.COLOR_BGR2BGRA\n        )  # create alpha channel\n        # extract alpha channel\n        alpha_bordered_frame[:, :, 3] = 0\n        alpha_bordered_frame[\n            self.__border_size : self.__border_size + self.__frame_height,\n            self.__border_size : self.__border_size + self.frame_width,\n            3,\n        ] = 255\n\n        # extracting Transformations w.r.t frame index\n        dx = self.__frame_transforms_smoothed[queue_frame_index, 0]  # x-axis\n        dy = self.__frame_transforms_smoothed[queue_frame_index, 1]  # y-axis\n        da = self.__frame_transforms_smoothed[queue_frame_index, 2]  # angle\n\n        # building 2x3 transformation matrix from extracted transformations\n        queue_frame_transform = np.zeros((2, 3), np.float32)\n        queue_frame_transform[0, 0] = np.cos(da)\n        queue_frame_transform[0, 1] = -np.sin(da)\n        queue_frame_transform[1, 0] = np.sin(da)\n        queue_frame_transform[1, 1] = np.cos(da)\n        queue_frame_transform[0, 2] = dx\n        queue_frame_transform[1, 2] = dy\n\n        # Applying an affine transformation to the frame\n        frame_wrapped = cv2.warpAffine(\n            alpha_bordered_frame,\n            queue_frame_transform,\n            alpha_bordered_frame.shape[:2][::-1],\n            borderMode=self.__border_mode,\n        )\n\n        # drop alpha channel\n        frame_stabilized = frame_wrapped[:, :, :3]\n\n        # crop and zoom\n        if self.__crop_n_zoom:\n            # crop stabilized frame\n            frame_cropped = frame_stabilized[\n                self.__crop_n_zoom : -self.__crop_n_zoom,\n                self.__crop_n_zoom : -self.__crop_n_zoom,\n            ]\n            # zoom stabilized frame\n            frame_stabilized = cv2.resize(\n                frame_cropped,\n                self.__frame_size[::-1],\n                interpolation=self.__interpolation,\n            )\n\n        # finally return stabilized frame\n        return frame_stabilized\n\n    def clean(self):\n        \"\"\"\n        Cleans Stabilizer resources\n        \"\"\"\n        # check if deque present\n        if self.__frame_queue:\n            # clear frame deque\n            self.__frame_queue.clear()\n            # clear frame indexes deque\n            self.__frame_queue_indexes.clear()\n</code></pre> <p> </p>"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.__init__","title":"<code>__init__(self, smoothing_radius=25, border_type='black', border_size=0, crop_n_zoom=False, logging=False)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the Stabilizer class.</p> <p>Parameters:</p> Name Type Description Default <code>smoothing_radius</code> <code>int</code> <p>alter averaging window size.</p> <code>25</code> <code>border_type</code> <code>str</code> <p>changes the extended border type.</p> <code>'black'</code> <code>border_size</code> <code>int</code> <p>enables and set the value for extended border size to reduce the black borders.</p> <code>0</code> <code>crop_n_zoom</code> <code>bool</code> <p>enables cropping and zooming of frames(to original size) to reduce the black borders.</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>def __init__(\n    self,\n    smoothing_radius=25,\n    border_type=\"black\",\n    border_size=0,\n    crop_n_zoom=False,\n    logging=False,\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the Stabilizer class.\n\n    Parameters:\n        smoothing_radius (int): alter averaging window size.\n        border_type (str): changes the extended border type.\n        border_size (int): enables and set the value for extended border size to reduce the black borders.\n        crop_n_zoom (bool): enables cropping and zooming of frames(to original size) to reduce the black borders.\n        logging (bool): enables/disables logging.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # initialize deques for handling input frames and its indexes\n    self.__frame_queue = deque(maxlen=smoothing_radius)\n    self.__frame_queue_indexes = deque(maxlen=smoothing_radius)\n\n    # define and create Adaptive histogram equalization (AHE) object for optimizations\n    self.__clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n\n    # initialize global vars\n    self.__smoothing_radius = smoothing_radius  # averaging window, handles the quality of stabilization at expense of latency and sudden panning\n    self.__smoothed_path = None  # handles the smoothed path with box filter\n    self.__path = None  # handles path i.e cumulative sum of previous_2_current transformations along a axis\n    self.__transforms = []  # handles previous_2_current transformations [dx,dy,da]\n    self.__frame_transforms_smoothed = None  # handles smoothed array of previous_2_current transformations w.r.t to frames\n    self.__previous_gray = None  # handles previous gray frame\n    self.__previous_keypoints = (\n        None  # handles previous detect_GFTTed keypoints w.r.t previous gray frame\n    )\n    self.__frame_height, self.frame_width = (\n        0,\n        0,\n    )  # handles width and height of input frames\n    self.__crop_n_zoom = 0  # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable.\n\n    # if check if crop_n_zoom defined\n    if crop_n_zoom and border_size:\n        self.__crop_n_zoom = border_size  # crops and zoom frame to original size\n        self.__border_size = 0  # zero out border size\n        self.__frame_size = None  # handles frame size for zooming\n        self.__logging and logger.debug(\n            \"Setting Cropping margin {} pixels\".format(border_size)\n        )\n    else:\n        # Add output borders to frame\n        self.__border_size = border_size\n        self.__logging and border_size and logger.debug(\n            \"Setting Border size {} pixels\".format(border_size)\n        )\n\n    # define valid border modes\n    border_modes = {\n        \"black\": cv2.BORDER_CONSTANT,\n        \"reflect\": cv2.BORDER_REFLECT,\n        \"reflect_101\": cv2.BORDER_REFLECT_101,\n        \"replicate\": cv2.BORDER_REPLICATE,\n        \"wrap\": cv2.BORDER_WRAP,\n    }\n    # choose valid border_mode from border_type\n    if border_type in [\"black\", \"reflect\", \"reflect_101\", \"replicate\", \"wrap\"]:\n        if not crop_n_zoom:\n            # initialize global border mode variable\n            self.__border_mode = border_modes[border_type]\n            self.__logging and border_type != \"black\" and logger.info(\n                \"Setting Border type: {}\".format(border_type)\n            )\n        else:\n            # log and reset to default\n            self.__logging and border_type != \"black\" and logger.debug(\n                \"Setting border type is disabled if cropping is enabled!\"\n            )\n            self.__border_mode = border_modes[\"black\"]\n    else:\n        # otherwise log if not\n        self.__logging and logger.debug(\"Invalid input border type!\")\n        self.__border_mode = border_modes[\"black\"]  # reset to default mode\n\n    # define OpenCV version\n    self.__cv2_version = check_CV_version()\n\n    # retrieve best interpolation\n    self.__interpolation = retrieve_best_interpolation(\n        [\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n    )\n\n    # define normalized box filter\n    self.__box_filter = np.ones(smoothing_radius) / smoothing_radius\n</code></pre>"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.clean","title":"<code>clean(self)</code>","text":"<p>Cleans Stabilizer resources</p> Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>def clean(self):\n    \"\"\"\n    Cleans Stabilizer resources\n    \"\"\"\n    # check if deque present\n    if self.__frame_queue:\n        # clear frame deque\n        self.__frame_queue.clear()\n        # clear frame indexes deque\n        self.__frame_queue_indexes.clear()\n</code></pre>"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.stabilize","title":"<code>stabilize(self, frame)</code>","text":"<p>This method takes an unstabilized video frame, and returns a stabilized one.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs unstabilized video frames.</p> required Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>def stabilize(self, frame):\n    \"\"\"\n    This method takes an unstabilized video frame, and returns a stabilized one.\n\n    Parameters:\n        frame (numpy.ndarray): inputs unstabilized video frames.\n    \"\"\"\n    # check if frame is None\n    if frame is None:\n        # return if it does\n        return\n\n    # save frame size for zooming\n    if self.__crop_n_zoom and self.__frame_size == None:\n        self.__frame_size = frame.shape[:2]\n\n    # initiate transformations capturing\n    if not self.__frame_queue:\n        # for first frame\n        previous_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to gray\n        previous_gray = self.__clahe.apply(previous_gray)  # optimize gray frame\n        self.__previous_keypoints = cv2.goodFeaturesToTrack(\n            previous_gray,\n            maxCorners=200,\n            qualityLevel=0.05,\n            minDistance=30.0,\n            blockSize=3,\n            mask=None,\n            useHarrisDetector=False,\n            k=0.04,\n        )  # track features using GFTT\n        self.__frame_height, self.frame_width = frame.shape[\n            :2\n        ]  # save input frame height and width\n        self.__frame_queue.append(frame)  # save frame to deque\n        self.__frame_queue_indexes.append(0)  # save frame index to deque\n        self.__previous_gray = previous_gray[\n            :\n        ]  # save gray frame clone for further processing\n\n    elif self.__frame_queue_indexes[-1] &lt; self.__smoothing_radius - 1:\n        # for rest of frames\n        self.__frame_queue.append(frame)  # save frame to deque\n        self.__frame_queue_indexes.append(\n            self.__frame_queue_indexes[-1] + 1\n        )  # save frame index\n        self.__generate_transformations()  # generate transformations\n    else:\n        # start applying transformations\n        self.__frame_queue.append(frame)  # save frame to deque\n        self.__frame_queue_indexes.append(\n            self.__frame_queue_indexes[-1] + 1\n        )  # save frame index\n        self.__generate_transformations()  # generate transformations\n        # calculate smooth path once transformation capturing is completed\n        for i in range(3):\n            # apply normalized box filter to the path\n            self.__smoothed_path[:, i] = self.__box_filter_convolve(\n                (self.__path[:, i]), window_size=self.__smoothing_radius\n            )\n        # calculate deviation of path from smoothed path\n        deviation = self.__smoothed_path - self.__path\n        # save smoothed transformation\n        self.__frame_transforms_smoothed = self.frame_transform + deviation\n        # return transformation applied stabilized frame\n        return self.__apply_transformations()\n</code></pre>"},{"location":"bonus/reference/streamgear/","title":"API References","text":"<p>StreamGear API usage examples for: Single-Source Mode \u27b6 and Real-time Frames Mode \u27b6</p> <p>StreamGear API parameters are explained here \u27b6</p> <p>StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH and HLS) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content.</p> <p>SteamGear easily transcodes source videos/audio files &amp; real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of suitable length. These segments make it possible to stream videos at different quality levels (different bitrate or spatial resolutions) and can be switched in the middle of a video from one quality level to another - if bandwidth permits - on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests.</p> <p>SteamGear also creates a Manifest/Playlist file (such as MPD in-case of DASH and M3U8 in-case of HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session.</p> <p>SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP live streaming).</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>class StreamGear:\n    \"\"\"\n    StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH and HLS) in just few lines of python code.\n    StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content.\n\n    SteamGear easily transcodes source videos/audio files &amp; real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of suitable length. These segments make it\n    possible to stream videos at different quality levels _(different bitrate or spatial resolutions)_ and can be switched in the middle of a video from one quality level to another - if bandwidth\n    permits - on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests.\n\n    SteamGear also creates a Manifest/Playlist file (such as MPD in-case of DASH and M3U8 in-case of HLS) besides segments that describe these segment information\n    (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session.\n\n    SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP live streaming).\n    \"\"\"\n\n    def __init__(\n        self, output=\"\", format=\"dash\", custom_ffmpeg=\"\", logging=False, **stream_params\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the StreamGear class.\n\n        Parameters:\n            output (str): sets the valid filename/path for generating the StreamGear assets.\n            format (str): select the adaptive HTTP streaming format(DASH and HLS).\n            custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n            logging (bool): enables/disables logging.\n            stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properties.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # checks if machine in-use is running windows os or not\n        self.__os_windows = True if os.name == \"nt\" else False\n\n        # initialize various class variables\n        # handles user-defined parameters\n        self.__params = {}\n        # handle input video/frame resolution and channels\n        self.__inputheight = None\n        self.__inputwidth = None\n        self.__inputchannels = None\n        self.__sourceframerate = None\n        # handle process to be frames written\n        self.__process = None\n        # handle valid FFmpeg assets location\n        self.__ffmpeg = \"\"\n        # handle one time process for valid process initialization\n        self.__initiate_stream = True\n\n        # cleans and reformat user-defined parameters\n        self.__params = {\n            str(k).strip(): (v.strip() if isinstance(v, str) else v)\n            for k, v in stream_params.items()\n        }\n\n        # handle where to save the downloaded FFmpeg Static assets on Windows(if specified)\n        __ffmpeg_download_path = self.__params.pop(\"-ffmpeg_download_path\", \"\")\n        if not isinstance(__ffmpeg_download_path, (str)):\n            # reset improper values\n            __ffmpeg_download_path = \"\"\n\n        # validate the FFmpeg assets and return location (also downloads static assets on windows)\n        self.__ffmpeg = get_valid_ffmpeg_path(\n            str(custom_ffmpeg),\n            self.__os_windows,\n            ffmpeg_download_path=__ffmpeg_download_path,\n            logging=self.__logging,\n        )\n\n        # check if valid FFmpeg path returned\n        if self.__ffmpeg:\n            self.__logging and logger.debug(\n                \"Found valid FFmpeg executables: `{}`.\".format(self.__ffmpeg)\n            )\n        else:\n            # else raise error\n            raise RuntimeError(\n                \"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\"\n            )\n\n        # handle streaming format\n        supported_formats = [\"dash\", \"hls\"]  # TODO will be extended in future\n        if format and isinstance(format, str):\n            _format = format.strip().lower()\n            if _format in supported_formats:\n                self.__format = _format\n                logger.info(\n                    \"StreamGear will generate asset files for {} streaming format.\".format(\n                        self.__format.upper()\n                    )\n                )\n            elif difflib.get_close_matches(_format, supported_formats):\n                raise ValueError(\n                    \"[StreamGear:ERROR] :: Incorrect `format` parameter value! Did you mean `{}`?\".format(\n                        difflib.get_close_matches(_format, supported_formats)[0]\n                    )\n                )\n            else:\n                raise ValueError(\n                    \"[StreamGear:ERROR] :: The `format` parameter value `{}` not valid/supported!\".format(\n                        format\n                    )\n                )\n        else:\n            raise ValueError(\n                \"[StreamGear:ERROR] :: The `format` parameter value is Missing or Invalid!\"\n            )\n\n        # handle Audio-Input\n        audio = self.__params.pop(\"-audio\", False)\n        if audio and isinstance(audio, str):\n            if os.path.isfile(audio):\n                self.__audio = os.path.abspath(audio)\n            elif is_valid_url(self.__ffmpeg, url=audio, logging=self.__logging):\n                self.__audio = audio\n            else:\n                self.__audio = False\n        elif audio and isinstance(audio, list):\n            self.__audio = audio\n        else:\n            self.__audio = False\n        # log external audio source\n        self.__audio and self.__logging and logger.debug(\n            \"External audio source `{}` detected.\".format(self.__audio)\n        )\n\n        # handle Video-Source input\n        source = self.__params.pop(\"-video_source\", False)\n        # Check if input is valid string\n        if source and isinstance(source, str) and len(source) &gt; 1:\n            # Differentiate input\n            if os.path.isfile(source):\n                self.__video_source = os.path.abspath(source)\n            elif is_valid_url(self.__ffmpeg, url=source, logging=self.__logging):\n                self.__video_source = source\n            else:\n                # discard the value otherwise\n                self.__video_source = False\n\n            # Validate input\n            if self.__video_source:\n                validation_results = validate_video(\n                    self.__ffmpeg, video_path=self.__video_source\n                )\n                assert not (\n                    validation_results is None\n                ), \"[StreamGear:ERROR] :: Given `{}` video_source is Invalid, Check Again!\".format(\n                    self.__video_source\n                )\n                self.__aspect_source = validation_results[\"resolution\"]\n                self.__fps_source = validation_results[\"framerate\"]\n                # log it\n                self.__logging and logger.debug(\n                    \"Given video_source is valid and has {}x{} resolution, and a framerate of {} fps.\".format(\n                        self.__aspect_source[0],\n                        self.__aspect_source[1],\n                        self.__fps_source,\n                    )\n                )\n            else:\n                # log warning\n                logger.warning(\"Discarded invalid `-video_source` value provided.\")\n        else:\n            if source:\n                # log warning if source provided\n                logger.warning(\"Invalid `-video_source` value provided.\")\n            else:\n                # log normally\n                logger.info(\"No `-video_source` value provided.\")\n            # discard the value otherwise\n            self.__video_source = False\n\n        # handle user-defined framerate\n        self.__inputframerate = self.__params.pop(\"-input_framerate\", 0.0)\n        if isinstance(self.__inputframerate, (float, int)):\n            # must be float\n            self.__inputframerate = float(self.__inputframerate)\n        else:\n            # reset improper values\n            self.__inputframerate = 0.0\n\n        # handle old assets\n        clear_assets = self.__params.pop(\"-clear_prev_assets\", False)\n        if isinstance(clear_assets, bool):\n            self.__clear_assets = clear_assets\n            # log if clearing assets is enabled\n            clear_assets and logger.info(\n                \"The `-clear_prev_assets` parameter is enabled successfully. All previous StreamGear API assets for `{}` format will be removed for this run.\".format(\n                    self.__format.upper()\n                )\n            )\n        else:\n            # reset improper values\n            self.__clear_assets = False\n\n        # handle whether to livestream?\n        livestreaming = self.__params.pop(\"-livestream\", False)\n        if isinstance(livestreaming, bool) and livestreaming:\n            # NOTE:  `livestream` is only available with real-time mode.\n            self.__livestreaming = livestreaming if not (self.__video_source) else False\n            if self.__video_source:\n                logger.error(\n                    \"Live-Streaming is only available with Real-time Mode. Refer docs for more information.\"\n                )\n            else:\n                # log if live streaming is enabled\n                livestreaming and logger.info(\n                    \"Live-Streaming is successfully enabled for this run.\"\n                )\n        else:\n            # reset improper values\n            self.__livestreaming = False\n\n        # handle the special-case of forced-termination\n        enable_force_termination = self.__params.pop(\"-enable_force_termination\", False)\n        # check if value is valid\n        if isinstance(enable_force_termination, bool):\n            self.__forced_termination = enable_force_termination\n            # log if forced termination is enabled\n            self.__forced_termination and logger.warning(\n                \"Forced termination is enabled for this run. This may result in corrupted output in certain scenarios!\"\n            )\n        else:\n            # handle improper values\n            self.__forced_termination = False\n\n        # handle streaming format\n        supported_formats = [\"dash\", \"hls\"]  # TODO will be extended in future\n        if format and isinstance(format, str):\n            _format = format.strip().lower()\n            if _format in supported_formats:\n                self.__format = _format\n                logger.info(\n                    \"StreamGear will generate asset files for {} streaming format.\".format(\n                        self.__format.upper()\n                    )\n                )\n            elif difflib.get_close_matches(_format, supported_formats):\n                raise ValueError(\n                    \"[StreamGear:ERROR] :: Incorrect `format` parameter value! Did you mean `{}`?\".format(\n                        difflib.get_close_matches(_format, supported_formats)[0]\n                    )\n                )\n            else:\n                raise ValueError(\n                    \"[StreamGear:ERROR] :: The `format` parameter value `{}` not valid/supported!\".format(\n                        format\n                    )\n                )\n        else:\n            raise ValueError(\n                \"[StreamGear:ERROR] :: The `format` parameter value is Missing or Invalid!\"\n            )\n\n        # handles output asset filenames\n        if output:\n            # validate this class has the access rights to specified directory or not\n            abs_path = os.path.abspath(output)\n            # check if given output is a valid system path\n            if check_WriteAccess(\n                os.path.dirname(abs_path),\n                is_windows=self.__os_windows,\n                logging=self.__logging,\n            ):\n                # get all assets extensions\n                valid_extension = \"mpd\" if self.__format == \"dash\" else \"m3u8\"\n                assets_exts = [\n                    (\"chunk-stream\", \".m4s\"),  # filename prefix, extension\n                    (\"chunk-stream\", \".ts\"),  # filename prefix, extension\n                    \".{}\".format(valid_extension),\n                ]\n                # add source file extension too\n                self.__video_source and assets_exts.append(\n                    (\n                        \"chunk-stream\",\n                        os.path.splitext(self.__video_source)[1],\n                    )  # filename prefix, extension\n                )\n                # handle output\n                # check if path is a directory\n                if os.path.isdir(abs_path):\n                    # clear previous assets if specified\n                    self.__clear_assets and delete_ext_safe(\n                        abs_path, assets_exts, logging=self.__logging\n                    )\n                    # auto-assign valid name and adds it to path\n                    abs_path = os.path.join(\n                        abs_path,\n                        \"{}-{}.{}\".format(\n                            self.__format,\n                            time.strftime(\"%Y%m%d-%H%M%S\"),\n                            valid_extension,\n                        ),\n                    )\n                # or check if path is a file\n                elif os.path.isfile(abs_path) and self.__clear_assets:\n                    # clear previous assets if specified\n                    delete_ext_safe(\n                        os.path.dirname(abs_path),\n                        assets_exts,\n                        logging=self.__logging,\n                    )\n                # check if path has valid file extension\n                assert abs_path.endswith(\n                    valid_extension\n                ), \"Given `{}` path has invalid file-extension w.r.t selected format: `{}`!\".format(\n                    output, self.__format.upper()\n                )\n                self.__logging and logger.debug(\n                    \"Output Path:`{}` is successfully configured for generating streaming assets.\".format(\n                        abs_path\n                    )\n                )\n                # workaround patch for Windows only,\n                # others platforms will not be affected\n                self.__out_file = abs_path.replace(\"\\\\\", \"/\")\n            # check if given output is a valid URL\n            elif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\n                self.__logging and logger.debug(\n                    \"URL:`{}` is valid and successfully configured for generating streaming assets.\".format(\n                        output\n                    )\n                )\n                self.__out_file = output\n            # raise ValueError otherwise\n            else:\n                raise ValueError(\n                    \"[StreamGear:ERROR] :: The output parameter value:`{}` is not valid/supported!\".format(\n                        output\n                    )\n                )\n        else:\n            # raise ValueError otherwise\n            raise ValueError(\n                \"[StreamGear:ERROR] :: Kindly provide a valid `output` parameter value. Refer Docs for more information.\"\n            )\n\n        # log Mode of operation\n        self.__video_source and logger.info(\n            \"StreamGear has been successfully configured for {} Mode.\".format(\n                \"Single-Source\" if self.__video_source else \"Real-time Frames\"\n            )\n        )\n\n    @deprecated(\n        parameter=\"rgb_mode\",\n        message=\"The `rgb_mode` parameter is deprecated and will be removed in a future version. Only BGR format frames will be supported going forward.\",\n    )\n    def stream(self, frame, rgb_mode=False):\n        \"\"\"\n        Pipes `ndarray` frames to FFmpeg Pipeline for transcoding them into chunked-encoded media segments of\n        streaming formats such as MPEG-DASH and HLS.\n\n        !!! warning \"[DEPRECATION NOTICE]: The `rgb_mode` parameter is deprecated and will be removed in a future version.\"\n\n        Parameters:\n            frame (ndarray): a valid numpy frame\n            rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_.\n        \"\"\"\n        # check if function is called in correct context\n        if self.__video_source:\n            raise RuntimeError(\n                \"[StreamGear:ERROR] :: The `stream()` method cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\"\n            )\n        # None-Type frames will be skipped\n        if frame is None:\n            return\n        # extract height, width and number of channels of frame\n        height, width = frame.shape[:2]\n        channels = frame.shape[-1] if frame.ndim == 3 else 1\n        # assign values to class variables on first run\n        if self.__initiate_stream:\n            self.__inputheight = height\n            self.__inputwidth = width\n            self.__inputchannels = channels\n            self.__sourceframerate = (\n                25.0 if not (self.__inputframerate) else self.__inputframerate\n            )\n            self.__logging and logger.debug(\n                \"InputFrame =&gt; Height:{} Width:{} Channels:{}\".format(\n                    self.__inputheight, self.__inputwidth, self.__inputchannels\n                )\n            )\n        # validate size of frame\n        if height != self.__inputheight or width != self.__inputwidth:\n            raise ValueError(\"[StreamGear:ERROR] :: All frames must have same size!\")\n        # validate number of channels\n        if channels != self.__inputchannels:\n            raise ValueError(\n                \"[StreamGear:ERROR] :: All frames must have same number of channels!\"\n            )\n        # initiate FFmpeg process on first run\n        if self.__initiate_stream:\n            # launch pre-processing\n            self.__PreProcess(channels=channels, rgb=rgb_mode)\n            # Check status of the process\n            assert self.__process is not None\n\n        # write the frame to pipeline\n        try:\n            self.__process.stdin.write(frame.tobytes())\n        except (OSError, IOError):\n            # log something is wrong!\n            logger.error(\n                \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\"\n            )\n            raise ValueError  # for testing purpose only\n\n    def transcode_source(self):\n        \"\"\"\n        Transcodes an entire video file _(with or without audio)_ into chunked-encoded media segments of\n        streaming formats such as MPEG-DASH and HLS.\n        \"\"\"\n        # check if function is called in correct context\n        if not (self.__video_source):\n            raise RuntimeError(\n                \"[StreamGear:ERROR] :: The `transcode_source()` method cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\"\n            )\n        # assign height, width and framerate\n        self.__inputheight = int(self.__aspect_source[1])\n        self.__inputwidth = int(self.__aspect_source[0])\n        self.__sourceframerate = float(self.__fps_source)\n        # launch pre-processing\n        self.__PreProcess()\n\n    def __PreProcess(self, channels=0, rgb=False):\n        \"\"\"\n        Internal method that pre-processes default FFmpeg parameters before starting pipelining.\n\n        Parameters:\n            channels (int): Number of channels\n            rgb (boolean): activates RGB mode _(if enabled)_.\n        \"\"\"\n        # turn off initiate flag\n        self.__initiate_stream = False\n        # initialize I/O parameters\n        input_parameters = OrderedDict()\n        output_parameters = OrderedDict()\n        # pre-assign default codec parameters (if not assigned by user).\n        default_codec = \"libx264rgb\" if rgb else \"libx264\"\n        output_vcodec = self.__params.pop(\"-vcodec\", default_codec)\n        # enforce default encoder if stream copy specified\n        # in Real-time Frames Mode\n        output_parameters[\"-vcodec\"] = (\n            default_codec\n            if output_vcodec == \"copy\"\n            and (not (self.__video_source) or \"-streams\" in self.__params)\n            else output_vcodec\n        )\n        # enforce compatibility with stream copy\n        if output_parameters[\"-vcodec\"] != \"copy\":\n            # NOTE: these parameters only supported when stream copy not defined\n            output_parameters[\"-vf\"] = self.__params.pop(\"-vf\", \"format=yuv420p\")\n            # Non-essential `-aspect` parameter is removed from the default pipeline.\n        else:\n            # log warnings if stream copy specified in Real-time Frames Mode\n            not (self.__video_source) and logger.error(\n                \"Stream copy is not compatible with Real-time Frames Mode as it require re-encoding of incoming frames. Discarding the `-vcodec copy` parameter!\"\n            )\n            (\"-streams\" in self.__params) and logger.error(\n                \"Stream copying is incompatible with Custom Streams as it require re-encoding for each additional stream. Discarding the `-vcodec copy` parameter!\"\n            )\n            # log warnings for these parameters\n            self.__params.pop(\"-vf\", False) and logger.warning(\n                \"Filtering and stream copy cannot be used together. Discarding specified `-vf` parameter!\"\n            )\n            self.__params.pop(\"-aspect\", False) and logger.warning(\n                \"Overriding aspect ratio with stream copy may produce invalid files. Discarding specified `-aspect` parameter!\"\n            )\n\n        # enable optimizations w.r.t selected codec\n        ### OPTIMIZATION-1 ###\n        if output_parameters[\"-vcodec\"] in [\n            \"libx264\",\n            \"libx264rgb\",\n            \"libx265\",\n            \"libvpx-vp9\",\n        ]:\n            output_parameters[\"-crf\"] = self.__params.pop(\"-crf\", \"20\")\n        ### OPTIMIZATION-2 ###\n        if output_parameters[\"-vcodec\"] == \"libx264\":\n            if not (self.__video_source):\n                output_parameters[\"-profile:v\"] = self.__params.pop(\n                    \"-profile:v\", \"high\"\n                )\n        ### OPTIMIZATION-3 ###\n        if output_parameters[\"-vcodec\"] in [\"libx264\", \"libx264rgb\"]:\n            output_parameters[\"-tune\"] = self.__params.pop(\"-tune\", \"zerolatency\")\n            output_parameters[\"-preset\"] = self.__params.pop(\"-preset\", \"veryfast\")\n        ### OPTIMIZATION-4 ###\n        if output_parameters[\"-vcodec\"] == \"libx265\":\n            output_parameters[\"-x265-params\"] = self.__params.pop(\n                \"-x265-params\", \"lossless=1\"\n            )\n\n        # enable audio (if present)\n        if self.__audio:\n            # validate audio source\n            bitrate = validate_audio(self.__ffmpeg, source=self.__audio)\n            if bitrate:\n                logger.info(\n                    \"Detected External Audio Source is valid, and will be used for generating streams.\"\n                )\n                # assign audio source\n                output_parameters[\n                    \"{}\".format(\n                        \"-core_asource\" if isinstance(self.__audio, list) else \"-i\"\n                    )\n                ] = self.__audio\n                # assign audio codec\n                output_parameters[\"-acodec\"] = self.__params.pop(\"-acodec\", \"aac\")\n                output_parameters[\"a_bitrate\"] = bitrate  # temporary handler\n                output_parameters[\"-core_audio\"] = (\n                    [\"-map\", \"1:a:0\"] if self.__format == \"dash\" else []\n                )\n            else:\n                # discard invalid audio\n                logger.warning(\n                    \"Audio source `{}` is not valid, Skipped!\".format(self.__audio)\n                )\n                self.__audio = False\n        # validate input video's audio source if available\n        elif self.__video_source:\n            bitrate = validate_audio(self.__ffmpeg, source=self.__video_source)\n            if bitrate:\n                logger.info(\"Input video's audio source will be used for this run.\")\n                # assign audio codec\n                output_parameters[\"-acodec\"] = self.__params.pop(\n                    \"-acodec\",\n                    \"aac\" if (\"-streams\" in self.__params) else \"copy\",\n                )\n                if output_parameters[\"-acodec\"] != \"copy\":\n                    output_parameters[\"a_bitrate\"] = bitrate  # temporary handler\n            else:\n                logger.info(\n                    \"No valid audio source available in the input video. Disabling audio while generating streams.\"\n                )\n        else:\n            logger.info(\n                \"No valid audio source provided. Disabling audio while generating streams.\"\n            )\n        # enable audio optimizations based on audio codec\n        if \"-acodec\" in output_parameters and output_parameters[\"-acodec\"] == \"aac\":\n            output_parameters[\"-movflags\"] = \"+faststart\"\n\n        # set input framerate\n        if self.__sourceframerate &gt; 0.0 and not (self.__video_source):\n            # set input framerate\n            self.__logging and logger.debug(\n                \"Setting Input framerate: {}\".format(self.__sourceframerate)\n            )\n            input_parameters[\"-framerate\"] = str(self.__sourceframerate)\n\n        # handle input resolution and pixel format\n        if not (self.__video_source):\n            dimensions = \"{}x{}\".format(self.__inputwidth, self.__inputheight)\n            input_parameters[\"-video_size\"] = str(dimensions)\n            # handles pix_fmt based on channels(HACK)\n            if channels == 1:\n                input_parameters[\"-pix_fmt\"] = \"gray\"\n            elif channels == 2:\n                input_parameters[\"-pix_fmt\"] = \"ya8\"\n            elif channels == 3:\n                input_parameters[\"-pix_fmt\"] = \"rgb24\" if rgb else \"bgr24\"\n            elif channels == 4:\n                input_parameters[\"-pix_fmt\"] = \"rgba\" if rgb else \"bgra\"\n            else:\n                raise ValueError(\n                    \"[StreamGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\"\n                )\n        # process assigned format parameters\n        process_params = self.__handle_streams(\n            input_params=input_parameters, output_params=output_parameters\n        )\n        # check if processing completed successfully\n        assert not (\n            process_params is None\n        ), \"[StreamGear:ERROR] :: `{}` stream cannot be initiated properly!\".format(\n            self.__format.upper()\n        )\n        # Finally start FFmpeg pipeline and process everything\n        self.__Build_n_Execute(process_params[0], process_params[1])\n\n    def __handle_streams(self, input_params, output_params):\n        \"\"\"\n        An internal function that parses various streams and its parameters.\n\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n        # handle bit-per-pixels\n        bpp = self.__params.pop(\"-bpp\", 0.1000)\n        if isinstance(bpp, float) and bpp &gt;= 0.001:\n            bpp = float(bpp)\n        else:\n            # reset to default if invalid\n            bpp = 0.1000\n        # log it\n        bpp and self.__logging and logger.debug(\n            \"Setting bit-per-pixels: {} for this stream.\".format(bpp)\n        )\n\n        # handle gop\n        gop = self.__params.pop(\"-gop\", 2 * int(self.__sourceframerate))\n        if isinstance(gop, (int, float)) and gop &gt;= 0:\n            gop = int(gop)\n        else:\n            # reset to some recommended value\n            gop = 2 * int(self.__sourceframerate)\n        # log it\n        gop and self.__logging and logger.debug(\n            \"Setting GOP: {} for this stream.\".format(gop)\n        )\n\n        # define default stream and its mapping\n        if self.__format == \"hls\":\n            output_params[\"-corev0\"] = [\"-map\", \"0:v\"]\n            if \"-acodec\" in output_params:\n                output_params[\"-corea0\"] = [\n                    \"-map\",\n                    \"{}:a\".format(1 if \"-core_audio\" in output_params else 0),\n                ]\n        else:\n            output_params[\"-map\"] = 0\n\n        # assign default output resolution\n        if \"-s:v:0\" in self.__params:\n            # prevent duplicates\n            del self.__params[\"-s:v:0\"]\n        if output_params[\"-vcodec\"] != \"copy\":\n            output_params[\"-s:v:0\"] = \"{}x{}\".format(\n                self.__inputwidth, self.__inputheight\n            )\n        # assign default output video-bitrate\n        if \"-b:v:0\" in self.__params:\n            # prevent duplicates\n            del self.__params[\"-b:v:0\"]\n        if output_params[\"-vcodec\"] != \"copy\":\n            output_params[\"-b:v:0\"] = (\n                str(\n                    get_video_bitrate(\n                        int(self.__inputwidth),\n                        int(self.__inputheight),\n                        self.__sourceframerate,\n                        bpp,\n                    )\n                )\n                + \"k\"\n            )\n\n        # assign default output audio-bitrate\n        if \"-b:a:0\" in self.__params:\n            # prevent duplicates\n            del self.__params[\"-b:a:0\"]\n        # extract and assign audio-bitrate from temporary handler\n        a_bitrate = output_params.pop(\"a_bitrate\", False)\n        if \"-acodec\" in output_params and a_bitrate:\n            output_params[\"-b:a:0\"] = a_bitrate\n\n        # handle user-defined streams\n        streams = self.__params.pop(\"-streams\", {})\n        output_params = self.__evaluate_streams(streams, output_params, bpp)\n\n        # define additional streams optimization parameters\n        if output_params[\"-vcodec\"] in [\"libx264\", \"libx264rgb\"]:\n            if not \"-bf\" in self.__params:\n                output_params[\"-bf\"] = 1\n            if not \"-sc_threshold\" in self.__params:\n                output_params[\"-sc_threshold\"] = 0\n            if not \"-keyint_min\" in self.__params:\n                output_params[\"-keyint_min\"] = gop\n        if (\n            output_params[\"-vcodec\"] in [\"libx264\", \"libx264rgb\", \"libvpx-vp9\"]\n            and not \"-g\" in self.__params\n        ):\n            output_params[\"-g\"] = gop\n        if output_params[\"-vcodec\"] == \"libx265\":\n            output_params[\"-core_x265\"] = [\n                \"-x265-params\",\n                \"keyint={}:min-keyint={}\".format(gop, gop),\n            ]\n\n        # process given dash/hls stream and return it\n        if self.__format == \"dash\":\n            processed_params = self.__generate_dash_stream(\n                input_params=input_params,\n                output_params=output_params,\n            )\n        else:\n            processed_params = self.__generate_hls_stream(\n                input_params=input_params,\n                output_params=output_params,\n            )\n        return processed_params\n\n    def __evaluate_streams(self, streams, output_params, bpp):\n        \"\"\"\n        Internal function that Extracts, Evaluates &amp; Validates user-defined streams\n\n        Parameters:\n            streams (dict): Individual streams formatted as list of dict.\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n        # temporary streams count variable\n        output_params[\"stream_count\"] = 1  # default is 1\n\n        # check if streams are empty\n        if not streams:\n            logger.info(\"No additional `-streams` are provided.\")\n            return output_params\n\n        # check if streams are valid\n        if isinstance(streams, list) and all(isinstance(x, dict) for x in streams):\n            # keep track of streams\n            stream_count = 1\n            # calculate source aspect-ratio\n            source_aspect_ratio = self.__inputwidth / self.__inputheight\n            # log the process\n            self.__logging and logger.debug(\n                \"Processing {} streams.\".format(len(streams))\n            )\n            # iterate over given streams\n            for idx, stream in enumerate(streams):\n                # log stream processing\n                self.__logging and logger.debug(\"Processing Stream: #{}\".format(idx))\n                # make copy\n                stream_copy = stream.copy()\n                # handle intermediate stream data as dictionary\n                intermediate_dict = {}\n                # define and map stream to intermediate dict\n                if self.__format == \"hls\":\n                    intermediate_dict[\"-corev{}\".format(stream_count)] = [\"-map\", \"0:v\"]\n                    if \"-acodec\" in output_params:\n                        intermediate_dict[\"-corea{}\".format(stream_count)] = [\n                            \"-map\",\n                            \"{}:a\".format(1 if \"-core_audio\" in output_params else 0),\n                        ]\n                else:\n                    intermediate_dict[\"-core{}\".format(stream_count)] = [\"-map\", \"0\"]\n\n                # extract resolution &amp; individual dimension of stream\n                resolution = stream.pop(\"-resolution\", \"\")\n                dimensions = (\n                    resolution.lower().split(\"x\")\n                    if (resolution and isinstance(resolution, str))\n                    else []\n                )\n                # validate resolution\n                if (\n                    len(dimensions) == 2\n                    and dimensions[0].isnumeric()\n                    and dimensions[1].isnumeric()\n                ):\n                    # verify resolution is w.r.t source aspect-ratio\n                    expected_width = math.floor(\n                        int(dimensions[1]) * source_aspect_ratio\n                    )\n                    if int(dimensions[0]) != expected_width:\n                        logger.warning(\n                            \"The provided stream resolution '{}' does not align with the source aspect ratio. Output stream may appear distorted!\".format(\n                                resolution\n                            )\n                        )\n                    # assign stream resolution to intermediate dict\n                    intermediate_dict[\"-s:v:{}\".format(stream_count)] = resolution\n                else:\n                    # otherwise log error and skip stream\n                    logger.error(\n                        \"Missing `-resolution` value. Invalid stream `{}` Skipped!\".format(\n                            stream_copy\n                        )\n                    )\n                    continue\n\n                # verify given stream video-bitrate\n                video_bitrate = stream.pop(\"-video_bitrate\", \"\")\n                if (\n                    video_bitrate\n                    and isinstance(video_bitrate, str)\n                    and video_bitrate.endswith((\"k\", \"M\"))\n                ):\n                    # assign it\n                    intermediate_dict[\"-b:v:{}\".format(stream_count)] = video_bitrate\n                else:\n                    # otherwise calculate video-bitrate\n                    fps = stream.pop(\"-framerate\", 0.0)\n                    if dimensions and isinstance(fps, (float, int)) and fps &gt; 0:\n                        intermediate_dict[\"-b:v:{}\".format(stream_count)] = (\n                            \"{}k\".format(\n                                get_video_bitrate(\n                                    int(dimensions[0]), int(dimensions[1]), fps, bpp\n                                )\n                            )\n                        )\n                    else:\n                        # If everything fails, log and skip the stream!\n                        logger.error(\n                            \"Unable to determine Video-Bitrate for the stream `{}`. Skipped!\".format(\n                                stream_copy\n                            )\n                        )\n                        continue\n                # verify given stream audio-bitrate\n                audio_bitrate = stream.pop(\"-audio_bitrate\", \"\")\n                if \"-acodec\" in output_params:\n                    if audio_bitrate and audio_bitrate.endswith((\"k\", \"M\")):\n                        intermediate_dict[\"-b:a:{}\".format(stream_count)] = (\n                            audio_bitrate\n                        )\n                    else:\n                        # otherwise calculate audio-bitrate\n                        if dimensions:\n                            aspect_width = int(dimensions[0])\n                            intermediate_dict[\"-b:a:{}\".format(stream_count)] = (\n                                \"{}k\".format(128 if (aspect_width &gt; 800) else 96)\n                            )\n                # update output parameters\n                output_params.update(intermediate_dict)\n                # clear intermediate dict\n                intermediate_dict.clear()\n                # clear stream copy\n                stream_copy.clear()\n                # increment to next stream\n                stream_count += 1\n                # log stream processing\n                self.__logging and logger.debug(\n                    \"Processed #{} stream successfully.\".format(idx)\n                )\n            # store stream count\n            output_params[\"stream_count\"] = stream_count\n            # log streams processing\n            self.__logging and logger.debug(\"All streams processed successfully!\")\n        else:\n            # skip and log\n            logger.warning(\"Invalid type `-streams` skipped!\")\n\n        return output_params\n\n    def __generate_hls_stream(self, input_params, output_params):\n        \"\"\"\n        An internal function that parses user-defined parameters and generates\n        suitable FFmpeg Terminal Command for transcoding input into HLS Stream.\n\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n        # validate `hls_segment_type`\n        default_hls_segment_type = self.__params.pop(\"-hls_segment_type\", \"mpegts\")\n        if isinstance(\n            default_hls_segment_type, str\n        ) and default_hls_segment_type.strip() in [\"fmp4\", \"mpegts\"]:\n            output_params[\"-hls_segment_type\"] = default_hls_segment_type.strip()\n        else:\n            # otherwise reset to default\n            logger.warning(\"Invalid `-hls_segment_type` value skipped!\")\n            output_params[\"-hls_segment_type\"] = \"mpegts\"\n        # gather required parameters\n        if self.__livestreaming:\n            # `hls_list_size` must be greater than or equal to 0\n            default_hls_list_size = self.__params.pop(\"-hls_list_size\", 6)\n            if isinstance(default_hls_list_size, int) and default_hls_list_size &gt;= 0:\n                output_params[\"-hls_list_size\"] = default_hls_list_size\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-hls_list_size` value skipped!\")\n                output_params[\"-hls_list_size\"] = 6\n            # `hls_init_time` must be greater than or equal to 0\n            default_hls_init_time = self.__params.pop(\"-hls_init_time\", 4)\n            if isinstance(default_hls_init_time, int) and default_hls_init_time &gt;= 0:\n                output_params[\"-hls_init_time\"] = default_hls_init_time\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-hls_init_time` value skipped!\")\n                output_params[\"-hls_init_time\"] = 4\n            # `hls_time` must be greater than or equal to 0\n            default_hls_time = self.__params.pop(\"-hls_time\", 4)\n            if isinstance(default_hls_time, int) and default_hls_time &gt;= 0:\n                output_params[\"-hls_time\"] = default_hls_time\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-hls_time` value skipped!\")\n                output_params[\"-hls_time\"] = 6\n            # `hls_flags` must be string\n            default_hls_flags = self.__params.pop(\n                \"-hls_flags\", \"delete_segments+discont_start+split_by_time\"\n            )\n            if isinstance(default_hls_flags, str):\n                output_params[\"-hls_flags\"] = default_hls_flags\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-hls_flags` value skipped!\")\n                output_params[\"-hls_flags\"] = (\n                    \"delete_segments+discont_start+split_by_time\"\n                )\n            # clean everything at exit?\n            remove_at_exit = self.__params.pop(\"-remove_at_exit\", 0)\n            if isinstance(remove_at_exit, int) and remove_at_exit in [\n                0,\n                1,\n            ]:\n                output_params[\"-remove_at_exit\"] = remove_at_exit\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-remove_at_exit` value skipped!\")\n                output_params[\"-remove_at_exit\"] = 0\n        else:\n            # enforce \"contain all the segments\"\n            output_params[\"-hls_list_size\"] = 0\n            output_params[\"-hls_playlist_type\"] = \"vod\"\n\n        # handle base URL for absolute paths\n        hls_base_url = self.__params.pop(\"-hls_base_url\", \"\")\n        if isinstance(hls_base_url, str):\n            output_params[\"-hls_base_url\"] = hls_base_url\n        else:\n            # otherwise reset to default\n            logger.warning(\"Invalid `-hls_base_url` value skipped!\")\n            output_params[\"-hls_base_url\"] = \"\"\n\n        # Hardcoded HLS parameters (Refer FFmpeg docs for more info.)\n        output_params[\"-allowed_extensions\"] = \"ALL\"\n        # Handling &lt;hls_segment_filename&gt;\n        # Here filename will be based on `stream_count` dict parameter that\n        # would be used to check whether stream is multi-variant(&gt;1) or single(0-1)\n        segment_template = (\n            \"{}-stream%v-%03d.{}\"\n            if output_params[\"stream_count\"] &gt; 1\n            else \"{}-stream-%03d.{}\"\n        )\n        output_params[\"-hls_segment_filename\"] = segment_template.format(\n            os.path.join(os.path.dirname(self.__out_file), \"chunk\"),\n            \"m4s\" if output_params[\"-hls_segment_type\"] == \"fmp4\" else \"ts\",\n        )\n        # Hardcoded HLS parameters (Refer FFmpeg docs for more info.)\n        output_params[\"-hls_allow_cache\"] = 0\n        # enable hls formatting\n        output_params[\"-f\"] = \"hls\"\n        # return HLS params\n        return (input_params, output_params)\n\n    def __generate_dash_stream(self, input_params, output_params):\n        \"\"\"\n        An internal function that parses user-defined parameters and generates\n        suitable FFmpeg Terminal Command for transcoding input into MPEG-dash Stream.\n\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n\n        # Check if live-streaming or not?\n        if self.__livestreaming:\n            # `extra_window_size` must be greater than or equal to 0\n            window_size = self.__params.pop(\"-window_size\", 5)\n            if isinstance(window_size, int) and window_size &gt;= 0:\n                output_params[\"-window_size\"] = window_size\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-window_size` value skipped!\")\n                output_params[\"-window_size\"] = 5\n            # `extra_window_size` must be greater than or equal to 0\n            extra_window_size = self.__params.pop(\"-extra_window_size\", 5)\n            if isinstance(extra_window_size, int) and extra_window_size &gt;= 0:\n                output_params[\"-extra_window_size\"] = window_size\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-extra_window_size` value skipped!\")\n                output_params[\"-extra_window_size\"] = 5\n            # clean everything at exit?\n            remove_at_exit = self.__params.pop(\"-remove_at_exit\", 0)\n            if isinstance(remove_at_exit, int) and remove_at_exit in [\n                0,\n                1,\n            ]:\n                output_params[\"-remove_at_exit\"] = remove_at_exit\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-remove_at_exit` value skipped!\")\n                output_params[\"-remove_at_exit\"] = 0\n            # `seg_duration` must be greater than or equal to 0\n            seg_duration = self.__params.pop(\"-seg_duration\", 20)\n            if isinstance(seg_duration, int) and seg_duration &gt;= 0:\n                output_params[\"-seg_duration\"] = seg_duration\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-seg_duration` value skipped!\")\n                output_params[\"-seg_duration\"] = 20\n            # Disable (0) the use of a SegmentTimeline inside a SegmentTemplate.\n            output_params[\"-use_timeline\"] = 0\n        else:\n            # `seg_duration` must be greater than or equal to 0\n            seg_duration = self.__params.pop(\"-seg_duration\", 5)\n            if isinstance(seg_duration, int) and seg_duration &gt;= 0:\n                output_params[\"-seg_duration\"] = seg_duration\n            else:\n                # otherwise reset to default\n                logger.warning(\"Invalid `-seg_duration` value skipped!\")\n                output_params[\"-seg_duration\"] = 5\n            # Enable (1) the use of a SegmentTimeline inside a SegmentTemplate.\n            output_params[\"-use_timeline\"] = 1\n\n        # Finally, some hardcoded DASH parameters (Refer FFmpeg docs for more info.)\n        output_params[\"-use_template\"] = 1\n        output_params[\"-adaptation_sets\"] = \"id=0,streams=v {}\".format(\n            \"id=1,streams=a\" if (\"-acodec\" in output_params) else \"\"\n        )\n        # enable dash formatting\n        output_params[\"-f\"] = \"dash\"\n        # return DASH params\n        return (input_params, output_params)\n\n    def __Build_n_Execute(self, input_params, output_params):\n        \"\"\"\n        An Internal function that launches FFmpeg subprocess and pipelines commands.\n\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n        # handle audio source if present\n        \"-core_asource\" in output_params and output_params.move_to_end(\n            \"-core_asource\", last=False\n        )\n        # handle `-i` parameter\n        \"-i\" in output_params and output_params.move_to_end(\"-i\", last=False)\n        # copy streams count\n        stream_count = output_params.pop(\"stream_count\", 1)\n\n        # convert input parameters to list\n        input_commands = dict2Args(input_params)\n        # convert output parameters to list\n        output_commands = dict2Args(output_params)\n        # convert any additional parameters to list\n        stream_commands = dict2Args(self.__params)\n\n        # create exclusive HLS params\n        hls_commands = []\n        # handle HLS multi-variant streams\n        if self.__format == \"hls\" and stream_count &gt; 1:\n            stream_map = \"\"\n            for count in range(0, stream_count):\n                stream_map += \"v:{}{} \".format(\n                    count, \",a:{}\".format(count) if \"-acodec\" in output_params else \",\"\n                )\n            hls_commands += [\n                \"-master_pl_name\",\n                os.path.basename(self.__out_file),\n                \"-var_stream_map\",\n                stream_map.strip(),\n                os.path.join(os.path.dirname(self.__out_file), \"stream_%v.m3u8\"),\n            ]\n\n        # log it if enabled\n        self.__logging and logger.debug(\n            \"User-Defined Output parameters: `{}`\".format(\n                \" \".join(output_commands) if output_commands else None\n            )\n        )\n        self.__logging and logger.debug(\n            \"Additional parameters: `{}`\".format(\n                \" \".join(stream_commands) if stream_commands else None\n            )\n        )\n        # build FFmpeg command from parameters\n        ffmpeg_cmd = None\n        # ensuring less cluttering if silent mode\n        hide_banner = [] if self.__logging else [\"-hide_banner\"]\n        # format commands\n        if self.__video_source:\n            ffmpeg_cmd = (\n                [self.__ffmpeg, \"-y\"]\n                + ([\"-re\"] if self.__livestreaming else [])  # pseudo live-streaming\n                + hide_banner\n                + [\"-i\", self.__video_source]\n                + input_commands\n                + output_commands\n                + stream_commands\n            )\n        else:\n            ffmpeg_cmd = (\n                [self.__ffmpeg, \"-y\"]\n                + hide_banner\n                + [\"-f\", \"rawvideo\", \"-vcodec\", \"rawvideo\"]\n                + input_commands\n                + [\"-i\", \"-\"]\n                + output_commands\n                + stream_commands\n            )\n        # format outputs\n        ffmpeg_cmd.extend([self.__out_file] if not (hls_commands) else hls_commands)\n        # Launch the FFmpeg pipeline with built command\n        logger.critical(\"Transcoding streaming chunks. Please wait...\")  # log it\n        self.__process = sp.Popen(\n            ffmpeg_cmd,\n            stdin=sp.PIPE,\n            stdout=(\n                sp.DEVNULL\n                if (not self.__video_source and not self.__logging)\n                else sp.PIPE\n            ),\n            stderr=None if self.__logging else sp.STDOUT,\n        )\n        # post handle progress bar and runtime errors in case of video_source\n        if self.__video_source:\n            return_code = 0\n            pbar = None\n            sec_prev = 0\n            if self.__logging:\n                self.__process.communicate()\n                return_code = self.__process.returncode\n            else:\n                # iterate until stdout runs out\n                while True:\n                    # read and process data\n                    data = self.__process.stdout.readline()\n                    if data:\n                        data = data.decode(\"utf-8\")\n                        # extract duration and time-left\n                        if pbar is None and \"Duration:\" in data:\n                            # extract time in seconds\n                            sec_duration = extract_time(data)\n                            # initiate progress bar\n                            pbar = tqdm(\n                                total=sec_duration,\n                                desc=\"Processing Frames\",\n                                unit=\"frame\",\n                            )\n                        elif \"time=\" in data:\n                            # extract time in seconds\n                            sec_current = extract_time(data)\n                            # update progress bar\n                            if sec_current:\n                                pbar.update(sec_current - sec_prev)\n                                sec_prev = sec_current\n                    else:\n                        # poll if no data\n                        if self.__process.poll() is not None:\n                            break\n                return_code = self.__process.poll()\n            # close progress bar\n            not (pbar is None) and pbar.close()\n            # handle return_code\n            if return_code != 0:\n                # log and raise error if return_code is `1`\n                logger.error(\n                    \"StreamGear failed to initiate stream for this video source!\"\n                )\n                raise sp.CalledProcessError(return_code, ffmpeg_cmd)\n            else:\n                # log if successful\n                logger.critical(\n                    \"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\".format(\n                        self.__format.upper()\n                    )\n                )\n\n    def __enter__(self):\n        \"\"\"\n        Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n\n        **Returns:** Returns a reference to the StreamGear Class\n        \"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        \"\"\"\n        self.close()\n\n    @deprecated(\n        message=\"The `terminate()` method will be removed in the next release. Kindly use `close()` method instead.\"\n    )\n    def terminate(self):\n        \"\"\"\n        !!! warning \"[DEPRECATION NOTICE]: This method is now deprecated and will be removed in a future release.\"\n\n        This function ensures backward compatibility for the `terminate()` method to maintain the API on existing systems.\n        It achieves this by calling the new `close()` method to terminate various\n        StreamGear processes.\n        \"\"\"\n\n        self.close()\n\n    def close(self):\n        \"\"\"\n        Safely terminates various StreamGear process.\n        \"\"\"\n        # log termination\n        self.__logging and logger.debug(\"Terminating StreamGear Processes.\")\n\n        # return if no process was initiated at first place\n        if self.__process is None or not (self.__process.poll() is None):\n            return\n        # close `stdin` output\n        self.__process.stdin and self.__process.stdin.close()\n        # close `stdout` output\n        self.__process.stdout and self.__process.stdout.close()\n        # forced termination if specified.\n        if self.__forced_termination:\n            self.__process.terminate()\n        # handle device audio streams\n        elif self.__audio and isinstance(self.__audio, list):\n            # send `CTRL_BREAK_EVENT` signal if Windows else `SIGINT`\n            self.__process.send_signal(\n                signal.CTRL_BREAK_EVENT if self.__os_windows else signal.SIGINT\n            )\n        # wait if process is still processing\n        self.__process.wait()\n        # discard process\n        self.__process = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__enter__","title":"<code>__enter__(self)</code>  <code>special</code>","text":"<p>Handles entry with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> <p>Returns: Returns a reference to the StreamGear Class</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def __enter__(self):\n    \"\"\"\n    Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n\n    **Returns:** Returns a reference to the StreamGear Class\n    \"\"\"\n    return self\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__exit__","title":"<code>__exit__(self, exc_type, exc_val, exc_tb)</code>  <code>special</code>","text":"<p>Handles exit with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"\n    Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    \"\"\"\n    self.close()\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__init__","title":"<code>__init__(self, output='', format='dash', custom_ffmpeg='', logging=False, **stream_params)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the StreamGear class.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str</code> <p>sets the valid filename/path for generating the StreamGear assets.</p> <code>''</code> <code>format</code> <code>str</code> <p>select the adaptive HTTP streaming format(DASH and HLS).</p> <code>'dash'</code> <code>custom_ffmpeg</code> <code>str</code> <p>assigns the location of custom path/directory for custom FFmpeg executables.</p> <code>''</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>stream_params</code> <code>dict</code> <p>provides the flexibility to control supported internal parameters and FFmpeg properties.</p> <code>{}</code> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def __init__(\n    self, output=\"\", format=\"dash\", custom_ffmpeg=\"\", logging=False, **stream_params\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the StreamGear class.\n\n    Parameters:\n        output (str): sets the valid filename/path for generating the StreamGear assets.\n        format (str): select the adaptive HTTP streaming format(DASH and HLS).\n        custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n        logging (bool): enables/disables logging.\n        stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properties.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # checks if machine in-use is running windows os or not\n    self.__os_windows = True if os.name == \"nt\" else False\n\n    # initialize various class variables\n    # handles user-defined parameters\n    self.__params = {}\n    # handle input video/frame resolution and channels\n    self.__inputheight = None\n    self.__inputwidth = None\n    self.__inputchannels = None\n    self.__sourceframerate = None\n    # handle process to be frames written\n    self.__process = None\n    # handle valid FFmpeg assets location\n    self.__ffmpeg = \"\"\n    # handle one time process for valid process initialization\n    self.__initiate_stream = True\n\n    # cleans and reformat user-defined parameters\n    self.__params = {\n        str(k).strip(): (v.strip() if isinstance(v, str) else v)\n        for k, v in stream_params.items()\n    }\n\n    # handle where to save the downloaded FFmpeg Static assets on Windows(if specified)\n    __ffmpeg_download_path = self.__params.pop(\"-ffmpeg_download_path\", \"\")\n    if not isinstance(__ffmpeg_download_path, (str)):\n        # reset improper values\n        __ffmpeg_download_path = \"\"\n\n    # validate the FFmpeg assets and return location (also downloads static assets on windows)\n    self.__ffmpeg = get_valid_ffmpeg_path(\n        str(custom_ffmpeg),\n        self.__os_windows,\n        ffmpeg_download_path=__ffmpeg_download_path,\n        logging=self.__logging,\n    )\n\n    # check if valid FFmpeg path returned\n    if self.__ffmpeg:\n        self.__logging and logger.debug(\n            \"Found valid FFmpeg executables: `{}`.\".format(self.__ffmpeg)\n        )\n    else:\n        # else raise error\n        raise RuntimeError(\n            \"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\"\n        )\n\n    # handle streaming format\n    supported_formats = [\"dash\", \"hls\"]  # TODO will be extended in future\n    if format and isinstance(format, str):\n        _format = format.strip().lower()\n        if _format in supported_formats:\n            self.__format = _format\n            logger.info(\n                \"StreamGear will generate asset files for {} streaming format.\".format(\n                    self.__format.upper()\n                )\n            )\n        elif difflib.get_close_matches(_format, supported_formats):\n            raise ValueError(\n                \"[StreamGear:ERROR] :: Incorrect `format` parameter value! Did you mean `{}`?\".format(\n                    difflib.get_close_matches(_format, supported_formats)[0]\n                )\n            )\n        else:\n            raise ValueError(\n                \"[StreamGear:ERROR] :: The `format` parameter value `{}` not valid/supported!\".format(\n                    format\n                )\n            )\n    else:\n        raise ValueError(\n            \"[StreamGear:ERROR] :: The `format` parameter value is Missing or Invalid!\"\n        )\n\n    # handle Audio-Input\n    audio = self.__params.pop(\"-audio\", False)\n    if audio and isinstance(audio, str):\n        if os.path.isfile(audio):\n            self.__audio = os.path.abspath(audio)\n        elif is_valid_url(self.__ffmpeg, url=audio, logging=self.__logging):\n            self.__audio = audio\n        else:\n            self.__audio = False\n    elif audio and isinstance(audio, list):\n        self.__audio = audio\n    else:\n        self.__audio = False\n    # log external audio source\n    self.__audio and self.__logging and logger.debug(\n        \"External audio source `{}` detected.\".format(self.__audio)\n    )\n\n    # handle Video-Source input\n    source = self.__params.pop(\"-video_source\", False)\n    # Check if input is valid string\n    if source and isinstance(source, str) and len(source) &gt; 1:\n        # Differentiate input\n        if os.path.isfile(source):\n            self.__video_source = os.path.abspath(source)\n        elif is_valid_url(self.__ffmpeg, url=source, logging=self.__logging):\n            self.__video_source = source\n        else:\n            # discard the value otherwise\n            self.__video_source = False\n\n        # Validate input\n        if self.__video_source:\n            validation_results = validate_video(\n                self.__ffmpeg, video_path=self.__video_source\n            )\n            assert not (\n                validation_results is None\n            ), \"[StreamGear:ERROR] :: Given `{}` video_source is Invalid, Check Again!\".format(\n                self.__video_source\n            )\n            self.__aspect_source = validation_results[\"resolution\"]\n            self.__fps_source = validation_results[\"framerate\"]\n            # log it\n            self.__logging and logger.debug(\n                \"Given video_source is valid and has {}x{} resolution, and a framerate of {} fps.\".format(\n                    self.__aspect_source[0],\n                    self.__aspect_source[1],\n                    self.__fps_source,\n                )\n            )\n        else:\n            # log warning\n            logger.warning(\"Discarded invalid `-video_source` value provided.\")\n    else:\n        if source:\n            # log warning if source provided\n            logger.warning(\"Invalid `-video_source` value provided.\")\n        else:\n            # log normally\n            logger.info(\"No `-video_source` value provided.\")\n        # discard the value otherwise\n        self.__video_source = False\n\n    # handle user-defined framerate\n    self.__inputframerate = self.__params.pop(\"-input_framerate\", 0.0)\n    if isinstance(self.__inputframerate, (float, int)):\n        # must be float\n        self.__inputframerate = float(self.__inputframerate)\n    else:\n        # reset improper values\n        self.__inputframerate = 0.0\n\n    # handle old assets\n    clear_assets = self.__params.pop(\"-clear_prev_assets\", False)\n    if isinstance(clear_assets, bool):\n        self.__clear_assets = clear_assets\n        # log if clearing assets is enabled\n        clear_assets and logger.info(\n            \"The `-clear_prev_assets` parameter is enabled successfully. All previous StreamGear API assets for `{}` format will be removed for this run.\".format(\n                self.__format.upper()\n            )\n        )\n    else:\n        # reset improper values\n        self.__clear_assets = False\n\n    # handle whether to livestream?\n    livestreaming = self.__params.pop(\"-livestream\", False)\n    if isinstance(livestreaming, bool) and livestreaming:\n        # NOTE:  `livestream` is only available with real-time mode.\n        self.__livestreaming = livestreaming if not (self.__video_source) else False\n        if self.__video_source:\n            logger.error(\n                \"Live-Streaming is only available with Real-time Mode. Refer docs for more information.\"\n            )\n        else:\n            # log if live streaming is enabled\n            livestreaming and logger.info(\n                \"Live-Streaming is successfully enabled for this run.\"\n            )\n    else:\n        # reset improper values\n        self.__livestreaming = False\n\n    # handle the special-case of forced-termination\n    enable_force_termination = self.__params.pop(\"-enable_force_termination\", False)\n    # check if value is valid\n    if isinstance(enable_force_termination, bool):\n        self.__forced_termination = enable_force_termination\n        # log if forced termination is enabled\n        self.__forced_termination and logger.warning(\n            \"Forced termination is enabled for this run. This may result in corrupted output in certain scenarios!\"\n        )\n    else:\n        # handle improper values\n        self.__forced_termination = False\n\n    # handle streaming format\n    supported_formats = [\"dash\", \"hls\"]  # TODO will be extended in future\n    if format and isinstance(format, str):\n        _format = format.strip().lower()\n        if _format in supported_formats:\n            self.__format = _format\n            logger.info(\n                \"StreamGear will generate asset files for {} streaming format.\".format(\n                    self.__format.upper()\n                )\n            )\n        elif difflib.get_close_matches(_format, supported_formats):\n            raise ValueError(\n                \"[StreamGear:ERROR] :: Incorrect `format` parameter value! Did you mean `{}`?\".format(\n                    difflib.get_close_matches(_format, supported_formats)[0]\n                )\n            )\n        else:\n            raise ValueError(\n                \"[StreamGear:ERROR] :: The `format` parameter value `{}` not valid/supported!\".format(\n                    format\n                )\n            )\n    else:\n        raise ValueError(\n            \"[StreamGear:ERROR] :: The `format` parameter value is Missing or Invalid!\"\n        )\n\n    # handles output asset filenames\n    if output:\n        # validate this class has the access rights to specified directory or not\n        abs_path = os.path.abspath(output)\n        # check if given output is a valid system path\n        if check_WriteAccess(\n            os.path.dirname(abs_path),\n            is_windows=self.__os_windows,\n            logging=self.__logging,\n        ):\n            # get all assets extensions\n            valid_extension = \"mpd\" if self.__format == \"dash\" else \"m3u8\"\n            assets_exts = [\n                (\"chunk-stream\", \".m4s\"),  # filename prefix, extension\n                (\"chunk-stream\", \".ts\"),  # filename prefix, extension\n                \".{}\".format(valid_extension),\n            ]\n            # add source file extension too\n            self.__video_source and assets_exts.append(\n                (\n                    \"chunk-stream\",\n                    os.path.splitext(self.__video_source)[1],\n                )  # filename prefix, extension\n            )\n            # handle output\n            # check if path is a directory\n            if os.path.isdir(abs_path):\n                # clear previous assets if specified\n                self.__clear_assets and delete_ext_safe(\n                    abs_path, assets_exts, logging=self.__logging\n                )\n                # auto-assign valid name and adds it to path\n                abs_path = os.path.join(\n                    abs_path,\n                    \"{}-{}.{}\".format(\n                        self.__format,\n                        time.strftime(\"%Y%m%d-%H%M%S\"),\n                        valid_extension,\n                    ),\n                )\n            # or check if path is a file\n            elif os.path.isfile(abs_path) and self.__clear_assets:\n                # clear previous assets if specified\n                delete_ext_safe(\n                    os.path.dirname(abs_path),\n                    assets_exts,\n                    logging=self.__logging,\n                )\n            # check if path has valid file extension\n            assert abs_path.endswith(\n                valid_extension\n            ), \"Given `{}` path has invalid file-extension w.r.t selected format: `{}`!\".format(\n                output, self.__format.upper()\n            )\n            self.__logging and logger.debug(\n                \"Output Path:`{}` is successfully configured for generating streaming assets.\".format(\n                    abs_path\n                )\n            )\n            # workaround patch for Windows only,\n            # others platforms will not be affected\n            self.__out_file = abs_path.replace(\"\\\\\", \"/\")\n        # check if given output is a valid URL\n        elif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\n            self.__logging and logger.debug(\n                \"URL:`{}` is valid and successfully configured for generating streaming assets.\".format(\n                    output\n                )\n            )\n            self.__out_file = output\n        # raise ValueError otherwise\n        else:\n            raise ValueError(\n                \"[StreamGear:ERROR] :: The output parameter value:`{}` is not valid/supported!\".format(\n                    output\n                )\n            )\n    else:\n        # raise ValueError otherwise\n        raise ValueError(\n            \"[StreamGear:ERROR] :: Kindly provide a valid `output` parameter value. Refer Docs for more information.\"\n        )\n\n    # log Mode of operation\n    self.__video_source and logger.info(\n        \"StreamGear has been successfully configured for {} Mode.\".format(\n            \"Single-Source\" if self.__video_source else \"Real-time Frames\"\n        )\n    )\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.close","title":"<code>close(self)</code>","text":"<p>Safely terminates various StreamGear process.</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def close(self):\n    \"\"\"\n    Safely terminates various StreamGear process.\n    \"\"\"\n    # log termination\n    self.__logging and logger.debug(\"Terminating StreamGear Processes.\")\n\n    # return if no process was initiated at first place\n    if self.__process is None or not (self.__process.poll() is None):\n        return\n    # close `stdin` output\n    self.__process.stdin and self.__process.stdin.close()\n    # close `stdout` output\n    self.__process.stdout and self.__process.stdout.close()\n    # forced termination if specified.\n    if self.__forced_termination:\n        self.__process.terminate()\n    # handle device audio streams\n    elif self.__audio and isinstance(self.__audio, list):\n        # send `CTRL_BREAK_EVENT` signal if Windows else `SIGINT`\n        self.__process.send_signal(\n            signal.CTRL_BREAK_EVENT if self.__os_windows else signal.SIGINT\n        )\n    # wait if process is still processing\n    self.__process.wait()\n    # discard process\n    self.__process = None\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.stream","title":"<code>stream(self, frame, rgb_mode=False)</code>","text":"<p>Pipes <code>ndarray</code> frames to FFmpeg Pipeline for transcoding them into chunked-encoded media segments of streaming formats such as MPEG-DASH and HLS.</p> <p>[DEPRECATION NOTICE]: The <code>rgb_mode</code> parameter is deprecated and will be removed in a future version.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>a valid numpy frame</p> required <code>rgb_mode</code> <code>boolean</code> <p>enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format instead of default BGR).</p> <code>False</code> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>@deprecated(\n    parameter=\"rgb_mode\",\n    message=\"The `rgb_mode` parameter is deprecated and will be removed in a future version. Only BGR format frames will be supported going forward.\",\n)\ndef stream(self, frame, rgb_mode=False):\n    \"\"\"\n    Pipes `ndarray` frames to FFmpeg Pipeline for transcoding them into chunked-encoded media segments of\n    streaming formats such as MPEG-DASH and HLS.\n\n    !!! warning \"[DEPRECATION NOTICE]: The `rgb_mode` parameter is deprecated and will be removed in a future version.\"\n\n    Parameters:\n        frame (ndarray): a valid numpy frame\n        rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_.\n    \"\"\"\n    # check if function is called in correct context\n    if self.__video_source:\n        raise RuntimeError(\n            \"[StreamGear:ERROR] :: The `stream()` method cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\"\n        )\n    # None-Type frames will be skipped\n    if frame is None:\n        return\n    # extract height, width and number of channels of frame\n    height, width = frame.shape[:2]\n    channels = frame.shape[-1] if frame.ndim == 3 else 1\n    # assign values to class variables on first run\n    if self.__initiate_stream:\n        self.__inputheight = height\n        self.__inputwidth = width\n        self.__inputchannels = channels\n        self.__sourceframerate = (\n            25.0 if not (self.__inputframerate) else self.__inputframerate\n        )\n        self.__logging and logger.debug(\n            \"InputFrame =&gt; Height:{} Width:{} Channels:{}\".format(\n                self.__inputheight, self.__inputwidth, self.__inputchannels\n            )\n        )\n    # validate size of frame\n    if height != self.__inputheight or width != self.__inputwidth:\n        raise ValueError(\"[StreamGear:ERROR] :: All frames must have same size!\")\n    # validate number of channels\n    if channels != self.__inputchannels:\n        raise ValueError(\n            \"[StreamGear:ERROR] :: All frames must have same number of channels!\"\n        )\n    # initiate FFmpeg process on first run\n    if self.__initiate_stream:\n        # launch pre-processing\n        self.__PreProcess(channels=channels, rgb=rgb_mode)\n        # Check status of the process\n        assert self.__process is not None\n\n    # write the frame to pipeline\n    try:\n        self.__process.stdin.write(frame.tobytes())\n    except (OSError, IOError):\n        # log something is wrong!\n        logger.error(\n            \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\"\n        )\n        raise ValueError  # for testing purpose only\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.terminate","title":"<code>terminate(self)</code>","text":"<p>[DEPRECATION NOTICE]: This method is now deprecated and will be removed in a future release.</p> <p>This function ensures backward compatibility for the <code>terminate()</code> method to maintain the API on existing systems. It achieves this by calling the new <code>close()</code> method to terminate various StreamGear processes.</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>@deprecated(\n    message=\"The `terminate()` method will be removed in the next release. Kindly use `close()` method instead.\"\n)\ndef terminate(self):\n    \"\"\"\n    !!! warning \"[DEPRECATION NOTICE]: This method is now deprecated and will be removed in a future release.\"\n\n    This function ensures backward compatibility for the `terminate()` method to maintain the API on existing systems.\n    It achieves this by calling the new `close()` method to terminate various\n    StreamGear processes.\n    \"\"\"\n\n    self.close()\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.transcode_source","title":"<code>transcode_source(self)</code>","text":"<p>Transcodes an entire video file (with or without audio) into chunked-encoded media segments of streaming formats such as MPEG-DASH and HLS.</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def transcode_source(self):\n    \"\"\"\n    Transcodes an entire video file _(with or without audio)_ into chunked-encoded media segments of\n    streaming formats such as MPEG-DASH and HLS.\n    \"\"\"\n    # check if function is called in correct context\n    if not (self.__video_source):\n        raise RuntimeError(\n            \"[StreamGear:ERROR] :: The `transcode_source()` method cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\"\n        )\n    # assign height, width and framerate\n    self.__inputheight = int(self.__aspect_source[1])\n    self.__inputwidth = int(self.__aspect_source[0])\n    self.__sourceframerate = float(self.__fps_source)\n    # launch pre-processing\n    self.__PreProcess()\n</code></pre>"},{"location":"bonus/reference/videogear/","title":"API References","text":"<p>VideoGear API usage examples can be found here \u27b6</p> <p>VideoGear API parameters are explained here \u27b6</p> <p>VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag.</p> <p>VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>class VideoGear:\n    \"\"\"\n    VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class.\n    VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and\n    their parameters with an exclusive enablePiCamera boolean flag.\n\n    VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables\n    easy stabilization for various video-streams (real-time or not)\n    with minimum effort and writing way fewer lines of code.\n    \"\"\"\n\n    def __init__(\n        self,\n        # VideoGear parameters\n        enablePiCamera=False,\n        stabilize=False,\n        # PiGear parameters\n        camera_num=0,\n        resolution=(640, 480),\n        framerate=30,\n        # CamGear parameters\n        source=0,\n        stream_mode=False,\n        backend=0,\n        # common parameters\n        time_delay=0,\n        colorspace=None,\n        logging=False,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the VideoGear class.\n\n        Parameters:\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # initialize stabilizer\n        self.__stabilization_mode = stabilize\n\n        # reformat dictionary\n        options = {str(k).strip(): v for k, v in options.items()}\n\n        if self.__stabilization_mode:\n            from .stabilizer import Stabilizer\n\n            s_radius = options.pop(\"SMOOTHING_RADIUS\", 25)\n            if not isinstance(s_radius, int):\n                s_radius = 25\n\n            border_size = options.pop(\"BORDER_SIZE\", 0)\n            if not isinstance(border_size, int):\n                border_size = 0\n\n            border_type = options.pop(\"BORDER_TYPE\", \"black\")\n            if not isinstance(border_type, str):\n                border_type = \"black\"\n\n            crop_n_zoom = options.pop(\"CROP_N_ZOOM\", False)\n            if not isinstance(crop_n_zoom, bool):\n                crop_n_zoom = False\n\n            self.__stabilizer_obj = Stabilizer(\n                smoothing_radius=s_radius,\n                border_type=border_type,\n                border_size=border_size,\n                crop_n_zoom=crop_n_zoom,\n                logging=logging,\n            )\n            self.__logging and logger.debug(\n                \"Enabling Stabilization Mode for the current video source!\"\n            )  # log info\n\n        if enablePiCamera:\n            # only import the pigear module only if required\n            from .pigear import PiGear\n\n            # initialize the picamera stream by enabling PiGear API\n            self.stream = PiGear(\n                camera_num=camera_num,\n                resolution=resolution,\n                framerate=framerate,\n                colorspace=colorspace,\n                logging=logging,\n                time_delay=time_delay,\n                **options\n            )\n        else:\n            # otherwise, we are using OpenCV so initialize the webcam\n            # stream by activating CamGear API\n            self.stream = CamGear(\n                source=source,\n                stream_mode=stream_mode,\n                backend=backend,\n                colorspace=colorspace,\n                logging=logging,\n                time_delay=time_delay,\n                **options\n            )\n\n        # initialize framerate variable\n        self.framerate = self.stream.framerate\n\n    def start(self):\n        \"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon of API in use.\n\n        **Returns:** A reference to the selected class object.\n        \"\"\"\n        self.stream.start()\n        return self\n\n    def read(self):\n        \"\"\"\n        Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame\n        buffer in the memory, and blocks the thread if the deque is full.\n\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n        while self.__stabilization_mode:\n            frame = self.stream.read()\n            if frame is None:\n                break\n            frame_stab = self.__stabilizer_obj.stabilize(frame)\n            if not (frame_stab is None):\n                return frame_stab\n        return self.stream.read()\n\n    def stop(self):\n        \"\"\"\n        Safely terminates the thread, and release the respective multi-threaded resources.\n        \"\"\"\n        self.stream.stop()\n        # logged\n        self.__logging and logger.debug(\"Terminating VideoGear.\")\n        # clean queue\n        self.__stabilization_mode and self.__stabilizer_obj.clean()\n</code></pre> <p> </p>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.__init__","title":"<code>__init__(self, enablePiCamera=False, stabilize=False, camera_num=0, resolution=(640, 480), framerate=30, source=0, stream_mode=False, backend=0, time_delay=0, colorspace=None, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the VideoGear class.</p> <p>Parameters:</p> Name Type Description Default <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>30</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>0</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def __init__(\n    self,\n    # VideoGear parameters\n    enablePiCamera=False,\n    stabilize=False,\n    # PiGear parameters\n    camera_num=0,\n    resolution=(640, 480),\n    framerate=30,\n    # CamGear parameters\n    source=0,\n    stream_mode=False,\n    backend=0,\n    # common parameters\n    time_delay=0,\n    colorspace=None,\n    logging=False,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the VideoGear class.\n\n    Parameters:\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # initialize stabilizer\n    self.__stabilization_mode = stabilize\n\n    # reformat dictionary\n    options = {str(k).strip(): v for k, v in options.items()}\n\n    if self.__stabilization_mode:\n        from .stabilizer import Stabilizer\n\n        s_radius = options.pop(\"SMOOTHING_RADIUS\", 25)\n        if not isinstance(s_radius, int):\n            s_radius = 25\n\n        border_size = options.pop(\"BORDER_SIZE\", 0)\n        if not isinstance(border_size, int):\n            border_size = 0\n\n        border_type = options.pop(\"BORDER_TYPE\", \"black\")\n        if not isinstance(border_type, str):\n            border_type = \"black\"\n\n        crop_n_zoom = options.pop(\"CROP_N_ZOOM\", False)\n        if not isinstance(crop_n_zoom, bool):\n            crop_n_zoom = False\n\n        self.__stabilizer_obj = Stabilizer(\n            smoothing_radius=s_radius,\n            border_type=border_type,\n            border_size=border_size,\n            crop_n_zoom=crop_n_zoom,\n            logging=logging,\n        )\n        self.__logging and logger.debug(\n            \"Enabling Stabilization Mode for the current video source!\"\n        )  # log info\n\n    if enablePiCamera:\n        # only import the pigear module only if required\n        from .pigear import PiGear\n\n        # initialize the picamera stream by enabling PiGear API\n        self.stream = PiGear(\n            camera_num=camera_num,\n            resolution=resolution,\n            framerate=framerate,\n            colorspace=colorspace,\n            logging=logging,\n            time_delay=time_delay,\n            **options\n        )\n    else:\n        # otherwise, we are using OpenCV so initialize the webcam\n        # stream by activating CamGear API\n        self.stream = CamGear(\n            source=source,\n            stream_mode=stream_mode,\n            backend=backend,\n            colorspace=colorspace,\n            logging=logging,\n            time_delay=time_delay,\n            **options\n        )\n\n    # initialize framerate variable\n    self.framerate = self.stream.framerate\n</code></pre>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def read(self):\n    \"\"\"\n    Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame\n    buffer in the memory, and blocks the thread if the deque is full.\n\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n    while self.__stabilization_mode:\n        frame = self.stream.read()\n        if frame is None:\n            break\n        frame_stab = self.__stabilizer_obj.stabilize(frame)\n        if not (frame_stab is None):\n            return frame_stab\n    return self.stream.read()\n</code></pre>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon of API in use.</p> <p>Returns: A reference to the selected class object.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def start(self):\n    \"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon of API in use.\n\n    **Returns:** A reference to the selected class object.\n    \"\"\"\n    self.stream.start()\n    return self\n</code></pre>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the respective multi-threaded resources.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def stop(self):\n    \"\"\"\n    Safely terminates the thread, and release the respective multi-threaded resources.\n    \"\"\"\n    self.stream.stop()\n    # logged\n    self.__logging and logger.debug(\"Terminating VideoGear.\")\n    # clean queue\n    self.__stabilization_mode and self.__stabilizer_obj.clean()\n</code></pre>"},{"location":"bonus/reference/webgear/","title":"API References","text":"<p>WebGear API usage examples can be found here \u27b6</p> <p>WebGear API parameters are explained here \u27b6</p> <p>WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser.</p> <p>WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.</p> <p>WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video.</p> <p>In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>class WebGear:\n    \"\"\"\n    WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser.\n\n    WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can\n    flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating\n    engine(with Jinja2), etc.\n\n    WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression)\n    and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality\n    is not the best, since JPEG compression is not very efficient for motion video.\n\n    In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal\n    wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.\n    \"\"\"\n\n    def __init__(\n        self,\n        enablePiCamera=False,\n        stabilize=False,\n        source=None,\n        camera_num=0,\n        stream_mode=False,\n        backend=0,\n        colorspace=None,\n        resolution=(640, 480),\n        framerate=25,\n        logging=False,\n        time_delay=0,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the WebGear class.\n\n        Parameters:\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # raise error(s) for critical Class imports\n        import_dependency_safe(\"starlette\" if starlette is None else \"\")\n        import_dependency_safe(\n            \"simplejpeg\" if simplejpeg is None else \"\", min_version=\"1.6.1\"\n        )\n\n        # initialize global params\n        self.__skip_generate_webdata = False  # generate webgear data by default\n        # define frame-compression handler\n        self.__jpeg_compression_quality = 90  # 90% quality\n        self.__jpeg_compression_fastdct = True  # fastest DCT on by default\n        self.__jpeg_compression_fastupsample = False  # fastupsample off by default\n        self.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\n        self.__frame_size_reduction = 25  # use 25% reduction\n        # retrieve interpolation for reduction\n        self.__interpolation = retrieve_best_interpolation(\n            [\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n        )\n\n        custom_video_endpoint = \"\"  # custom video endpoint path\n        custom_data_location = \"\"  # path to save data-files to custom location\n        data_path = \"\"  # path to WebGear data-files\n        overwrite_default = False\n        self.__enable_inf = False  # continue frames even when video ends.\n\n        # reformat dictionary\n        options = {str(k).strip(): v for k, v in options.items()}\n\n        # assign values to global variables if specified and valid\n        if options:\n            # check whether to disable Data-Files Auto-Generation WorkFlow\n            if \"skip_generate_webdata\" in options:\n                value = options[\"skip_generate_webdata\"]\n                # enable jpeg fastdct\n                if isinstance(value, bool):\n                    self.__skip_generate_webdata = value\n                else:\n                    logger.warning(\"Skipped invalid `skip_generate_webdata` value!\")\n                del options[\"skip_generate_webdata\"]  # clean\n\n            if \"jpeg_compression_colorspace\" in options:\n                value = options[\"jpeg_compression_colorspace\"]\n                if isinstance(value, str) and value.strip().upper() in [\n                    \"RGB\",\n                    \"BGR\",\n                    \"RGBX\",\n                    \"BGRX\",\n                    \"XBGR\",\n                    \"XRGB\",\n                    \"GRAY\",\n                    \"RGBA\",\n                    \"BGRA\",\n                    \"ABGR\",\n                    \"ARGB\",\n                    \"CMYK\",\n                ]:\n                    # set encoding colorspace\n                    self.__jpeg_compression_colorspace = value.strip().upper()\n                else:\n                    logger.warning(\n                        \"Skipped invalid `jpeg_compression_colorspace` value!\"\n                    )\n                del options[\"jpeg_compression_colorspace\"]  # clean\n\n            if \"jpeg_compression_quality\" in options:\n                value = options[\"jpeg_compression_quality\"]\n                # set valid jpeg quality\n                if isinstance(value, (int, float)) and value &gt;= 10 and value &lt;= 100:\n                    self.__jpeg_compression_quality = int(value)\n                else:\n                    logger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\n                del options[\"jpeg_compression_quality\"]  # clean\n\n            if \"jpeg_compression_fastdct\" in options:\n                value = options[\"jpeg_compression_fastdct\"]\n                # enable jpeg fastdct\n                if isinstance(value, bool):\n                    self.__jpeg_compression_fastdct = value\n                else:\n                    logger.warning(\"Skipped invalid `jpeg_compression_fastdct` value!\")\n                del options[\"jpeg_compression_fastdct\"]  # clean\n\n            if \"jpeg_compression_fastupsample\" in options:\n                value = options[\"jpeg_compression_fastupsample\"]\n                # enable jpeg  fastupsample\n                if isinstance(value, bool):\n                    self.__jpeg_compression_fastupsample = value\n                else:\n                    logger.warning(\n                        \"Skipped invalid `jpeg_compression_fastupsample` value!\"\n                    )\n                del options[\"jpeg_compression_fastupsample\"]  # clean\n\n            if \"frame_size_reduction\" in options:\n                value = options[\"frame_size_reduction\"]\n                if isinstance(value, (int, float)) and value &gt;= 0 and value &lt;= 90:\n                    self.__frame_size_reduction = value\n                else:\n                    logger.warning(\"Skipped invalid `frame_size_reduction` value!\")\n                del options[\"frame_size_reduction\"]  # clean\n\n            if \"custom_video_endpoint\" in options:\n                value = options[\"custom_video_endpoint\"]\n                if value and isinstance(value, str) and value.strip().isalnum():\n                    custom_video_endpoint = value.strip()\n                    logging and logger.critical(\n                        \"Using custom video endpoint path: `/{}`\".format(\n                            custom_video_endpoint\n                        )\n                    )\n                else:\n                    logger.warning(\"Skipped invalid `custom_video_endpoint` value!\")\n                del options[\"custom_video_endpoint\"]  # clean\n\n            if \"custom_data_location\" in options:\n                value = options[\"custom_data_location\"]\n                if value and isinstance(value, str):\n                    assert os.access(\n                        value, os.W_OK\n                    ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to '{}' directory!\".format(\n                        value\n                    )\n                    assert os.path.isdir(\n                        os.path.abspath(value)\n                    ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\n                    custom_data_location = os.path.abspath(value)\n                else:\n                    logger.warning(\"Skipped invalid `custom_data_location` value!\")\n                del options[\"custom_data_location\"]  # clean\n\n            if \"overwrite_default_files\" in options:\n                value = options[\"overwrite_default_files\"]\n                if isinstance(value, bool):\n                    overwrite_default = value\n                else:\n                    logger.warning(\"Skipped invalid `overwrite_default_files` value!\")\n                del options[\"overwrite_default_files\"]  # clean\n\n            if \"enable_infinite_frames\" in options:\n                value = options[\"enable_infinite_frames\"]\n                if isinstance(value, bool):\n                    self.__enable_inf = value\n                else:\n                    logger.warning(\"Skipped invalid `enable_infinite_frames` value!\")\n                del options[\"enable_infinite_frames\"]  # clean\n\n        # check if disable Data-Files Auto-Generation WorkFlow is disabled\n        if not self.__skip_generate_webdata:\n            # check if custom data path is specified\n            if custom_data_location:\n                data_path = generate_webdata(\n                    custom_data_location,\n                    c_name=\"webgear\",\n                    overwrite_default=overwrite_default,\n                    logging=logging,\n                )\n            else:\n                # otherwise generate suitable path\n                data_path = generate_webdata(\n                    os.path.join(expanduser(\"~\"), \".vidgear\"),\n                    c_name=\"webgear\",\n                    overwrite_default=overwrite_default,\n                    logging=logging,\n                )\n\n            # log it\n            self.__logging and logger.debug(\n                \"`{}` is the default location for saving WebGear data-files.\".format(\n                    data_path\n                )\n            )\n            # define Jinja2 templates handler\n            self.__templates = Jinja2Templates(\n                directory=\"{}/templates\".format(data_path)\n            )\n            # define routing tables\n            self.routes = [\n                Route(\"/\", endpoint=self.__homepage),\n                Route(\n                    \"/{}\".format(\n                        custom_video_endpoint if custom_video_endpoint else \"video\"\n                    ),\n                    endpoint=self.__video,\n                ),\n                Mount(\n                    \"/static\",\n                    app=StaticFiles(directory=\"{}/static\".format(data_path)),\n                    name=\"static\",\n                ),\n            ]\n        else:\n            # log it\n            self.__logging and logger.critical(\n                \"WebGear Data-Files Auto-Generation WorkFlow has been manually disabled.\"\n            )\n            # define routing tables\n            self.routes = [\n                Route(\n                    \"/{}\".format(\n                        custom_video_endpoint if custom_video_endpoint else \"video\"\n                    ),\n                    endpoint=self.__video,\n                ),\n            ]\n            # log exceptions\n            self.__logging and logger.warning(\n                \"Only `/video` route is available for this instance.\"\n            )\n\n        # define custom exception handlers\n        self.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n        # define middleware support\n        self.middleware = []\n        # Handle video source\n        if source is None:\n            self.config = {\"generator\": None}\n            self.__stream = None\n        else:\n            # define stream with necessary params\n            self.__stream = VideoGear(\n                enablePiCamera=enablePiCamera,\n                stabilize=stabilize,\n                source=source,\n                camera_num=camera_num,\n                stream_mode=stream_mode,\n                backend=backend,\n                colorspace=colorspace,\n                resolution=resolution,\n                framerate=framerate,\n                logging=logging,\n                time_delay=time_delay,\n                **options\n            )\n            # define default frame generator in configuration\n            self.config = {\"generator\": self.__producer}\n\n        # log if specified\n        if self.__logging:\n            if source is None:\n                logger.warning(\n                    \"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\"\n                )\n            else:\n                logger.debug(\n                    \"Enabling JPEG Frame-Compression with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\n                        self.__jpeg_compression_colorspace,\n                        self.__jpeg_compression_quality,\n                        \"enabled\" if self.__jpeg_compression_fastdct else \"disabled\",\n                        (\n                            \"enabled\"\n                            if self.__jpeg_compression_fastupsample\n                            else \"disabled\"\n                        ),\n                    )\n                )\n\n        # copying original routing tables for further validation\n        self.__rt_org_copy = self.routes[:]\n        # initialize blank frame\n        self.blank_frame = None\n        # keeps check if producer loop should be running\n        self.__isrunning = True\n\n    def __call__(self):\n        \"\"\"\n        Implements a custom Callable method for WebGear application.\n        \"\"\"\n        # validate routing tables\n        assert not (self.routes is None), \"Routing tables are NoneType!\"\n        if not isinstance(self.routes, list) or not all(\n            x in self.routes for x in self.__rt_org_copy\n        ):\n            raise RuntimeError(\"[WebGear:ERROR] :: Routing tables are not valid!\")\n\n        # validate middlewares\n        assert not (self.middleware is None), \"Middlewares are NoneType!\"\n        if self.middleware and (\n            not isinstance(self.middleware, list)\n            or not all(isinstance(x, Middleware) for x in self.middleware)\n        ):\n            raise RuntimeError(\"[WebGear:ERROR] :: Middlewares are not valid!\")\n\n        # validate assigned frame generator in WebGear configuration\n        if isinstance(self.config, dict) and \"generator\" in self.config:\n            # check if its  assigned value is a asynchronous generator\n            if self.config[\"generator\"] is None or not inspect.isasyncgen(\n                self.config[\"generator\"]()\n            ):\n                # otherwise raise error\n                raise ValueError(\n                    \"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\"\n                )\n        else:\n            # raise error if validation fails\n            raise RuntimeError(\"[WebGear:ERROR] :: Assigned configuration is invalid!\")\n\n        # initiate stream\n        self.__logging and logger.debug(\"Initiating Video Streaming.\")\n        if not (self.__stream is None):\n            self.__stream.start()\n        # return Starlette application\n        self.__logging and logger.debug(\"Running Starlette application.\")\n        return Starlette(\n            debug=(True if self.__logging else False),\n            routes=self.routes,\n            middleware=self.middleware,\n            exception_handlers=self.__exception_handlers,\n            lifespan=self.__lifespan,\n        )\n\n    async def __producer(self):\n        \"\"\"\n        WebGear's default asynchronous frame producer/generator.\n        \"\"\"\n        # loop over frames\n        while self.__isrunning:\n            # read frame\n            frame = self.__stream.read()\n\n            # display blank if NoneType\n            if frame is None:\n                frame = (\n                    self.blank_frame\n                    if self.blank_frame is None\n                    else self.blank_frame[:]\n                )\n                if not self.__enable_inf:\n                    self.__isrunning = False\n            else:\n                # create blank\n                if self.blank_frame is None:\n                    self.blank_frame = create_blank_frame(\n                        frame=frame,\n                        text=\"No Input\" if self.__enable_inf else \"The End\",\n                        logging=self.__logging,\n                    )\n\n            # reducer frames size if specified\n            if self.__frame_size_reduction:\n                frame = await reducer(\n                    frame,\n                    percentage=self.__frame_size_reduction,\n                    interpolation=self.__interpolation,\n                )\n\n            # handle JPEG encoding\n            if self.__jpeg_compression_colorspace == \"GRAY\":\n                if frame.ndim == 2:\n                    # patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\n                    frame = np.expand_dims(frame, axis=2)\n                encodedImage = simplejpeg.encode_jpeg(\n                    frame,\n                    quality=self.__jpeg_compression_quality,\n                    colorspace=self.__jpeg_compression_colorspace,\n                    fastdct=self.__jpeg_compression_fastdct,\n                )\n            else:\n                encodedImage = simplejpeg.encode_jpeg(\n                    frame,\n                    quality=self.__jpeg_compression_quality,\n                    colorspace=self.__jpeg_compression_colorspace,\n                    colorsubsampling=\"422\",\n                    fastdct=self.__jpeg_compression_fastdct,\n                )\n\n            # yield frame in byte format\n            yield (\n                b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\"\n            )\n            # sleep for sometime.\n            await asyncio.sleep(0)\n\n    async def __video(self, scope):\n        \"\"\"\n        Returns a async video streaming response.\n        \"\"\"\n        assert scope[\"type\"] in [\"http\", \"https\"]\n        return StreamingResponse(\n            self.config[\"generator\"](),\n            media_type=\"multipart/x-mixed-replace; boundary=frame\",\n        )\n\n    async def __homepage(self, request):\n        \"\"\"\n        Returns an HTML index page.\n        \"\"\"\n        return (\n            self.__templates.TemplateResponse(request, \"index.html\")\n            if not self.__skip_generate_webdata\n            else JSONResponse(\n                {\"detail\": \"WebGear Data-Files Auto-Generation WorkFlow is disabled!\"},\n                status_code=404,\n            )\n        )\n\n    async def __not_found(self, request, exc):\n        \"\"\"\n        Returns an HTML 404 page.\n        \"\"\"\n        return (\n            self.__templates.TemplateResponse(request, \"404.html\", status_code=404)\n            if not self.__skip_generate_webdata\n            else JSONResponse(\n                {\"detail\": \"WebGear Data-Files Auto-Generation WorkFlow is disabled!\"},\n                status_code=404,\n            )\n        )\n\n    async def __server_error(self, request, exc):\n        \"\"\"\n        Returns an HTML 500 page.\n        \"\"\"\n        return (\n            self.__templates.TemplateResponse(request, \"500.html\", status_code=500)\n            if not self.__skip_generate_webdata\n            else JSONResponse(\n                {\"detail\": \"WebGear Data-Files Auto-Generation WorkFlow is disabled!\"},\n                status_code=500,\n            )\n        )\n\n    @contextlib.asynccontextmanager\n    async def __lifespan(self, context):\n        try:\n            yield\n        finally:\n            # close Video Server\n            self.shutdown()\n\n    def shutdown(self):\n        \"\"\"\n        Implements a Callable to be run on application shutdown\n        \"\"\"\n        if not (self.__stream is None):\n            self.__logging and logger.debug(\"Closing Video Streaming.\")\n            # stops producer\n            self.__isrunning = False\n            # stops VideoGear stream\n            self.__stream.stop()\n            # prevent any re-iteration\n            self.__stream = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__call__","title":"<code>__call__(self)</code>  <code>special</code>","text":"<p>Implements a custom Callable method for WebGear application.</p> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>def __call__(self):\n    \"\"\"\n    Implements a custom Callable method for WebGear application.\n    \"\"\"\n    # validate routing tables\n    assert not (self.routes is None), \"Routing tables are NoneType!\"\n    if not isinstance(self.routes, list) or not all(\n        x in self.routes for x in self.__rt_org_copy\n    ):\n        raise RuntimeError(\"[WebGear:ERROR] :: Routing tables are not valid!\")\n\n    # validate middlewares\n    assert not (self.middleware is None), \"Middlewares are NoneType!\"\n    if self.middleware and (\n        not isinstance(self.middleware, list)\n        or not all(isinstance(x, Middleware) for x in self.middleware)\n    ):\n        raise RuntimeError(\"[WebGear:ERROR] :: Middlewares are not valid!\")\n\n    # validate assigned frame generator in WebGear configuration\n    if isinstance(self.config, dict) and \"generator\" in self.config:\n        # check if its  assigned value is a asynchronous generator\n        if self.config[\"generator\"] is None or not inspect.isasyncgen(\n            self.config[\"generator\"]()\n        ):\n            # otherwise raise error\n            raise ValueError(\n                \"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\"\n            )\n    else:\n        # raise error if validation fails\n        raise RuntimeError(\"[WebGear:ERROR] :: Assigned configuration is invalid!\")\n\n    # initiate stream\n    self.__logging and logger.debug(\"Initiating Video Streaming.\")\n    if not (self.__stream is None):\n        self.__stream.start()\n    # return Starlette application\n    self.__logging and logger.debug(\"Running Starlette application.\")\n    return Starlette(\n        debug=(True if self.__logging else False),\n        routes=self.routes,\n        middleware=self.middleware,\n        exception_handlers=self.__exception_handlers,\n        lifespan=self.__lifespan,\n    )\n</code></pre>"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__init__","title":"<code>__init__(self, enablePiCamera=False, stabilize=False, source=None, camera_num=0, stream_mode=False, backend=0, colorspace=None, resolution=(640, 480), framerate=25, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the WebGear class.</p> <p>Parameters:</p> Name Type Description Default <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>25</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>None</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>def __init__(\n    self,\n    enablePiCamera=False,\n    stabilize=False,\n    source=None,\n    camera_num=0,\n    stream_mode=False,\n    backend=0,\n    colorspace=None,\n    resolution=(640, 480),\n    framerate=25,\n    logging=False,\n    time_delay=0,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the WebGear class.\n\n    Parameters:\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # raise error(s) for critical Class imports\n    import_dependency_safe(\"starlette\" if starlette is None else \"\")\n    import_dependency_safe(\n        \"simplejpeg\" if simplejpeg is None else \"\", min_version=\"1.6.1\"\n    )\n\n    # initialize global params\n    self.__skip_generate_webdata = False  # generate webgear data by default\n    # define frame-compression handler\n    self.__jpeg_compression_quality = 90  # 90% quality\n    self.__jpeg_compression_fastdct = True  # fastest DCT on by default\n    self.__jpeg_compression_fastupsample = False  # fastupsample off by default\n    self.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\n    self.__frame_size_reduction = 25  # use 25% reduction\n    # retrieve interpolation for reduction\n    self.__interpolation = retrieve_best_interpolation(\n        [\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n    )\n\n    custom_video_endpoint = \"\"  # custom video endpoint path\n    custom_data_location = \"\"  # path to save data-files to custom location\n    data_path = \"\"  # path to WebGear data-files\n    overwrite_default = False\n    self.__enable_inf = False  # continue frames even when video ends.\n\n    # reformat dictionary\n    options = {str(k).strip(): v for k, v in options.items()}\n\n    # assign values to global variables if specified and valid\n    if options:\n        # check whether to disable Data-Files Auto-Generation WorkFlow\n        if \"skip_generate_webdata\" in options:\n            value = options[\"skip_generate_webdata\"]\n            # enable jpeg fastdct\n            if isinstance(value, bool):\n                self.__skip_generate_webdata = value\n            else:\n                logger.warning(\"Skipped invalid `skip_generate_webdata` value!\")\n            del options[\"skip_generate_webdata\"]  # clean\n\n        if \"jpeg_compression_colorspace\" in options:\n            value = options[\"jpeg_compression_colorspace\"]\n            if isinstance(value, str) and value.strip().upper() in [\n                \"RGB\",\n                \"BGR\",\n                \"RGBX\",\n                \"BGRX\",\n                \"XBGR\",\n                \"XRGB\",\n                \"GRAY\",\n                \"RGBA\",\n                \"BGRA\",\n                \"ABGR\",\n                \"ARGB\",\n                \"CMYK\",\n            ]:\n                # set encoding colorspace\n                self.__jpeg_compression_colorspace = value.strip().upper()\n            else:\n                logger.warning(\n                    \"Skipped invalid `jpeg_compression_colorspace` value!\"\n                )\n            del options[\"jpeg_compression_colorspace\"]  # clean\n\n        if \"jpeg_compression_quality\" in options:\n            value = options[\"jpeg_compression_quality\"]\n            # set valid jpeg quality\n            if isinstance(value, (int, float)) and value &gt;= 10 and value &lt;= 100:\n                self.__jpeg_compression_quality = int(value)\n            else:\n                logger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\n            del options[\"jpeg_compression_quality\"]  # clean\n\n        if \"jpeg_compression_fastdct\" in options:\n            value = options[\"jpeg_compression_fastdct\"]\n            # enable jpeg fastdct\n            if isinstance(value, bool):\n                self.__jpeg_compression_fastdct = value\n            else:\n                logger.warning(\"Skipped invalid `jpeg_compression_fastdct` value!\")\n            del options[\"jpeg_compression_fastdct\"]  # clean\n\n        if \"jpeg_compression_fastupsample\" in options:\n            value = options[\"jpeg_compression_fastupsample\"]\n            # enable jpeg  fastupsample\n            if isinstance(value, bool):\n                self.__jpeg_compression_fastupsample = value\n            else:\n                logger.warning(\n                    \"Skipped invalid `jpeg_compression_fastupsample` value!\"\n                )\n            del options[\"jpeg_compression_fastupsample\"]  # clean\n\n        if \"frame_size_reduction\" in options:\n            value = options[\"frame_size_reduction\"]\n            if isinstance(value, (int, float)) and value &gt;= 0 and value &lt;= 90:\n                self.__frame_size_reduction = value\n            else:\n                logger.warning(\"Skipped invalid `frame_size_reduction` value!\")\n            del options[\"frame_size_reduction\"]  # clean\n\n        if \"custom_video_endpoint\" in options:\n            value = options[\"custom_video_endpoint\"]\n            if value and isinstance(value, str) and value.strip().isalnum():\n                custom_video_endpoint = value.strip()\n                logging and logger.critical(\n                    \"Using custom video endpoint path: `/{}`\".format(\n                        custom_video_endpoint\n                    )\n                )\n            else:\n                logger.warning(\"Skipped invalid `custom_video_endpoint` value!\")\n            del options[\"custom_video_endpoint\"]  # clean\n\n        if \"custom_data_location\" in options:\n            value = options[\"custom_data_location\"]\n            if value and isinstance(value, str):\n                assert os.access(\n                    value, os.W_OK\n                ), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to '{}' directory!\".format(\n                    value\n                )\n                assert os.path.isdir(\n                    os.path.abspath(value)\n                ), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\n                custom_data_location = os.path.abspath(value)\n            else:\n                logger.warning(\"Skipped invalid `custom_data_location` value!\")\n            del options[\"custom_data_location\"]  # clean\n\n        if \"overwrite_default_files\" in options:\n            value = options[\"overwrite_default_files\"]\n            if isinstance(value, bool):\n                overwrite_default = value\n            else:\n                logger.warning(\"Skipped invalid `overwrite_default_files` value!\")\n            del options[\"overwrite_default_files\"]  # clean\n\n        if \"enable_infinite_frames\" in options:\n            value = options[\"enable_infinite_frames\"]\n            if isinstance(value, bool):\n                self.__enable_inf = value\n            else:\n                logger.warning(\"Skipped invalid `enable_infinite_frames` value!\")\n            del options[\"enable_infinite_frames\"]  # clean\n\n    # check if disable Data-Files Auto-Generation WorkFlow is disabled\n    if not self.__skip_generate_webdata:\n        # check if custom data path is specified\n        if custom_data_location:\n            data_path = generate_webdata(\n                custom_data_location,\n                c_name=\"webgear\",\n                overwrite_default=overwrite_default,\n                logging=logging,\n            )\n        else:\n            # otherwise generate suitable path\n            data_path = generate_webdata(\n                os.path.join(expanduser(\"~\"), \".vidgear\"),\n                c_name=\"webgear\",\n                overwrite_default=overwrite_default,\n                logging=logging,\n            )\n\n        # log it\n        self.__logging and logger.debug(\n            \"`{}` is the default location for saving WebGear data-files.\".format(\n                data_path\n            )\n        )\n        # define Jinja2 templates handler\n        self.__templates = Jinja2Templates(\n            directory=\"{}/templates\".format(data_path)\n        )\n        # define routing tables\n        self.routes = [\n            Route(\"/\", endpoint=self.__homepage),\n            Route(\n                \"/{}\".format(\n                    custom_video_endpoint if custom_video_endpoint else \"video\"\n                ),\n                endpoint=self.__video,\n            ),\n            Mount(\n                \"/static\",\n                app=StaticFiles(directory=\"{}/static\".format(data_path)),\n                name=\"static\",\n            ),\n        ]\n    else:\n        # log it\n        self.__logging and logger.critical(\n            \"WebGear Data-Files Auto-Generation WorkFlow has been manually disabled.\"\n        )\n        # define routing tables\n        self.routes = [\n            Route(\n                \"/{}\".format(\n                    custom_video_endpoint if custom_video_endpoint else \"video\"\n                ),\n                endpoint=self.__video,\n            ),\n        ]\n        # log exceptions\n        self.__logging and logger.warning(\n            \"Only `/video` route is available for this instance.\"\n        )\n\n    # define custom exception handlers\n    self.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n    # define middleware support\n    self.middleware = []\n    # Handle video source\n    if source is None:\n        self.config = {\"generator\": None}\n        self.__stream = None\n    else:\n        # define stream with necessary params\n        self.__stream = VideoGear(\n            enablePiCamera=enablePiCamera,\n            stabilize=stabilize,\n            source=source,\n            camera_num=camera_num,\n            stream_mode=stream_mode,\n            backend=backend,\n            colorspace=colorspace,\n            resolution=resolution,\n            framerate=framerate,\n            logging=logging,\n            time_delay=time_delay,\n            **options\n        )\n        # define default frame generator in configuration\n        self.config = {\"generator\": self.__producer}\n\n    # log if specified\n    if self.__logging:\n        if source is None:\n            logger.warning(\n                \"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\"\n            )\n        else:\n            logger.debug(\n                \"Enabling JPEG Frame-Compression with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\n                    self.__jpeg_compression_colorspace,\n                    self.__jpeg_compression_quality,\n                    \"enabled\" if self.__jpeg_compression_fastdct else \"disabled\",\n                    (\n                        \"enabled\"\n                        if self.__jpeg_compression_fastupsample\n                        else \"disabled\"\n                    ),\n                )\n            )\n\n    # copying original routing tables for further validation\n    self.__rt_org_copy = self.routes[:]\n    # initialize blank frame\n    self.blank_frame = None\n    # keeps check if producer loop should be running\n    self.__isrunning = True\n</code></pre>"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.shutdown","title":"<code>shutdown(self)</code>","text":"<p>Implements a Callable to be run on application shutdown</p> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>def shutdown(self):\n    \"\"\"\n    Implements a Callable to be run on application shutdown\n    \"\"\"\n    if not (self.__stream is None):\n        self.__logging and logger.debug(\"Closing Video Streaming.\")\n        # stops producer\n        self.__isrunning = False\n        # stops VideoGear stream\n        self.__stream.stop()\n        # prevent any re-iteration\n        self.__stream = None\n</code></pre>"},{"location":"bonus/reference/webgear_rtc/","title":"API References","text":"<p>WebGear_RTC API usage examples can be found here \u27b6</p> <p>WebGear_RTC API parameters are explained here \u27b6</p> <p>WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms.</p> <p>WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.</p> <p>WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to easily establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom Server as a source to transform frames easily before sending them across the network(see this doc example).</p> <p>WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.</p> <p>Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs.</p> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>class WebGear_RTC:\n    \"\"\"\n    WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which\n    makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on\n    all major platforms.\n\n    WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time\n    Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive\n    Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.\n\n    WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment)\n    protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to easily\n    establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom Server\n    as a source to transform frames easily before sending them across the network(see this doc example).\n\n    WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of\n    shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.\n\n    Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both\n    CamGear and PiGear APIs.\n    \"\"\"\n\n    def __init__(\n        self,\n        enablePiCamera=False,\n        stabilize=False,\n        source=None,\n        camera_num=0,\n        stream_mode=False,\n        backend=0,\n        colorspace=None,\n        resolution=(640, 480),\n        framerate=25,\n        logging=False,\n        time_delay=0,\n        **options\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the WebGear_RTC class.\n\n        Parameters:\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # raise error(s) for critical Class imports\n        import_dependency_safe(\"starlette\" if starlette is None else \"\")\n        import_dependency_safe(\"aiortc\" if aiortc is None else \"\")\n\n        # initialize global params\n        custom_data_location = \"\"  # path to save data-files to custom location\n        data_path = \"\"  # path to WebGear_RTC data-files\n        overwrite_default = False\n        self.__relay = None  # act as broadcaster\n\n        # reformat dictionary\n        options = {str(k).strip(): v for k, v in options.items()}\n\n        # assign values to global variables if specified and valid\n        if options:\n            if \"custom_data_location\" in options:\n                value = options[\"custom_data_location\"]\n                if isinstance(value, str):\n                    assert os.access(\n                        value, os.W_OK\n                    ), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to '{}' directory!\".format(\n                        value\n                    )\n                    assert os.path.isdir(\n                        os.path.abspath(value)\n                    ), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\n                    custom_data_location = os.path.abspath(value)\n                else:\n                    logger.warning(\"Skipped invalid `custom_data_location` value!\")\n                del options[\"custom_data_location\"]  # clean\n\n            if \"overwrite_default_files\" in options:\n                value = options[\"overwrite_default_files\"]\n                if isinstance(value, bool):\n                    overwrite_default = value\n                else:\n                    logger.warning(\"Skipped invalid `overwrite_default_files` value!\")\n                del options[\"overwrite_default_files\"]  # clean\n\n            if \"enable_live_broadcast\" in options:\n                value = options[\"enable_live_broadcast\"]\n                if isinstance(value, bool):\n                    if value:\n                        self.__relay = MediaRelay()\n                        options[\"enable_infinite_frames\"] = (\n                            True  # enforce infinite frames\n                        )\n                        logger.critical(\n                            \"Enabled live broadcasting for Peer connection(s).\"\n                        )\n                    else:\n                        None\n                else:\n                    logger.warning(\"Skipped invalid `enable_live_broadcast` value!\")\n                del options[\"enable_live_broadcast\"]  # clean\n\n        # check if custom certificates path is specified\n        if custom_data_location:\n            data_path = generate_webdata(\n                custom_data_location,\n                c_name=\"webgear_rtc\",\n                overwrite_default=overwrite_default,\n                logging=logging,\n            )\n        else:\n            # otherwise generate suitable path\n            data_path = generate_webdata(\n                os.path.join(expanduser(\"~\"), \".vidgear\"),\n                c_name=\"webgear_rtc\",\n                overwrite_default=overwrite_default,\n                logging=logging,\n            )\n\n        # log it\n        self.__logging and logger.debug(\n            \"`{}` is the default location for saving WebGear_RTC data-files.\".format(\n                data_path\n            )\n        )\n\n        # define Jinja2 templates handler\n        self.__templates = Jinja2Templates(directory=\"{}/templates\".format(data_path))\n\n        # define custom exception handlers\n        self.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n        # define routing tables\n        self.routes = [\n            Route(\"/\", endpoint=self.__homepage),\n            Route(\"/offer\", self.__offer, methods=[\"GET\", \"POST\"]),\n            Mount(\n                \"/static\",\n                app=StaticFiles(directory=\"{}/static\".format(data_path)),\n                name=\"static\",\n            ),\n        ]\n\n        # define middleware support\n        self.middleware = []\n\n        # Handle RTC video server\n        if \"custom_stream\" in options or not (source is None):\n            # Handle video source\n            self.__default_rtc_server = RTC_VideoServer(\n                enablePiCamera=enablePiCamera,\n                stabilize=stabilize,\n                source=source,\n                camera_num=camera_num,\n                stream_mode=stream_mode,\n                backend=backend,\n                colorspace=colorspace,\n                resolution=resolution,\n                framerate=framerate,\n                logging=logging,\n                time_delay=time_delay,\n                **options\n            )\n            # add exclusive reset connection node\n            self.routes.append(\n                Route(\"/close_connection\", self.__reset_connections, methods=[\"POST\"])\n            )\n        else:\n            raise ValueError(\n                \"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\"\n            )\n\n        # copying original routing tables for further validation\n        self.__rt_org_copy = self.routes[:]\n        # collects peer RTC connections\n        self.__pcs = set()\n\n    def __call__(self):\n        \"\"\"\n        Implements a custom Callable method for WebGear_RTC application.\n        \"\"\"\n        # validate routing tables\n        assert not (self.routes is None), \"Routing tables are NoneType!\"\n        if not isinstance(self.routes, list) or not all(\n            x in self.routes for x in self.__rt_org_copy\n        ):\n            raise RuntimeError(\"[WebGear_RTC:ERROR] :: Routing tables are not valid!\")\n\n        # validate middlewares\n        assert not (self.middleware is None), \"Middlewares are NoneType!\"\n        if self.middleware and (\n            not isinstance(self.middleware, list)\n            or not all(isinstance(x, Middleware) for x in self.middleware)\n        ):\n            raise RuntimeError(\"[WebGear_RTC:ERROR] :: Middlewares are not valid!\")\n\n        # return Starlette application\n        self.__logging and logger.debug(\"Running Starlette application.\")\n        return Starlette(\n            debug=(True if self.__logging else False),\n            routes=self.routes,\n            middleware=self.middleware,\n            exception_handlers=self.__exception_handlers,\n            lifespan=self.__lifespan,\n        )\n\n    async def __offer(self, request):\n        \"\"\"\n        Generates JSON Response with a WebRTC Peer Connection of Video Server.\n        \"\"\"\n        # get offer from params\n        params = await request.json()\n        offer = RTCSessionDescription(sdp=params[\"sdp\"], type=params[\"type\"])\n\n        # initiate stream\n        if not (self.__default_rtc_server is None) and not (\n            self.__default_rtc_server.is_launched\n        ):\n            self.__logging and logger.debug(\"Initiating Video Streaming.\")\n            self.__default_rtc_server.launch()\n\n        # setup RTC peer connection - interface represents a WebRTC connection\n        # between the local computer and a remote peer.\n        pc = RTCPeerConnection()\n        self.__pcs.add(pc)\n        self.__logging and logger.info(\"Created WebRTC Peer Connection.\")\n\n        # track ICE connection state changes\n        @pc.on(\"iceconnectionstatechange\")\n        async def on_iceconnectionstatechange():\n            if pc.iceConnectionState == \"failed\":\n                logger.error(\"ICE connection state failed.\")\n                # check if Live Broadcasting is enabled\n                if self.__relay is None:\n                    # if not, close connection.\n                    await pc.close()\n                    self.__pcs.discard(pc)\n            else:\n                logger.debug(\"ICE connection state is %s\" % pc.iceConnectionState)\n\n        # Change the remote description associated with the connection.\n        await pc.setRemoteDescription(offer)\n        # retrieve list of RTCRtpTransceiver objects that are currently attached to the connection\n        for t in pc.getTransceivers():\n            # Increments performance significantly, IDK why this works as H265 codec is not even supported :D\n            capabilities = RTCRtpSender.getCapabilities(\"video\")\n            preferences = list(filter(lambda x: x.name == \"H265\", capabilities.codecs))\n            t.setCodecPreferences(preferences)\n            # add video server to peer track\n            if t.kind == \"video\":\n                pc.addTrack(\n                    self.__relay.subscribe(self.__default_rtc_server)\n                    if not (self.__relay is None)\n                    else self.__default_rtc_server\n                )\n\n        # Create an SDP answer to an offer received from a remote peer\n        answer = await pc.createAnswer()\n\n        # Change the local description for the answer\n        await pc.setLocalDescription(answer)\n\n        # return Starlette json response\n        return JSONResponse(\n            {\"sdp\": pc.localDescription.sdp, \"type\": pc.localDescription.type}\n        )\n\n    async def __homepage(self, request):\n        \"\"\"\n        Return an HTML index page.\n        \"\"\"\n        return self.__templates.TemplateResponse(request, \"index.html\")\n\n    async def __not_found(self, request, exc):\n        \"\"\"\n        Return an HTML 404 page.\n        \"\"\"\n        return self.__templates.TemplateResponse(request, \"404.html\", status_code=404)\n\n    async def __server_error(self, request, exc):\n        \"\"\"\n        Return an HTML 500 page.\n        \"\"\"\n        return self.__templates.TemplateResponse(request, \"500.html\", status_code=500)\n\n    async def __reset_connections(self, request):\n        \"\"\"\n        Resets all connections and recreates VideoServer timestamps\n        \"\"\"\n        # get additional parameter\n        parameter = await request.json()\n        # check if Live Broadcasting is enabled\n        if (\n            self.__relay is None\n            and not (self.__default_rtc_server is None)\n            and (self.__default_rtc_server.is_running)\n        ):\n            logger.critical(\"Resetting Server\")\n            # close old peer connections\n            if parameter != 0:  # disable if specified explicitly\n                coros = [\n                    pc.close() for pc in self.__pcs if pc.iceConnectionState != \"closed\"\n                ]\n                await asyncio.gather(*coros)\n                self.__pcs.clear()\n            await self.__default_rtc_server.reset()\n            return PlainTextResponse(\"OK\")\n        else:\n            # if does, then do nothing\n            return PlainTextResponse(\"DISABLED\")\n\n    @contextlib.asynccontextmanager\n    async def __lifespan(self, context):\n        try:\n            yield\n        finally:\n            # close Video Server\n            self.shutdown()\n            # collects peer RTC connections\n            coros = [\n                pc.close() for pc in self.__pcs if pc.iceConnectionState != \"closed\"\n            ]\n            await asyncio.gather(*coros)\n            self.__pcs.clear()\n\n    def shutdown(self):\n        \"\"\"\n        Gracefully shutdown video-server\n        \"\"\"\n        if not (self.__default_rtc_server is None):\n            self.__logging and logger.debug(\"Closing Video Server.\")\n            self.__default_rtc_server.terminate()\n            self.__default_rtc_server = None\n        # terminate internal server aswell.\n        self.__default_rtc_server = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.__call__","title":"<code>__call__(self)</code>  <code>special</code>","text":"<p>Implements a custom Callable method for WebGear_RTC application.</p> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>def __call__(self):\n    \"\"\"\n    Implements a custom Callable method for WebGear_RTC application.\n    \"\"\"\n    # validate routing tables\n    assert not (self.routes is None), \"Routing tables are NoneType!\"\n    if not isinstance(self.routes, list) or not all(\n        x in self.routes for x in self.__rt_org_copy\n    ):\n        raise RuntimeError(\"[WebGear_RTC:ERROR] :: Routing tables are not valid!\")\n\n    # validate middlewares\n    assert not (self.middleware is None), \"Middlewares are NoneType!\"\n    if self.middleware and (\n        not isinstance(self.middleware, list)\n        or not all(isinstance(x, Middleware) for x in self.middleware)\n    ):\n        raise RuntimeError(\"[WebGear_RTC:ERROR] :: Middlewares are not valid!\")\n\n    # return Starlette application\n    self.__logging and logger.debug(\"Running Starlette application.\")\n    return Starlette(\n        debug=(True if self.__logging else False),\n        routes=self.routes,\n        middleware=self.middleware,\n        exception_handlers=self.__exception_handlers,\n        lifespan=self.__lifespan,\n    )\n</code></pre>"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.__init__","title":"<code>__init__(self, enablePiCamera=False, stabilize=False, source=None, camera_num=0, stream_mode=False, backend=0, colorspace=None, resolution=(640, 480), framerate=25, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the WebGear_RTC class.</p> <p>Parameters:</p> Name Type Description Default <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>25</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>None</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>def __init__(\n    self,\n    enablePiCamera=False,\n    stabilize=False,\n    source=None,\n    camera_num=0,\n    stream_mode=False,\n    backend=0,\n    colorspace=None,\n    resolution=(640, 480),\n    framerate=25,\n    logging=False,\n    time_delay=0,\n    **options\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the WebGear_RTC class.\n\n    Parameters:\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # raise error(s) for critical Class imports\n    import_dependency_safe(\"starlette\" if starlette is None else \"\")\n    import_dependency_safe(\"aiortc\" if aiortc is None else \"\")\n\n    # initialize global params\n    custom_data_location = \"\"  # path to save data-files to custom location\n    data_path = \"\"  # path to WebGear_RTC data-files\n    overwrite_default = False\n    self.__relay = None  # act as broadcaster\n\n    # reformat dictionary\n    options = {str(k).strip(): v for k, v in options.items()}\n\n    # assign values to global variables if specified and valid\n    if options:\n        if \"custom_data_location\" in options:\n            value = options[\"custom_data_location\"]\n            if isinstance(value, str):\n                assert os.access(\n                    value, os.W_OK\n                ), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to '{}' directory!\".format(\n                    value\n                )\n                assert os.path.isdir(\n                    os.path.abspath(value)\n                ), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\n                custom_data_location = os.path.abspath(value)\n            else:\n                logger.warning(\"Skipped invalid `custom_data_location` value!\")\n            del options[\"custom_data_location\"]  # clean\n\n        if \"overwrite_default_files\" in options:\n            value = options[\"overwrite_default_files\"]\n            if isinstance(value, bool):\n                overwrite_default = value\n            else:\n                logger.warning(\"Skipped invalid `overwrite_default_files` value!\")\n            del options[\"overwrite_default_files\"]  # clean\n\n        if \"enable_live_broadcast\" in options:\n            value = options[\"enable_live_broadcast\"]\n            if isinstance(value, bool):\n                if value:\n                    self.__relay = MediaRelay()\n                    options[\"enable_infinite_frames\"] = (\n                        True  # enforce infinite frames\n                    )\n                    logger.critical(\n                        \"Enabled live broadcasting for Peer connection(s).\"\n                    )\n                else:\n                    None\n            else:\n                logger.warning(\"Skipped invalid `enable_live_broadcast` value!\")\n            del options[\"enable_live_broadcast\"]  # clean\n\n    # check if custom certificates path is specified\n    if custom_data_location:\n        data_path = generate_webdata(\n            custom_data_location,\n            c_name=\"webgear_rtc\",\n            overwrite_default=overwrite_default,\n            logging=logging,\n        )\n    else:\n        # otherwise generate suitable path\n        data_path = generate_webdata(\n            os.path.join(expanduser(\"~\"), \".vidgear\"),\n            c_name=\"webgear_rtc\",\n            overwrite_default=overwrite_default,\n            logging=logging,\n        )\n\n    # log it\n    self.__logging and logger.debug(\n        \"`{}` is the default location for saving WebGear_RTC data-files.\".format(\n            data_path\n        )\n    )\n\n    # define Jinja2 templates handler\n    self.__templates = Jinja2Templates(directory=\"{}/templates\".format(data_path))\n\n    # define custom exception handlers\n    self.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n    # define routing tables\n    self.routes = [\n        Route(\"/\", endpoint=self.__homepage),\n        Route(\"/offer\", self.__offer, methods=[\"GET\", \"POST\"]),\n        Mount(\n            \"/static\",\n            app=StaticFiles(directory=\"{}/static\".format(data_path)),\n            name=\"static\",\n        ),\n    ]\n\n    # define middleware support\n    self.middleware = []\n\n    # Handle RTC video server\n    if \"custom_stream\" in options or not (source is None):\n        # Handle video source\n        self.__default_rtc_server = RTC_VideoServer(\n            enablePiCamera=enablePiCamera,\n            stabilize=stabilize,\n            source=source,\n            camera_num=camera_num,\n            stream_mode=stream_mode,\n            backend=backend,\n            colorspace=colorspace,\n            resolution=resolution,\n            framerate=framerate,\n            logging=logging,\n            time_delay=time_delay,\n            **options\n        )\n        # add exclusive reset connection node\n        self.routes.append(\n            Route(\"/close_connection\", self.__reset_connections, methods=[\"POST\"])\n        )\n    else:\n        raise ValueError(\n            \"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\"\n        )\n\n    # copying original routing tables for further validation\n    self.__rt_org_copy = self.routes[:]\n    # collects peer RTC connections\n    self.__pcs = set()\n</code></pre>"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.shutdown","title":"<code>shutdown(self)</code>","text":"<p>Gracefully shutdown video-server</p> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>def shutdown(self):\n    \"\"\"\n    Gracefully shutdown video-server\n    \"\"\"\n    if not (self.__default_rtc_server is None):\n        self.__logging and logger.debug(\"Closing Video Server.\")\n        self.__default_rtc_server.terminate()\n        self.__default_rtc_server = None\n    # terminate internal server aswell.\n    self.__default_rtc_server = None\n</code></pre>"},{"location":"bonus/reference/writegear/","title":"API References","text":"<p>WriteGear API usage examples for: Compression Mode \u27b6 and Non-Compression Mode \u27b6</p> <p>WriteGear API parameters are explained for: Compression Mode \u27b6 and Non-Compression Mode \u27b6</p> <p>WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data.</p> <p>WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specification (such as bitrate, codec, framerate, resolution, subtitles, etc.). It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code.</p> <p>Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function without relying on any third-party API.</p> <p>In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.</p> Modes of Operation <p>WriteGear primarily operates in following modes:</p> <ul> <li> <p>Compression Mode: In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files.                         This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly,                         and while doing that it robustly handles all errors/warnings quietly.</p> </li> <li> <p>Non-Compression Mode: In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all                             parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters                             and other important features like video compression, audio encoding, etc.</p> </li> </ul> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>class WriteGear:\n    \"\"\"\n    WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data.\n\n    WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless\n    compressed video-file with any suitable specification (such as bitrate, codec, framerate, resolution, subtitles, etc.). It is powerful enough to perform complex tasks such as\n    Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code.\n\n    Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function without relying on any\n    third-party API.\n\n    In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.\n\n    ??? tip \"Modes of Operation\"\n\n        WriteGear primarily operates in following modes:\n\n        * **Compression Mode**: In this mode, WriteGear utilizes powerful **FFmpeg** inbuilt encoders to encode lossless multimedia files.\n                                This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly,\n                                and while doing that it robustly handles all errors/warnings quietly.\n\n        * **Non-Compression Mode**: In this mode, WriteGear utilizes basic **OpenCV's inbuilt VideoWriter API** tools. This mode also supports all\n                                    parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters\n                                    and other important features like video compression, audio encoding, etc.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        output=\"\",\n        compression_mode=True,\n        custom_ffmpeg=\"\",\n        logging=False,\n        **output_params\n    ):\n        \"\"\"\n        This constructor method initializes the object state and attributes of the WriteGear class.\n\n        Parameters:\n            output (str): sets the valid filename/path/URL for encoding.\n            compression_mode (bool): selects the WriteGear's Primary Mode of Operation.\n            custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n            logging (bool): enables/disables logging.\n            output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properties.\n        \"\"\"\n        # enable logging if specified\n        self.__logging = logging if isinstance(logging, bool) else False\n\n        # print current version\n        logcurr_vidgear_ver(logging=self.__logging)\n\n        # check if user not using depreciated `output_filename` parameter\n        assert (\n            not \"output_filename\" in output_params\n        ), \"[WriteGear:ERROR] :: The `output_filename` parameter has been renamed to `output`. Refer Docs for more info.\"\n\n        # assign parameter values to class variables\n        # enables compression if enabled\n        self.__compression = (\n            compression_mode if isinstance(compression_mode, bool) else False\n        )\n        # specifies if machine in-use is running Windows OS or not\n        self.__os_windows = True if os.name == \"nt\" else False\n\n        # initialize various important class variables\n        self.__output_parameters = {}  # handles output parameters\n        self.__inputheight = None  # handles input frames height\n        self.__inputwidth = None  # handles input frames width\n        self.__inputchannels = None  # handles input frames channels\n        self.__inputdtype = None  # handles input frames dtype\n        self.__process = None  # handles Encoding class/process\n        self.__ffmpeg = \"\"  # handles valid FFmpeg binaries location\n        self.__initiate_process = (\n            True  # handles initiate one-time process for generating pipeline\n        )\n        self.__ffmpeg_window_disabler_patch = (\n            False  # handles disabling window for ffmpeg subprocess on Windows\n        )\n        self.__out_file = None  # handles output\n        gstpipeline_mode = False  # handles GStreamer Pipeline Mode\n\n        # handles output\n        if not output:\n            # raise error otherwise\n            raise ValueError(\n                \"[WriteGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more info.\"\n            )\n        else:\n            # validate output is a system file/directory\n            # and Whether WriteGear has the write rights\n            # to specified file/directory or not\n            abs_path = os.path.abspath(output)\n            if check_WriteAccess(\n                os.path.dirname(abs_path),\n                is_windows=self.__os_windows,\n                logging=self.__logging,\n            ):\n                # check if given path is directory\n                if os.path.isdir(abs_path):\n                    # then, auto-assign valid name and adds it to path\n                    abs_path = os.path.join(\n                        abs_path,\n                        \"VidGear-{}.mp4\".format(time.strftime(\"%Y%m%d-%H%M%S\")),\n                    )\n                # assign output file absolute\n                # path to class variable if valid\n                self.__out_file = abs_path\n            else:\n                # log note otherwise\n                logger.info(\n                    \"`{}` isn't a valid system path or directory. Skipped!\".format(\n                        output\n                    )\n                )\n\n        # cleans and reformat output parameters\n        self.__output_parameters = {\n            str(k).strip(): (v.strip() if isinstance(v, str) else v)\n            for k, v in output_params.items()\n        }\n        # log it if specified\n        self.__logging and logger.debug(\n            \"Output Parameters: `{}`\".format(self.__output_parameters)\n        )\n\n        # handles FFmpeg binaries validity\n        # in Compression mode\n        if self.__compression:\n            # log it if specified\n            self.__logging and logger.debug(\n                \"Compression Mode is enabled therefore checking for valid FFmpeg executable.\"\n            )\n\n            # handles where to save the downloaded FFmpeg Static Binaries\n            # on Windows(if specified)\n            __ffmpeg_download_path = self.__output_parameters.pop(\n                \"-ffmpeg_download_path\", \"\"\n            )\n            # check if value is valid\n            if not isinstance(__ffmpeg_download_path, (str)):\n                # reset improper values\n                __ffmpeg_download_path = \"\"\n\n            # handle user-defined output resolution (must be a tuple or list)\n            # in Compression Mode only.\n            self.__output_dimensions = self.__output_parameters.pop(\n                \"-output_dimensions\", None\n            )\n            # check if value is valid\n            if not isinstance(self.__output_dimensions, (list, tuple)):\n                # reset improper values\n                self.__output_dimensions = None\n\n            # handle user defined input framerate of encoding pipeline\n            # in Compression Mode only.\n            self.__inputframerate = self.__output_parameters.pop(\n                \"-input_framerate\", 0.0\n            )\n            # check if value is valid\n            if not isinstance(self.__inputframerate, (float, int)):\n                # reset improper values\n                self.__inputframerate = 0.0\n            else:\n                # must be float\n                self.__inputframerate = float(self.__inputframerate)\n\n            # handle user-defined input frames pixel-format in Compression Mode only.\n            self.__inputpixfmt = self.__output_parameters.pop(\"-input_pixfmt\", None)\n            # check if value is valid\n            if not isinstance(self.__inputpixfmt, str):\n                # reset improper values\n                self.__inputpixfmt = None\n            else:\n                # must be exact\n                self.__inputpixfmt = self.__inputpixfmt.strip()\n\n            # handle user-defined FFmpeg command pre-headers(must be a list)\n            # in Compression Mode only.\n            self.__ffmpeg_preheaders = self.__output_parameters.pop(\"-ffpreheaders\", [])\n            # check if value is valid\n            if not isinstance(self.__ffmpeg_preheaders, list):\n                # reset improper values\n                self.__ffmpeg_preheaders = []\n\n            # handle the special-case of forced-termination (only for Compression mode)\n            disable_force_termination = self.__output_parameters.pop(\n                \"-disable_force_termination\",\n                False if (\"-i\" in self.__output_parameters) else True,\n            )\n            # check if value is valid\n            if isinstance(disable_force_termination, bool):\n                self.__forced_termination = not (disable_force_termination)\n            else:\n                # handle improper values\n                self.__forced_termination = (\n                    True if (\"-i\" in self.__output_parameters) else False\n                )\n\n            # handles disabling window for ffmpeg subprocess on Windows OS (only for Compression mode)\n            # this patch prevents ffmpeg creation window from opening when building exe files\n            ffmpeg_window_disabler_patch = self.__output_parameters.pop(\n                \"-disable_ffmpeg_window\", False\n            )\n            # check if value is valid\n            if not self.__os_windows or logging:\n                logger.warning(\n                    \"Optional `-disable_ffmpeg_window` flag is only available on Windows OS with `logging=False`. Discarding!\"\n                )\n            elif isinstance(ffmpeg_window_disabler_patch, bool):\n                self.__ffmpeg_window_disabler_patch = ffmpeg_window_disabler_patch\n            else:\n                # handle improper values\n                self.__ffmpeg_window_disabler_patch = False\n\n            # validate the FFmpeg path/binaries and returns valid executable FFmpeg\n            # location/path (also auto-downloads static binaries on Windows OS)\n            self.__ffmpeg = get_valid_ffmpeg_path(\n                custom_ffmpeg,\n                self.__os_windows,\n                ffmpeg_download_path=__ffmpeg_download_path,\n                logging=self.__logging,\n            )\n            # check if valid executable FFmpeg location/path\n            if self.__ffmpeg:\n                # log it if found\n                self.__logging and logger.debug(\n                    \"Found valid FFmpeg executable: `{}`.\".format(self.__ffmpeg)\n                )\n            else:\n                # otherwise disable Compression Mode\n                # and switch to Non-compression mode\n                logger.warning(\n                    \"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\"\n                )\n                if self.__logging and not self.__os_windows:\n                    logger.debug(\n                        \"Kindly install a working FFmpeg module or provide a valid custom FFmpeg binary path. See docs for more info.\"\n                    )\n                # compression mode disabled\n                self.__compression = False\n        else:\n            # handle GStreamer Pipeline Mode (only for Non-compression mode)\n            if \"-gst_pipeline_mode\" in self.__output_parameters:\n                # check if value is valid\n                if isinstance(self.__output_parameters[\"-gst_pipeline_mode\"], bool):\n                    gstpipeline_mode = self.__output_parameters[\n                        \"-gst_pipeline_mode\"\n                    ] and check_gstreamer_support(logging=logging)\n                    self.__logging and logger.debug(\n                        \"GStreamer Pipeline Mode successfully activated!\"\n                    )\n                else:\n                    # reset improper values\n                    gstpipeline_mode = False\n                    # log it\n                    self.__logging and logger.warning(\n                        \"GStreamer Pipeline Mode failed to activate!\"\n                    )\n\n        # handle output differently in Compression/Non-compression Modes\n        if self.__compression and self.__ffmpeg:\n            # check if output falls in exclusive cases\n            if self.__out_file is None:\n                if (\n                    platform.system() == \"Linux\"\n                    and pathlib.Path(output).is_char_device()\n                ):\n                    # check whether output is a Linux video device path (such as `/dev/video0`)\n                    self.__logging and logger.debug(\n                        \"Path:`{}` is a valid Linux Video Device path.\".format(output)\n                    )\n                    self.__out_file = output\n                elif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\n                    # check whether output is a valid URL instead\n                    self.__logging and logger.debug(\n                        \"URL:`{}` is valid and successfully configured for streaming.\".format(\n                            output\n                        )\n                    )\n                    self.__out_file = output\n                else:\n                    # raise error otherwise\n                    raise ValueError(\n                        \"[WriteGear:ERROR] :: output value:`{}` is not supported in Compression Mode.\".format(\n                            output\n                        )\n                    )\n            # log if forced termination is enabled\n            self.__forced_termination and logger.debug(\n                \"Forced termination is enabled for this FFmpeg process.\"\n            )\n            # log Compression is enabled\n            self.__logging and logger.debug(\n                \"Compression Mode with FFmpeg backend is configured properly.\"\n            )\n        else:\n            # raise error if not valid input\n            if self.__out_file is None and not gstpipeline_mode:\n                raise ValueError(\n                    \"[WriteGear:ERROR] :: output value:`{}` is not supported in Non-Compression Mode.\".format(\n                        output\n                    )\n                )\n\n            # check if GStreamer Pipeline Mode is enabled\n            if gstpipeline_mode:\n                # enforce GStreamer backend\n                self.__output_parameters[\"-backend\"] = \"CAP_GSTREAMER\"\n                # enforce original output value\n                self.__out_file = output\n\n            # log it\n            self.__logging and logger.debug(\n                \"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\"\n            )\n\n            # log if Compression is disabled\n            logger.critical(\n                \"Compression Mode is disabled, Activating OpenCV built-in Writer!\"\n            )\n\n    def write(self, frame, rgb_mode=False):\n        \"\"\"\n        Pipelines `ndarray` frames to respective API _(**FFmpeg** in Compression Mode &amp; **OpenCV's VideoWriter API** in Non-Compression Mode)_.\n\n        Parameters:\n            frame (ndarray): a valid numpy frame\n            rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_.\n\n        \"\"\"\n        if frame is None:  # None-Type frames will be skipped\n            return\n\n        # get height, width, number of channels, and dtype of current frame\n        height, width = frame.shape[:2]\n        channels = frame.shape[-1] if frame.ndim == 3 else 1\n        dtype = frame.dtype\n\n        # assign values to class variables on first run\n        if self.__initiate_process:\n            self.__inputheight = height\n            self.__inputwidth = width\n            self.__inputchannels = channels\n            self.__inputdtype = dtype\n            self.__logging and logger.debug(\n                \"InputFrame =&gt; Height:{} Width:{} Channels:{} Datatype:{}\".format(\n                    self.__inputheight,\n                    self.__inputwidth,\n                    self.__inputchannels,\n                    self.__inputdtype,\n                )\n            )\n\n        # validate frame size\n        if height != self.__inputheight or width != self.__inputwidth:\n            raise ValueError(\n                \"[WriteGear:ERROR] :: All video-frames must have same size!\"\n            )\n        # validate number of channels in frame\n        if channels != self.__inputchannels:\n            raise ValueError(\n                \"[WriteGear:ERROR] :: All video-frames must have same number of channels!\"\n            )\n        # validate frame datatype\n        if dtype != self.__inputdtype:\n            raise ValueError(\n                \"[WriteGear:ERROR] :: All video-frames must have same datatype!\"\n            )\n\n        # checks if compression mode is enabled\n        if self.__compression:\n            # initiate FFmpeg process on first run\n            if self.__initiate_process:\n                # start pre-processing of FFmpeg parameters, and initiate process\n                self.__PreprocessFFParams(channels, dtype=dtype, rgb=rgb_mode)\n                # Check status of the process\n                assert self.__process is not None\n            try:\n                # try writing the frame bytes to the subprocess pipeline\n                self.__process.stdin.write(frame.tobytes())\n            except (OSError, IOError):\n                # log if something is wrong!\n                logger.error(\n                    \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe. Kindly Refer Docs!\"\n                )\n                raise ValueError  # for testing purpose only\n        else:\n            # otherwise initiate OpenCV's VideoWriter Class process\n            if self.__initiate_process:\n                # start VideoWriter Class process\n                self.__start_CVProcess()\n                # Check status of the process\n                assert self.__process is not None\n                # log one-time OpenCV warning\n                self.__logging and logger.info(\n                    \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet. Kindly switch on `compression_mode` to use them!\"\n                )\n            # write frame directly to\n            # VideoWriter Class process\n            self.__process.write(frame)\n\n    def __PreprocessFFParams(self, channels, dtype=None, rgb=False):\n        \"\"\"\n        Internal method that pre-processes FFmpeg Parameters before beginning to pipeline frames.\n\n        Parameters:\n            channels (int): Number of channels in input frame.\n            dtype (str): Datatype of input frame.\n            rgb_mode (boolean): Whether to activate `RGB mode`?\n        \"\"\"\n        # turn off initiate flag\n        self.__initiate_process = False\n        # initialize input parameters\n        input_parameters = {}\n\n        # handle output frames dimensions\n        dimensions = \"\"\n        if self.__output_dimensions is None:  # check if dimensions are given\n            dimensions += \"{}x{}\".format(\n                self.__inputwidth, self.__inputheight\n            )  # auto derive from frame\n        else:\n            dimensions += \"{}x{}\".format(\n                self.__output_dimensions[0], self.__output_dimensions[1]\n            )  # apply if defined\n        input_parameters[\"-s\"] = str(dimensions)\n\n        # handles user-defined and auto-assigned input pixel-formats\n        if not (\n            self.__inputpixfmt is None\n        ) and self.__inputpixfmt in get_supported_pixfmts(self.__ffmpeg):\n            # assign directly if valid\n            input_parameters[\"-pix_fmt\"] = self.__inputpixfmt\n        else:\n            # handles pix_fmt based on channels and dtype(HACK)\n            if dtype.kind == \"u\" and dtype.itemsize == 2:\n                # handle pix_fmt for frames with higher than 8-bit depth\n                pix_fmt = None\n                if channels == 1:\n                    pix_fmt = \"gray16\"\n                elif channels == 2:\n                    pix_fmt = \"ya16\"\n                elif channels == 3:\n                    pix_fmt = \"rgb48\" if rgb else \"bgr48\"\n                elif channels == 4:\n                    pix_fmt = \"rgba64\" if rgb else \"bgra64\"\n                else:\n                    # raise error otherwise\n                    raise ValueError(\n                        \"[WriteGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\"\n                    )\n                # Add endianness suffix (w.r.t byte-order)\n                input_parameters[\"-pix_fmt\"] = pix_fmt + (\n                    \"be\" if dtype.byteorder == \"&gt;\" else \"le\"\n                )\n            else:\n                # handle pix_fmt for frames with exactly 8-bit depth(`uint8`)\n                if channels == 1:\n                    input_parameters[\"-pix_fmt\"] = \"gray\"\n                elif channels == 2:\n                    input_parameters[\"-pix_fmt\"] = \"ya8\"\n                elif channels == 3:\n                    input_parameters[\"-pix_fmt\"] = \"rgb24\" if rgb else \"bgr24\"\n                elif channels == 4:\n                    input_parameters[\"-pix_fmt\"] = \"rgba\" if rgb else \"bgra\"\n                else:\n                    # raise error otherwise\n                    raise ValueError(\n                        \"[WriteGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\"\n                    )\n\n        # handles user-defined output video framerate\n        if self.__inputframerate &gt; 0.0:\n            # assign input framerate if valid\n            self.__logging and logger.debug(\n                \"Setting Input framerate: {}\".format(self.__inputframerate)\n            )\n            input_parameters[\"-framerate\"] = str(self.__inputframerate)\n\n        # initiate FFmpeg process\n        self.__start_FFProcess(\n            input_params=input_parameters, output_params=self.__output_parameters\n        )\n\n    def __start_FFProcess(self, input_params, output_params):\n        \"\"\"\n        An Internal method that launches FFmpeg subprocess pipeline in Compression Mode\n        for pipelining frames to `stdin`.\n\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n        # convert input parameters to argument list\n        input_parameters = dict2Args(input_params)\n\n        # handle output video encoder.\n        # get list of supported video-encoders\n        supported_vcodecs = get_supported_vencoders(self.__ffmpeg)\n        # dynamically select default encoder\n        default_vcodec = [\n            vcodec\n            for vcodec in [\"libx264\", \"libx265\", \"libxvid\", \"mpeg4\"]\n            if vcodec in supported_vcodecs\n        ][0] or \"unknown\"\n        # extract any user-defined encoder\n        if \"-c:v\" in output_params:\n            # assign it to the pipeline\n            output_params[\"-vcodec\"] = output_params.pop(\"-c:v\", default_vcodec)\n        if not \"-vcodec\" in output_params:\n            # auto-assign default video-encoder (if not assigned by user).\n            output_params[\"-vcodec\"] = default_vcodec\n        if (\n            default_vcodec != \"unknown\"\n            and not output_params[\"-vcodec\"] in supported_vcodecs\n        ):\n            # reset to default if not supported\n            logger.critical(\n                \"Provided FFmpeg does not support `{}` video-encoder. Switching to default supported `{}` encoder!\".format(\n                    output_params[\"-vcodec\"], default_vcodec\n                )\n            )\n            output_params[\"-vcodec\"] = default_vcodec\n\n        # assign optimizations based on selected video encoder(if any)\n        if output_params[\"-vcodec\"] in supported_vcodecs:\n            if output_params[\"-vcodec\"] in [\"libx265\", \"libx264\"]:\n                if not \"-crf\" in output_params:\n                    output_params[\"-crf\"] = \"18\"\n                if not \"-preset\" in output_params:\n                    output_params[\"-preset\"] = \"fast\"\n            if output_params[\"-vcodec\"] in [\"libxvid\", \"mpeg4\"]:\n                if not \"-qscale:v\" in output_params:\n                    output_params[\"-qscale:v\"] = \"3\"\n        else:\n            # raise error otherwise\n            raise RuntimeError(\n                \"[WriteGear:ERROR] :: Provided FFmpeg does not support any suitable/usable video-encoders for compression.\"\n                \" Kindly disable compression mode or switch to another FFmpeg binaries(if available).\"\n            )\n\n        # convert output parameters to argument list\n        output_parameters = dict2Args(output_params)\n\n        # format FFmpeg command\n        cmd = (\n            [self.__ffmpeg, \"-y\"]\n            + self.__ffmpeg_preheaders\n            + [\"-f\", \"rawvideo\", \"-vcodec\", \"rawvideo\"]\n            + input_parameters\n            + [\"-i\", \"-\"]\n            + output_parameters\n            + [self.__out_file]\n        )\n        # Launch the process with FFmpeg command\n        if self.__logging:\n            # log command in logging mode\n            logger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n            # In logging mode\n            self.__process = sp.Popen(cmd, stdin=sp.PIPE, stdout=sp.PIPE, stderr=None)\n        else:\n            # In silent mode\n            self.__process = sp.Popen(\n                cmd,\n                stdin=sp.PIPE,\n                stdout=sp.DEVNULL,\n                stderr=sp.STDOUT,\n                creationflags=(  # this prevents ffmpeg creation window from opening when building exe files on Windows\n                    sp.DETACHED_PROCESS if self.__ffmpeg_window_disabler_patch else 0\n                ),\n            )\n\n    def __enter__(self):\n        \"\"\"\n        Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n\n        **Returns:** Returns a reference to the WriteGear Class\n        \"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        \"\"\"\n        self.close()\n\n    def execute_ffmpeg_cmd(self, command=None):\n        \"\"\"\n\n        Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only).\n\n        Parameters:\n            command (list): inputs list data-type command.\n\n        \"\"\"\n        # check if valid command\n        if command is None or not (command):\n            logger.warning(\"Input command is empty, Nothing to execute!\")\n            return\n        else:\n            if not (isinstance(command, list)):\n                raise ValueError(\n                    \"[WriteGear:ERROR] :: Invalid input command datatype! Kindly read docs.\"\n                )\n\n        # check if Compression Mode is enabled\n        if not (self.__compression):\n            # raise error otherwise\n            raise RuntimeError(\n                \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\"\n            )\n\n        # add configured FFmpeg path\n        cmd = [self.__ffmpeg] + command\n\n        try:\n            # write frames to pipeline\n            if self.__logging:\n                # log command in logging mode\n                logger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n                # In logging mode\n                sp.run(cmd, stdin=sp.PIPE, stdout=sp.PIPE, stderr=None)\n            else:\n                # In silent mode\n                sp.run(cmd, stdin=sp.PIPE, stdout=sp.DEVNULL, stderr=sp.STDOUT)\n        except (OSError, IOError) as e:\n            # re-raise error\n            if self.__logging:\n                raise ValueError(\n                    \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\"\n                ) from None\n            else:\n                raise ValueError(\n                    \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\"\n                ) from e\n\n    def __start_CVProcess(self):\n        \"\"\"\n        An Internal method that launches OpenCV VideoWriter process in Non-Compression\n        Mode with given settings.\n        \"\"\"\n        # turn off initiate flag\n        self.__initiate_process = False\n\n        # initialize essential variables\n        FPS = 0\n        BACKEND = \"\"\n        FOURCC = 0\n        COLOR = True\n\n        # pre-assign default parameters (if not assigned by user).\n        if \"-fourcc\" not in self.__output_parameters:\n            FOURCC = cv2.VideoWriter_fourcc(*\"MJPG\")\n        if \"-fps\" not in self.__output_parameters:\n            FPS = 25\n\n        # auto-assign frame dimensions\n        HEIGHT = self.__inputheight\n        WIDTH = self.__inputwidth\n\n        # assign dict parameter values to variables\n        try:\n            for key, value in self.__output_parameters.items():\n                if key == \"-fourcc\":\n                    FOURCC = cv2.VideoWriter_fourcc(*(value.upper()))\n                elif key == \"-fps\":\n                    FPS = int(value)\n                elif key == \"-backend\":\n                    BACKEND = capPropId(value.upper())\n                elif key == \"-color\":\n                    COLOR = bool(value)\n                else:\n                    pass\n        except Exception as e:\n            # log and raise error if something is wrong\n            self.__logging and logger.exception(str(e))\n            raise ValueError(\n                \"[WriteGear:ERROR] :: Wrong Values passed to OpenCV Writer, Kindly Refer Docs!\"\n            )\n\n        # log values for debugging\n        self.__logging and logger.debug(\n            \"FILE_PATH: {}, FOURCC = {}, FPS = {}, WIDTH = {}, HEIGHT = {}, BACKEND = {}\".format(\n                self.__out_file, FOURCC, FPS, WIDTH, HEIGHT, BACKEND\n            )\n        )\n        # start different OpenCV VideoCapture processes\n        # for with and without Backend.\n        if BACKEND:\n            self.__process = cv2.VideoWriter(\n                self.__out_file,\n                apiPreference=BACKEND,\n                fourcc=FOURCC,\n                fps=FPS,\n                frameSize=(WIDTH, HEIGHT),\n                isColor=COLOR,\n            )\n        else:\n            self.__process = cv2.VideoWriter(\n                self.__out_file,\n                fourcc=FOURCC,\n                fps=FPS,\n                frameSize=(WIDTH, HEIGHT),\n                isColor=COLOR,\n            )\n        # check if OpenCV VideoCapture is opened successfully\n        assert (\n            self.__process.isOpened()\n        ), \"[WriteGear:ERROR] :: Failed to initialize OpenCV Writer!\"\n\n    def close(self):\n        \"\"\"\n        Safely terminates various WriteGear process.\n        \"\"\"\n        # log termination\n        self.__logging and logger.debug(\"Terminating WriteGear Processes.\")\n        # handle termination separately\n        if self.__compression:\n            # when Compression Mode is enabled\n            if self.__process is None or not (self.__process.poll() is None):\n                # return if no process initiated\n                # at first place\n                return\n            # close `stdin` output\n            self.__process.stdin and self.__process.stdin.close()\n            # close `stdout` output\n            self.__process.stdout and self.__process.stdout.close()\n            # forced termination if specified.\n            self.__forced_termination and self.__process.terminate()\n            # wait if process is still processing\n            self.__process.wait()\n        else:\n            # when Compression Mode is disabled\n            if self.__process is None:\n                # return if no process initiated\n                # at first place\n                return\n            # close it\n            self.__process.release()\n        # discard process\n        self.__process = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__enter__","title":"<code>__enter__(self)</code>  <code>special</code>","text":"<p>Handles entry with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> <p>Returns: Returns a reference to the WriteGear Class</p> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def __enter__(self):\n    \"\"\"\n    Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n\n    **Returns:** Returns a reference to the WriteGear Class\n    \"\"\"\n    return self\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__exit__","title":"<code>__exit__(self, exc_type, exc_val, exc_tb)</code>  <code>special</code>","text":"<p>Handles exit with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"\n    Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    \"\"\"\n    self.close()\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__init__","title":"<code>__init__(self, output='', compression_mode=True, custom_ffmpeg='', logging=False, **output_params)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the WriteGear class.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str</code> <p>sets the valid filename/path/URL for encoding.</p> <code>''</code> <code>compression_mode</code> <code>bool</code> <p>selects the WriteGear's Primary Mode of Operation.</p> <code>True</code> <code>custom_ffmpeg</code> <code>str</code> <p>assigns the location of custom path/directory for custom FFmpeg executables.</p> <code>''</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>output_params</code> <code>dict</code> <p>provides the flexibility to control supported internal parameters and FFmpeg properties.</p> <code>{}</code> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def __init__(\n    self,\n    output=\"\",\n    compression_mode=True,\n    custom_ffmpeg=\"\",\n    logging=False,\n    **output_params\n):\n    \"\"\"\n    This constructor method initializes the object state and attributes of the WriteGear class.\n\n    Parameters:\n        output (str): sets the valid filename/path/URL for encoding.\n        compression_mode (bool): selects the WriteGear's Primary Mode of Operation.\n        custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n        logging (bool): enables/disables logging.\n        output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properties.\n    \"\"\"\n    # enable logging if specified\n    self.__logging = logging if isinstance(logging, bool) else False\n\n    # print current version\n    logcurr_vidgear_ver(logging=self.__logging)\n\n    # check if user not using depreciated `output_filename` parameter\n    assert (\n        not \"output_filename\" in output_params\n    ), \"[WriteGear:ERROR] :: The `output_filename` parameter has been renamed to `output`. Refer Docs for more info.\"\n\n    # assign parameter values to class variables\n    # enables compression if enabled\n    self.__compression = (\n        compression_mode if isinstance(compression_mode, bool) else False\n    )\n    # specifies if machine in-use is running Windows OS or not\n    self.__os_windows = True if os.name == \"nt\" else False\n\n    # initialize various important class variables\n    self.__output_parameters = {}  # handles output parameters\n    self.__inputheight = None  # handles input frames height\n    self.__inputwidth = None  # handles input frames width\n    self.__inputchannels = None  # handles input frames channels\n    self.__inputdtype = None  # handles input frames dtype\n    self.__process = None  # handles Encoding class/process\n    self.__ffmpeg = \"\"  # handles valid FFmpeg binaries location\n    self.__initiate_process = (\n        True  # handles initiate one-time process for generating pipeline\n    )\n    self.__ffmpeg_window_disabler_patch = (\n        False  # handles disabling window for ffmpeg subprocess on Windows\n    )\n    self.__out_file = None  # handles output\n    gstpipeline_mode = False  # handles GStreamer Pipeline Mode\n\n    # handles output\n    if not output:\n        # raise error otherwise\n        raise ValueError(\n            \"[WriteGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more info.\"\n        )\n    else:\n        # validate output is a system file/directory\n        # and Whether WriteGear has the write rights\n        # to specified file/directory or not\n        abs_path = os.path.abspath(output)\n        if check_WriteAccess(\n            os.path.dirname(abs_path),\n            is_windows=self.__os_windows,\n            logging=self.__logging,\n        ):\n            # check if given path is directory\n            if os.path.isdir(abs_path):\n                # then, auto-assign valid name and adds it to path\n                abs_path = os.path.join(\n                    abs_path,\n                    \"VidGear-{}.mp4\".format(time.strftime(\"%Y%m%d-%H%M%S\")),\n                )\n            # assign output file absolute\n            # path to class variable if valid\n            self.__out_file = abs_path\n        else:\n            # log note otherwise\n            logger.info(\n                \"`{}` isn't a valid system path or directory. Skipped!\".format(\n                    output\n                )\n            )\n\n    # cleans and reformat output parameters\n    self.__output_parameters = {\n        str(k).strip(): (v.strip() if isinstance(v, str) else v)\n        for k, v in output_params.items()\n    }\n    # log it if specified\n    self.__logging and logger.debug(\n        \"Output Parameters: `{}`\".format(self.__output_parameters)\n    )\n\n    # handles FFmpeg binaries validity\n    # in Compression mode\n    if self.__compression:\n        # log it if specified\n        self.__logging and logger.debug(\n            \"Compression Mode is enabled therefore checking for valid FFmpeg executable.\"\n        )\n\n        # handles where to save the downloaded FFmpeg Static Binaries\n        # on Windows(if specified)\n        __ffmpeg_download_path = self.__output_parameters.pop(\n            \"-ffmpeg_download_path\", \"\"\n        )\n        # check if value is valid\n        if not isinstance(__ffmpeg_download_path, (str)):\n            # reset improper values\n            __ffmpeg_download_path = \"\"\n\n        # handle user-defined output resolution (must be a tuple or list)\n        # in Compression Mode only.\n        self.__output_dimensions = self.__output_parameters.pop(\n            \"-output_dimensions\", None\n        )\n        # check if value is valid\n        if not isinstance(self.__output_dimensions, (list, tuple)):\n            # reset improper values\n            self.__output_dimensions = None\n\n        # handle user defined input framerate of encoding pipeline\n        # in Compression Mode only.\n        self.__inputframerate = self.__output_parameters.pop(\n            \"-input_framerate\", 0.0\n        )\n        # check if value is valid\n        if not isinstance(self.__inputframerate, (float, int)):\n            # reset improper values\n            self.__inputframerate = 0.0\n        else:\n            # must be float\n            self.__inputframerate = float(self.__inputframerate)\n\n        # handle user-defined input frames pixel-format in Compression Mode only.\n        self.__inputpixfmt = self.__output_parameters.pop(\"-input_pixfmt\", None)\n        # check if value is valid\n        if not isinstance(self.__inputpixfmt, str):\n            # reset improper values\n            self.__inputpixfmt = None\n        else:\n            # must be exact\n            self.__inputpixfmt = self.__inputpixfmt.strip()\n\n        # handle user-defined FFmpeg command pre-headers(must be a list)\n        # in Compression Mode only.\n        self.__ffmpeg_preheaders = self.__output_parameters.pop(\"-ffpreheaders\", [])\n        # check if value is valid\n        if not isinstance(self.__ffmpeg_preheaders, list):\n            # reset improper values\n            self.__ffmpeg_preheaders = []\n\n        # handle the special-case of forced-termination (only for Compression mode)\n        disable_force_termination = self.__output_parameters.pop(\n            \"-disable_force_termination\",\n            False if (\"-i\" in self.__output_parameters) else True,\n        )\n        # check if value is valid\n        if isinstance(disable_force_termination, bool):\n            self.__forced_termination = not (disable_force_termination)\n        else:\n            # handle improper values\n            self.__forced_termination = (\n                True if (\"-i\" in self.__output_parameters) else False\n            )\n\n        # handles disabling window for ffmpeg subprocess on Windows OS (only for Compression mode)\n        # this patch prevents ffmpeg creation window from opening when building exe files\n        ffmpeg_window_disabler_patch = self.__output_parameters.pop(\n            \"-disable_ffmpeg_window\", False\n        )\n        # check if value is valid\n        if not self.__os_windows or logging:\n            logger.warning(\n                \"Optional `-disable_ffmpeg_window` flag is only available on Windows OS with `logging=False`. Discarding!\"\n            )\n        elif isinstance(ffmpeg_window_disabler_patch, bool):\n            self.__ffmpeg_window_disabler_patch = ffmpeg_window_disabler_patch\n        else:\n            # handle improper values\n            self.__ffmpeg_window_disabler_patch = False\n\n        # validate the FFmpeg path/binaries and returns valid executable FFmpeg\n        # location/path (also auto-downloads static binaries on Windows OS)\n        self.__ffmpeg = get_valid_ffmpeg_path(\n            custom_ffmpeg,\n            self.__os_windows,\n            ffmpeg_download_path=__ffmpeg_download_path,\n            logging=self.__logging,\n        )\n        # check if valid executable FFmpeg location/path\n        if self.__ffmpeg:\n            # log it if found\n            self.__logging and logger.debug(\n                \"Found valid FFmpeg executable: `{}`.\".format(self.__ffmpeg)\n            )\n        else:\n            # otherwise disable Compression Mode\n            # and switch to Non-compression mode\n            logger.warning(\n                \"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\"\n            )\n            if self.__logging and not self.__os_windows:\n                logger.debug(\n                    \"Kindly install a working FFmpeg module or provide a valid custom FFmpeg binary path. See docs for more info.\"\n                )\n            # compression mode disabled\n            self.__compression = False\n    else:\n        # handle GStreamer Pipeline Mode (only for Non-compression mode)\n        if \"-gst_pipeline_mode\" in self.__output_parameters:\n            # check if value is valid\n            if isinstance(self.__output_parameters[\"-gst_pipeline_mode\"], bool):\n                gstpipeline_mode = self.__output_parameters[\n                    \"-gst_pipeline_mode\"\n                ] and check_gstreamer_support(logging=logging)\n                self.__logging and logger.debug(\n                    \"GStreamer Pipeline Mode successfully activated!\"\n                )\n            else:\n                # reset improper values\n                gstpipeline_mode = False\n                # log it\n                self.__logging and logger.warning(\n                    \"GStreamer Pipeline Mode failed to activate!\"\n                )\n\n    # handle output differently in Compression/Non-compression Modes\n    if self.__compression and self.__ffmpeg:\n        # check if output falls in exclusive cases\n        if self.__out_file is None:\n            if (\n                platform.system() == \"Linux\"\n                and pathlib.Path(output).is_char_device()\n            ):\n                # check whether output is a Linux video device path (such as `/dev/video0`)\n                self.__logging and logger.debug(\n                    \"Path:`{}` is a valid Linux Video Device path.\".format(output)\n                )\n                self.__out_file = output\n            elif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\n                # check whether output is a valid URL instead\n                self.__logging and logger.debug(\n                    \"URL:`{}` is valid and successfully configured for streaming.\".format(\n                        output\n                    )\n                )\n                self.__out_file = output\n            else:\n                # raise error otherwise\n                raise ValueError(\n                    \"[WriteGear:ERROR] :: output value:`{}` is not supported in Compression Mode.\".format(\n                        output\n                    )\n                )\n        # log if forced termination is enabled\n        self.__forced_termination and logger.debug(\n            \"Forced termination is enabled for this FFmpeg process.\"\n        )\n        # log Compression is enabled\n        self.__logging and logger.debug(\n            \"Compression Mode with FFmpeg backend is configured properly.\"\n        )\n    else:\n        # raise error if not valid input\n        if self.__out_file is None and not gstpipeline_mode:\n            raise ValueError(\n                \"[WriteGear:ERROR] :: output value:`{}` is not supported in Non-Compression Mode.\".format(\n                    output\n                )\n            )\n\n        # check if GStreamer Pipeline Mode is enabled\n        if gstpipeline_mode:\n            # enforce GStreamer backend\n            self.__output_parameters[\"-backend\"] = \"CAP_GSTREAMER\"\n            # enforce original output value\n            self.__out_file = output\n\n        # log it\n        self.__logging and logger.debug(\n            \"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\"\n        )\n\n        # log if Compression is disabled\n        logger.critical(\n            \"Compression Mode is disabled, Activating OpenCV built-in Writer!\"\n        )\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.close","title":"<code>close(self)</code>","text":"<p>Safely terminates various WriteGear process.</p> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def close(self):\n    \"\"\"\n    Safely terminates various WriteGear process.\n    \"\"\"\n    # log termination\n    self.__logging and logger.debug(\"Terminating WriteGear Processes.\")\n    # handle termination separately\n    if self.__compression:\n        # when Compression Mode is enabled\n        if self.__process is None or not (self.__process.poll() is None):\n            # return if no process initiated\n            # at first place\n            return\n        # close `stdin` output\n        self.__process.stdin and self.__process.stdin.close()\n        # close `stdout` output\n        self.__process.stdout and self.__process.stdout.close()\n        # forced termination if specified.\n        self.__forced_termination and self.__process.terminate()\n        # wait if process is still processing\n        self.__process.wait()\n    else:\n        # when Compression Mode is disabled\n        if self.__process is None:\n            # return if no process initiated\n            # at first place\n            return\n        # close it\n        self.__process.release()\n    # discard process\n    self.__process = None\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.execute_ffmpeg_cmd","title":"<code>execute_ffmpeg_cmd(self, command=None)</code>","text":"<p>Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only).</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>list</code> <p>inputs list data-type command.</p> <code>None</code> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def execute_ffmpeg_cmd(self, command=None):\n    \"\"\"\n\n    Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only).\n\n    Parameters:\n        command (list): inputs list data-type command.\n\n    \"\"\"\n    # check if valid command\n    if command is None or not (command):\n        logger.warning(\"Input command is empty, Nothing to execute!\")\n        return\n    else:\n        if not (isinstance(command, list)):\n            raise ValueError(\n                \"[WriteGear:ERROR] :: Invalid input command datatype! Kindly read docs.\"\n            )\n\n    # check if Compression Mode is enabled\n    if not (self.__compression):\n        # raise error otherwise\n        raise RuntimeError(\n            \"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\"\n        )\n\n    # add configured FFmpeg path\n    cmd = [self.__ffmpeg] + command\n\n    try:\n        # write frames to pipeline\n        if self.__logging:\n            # log command in logging mode\n            logger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n            # In logging mode\n            sp.run(cmd, stdin=sp.PIPE, stdout=sp.PIPE, stderr=None)\n        else:\n            # In silent mode\n            sp.run(cmd, stdin=sp.PIPE, stdout=sp.DEVNULL, stderr=sp.STDOUT)\n    except (OSError, IOError) as e:\n        # re-raise error\n        if self.__logging:\n            raise ValueError(\n                \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\"\n            ) from None\n        else:\n            raise ValueError(\n                \"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\"\n            ) from e\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.write","title":"<code>write(self, frame, rgb_mode=False)</code>","text":"<p>Pipelines <code>ndarray</code> frames to respective API (FFmpeg in Compression Mode &amp; OpenCV's VideoWriter API in Non-Compression Mode).</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>a valid numpy frame</p> required <code>rgb_mode</code> <code>boolean</code> <p>enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR).</p> <code>False</code> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def write(self, frame, rgb_mode=False):\n    \"\"\"\n    Pipelines `ndarray` frames to respective API _(**FFmpeg** in Compression Mode &amp; **OpenCV's VideoWriter API** in Non-Compression Mode)_.\n\n    Parameters:\n        frame (ndarray): a valid numpy frame\n        rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_.\n\n    \"\"\"\n    if frame is None:  # None-Type frames will be skipped\n        return\n\n    # get height, width, number of channels, and dtype of current frame\n    height, width = frame.shape[:2]\n    channels = frame.shape[-1] if frame.ndim == 3 else 1\n    dtype = frame.dtype\n\n    # assign values to class variables on first run\n    if self.__initiate_process:\n        self.__inputheight = height\n        self.__inputwidth = width\n        self.__inputchannels = channels\n        self.__inputdtype = dtype\n        self.__logging and logger.debug(\n            \"InputFrame =&gt; Height:{} Width:{} Channels:{} Datatype:{}\".format(\n                self.__inputheight,\n                self.__inputwidth,\n                self.__inputchannels,\n                self.__inputdtype,\n            )\n        )\n\n    # validate frame size\n    if height != self.__inputheight or width != self.__inputwidth:\n        raise ValueError(\n            \"[WriteGear:ERROR] :: All video-frames must have same size!\"\n        )\n    # validate number of channels in frame\n    if channels != self.__inputchannels:\n        raise ValueError(\n            \"[WriteGear:ERROR] :: All video-frames must have same number of channels!\"\n        )\n    # validate frame datatype\n    if dtype != self.__inputdtype:\n        raise ValueError(\n            \"[WriteGear:ERROR] :: All video-frames must have same datatype!\"\n        )\n\n    # checks if compression mode is enabled\n    if self.__compression:\n        # initiate FFmpeg process on first run\n        if self.__initiate_process:\n            # start pre-processing of FFmpeg parameters, and initiate process\n            self.__PreprocessFFParams(channels, dtype=dtype, rgb=rgb_mode)\n            # Check status of the process\n            assert self.__process is not None\n        try:\n            # try writing the frame bytes to the subprocess pipeline\n            self.__process.stdin.write(frame.tobytes())\n        except (OSError, IOError):\n            # log if something is wrong!\n            logger.error(\n                \"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe. Kindly Refer Docs!\"\n            )\n            raise ValueError  # for testing purpose only\n    else:\n        # otherwise initiate OpenCV's VideoWriter Class process\n        if self.__initiate_process:\n            # start VideoWriter Class process\n            self.__start_CVProcess()\n            # Check status of the process\n            assert self.__process is not None\n            # log one-time OpenCV warning\n            self.__logging and logger.info(\n                \"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet. Kindly switch on `compression_mode` to use them!\"\n            )\n        # write frame directly to\n        # VideoWriter Class process\n        self.__process.write(frame)\n</code></pre>"},{"location":"contribution/PR/","title":"Submitting Pull Request(PR) Guidelines","text":""},{"location":"contribution/PR/#submitting-pull-requestpr-guidelines","title":"Submitting Pull Request(PR) Guidelines:","text":"<p>The following guidelines tells you how to submit a valid PR for vidGear:</p> <p>Working on your first Pull Request for VidGear?</p> <ul> <li> <p>If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here \u27b6</p> </li> <li> <p>If you're stuck at something, please join our Gitter community channel. We will help you get started!</p> </li> <li> <p>Kindly follow the EXEMPLARY  tag for some finest PR examples.</p> </li> </ul> <p> </p>"},{"location":"contribution/PR/#clone-testing-branch","title":"Clone Testing branch","text":"<p>Base Branch must be <code>testing</code> in your Pull Request</p> <p>Every PR MUST be pushed against VidGear's <code>testing</code> branch only, in order to trigger must needed CI testing workflows. If your's not, then change the base branch to <code>testing</code> \u27b6</p> <p>Make sure the <code>testing</code> branch of your Forked repository is up-to-date with VidGear, before starting working on Pull Request.</p> <p>You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest <code>testing</code> branch as follows:</p> Functions of different VidGear's Github Branches <p>Following are the base branches for VidGear's code in its Github Repository:</p> Master/MainTestingDevelopment <p>Branch Features:</p> <ul> <li>Most-Stable </li> <li>Includes the latest stable-release. </li> <li>Lacks any latest bug-fixes and changes.</li> <li>Everything CI tested.</li> </ul> <p>Cloning:</p> <pre><code># clone your forked repository and `cd` inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n</code></pre> <p>Branch Features:</p> <ul> <li>Stable.</li> <li>Includes latest stable bug-fixes and changes.</li> <li>Used for pushing PR commits. </li> <li>Everything CI tested.</li> </ul> <p>Cloning:</p> <pre><code># clone your forked repository and `cd` inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest testing branch\ngit checkout testing\n</code></pre> <p>Branch Features:</p> <ul> <li> Unstable.</li> <li>Includes latest experimental changes.</li> <li>Used for pushing experimental commits. </li> <li>Nothing CI tested.</li> </ul> <p>Cloning:</p> <pre><code># clone your forked repository and `cd` inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest development branch\ngit checkout development\n</code></pre> <p>Workflow: </p> <p>Typically any feature/improvement/bug-fix code flows as follows:</p> <p> </p> <pre><code># clone your forked repository(change with your username) and get inside\ngit clone https://github.com/{YOUR USERNAME}/vidgear.git &amp;&amp; cd vidgear\n\n# pull any recent updates\ngit pull\n\n# checkout the latest testing branch\ngit checkout testing\n\n# Now create your new branch with suitable name(such as \"subbranch_of_testing\")\ngit checkout -b subbranch_of_testing\n</code></pre> <p>Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.</p> <p> </p> <p> </p>"},{"location":"contribution/PR/#pr-submission-checklist","title":"PR Submission Checklist","text":"<p>There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library:</p> <ul> <li> <p> Submit a Related Issue:</p> </li> <li> <p>The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request.</p> </li> <li> <p> Submit a Draft Pull Request:</p> </li> <li> <p>Submit the draft pull request from the first day of your development.</p> </li> <li>Add a brief but descriptive title for your PR.</li> <li>Explain what the PR adds, fixes, or improves.</li> <li>In case of bug fixes, add a new unit test case that would fail against your bug fix.</li> <li>Provide output or screenshots, if you can.</li> <li>Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against testing branch). If it's somehow failing, then ask the maintainer for a review.</li> <li> <p>Click \"ready for review\" when finished.</p> </li> <li> <p> Test, Format &amp; lint code locally:</p> </li> <li> <p>Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6</p> </li> <li> <p> Make sensible commit messages:</p> </li> <li> <p>If your pull request fixes a separate issue number, remember to include <code>\"resolves #issue_number\"</code> in the commit message. Learn more about it here \u27b6.</p> </li> <li> <p>Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with <code>git commit --amend</code> command.</p> </li> <li> <p> Perform Integrity Checks: </p> <p>Any duplicate pull request will be Rejected!</p> </li> <li> <p>Search GitHub if there's a similar open or closed PR that relates to your submission.</p> </li> <li>Check if your purpose code matches the overall direction, simplicity, and structure of the VidGear and improves it.</li> <li> <p>Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6.</p> </li> <li> <p> Link your Issues:</p> <p>For more information on Linking a pull request to an issue, See this wiki doc\u27b6</p> </li> <li> <p>Finally, when you're confident enough, make your pull request public. </p> </li> <li>You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. </li> </ul> <p> </p> <p> </p>"},{"location":"contribution/PR/#testing-formatting-linting","title":"Testing, Formatting &amp; Linting","text":"<p>All Pull Request(s) must be tested, formatted &amp; linted against our library standards as discussed below:</p>"},{"location":"contribution/PR/#requirements","title":"Requirements","text":"<p>Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows:</p> <ul> <li> <p> Install additional python libraries:</p> <p>You can easily install these dependencies via pip:</p> MPEGDASH for Windows  <p>The <code>mpegdash</code> library has not yet been updated and bugs on windows machines. Therefore install the forked DEV-version of <code>mpegdash</code> as follows:</p> <pre><code>python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev2/mpegdash-0.3.0.dev2-py3-none-any.whl\n</code></pre> <pre><code>pip install --upgrade six flake8 black pytest pytest-asyncio mpegdash paramiko m3u8 async-asgi-testclient\n</code></pre> </li> <li> <p> Download Tests Dataset: </p> <p>To perform tests, you also need to download additional dataset (to your temp dir) by running <code>prepare_dataset.sh</code>  bash script as follows:</p> <pre><code>chmod +x scripts/bash/prepare_dataset.sh\n# On linux and MacOS\n.scripts/bash/prepare_dataset.sh\n# On Windows \nsh scripts/bash/prepare_dataset.sh\n</code></pre> </li> </ul>"},{"location":"contribution/PR/#running-tests","title":"Running Tests","text":"<p>All tests can be run with <code>pytest</code>(in VidGear's root folder) as follows:</p> <pre><code> pytest -sv  #-sv for verbose output.\n</code></pre>"},{"location":"contribution/PR/#formatting-linting","title":"Formatting &amp; Linting","text":"<p>For formatting and linting, following libraries are used:</p> <ul> <li> <p> Flake8: You must run <code>flake8</code> linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity:</p> <pre><code>flake8 {source_file_or_directory} --count --select=E9,F63,F7,F82 --show-source --statistics\n</code></pre> </li> <li> <p> Black:  Vidgear follows <code>black</code> formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: </p> <pre><code>black {source_file_or_directory}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"contribution/PR/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Q1. Why do my changes taking so long to be Reviewed and/or Merged?</p> <p>Submission Aftermaths</p> <ul> <li>After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.</li> <li>The changes will remain in <code>testing</code> branch until next VidGear version is released, then it will be merged into <code>master</code> branch.</li> <li>After a successful Merge, your newer contributions will be given priority over others. </li> </ul> <p>Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request.</p> <p>Q2. Would you accept a huge Pull Request with Lots of Changes?</p> <p>First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!</p> <p> </p>"},{"location":"contribution/issue/","title":"Submitting an Issue Guidelines","text":""},{"location":"contribution/issue/#submitting-an-issue-guidelines","title":"Submitting an Issue Guidelines","text":"<p>If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines:</p> First Issue on GitHub? <p>You can easily learn about it from creating an issue wiki.</p> <p>Info</p> <p>Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.</p>"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","title":"Search the Docs and Previous Issues","text":"<ul> <li>Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. </li> <li>For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel.</li> <li>Also, go comprehensively through our dedicated FAQ &amp; Troubleshooting section.</li> </ul>"},{"location":"contribution/issue/#gather-required-information","title":"Gather Required Information","text":"<ul> <li>All VidGear APIs provides a <code>logging</code> boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter <code>True</code> in the respective API for getting debug output, and paste it with your Issue. </li> <li>In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. </li> <li>Check and paste, exact VidGear version by running command <code>python -c \"import vidgear; print(vidgear.__version__)\"</code>.</li> </ul>"},{"location":"contribution/issue/#follow-the-issue-template","title":"Follow the Issue Template","text":"<ul> <li>Please format your issue by choosing the appropriate template. </li> <li>Any improper/insufficient reports will be marked with MISSING : INFORMATION  and MISSING : TEMPLATE  like labels, and if we don't hear back from you we may close the issue.</li> </ul>"},{"location":"contribution/issue/#raise-the-issue","title":"Raise the Issue","text":"<ul> <li>Add a brief but descriptive title for your issue.</li> <li>Keep the issue phrasing in context of the problem.</li> <li>Attach source-code/screenshots if you have one.</li> <li>Finally, raise it by choosing the appropriate Issue Template: Bug report \ud83d\udc1b, Proposal \ud83d\udca1, Question \u2754.</li> </ul>"},{"location":"gears/camgear/overview/","title":"Overview","text":""},{"location":"gears/camgear/overview/#camgear-api","title":"CamGear API","text":"CamGear API's generalized workflow"},{"location":"gears/camgear/overview/#overview","title":"Overview","text":"<p>CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras,  multimedia video file format (upto 4k tested), any network stream URL such as <code>http(s), rtp, rtsp, rtmp, mms, etc.</code> In addition to this, it also supports Gstreamer's RAW pipelines and various live video streaming sites like YouTube, Twitch, Dailymotion etc.</p> <p>CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters. It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.</p> <p>CamGear internally implements <code>yt_dlp</code> backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Twitch, and many more \u27b6</p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> <li> <p>You can use <code>framerate</code> class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6</p> </li> </ul> <p> </p>"},{"location":"gears/camgear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through CamGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/camgear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/camgear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/camgear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/camgear/params/","title":"Parameters","text":""},{"location":"gears/camgear/params/#camgear-api-parameters","title":"CamGear API Parameters","text":""},{"location":"gears/camgear/params/#source","title":"<code>source</code>","text":"<p>CamGear API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>CamGear(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>CamGear(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>): </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>CamGear(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>GStreamer Pipelining in WriteGear your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>CamGear(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/camgear/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/camgear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the input stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>CamGear(source=0, colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/camgear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>CamGear(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/camgear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nCamGear(source=0, **options)\n</code></pre> <p> </p>"},{"location":"gears/camgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>CamGear(source=0, logging=True)\n</code></pre> <p> </p>"},{"location":"gears/camgear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>CamGear(source=0, time_delay=1) # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/","title":"Usage Examples","text":""},{"location":"gears/camgear/usage/#camgear-api-usage-examples","title":"CamGear API Usage Examples:","text":"<p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/camgear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with CamGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = CamGear(source=\"myvideo.avi\").start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-streaming-websites","title":"Using Camgear with Streaming Websites","text":"<p>CamGear internally implements <code>yt_dlp</code> backend class for seamlessly pipelining live video-frames and metadata from various streaming services like Twitch, Vimeo, Dailymotion, and many more \u27b6. All you have to do is to provide the desired Video's URL to its <code>source</code> parameter, and enable its <code>stream_mode</code> parameter. </p> <p>The complete usage example for Dailymotion and Twitch URLs are as follows:</p> Bug in OpenCV's FFmpeg <p>To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos.</p> <p>Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support.</p> <p>Not all resolutions are supported with GStreamer Backend. See issue #244</p> Exclusive CamGear Attributes for <code>yt_dlp</code> backend <p>CamGear also provides exclusive attributes: </p> <ul> <li><code>STREAM_RESOLUTION</code> (for specifying stream resolution)</li> <li><code>STREAM_PARAMS</code> (for specifying  <code>yt_dlp</code> parameters) </li> </ul> <p>with its <code>options</code> dictionary parameter. More information can be found here \u27b6</p> Supported Streaming Websites <p>The list of all supported Streaming Websites URLs can be found here \u27b6</p> Accessing Stream's Metadata  <p>CamGear now provides <code>ytv_metadata</code> global parameter for accessing given Video's metadata as JSON Object. It can used as follows:</p> New in v0.2.4 <p><code>ytv_metadata</code> global parameter was added in <code>v0.2.4</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\n\n# Add YouTube Video URL as input source (for e.g https://www.dailymotion.com/video/x2yrnum)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\n    source=\"https://www.dailymotion.com/video/x2yrnum\", stream_mode=True, logging=True, **options\n).start()\n\n# get Video's metadata as JSON object\nvideo_metadata =  stream.ytv_metadata\n\n# print all available keys\nprint(video_metadata.keys())\n\n# get data like `title`\nprint(video_metadata[\"title\"])\n</code></pre> Dailymotion Twitch  <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n# set desired quality as 720p\noptions = {\"STREAM_RESOLUTION\": \"720p\"}\n\n# Add any desire Video URL as input source\n# for e.g https://vimeo.com/151666798\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\n    source=\"https://www.dailymotion.com/video/x2yrnum\",\n    stream_mode=True,\n    logging=True,\n    **options\n).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>If Twitch user is offline, CamGear will throw ValueError.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n# set desired quality as 720p\noptions = {\"STREAM_RESOLUTION\": \"720p\"}\n\n# Add any desire Video URL as input source\n# for e.g hhttps://www.twitch.tv/shroud\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\n    source=\"https://www.twitch.tv/shroud\",\n    stream_mode=True,\n    logging=True,\n    **options\n).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-youtube-videos","title":"Using Camgear with Youtube Videos","text":"<p>CamGear API also provides out-of-the-box support for pipelining live video-frames and metadata from  YouTube (Livestream + Normal) Videos. </p> <p>YouTube Playlists  are not supported yet.</p> <p>The complete usage example is as follows:</p> Bug in OpenCV's FFmpeg <p>To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos.</p> <p>Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support.</p> <p>Not all resolutions are supported with GStreamer Backend. See issue #244</p> Exclusive CamGear Attributes for <code>yt_dlp</code> backend <p>CamGear also provides exclusive attributes: </p> <ul> <li><code>STREAM_RESOLUTION</code> (for specifying stream resolution)</li> <li><code>STREAM_PARAMS</code> (for specifying  <code>yt_dlp</code> parameters) </li> </ul> <p>with its <code>options</code> dictionary parameter. More information can be found here \u27b6</p> Accessing Stream's Metadata  <p>CamGear now provides <code>ytv_metadata</code> global parameter for accessing given Video's metadata as JSON Object. It can used as follows:</p> New in v0.2.4 <p><code>ytv_metadata</code> global parameter was added in <code>v0.2.4</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\n\n# Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\n    source=\"https://youtu.be/uCy5OuSQnyA\", stream_mode=True, logging=True, **options\n).start()\n\n# get Video's metadata as JSON object\nvideo_metadata =  stream.ytv_metadata\n\n# print all available keys\nprint(video_metadata.keys())\n\n# get data like `title`\nprint(video_metadata[\"title\"])\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n# Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\n    source=\"https://youtu.be/uCy5OuSQnyA\", \n    stream_mode=True,\n    logging=True\n).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-variable-camera-properties","title":"Using CamGear with Variable Camera Properties","text":"<p>CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API. These tweak parameters can be used to transform input source Camera-Device properties (such as its brightness, saturation, framerate, resolution, gain etc.) seamlessly, and can be easily applied in CamGear API through its <code>options</code> dictionary parameter by formatting them as its attributes. </p> <p>The complete usage example is as follows:</p> <p>All the supported Source Tweak Parameters can be found here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n\n# define suitable tweak parameters for your stream.\noptions = {\n    \"CAP_PROP_FRAME_WIDTH\": 320, # resolution 320x240\n    \"CAP_PROP_FRAME_HEIGHT\": 240,\n    \"CAP_PROP_FPS\": 60, # framerate 60fps\n}\n\n# To open live video stream on webcam at first index(i.e. 0) \n# device and apply source tweak parameters\nstream = CamGear(source=0, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-direct-colorspace-manipulation","title":"Using Camgear with Direct Colorspace Manipulation","text":"<p>CamGear API also supports Direct Colorspace Manipulation, which is ideal for changing source colorspace on the run. </p> <p>A more detailed  information on colorspace manipulation can be found here \u27b6</p> <p>In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY  colorspace when W key is pressed, and then LAB colorspace when E key is pressed, finally default colorspace (i.e. BGR) when S key is pressed. Also, quit when Q key is pressed:</p> <p>Any incorrect or None-type value, will immediately revert the colorspace to default i.e. <code>BGR</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n# Open any source of your choice, like Webcam first index(i.e. 0)\n# and change its colorspace to `HSV`\nstream = CamGear(source=0, colorspace=\"COLOR_BGR2HSV\", logging=True).start()\n\n# loop over\nwhile True:\n\n    # read HSV frames\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the HSV frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n\n    # check if 'w' key is pressed\n    if key == ord(\"w\"):\n        # directly change colorspace at any instant\n        stream.color_space = cv2.COLOR_BGR2GRAY  # Now colorspace is GRAY\n\n    # check for 'e' key is pressed\n    if key == ord(\"e\"):\n        stream.color_space = cv2.COLOR_BGR2LAB  # Now colorspace is CieLAB\n\n    # check for 's' key is pressed\n    if key == ord(\"s\"):\n        stream.color_space = None  # Now colorspace is default(ie BGR)\n\n    # check for 'q' key is pressed\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/advanced/source_params/","title":"Source Tweak Parameters","text":""},{"location":"gears/camgear/advanced/source_params/#source-tweak-parameters-for-camgear-api","title":"Source Tweak Parameters for CamGear API","text":""},{"location":"gears/camgear/advanced/source_params/#overview","title":"Overview","text":"<p>With CamGear's <code>options</code> dictionary parameter, the user has the ability to alter various tweak parameters available within OpenCV's VideoCapture Class by formatting them as its attributes. </p> <p>These tweak parameters can be used to transform input Camera-Source properties (such as its brightness, saturation, resolution, iso, gain etc.) seamlessly. All parameters supported by CamGear API are disscussed in this document.</p> <p> </p>"},{"location":"gears/camgear/advanced/source_params/#exclusive-camgear-attributes","title":"Exclusive CamGear Attributes","text":"CamGear's Exclusive Attributes <p>In addition to Source Tweak Parameters, CamGear also provides some exclusive attributes for its <code>options</code> dictionary parameters. </p> <p>These attributes are as follows:</p> <ul> <li> <p> <code>STREAM_RESOLUTION</code> (string): This attribute can be used in CamGear's Stream Mode (<code>stream_mode=True</code>) for specifying supported stream resolution. Its possible values can be: <code>144p</code>, <code>240p</code>, <code>360p</code>, <code>480p</code>, <code>720p</code>, <code>1080p</code>, <code>1440p</code>, <code>2160p</code>, <code>4320p</code>, <code>worst</code>, <code>best</code>, and its default value is <code>best</code>. Its usage is as follows:</p> <p>In case specificed <code>STREAM_RESOLUTION</code> value is unavailable within Source Stream, it defaults to <code>best</code>!</p> <pre><code>options = {\"STREAM_RESOLUTION\": \"720p\"} # 720p stream will be used. \n</code></pre> <p>Its complete usage example is given here \u27b6</p> </li> <li> <p> <code>STREAM_PARAMS</code> (dict): This dictionary attribute can be used in CamGear's Stream Mode (<code>stream_mode=True</code>) for specifying parameters for its internal <code>yt_dlp</code> backend class. Its usage is as follows:</p> <p>All <code>STREAM_PARAMS</code> Supported Parameters</p> <ul> <li>All yt_dlp parameter can be found here \u27b6</li> </ul> <pre><code>options = {\"STREAM_PARAMS\": {\"nocheckcertificate\": True}} # disables verifying SSL certificates in yt_dlp\n</code></pre> </li> <li> <p> <code>THREADED_QUEUE_MODE</code> (boolean): This attribute can be used to override Threaded-Queue-Mode mode to manually disable it:</p> <p>Disabling Threaded-Queue-Mode can be dangerous! Read more here \u27b6</p> <pre><code>options = {\"THREADED_QUEUE_MODE\": False} # disable Threaded Queue Mode. \n</code></pre> </li> <li> <p> <code>THREAD_TIMEOUT</code> (int/float): This attribute can be used to override the timeout value(positive number), that blocks the video-thread for at most timeout seconds if no video-frame was available within that time, and otherwise raises the Empty exception to prevent any never-ending deadlocks. Its default value is <code>None</code>, meaning no timeout at all.  Its usage is as follows:</p> New in v0.2.1 <p><code>THREAD_TIMEOUT</code> attribute added in <code>v0.2.1</code>.</p> <pre><code>options = {\"THREAD_TIMEOUT\": 300} # set Video-Thread Timeout for 5mins. \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/camgear/advanced/source_params/#supported-source-tweak-parameters","title":"Supported Source Tweak Parameters","text":"<p>All Source Tweak Parameters supported by CamGear API are as follows:</p> <p>Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error.</p> <p>You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command <code>v4l2-ctl -d 0 --list-formats-ext</code> (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available).</p> <p>These parameters can be passed to CamGear's <code>options</code> dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6</p> <p> </p> Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc. CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve(). CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCapture APIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature <p> </p>"},{"location":"gears/netgear/overview/","title":"Overview","text":""},{"location":"gears/netgear/overview/#netgear-api","title":"NetGear API","text":"NetGear API generalized"},{"location":"gears/netgear/overview/#overview","title":"Overview","text":"<p>NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time.</p> <p>NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. </p> <p>NetGear also enables real-time JPEG Frame Compression capabilities for boosting performance significantly while sending video-frames over the network in real-time.</p> <p>Lazy Pirate pattern in NetGear API</p> <p>NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns(<code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) at both Server and Client ends, where its API instead of doing a blocking receive, will:</p> <ul> <li>Poll the socket and receive from it only when it's sure a reply has arrived.</li> <li>Attempt to reconnect, if no reply has arrived within a timeout period.</li> <li>Abandon the connection if there is still no reply after several requests.</li> </ul> <p>Netgear API also provides <code>max_retries</code> and <code>request_timeout</code> like attributes for controlling this polling.</p> <p>NetGear as of now seamlessly supports three ZeroMQ messaging patterns:</p> <ul> <li> zmq.PAIR (ZMQ Pair Pattern) </li> <li> zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern)</li> <li> zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern)</li> </ul> <p>whereas the supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> <p> </p>"},{"location":"gears/netgear/overview/#modes-of-operation","title":"Modes of Operation","text":""},{"location":"gears/netgear/overview/#primary-modes","title":"Primary Modes","text":"<p>NetGear API primarily has two modes of operations:</p> <ul> <li> <p>Send Mode: which employs <code>send()</code> function to send video frames over the network in real-time. Activate this mode by setting parameter <code>receive_mode = False</code>.</p> </li> <li> <p>Receive Mode: which employs <code>recv()</code> function to receive frames, sent over the network with Send Mode in real-time. Activate this mode by setting parameter <code>receive_mode = True</code>.</p> </li> </ul>"},{"location":"gears/netgear/overview/#exclusive-modes","title":"Exclusive Modes","text":"<p>In addition to the primary modes, NetGear API also offers application-specific Exclusive Modes:</p> <p>Also, checkout this compatibility chart for these modes interoperability.</p>"},{"location":"gears/netgear/overview/#a-multi-servers-mode","title":"A. Multi-Servers Mode","text":"<ul> <li>In this exclusive mode, NetGear API robustly handles multiple servers at once, thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. </li> <li>Each new Server on the network can be identified on the client's end by using its unique port address. </li> <li>You can learn about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#b-multi-clients-mode","title":"B. Multi-Clients Mode","text":"<ul> <li>In this exclusive mode, NetGear API robustly handles multiple clients at once, thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. </li> <li>Each new Client on the network can be uniquely identified on the Server's end by using its unique port address. </li> <li>You can learn about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#c-bidirectional-mode","title":"C. Bidirectional Mode","text":"<ul> <li>This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames. </li> <li>Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. </li> <li>You can learn more about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#d-ssh-tunneling-mode","title":"D. SSH Tunneling Mode","text":"<ul> <li>This exclusive mode allows you to connect NetGear via secure SSH connection over the untrusted network and access its intranet services across firewalls. </li> <li>This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. </li> <li>You can learn more about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#e-secure-mode","title":"E. Secure Mode","text":"<ul> <li>In this exclusive mode, NetGear API provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. </li> <li>You can learn more about this mode here \u27b6</li> </ul> <p>Important Information</p> <ul> <li> <p>When compiling/installing pyzmq on UNIX systems, it is generally recommended that zeromq binaries to be installed separately, via <code>homebrew, apt, yum, etc.</code> as follows:</p> <pre><code># Debian-based\nsudo apt-get install libzmq3-dev\n\n# RHEL-based\nsudo yum install libzmq3-devel\n\n# OSX-based\nbrew install zeromq\n</code></pre> <p>If zeromq binaries are not found, pyzmq will try to build <code>libzmq</code> as a Python Extension, though this is not guaranteed to work!</p> </li> <li> <p>It is advised to enable logging (<code>logging = True</code>) on the first run, to easily identify any runtime errors.</p> </li> <li> <p>Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all.</p> </li> <li> <p>Only either of two functions (i.e. <code>send()</code> and <code>recv()</code>) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using <code>send()</code> function in Receive Mode), will result in <code>ValueError</code>.</p> </li> <li> <p>Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90% in all connections.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through NetGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/netgear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/netgear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/netgear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/netgear/params/","title":"Parameters","text":""},{"location":"gears/netgear/params/#netgear-api-parameters","title":"NetGear API Parameters","text":""},{"location":"gears/netgear/params/#address","title":"<code>address</code>","text":"<p>This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is based on selected primary mode, i.e <code>'localhost'</code> for Send Mode and <code>'*'</code> for Receive Mode on a local machine.</p> <p>Usage:</p> <pre><code>NetGear(address=\"192.168.0.145\")\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#port","title":"<code>port</code>","text":"<p>This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered.</p> <p>Exception for Exclusive Modes</p> <p>In Multi-Servers Mode:</p> <ul> <li>A unique port number MUST be assigned to each Server on the network using this parameter. </li> <li>At Client end, a List/Tuple of all available Server(s) ports MUST be assigned using this same parameter. </li> <li>See its usage example here \u27b6.</li> </ul> <p>In Multi-Client Mode:</p> <ul> <li>A unique port number MUST be assigned to each Client on the network using this parameter. </li> <li>At Server end, a List/Tuple of all available Client(s) ports MUST be assigned using this same parameter. </li> <li>See its usage example here \u27b6.</li> </ul> <p>Data-Type: String or List/Tuple</p> <p>Default Value: Its default value is <code>'5555'</code></p> <p>Usage:</p> <pre><code>NetGear(port=\"5575\")\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#protocol","title":"<code>protocol</code>","text":"<p>This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: <code>'tcp'</code> and <code>'ipc'</code>.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'tcp'</code></p> <p>Usage:</p> <pre><code>NetGear(protocol=\"ipc\")\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#pattern","title":"<code>pattern</code>","text":"<p>This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> (i.e <code>zmq.PAIR</code>). </p> <p>Supported ZMQ patterns</p> <p>All supported ZMQ patterns for NetGear are:</p> <ul> <li><code>0</code> (.i.e. zmq.PAIR): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it.</li> <li><code>1</code> (.i.e. zmq.REQ/zmq.REP): In this pattern, it employs <code>ZMQ REQ</code> sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket <code>zmq.REQ</code> will block send unless it has successfully received a reply back and socket <code>zmq.REP</code> will block on recv() unless it has received a request.</li> <li><code>2</code> (.i.e. zmq.PUB/zmq.SUB): It is an another classic pattern where senders of messages, called publishers, do not program the messages to be sent directly to specific receivers, called subscribers. Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A <code>ZMQ.SUB</code> can connect to multiple <code>ZMQ.PUB</code> (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved.</li> </ul> <p>Usage:</p> <pre><code>NetGear(pattern=1) # sets zmq.REQ/zmq.REP pattern\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#receive_mode","title":"<code>receive_mode</code>","text":"<p>This parameter select the Netgear's Mode of operation. It basically activates <code>Receive Mode</code>(if <code>True</code>) and <code>Send Mode</code>(if <code>False</code>). Furthermore, <code>recv()</code> method will only work when this flag is enabled(i.e. <code>Receive Mode</code>), whereas <code>send()</code> method will only work when this flag is disabled(i.e.<code>Send Mode</code>). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>(i.e. Send Mode is activated by default).</p> <p>Usage:</p> <pre><code>NetGear(receive_mode=True) # activates Recieve Mode\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code></p> <p>Usage:</p> <p>Supported dictionary attributes for NetGear API</p> <ul> <li> <p><code>multiserver_mode</code> (boolean) : This internal attribute activates the exclusive Multi-Servers Mode, if enabled(<code>True</code>).</p> </li> <li> <p><code>multiclient_mode</code> (boolean) : This internal attribute activates the exclusive Multi-Clients Mode, if enabled(<code>True</code>).</p> </li> <li> <p><code>secure_mode</code> (integer) : This internal attribute selects the exclusive Secure Mode. Its possible values are: <code>0</code>(i.e. Grassland(no security)) or <code>1</code>(i.e. StoneHouse) or <code>2</code>(i.e. IronHouse).</p> </li> <li> <p><code>bidirectional_mode</code> (boolean) : This internal attribute activates the exclusive Bidirectional Mode, if enabled(<code>True</code>).</p> </li> <li> <p><code>ssh_tunnel_mode</code> (string) : This internal attribute activates the exclusive SSH Tunneling Mode at the Server-end only.</p> </li> <li> <p><code>ssh_tunnel_pwd</code> (string): In SSH Tunneling Mode, This internal attribute sets the password required to authorize Host for SSH Connection at the Server-end only. More information can be found here \u27b6</p> </li> <li> <p><code>ssh_tunnel_keyfile</code> (string): In SSH Tunneling Mode, This internal attribute sets path to Host key that provide another way to authenticate host for SSH Connection at the Server-end only. More information can be found here \u27b6</p> </li> <li> <p><code>custom_cert_location</code> (string) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6</p> </li> <li> <p><code>overwrite_cert</code> (boolean) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only. More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression</code>(bool/str): This internal attribute is used to activate(if <code>True</code>)/deactivate(if <code>False</code>) JPEG Frame Compression as well as to specify incoming frames colorspace with compression. By default colorspace is <code>BGR</code> and compression is enabled(<code>True</code>). More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression_quality</code>(int/float): This internal attribute controls the JPEG quantization factor in JPEG Frame Compression. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression_fastdct</code>(bool): This internal attributee if True, use fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality in JPEG Frame Compression. Its default value is also <code>True</code>. More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression_fastupsample</code>(bool): This internal attribute if True, use fastest color upsampling method. Its default value is <code>False</code>. More information can be found here \u27b6</p> </li> <li> <p><code>max_retries</code>(integer): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like (<code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) are being used. It's value can anything greater than <code>0</code>, and its default value is <code>3</code>.</p> </li> <li> <p><code>request_timeout</code>(integer): This internal attribute controls the timeout value (in seconds), after which the Server/Client exit itself with <code>Nonetype</code> value if it's unable to get any response/reply from the socket, when synchronous messaging patterns like (<code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) are being used. It's value can anything greater than <code>0</code>, and its default value is <code>10</code> seconds.</p> </li> <li> <p><code>subscriber_timeout</code>(integer): Similar to <code>request_timeout</code>, this internal attribute also controls the timeout value (in seconds) but for non-synchronous <code>zmq.PUB/zmq.SUB</code> pattern in compression mode, after which the Client(Subscriber) exit itself with <code>Nonetype</code> value if it's unable to get any response from the socket. It's value can anything greater than <code>0</code>, and its disabled by default (meaning the client will wait forever for response).</p> </li> <li> <p><code>flag</code>(integer): This PyZMQ attribute value can be either <code>0</code> or <code>zmq.NOBLOCK</code>( i.e. 1). More information can be found here \u27b6.</p> </li> </ul> <p>With flags=1 (i.e. <code>NOBLOCK</code>), NetGear raises <code>ZMQError</code> if no messages have arrived; otherwise, this waits until a message arrives.</p> <ul> <li> <p><code>copy</code>(boolean): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If <code>False</code> a object is returned, if <code>True</code> a string copy of the message is returned.</p> </li> <li> <p><code>track</code>(boolean): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. (ignored if <code>copy=True</code>).</p> </li> </ul> <p>The desired attributes can be passed to NetGear API as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n    \"secure_mode\": 2,\n    \"custom_cert_location\": \"/home/foo/foo1/foo2\",\n    \"overwrite_cert\": True,\n    \"flag\": 0, \n    \"copy\": True, \n    \"track\": False\n}\n# assigning it\nNetGear(logging=True, **options)\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/","title":"Usage Examples","text":""},{"location":"gears/netgear/usage/#netgear-api-usage-examples","title":"NetGear API Usage Examples:","text":"<p>Important Information</p> <ul> <li> <p>Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all.</p> </li> <li> <p>NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources.</p> </li> <li> <p>Only either of two functions (i.e. <code>send()</code> and <code>recv()</code>) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using <code>send()</code> function in Receive Mode), will result in <code>ValueError</code>.</p> </li> </ul> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/netgear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with NetGear API:</p>"},{"location":"gears/netgear/usage/#servers-end","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n\n# Define Netgear Server with default parameters\nserver = NetGear()\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre>"},{"location":"gears/netgear/usage/#clients-end","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n\n# define Netgear Client with `receive_mode = True` and default parameter\nclient = NetGear(receive_mode=True)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/#using-netgear-with-variable-parameters","title":"Using NetGear with Variable Parameters","text":""},{"location":"gears/netgear/usage/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/usage/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define Netgear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/#using-netgear-with-opencv","title":"Using NetGear with OpenCV","text":"<p>You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows:</p>"},{"location":"gears/netgear/usage/#clients-end_2","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# define tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=0,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the received frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/usage/#servers-end_2","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n\n# define tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=0,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        (grabbed, frame) = stream.read()\n\n        # check for frame if not grabbed\n        if not grabbed:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.release()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/#using-netgear-with-other-videocapture-gears","title":"Using NetGear with Other VideoCapture Gears","text":"<p>You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear:</p>"},{"location":"gears/netgear/usage/#clients-end_3","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/usage/#servers-end_3","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears import NetGear\n\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Start capturing live Monitor screen frames with default settings\nstream = ScreenGear().start()\n\n# Define Netgear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/","title":"Bidirectional Mode","text":""},{"location":"gears/netgear/advanced/bidirectional_mode/#bidirectional-mode-for-netgear-api","title":"Bidirectional Mode for NetGear API","text":"NetGear's Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#overview","title":"Overview","text":"<p>Bidirectional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with video-frames through its synchronous messaging patterns such as <code>zmq.PAIR</code> (ZMQ Pair Pattern) &amp; <code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern).</p> <p>In Bidirectional Mode, we utilizes the NetGear API's <code>message</code> parameter of <code>send()</code> method for sending data from Server-to-Client, and <code>return_data</code> parameter of <code>recv()</code> method to return data back from Client-to-Server all while transferring frames in real-time. </p> <p>This mode can be easily activated in NetGear through <code>bidirectional_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Important Information regarding Bidirectional Mode</p> <ul> <li> <p>In Bidirectional Mode, <code>zmq.PAIR</code>(ZMQ Pair) &amp; <code>zmq.REQ/zmq.REP</code>(ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in <code>ValueError</code>.</p> </li> <li> <p>Bidirectional Mode enables you to send data of ANY<sup>1</sup> Data-type along with frame bidirectionally.</p> </li> <li> <p>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</p> </li> <li> <p>Bidirectional Mode is smart enough to sense data (if available or not), and DOES NOT interfere with transferring of video-frames (unless data is huge), as both mechanisms works independently.</p> </li> <li> <p>Bidirectional Mode is now compatibile with both Multi-Servers mode and Multi-Clients mode exclusive modes.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#features-of-bidirectional-mode","title":"Features of Bidirectional Mode","text":"<ul> <li> <p> Enables easy-to-use seamless Bidirectional data transmission between two systems.</p> </li> <li> <p> Supports <code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code> messaging patterns.</p> </li> <li> <p> Support for sending data of almost any<sup>1</sup> datatype.</p> </li> <li> <p> Auto-enables reconnection if Server or Client disconnects prematurely.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#exclusive-parameters","title":"Exclusive Parameters","text":"<p>To send data bidirectionally, NetGear API provides two exclusive parameters for its methods:</p> <ul> <li> <p><code>message</code>: It enables user to send data to Client, directly through <code>send()</code> method at Server's end. </p> </li> <li> <p><code>return_data</code>: It enables user to send data back to Server, directly through <code>recv()</code> method at Client's end.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#usage-examples","title":"Usage Examples","text":""},{"location":"gears/netgear/advanced/bidirectional_mode/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API:</p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear Server with defined parameters\nserver = NetGear(logging=True, **options)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol>"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, logging=True, **options)\n\n# loop over\nwhile True:\n\n    # prepare data to be sent\n    target_data = \"Hi, I am a Client here.\"\n\n    # receive data from server and also send our data\n    data = client.recv(return_data=target_data)\n\n    # check for data if None\n    if data is None:\n        break\n\n    # extract server_data &amp; frame from data\n    server_data, frame = data\n\n    # again check for frame if None\n    if frame is None:\n        break\n\n    # {do something with the extracted frame and data here}\n\n    # lets print extracted server data\n    if not (server_data is None):\n        print(server_data)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","title":"Using Bidirectional Mode with Variable Parameters","text":""},{"location":"gears/netgear/advanced/bidirectional_mode/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # prepare data to be sent\n    target_data = \"Hi, I am a Client here.\"\n\n    # receive data from server and also send our data\n    data = client.recv(return_data=target_data)\n\n    # check for data if None\n    if data is None:\n        break\n\n    # extract server_data &amp; frame from data\n    server_data, frame = data\n\n    # again check for frame if None\n    if frame is None:\n        break\n\n    # {do something with the extracted frame and data here}\n\n    # lets print received server data\n    if not (server_data is None):\n        print(server_data)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_1","title":"Server End","text":"<p>Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nfrom libcamera import Transform\n\n# add various Picamera2 API tweaks\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\n\n# add various Picamera tweak parameters to dictionary\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","title":"Using Bidirectional Mode for Video-Frames Transfer","text":"<p>In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. </p> <p>This example is useful for building applications like Real-Time Video Chat.</p> <p>We're also using <code>reducer()</code> method for reducing frame-size on-the-go for additional performance.</p> <p>Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!</p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_2","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport numpy as np\nimport cv2\n\n# open any valid video stream(for e.g `test.mp4` file)\nstream = cv2.VideoCapture(\"test.mp4\")\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        (grabbed, frame) = stream.read()\n\n        # check for frame if not grabbed\n        if not grabbed:\n            break\n\n        # reducer frames size if you want more performance, otherwise comment this line\n        frame = reducer(frame, percentage=30)  # reduce frame by 30%\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # check data just received from Client is of numpy datatype\n        if not (recv_data is None) and isinstance(recv_data, np.ndarray):\n\n            # {do something with received numpy array here}\n\n            # Let's show it on output window\n            cv2.imshow(\"Received Frame\", recv_data)\n            key = cv2.waitKey(1) &amp; 0xFF\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.release()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end_1","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport cv2\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# again open the same video stream\nstream = cv2.VideoCapture(\"test.mp4\")\n\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True, **options)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # reducer frames size if you want more performance, otherwise comment this line\n    frame = reducer(frame, percentage=30)  # reduce frame by 30%\n\n    # receive data from server and also send our data\n    data = client.recv(return_data=frame)\n\n    # check for data if None\n    if data is None:\n        break\n\n    # extract server_data &amp; frame from data\n    server_data, frame = data\n\n    # again check for frame if None\n    if frame is None:\n        break\n\n    # {do something with the extracted frame and data here}\n\n    # lets print extracted server data\n    if not (server_data is None):\n        print(server_data)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression","text":"<p>This usage examples can be found here \u27b6</p> <p> </p> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its <code>return_data</code> parameter.</p> <p>\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/netgear/advanced/compression/","title":"Frame Compression","text":""},{"location":"gears/netgear/advanced/compression/#frame-compression-for-netgear-api","title":"Frame Compression for NetGear API","text":""},{"location":"gears/netgear/advanced/compression/#overview","title":"Overview","text":"<p>NetGear API enables real-time JPEG Frame Compression capabilities for optimizing performance significantly while sending frames over the network. </p> <p>For enabling Frame Compression, NetGear uses powerful <code>simplejpeg</code> library at its backend, which is based on recent versions of libjpeg-turbo JPEG image codec, to accelerate baseline JPEG compression and decompression on all modern systems. NetGear API employs its exposed <code>decode_jpeg</code> and <code>encode_jpeg</code> methods to encode video-frames to JFIF format  before sending it at Server, and cleverly decode it at the Client(s) all in real-time, thereby leveraging performance at cost of minor loss in frame quality.</p> <p>Frame Compression is enabled by default in NetGear, and can be easily controlled through <code>jpeg_compression_quality</code>, <code>jpeg_compression_fastdct</code>, <code>jpeg_compression_fastupsample</code> like attributes of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Useful Information about Frame Compression</p> <ul> <li>Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90%.</li> <li>Exclusive <code>jpeg_compression</code> attribute can also be used to disable Frame Compression.</li> <li>Frame Compression can leverage performance up-to 5-10% with exclusive performance attributes.</li> <li>Frame Compression is compatible with all messaging pattern and modes.</li> </ul> <p>Frame Compression is primarily controlled by Server end. That means, if Frame Compression is enabled at Server, then Client(s) will automatically enforce the Frame Compression with defined performance attributes. Otherwise if it is disabled, then Client(s) disables it too.</p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#exclusive-attributes","title":"Exclusive Attributes","text":"<p>For implementing Frame Compression, NetGear API currently provide following exclusive attribute for its <code>options</code> dictionary parameter to leverage performance with Frame Compression:</p> <ul> <li> <p><code>jpeg_compression</code>:  (bool/str) This internal attribute is used to activate/deactivate JPEG Frame Compression as well as to specify incoming frames colorspace with compression. Its usage is as follows:</p> <ul> <li> <p> For activating JPEG Frame Compression (Boolean):</p> <p>In this case, colorspace will default to <code>BGR</code>.</p> <p>You can set <code>jpeg_compression</code> value to <code>False</code> at Server end to completely disable Frame Compression.</p> <pre><code># enable jpeg encoding\noptions = {\"jpeg_compression\": True}\n</code></pre> </li> <li> <p> For specifying Input frames colorspace (String):</p> <p>In this case, JPEG Frame Compression is activated automatically.</p> <p>Supported colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p> <pre><code># Specify incoming frames are `grayscale`\noptions = {\"jpeg_compression\": \"GRAY\"}\n</code></pre> </li> </ul> </li> <li> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#performance-attributes","title":"Performance Attributes","text":"<ul> <li> <p><code>jpeg_compression_quality</code>: (int/float) This attribute controls the JPEG quantization factor. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. Its usage is as follows:</p> <pre><code># activate jpeg encoding and set quality 95%\noptions = {\"jpeg_compression\": True, \"jpeg_compression_quality\": 95}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastdct</code>: (bool) This attribute if True, NetGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also <code>True</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast dct\noptions = {\"jpeg_compression\": True, \"jpeg_compression_fastdct\": True}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastupsample</code>: (bool) This attribute if True, NetGear API use fastest color upsampling method. Its default value is <code>False</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast upsampling\noptions = {\"jpeg_compression\": True, \"jpeg_compression_fastupsample\": True}\n</code></pre> </li> </ul>"},{"location":"gears/netgear/advanced/compression/#usage-examples","title":"Usage Examples","text":""},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with Frame Compression in NetGear API:</p>"},{"location":"gears/netgear/advanced/compression/#server-end","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n\n# activate jpeg encoding and specify other related parameters\noptions = {\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/compression/#client-end","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <p>If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes.</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage-with-variable-colorspace","title":"Bare-Minimum Usage with Variable Colorspace","text":"<p>Frame Compression also supports specify incoming frames colorspace with compression. In following bare-minimum code, we will be sending GRAY frames from Server to Client:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6</p> <p>Supported colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p>"},{"location":"gears/netgear/advanced/compression/#server-end_1","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n\n# open any valid video stream(for e.g `test.mp4` file) and change its colorspace to grayscale\nstream = VideoGear(source=\"test.mp4\", colorspace=\"COLOR_BGR2GRAY\").start()\n\n# activate jpeg encoding and specify other related parameters\noptions = {\n    \"jpeg_compression\": \"GRAY\", # set grayscale\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read grayscale frames from stream\n        frame = stream.read()\n\n        # check for frame if None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send grayscale frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/compression/#client-end_1","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <p>If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes.</p> <p>Client's end also automatically enforces Server's colorspace, there's no need to define it again.</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True)\n\n# loop over\nwhile True:\n\n    # receive grayscale frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the grayscale frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Grayscale Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#using-frame-compression-with-variable-parameters","title":"Using Frame Compression with Variable Parameters","text":""},{"location":"gears/netgear/advanced/compression/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n\n# Define NetGear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n#  loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/compression/#server-end_2","title":"Server End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate jpeg encoding and specify other related parameters\noptions = {\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression","text":"<p>NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily enable Frame Compression with its performance attributes at both ends to boost performance bidirectionally.</p> <p>In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time for testing the real-time performance and synchronization between the Server and Client using Bidirectional Mode. Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end.</p> <p>This example is great for building applications like Real-time Video Chat System.</p> <p>This Dual Frame Compression feature also available for Multi-Clients Mode.</p> <p>We're also using <code>reducer()</code> Helper method for reducing frame-size on-the-go for additional performance.</p> <p>Remember to define Frame Compression's performance attributes both on Server and Client ends in Dual Frame Compression to boost performance bidirectionally!</p>"},{"location":"gears/netgear/advanced/compression/#server-end_3","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport numpy as np\nimport cv2\n\n# open any valid video stream(for e.g `test.mp4` file)\nstream = cv2.VideoCapture(\"test.mp4\")\n\n# activate Bidirectional mode and Frame Compression\noptions = {\n    \"bidirectional_mode\": True,\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 95,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        (grabbed, frame) = stream.read()\n\n        # check for frame if not grabbed\n        if not grabbed:\n            break\n\n        # reducer frames size if you want even more performance, otherwise comment this line\n        frame = reducer(frame, percentage=20)  # reduce frame by 20%\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # check data just received from Client is of numpy datatype\n        if not (recv_data is None) and isinstance(recv_data, np.ndarray):\n\n            # {do something with received numpy array here}\n\n            # Let's show it on output window\n            cv2.imshow(\"Received Frame\", recv_data)\n            key = cv2.waitKey(1) &amp; 0xFF\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.release()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/compression/#client-end_2","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport cv2\n\n# activate Bidirectional mode and Frame Compression\noptions = {\n    \"bidirectional_mode\": True,\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 95,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# again open the same video stream\nstream = cv2.VideoCapture(\"test.mp4\")\n\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True, **options)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # reducer frames size if you want even more performance, otherwise comment this line\n    frame = reducer(frame, percentage=20)  # reduce frame by 20%\n\n    # receive data from server and also send our data\n    data = client.recv(return_data=frame)\n\n    # check for data if None\n    if data is None:\n        break\n\n    # extract server_data &amp; frame from data\n    server_data, frame = data\n\n    # again check for frame if None\n    if frame is None:\n        break\n\n    # {do something with the extracted frame and data here}\n\n    # lets print extracted server data\n    if not (server_data is None):\n        print(server_data)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/","title":"Multi-Clients Mode","text":""},{"location":"gears/netgear/advanced/multi_client/#multi-clients-mode-for-netgear-api","title":"Multi-Clients Mode for NetGear API","text":"NetGear's Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#overview","title":"Overview","text":"<p>In Multi-Clients Mode, NetGear robustly handles Multiple Clients at once thereby able to broadcast frames and data across multiple Clients/Consumers in the network at same time. This mode works contrary to Multi-Servers Mode such that every new Client that connects to single Server can be identified by its unique port address on the network. </p> <p>The supported patterns for this mode are Publish/Subscribe (<code>zmq.PUB/zmq.SUB</code>) and Request/Reply(<code>zmq.REQ/zmq.REP</code>) and can be easily activated in NetGear API through <code>multiclient_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p>Multi-Clients Mode is best for broadcasting Meta-Data with Video-frames to specific limited number of clients in real time. But if you're looking to scale broadcast to a very large pool of clients, then see our WebGear or WebGear_RTC APIs.</p> <p> </p> <p>Important Information regarding Multi-Clients Mode</p> <ul> <li> <p>A unique PORT address MUST be assigned to each Client on the network using its <code>port</code> parameter.</p> </li> <li> <p>A list/tuple of PORT addresses of all unique Clients MUST be assigned at Server's end using its <code>port</code> parameter for a successful connection.</p> </li> <li> <p>Patterns <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>) and <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>) are the only supported pattern values for this Mode. Therefore, calling any other pattern value with is mode will result in <code>ValueError</code>.</p> </li> <li> <p>Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw <code>ValueError</code>.</p> </li> <li> <p>The <code>address</code> parameter value of each Client MUST exactly match the Server. </p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#features-of-multi-clients-mode","title":"Features of Multi-Clients Mode","text":"<ul> <li> <p> Enables Multiple Client(s) connection with a single Server.</p> </li> <li> <p> Ability to send any additional data of any datatype along with frames in real-time.</p> </li> <li> <p> Number of Clients can be extended to several numbers depending upon your system's hardware limit.</p> </li> <li> <p> Employs powerful Publish/Subscribe &amp; Request/Reply messaging patterns.</p> </li> <li> <p> Each new Client on the network can be identified at Server's end by their unique port addresses.</p> </li> <li> <p> NetGear API actively tracks the state of each connected Client.</p> </li> <li> <p> If the server gets disconnected, all the clients will automatically exit to save resources.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#usage-examples","title":"Usage Examples","text":"<p>Important</p> <ul> <li> <p>Frame/Data transmission will NOT START until all given Client(s) are connected to the Server.</p> </li> <li> <p>For sake of simplicity, in these examples we will use only two unique Clients, but the number of these Clients can be extended to SEVERAL numbers depending upon your Network bandwidth and System Capabilities.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>In this example, we will capturing live video-frames from a source (a.k.a Server) with a webcam connected to it. Afterwards, those captured frame will be sent over the network to two independent system (a.k.a Clients) using this Multi-Clients Mode in NetGear API. Finally, both Clients will be displaying received frames in Output Windows in real time.</p> <p>This example is useful for building applications like Real-Time Video Broadcasting to multiple clients in local network.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import CamGear\n\n# Open suitable video stream (webcam on first index in our case)\nstream = CamGear(source=0).start()\n\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of\n# all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=(5567, 5577),\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# Define received data dictionary\ndata_dict = {}\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if not None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame and also receive data from Client(s)\n        recv_data = server.send(frame)\n\n        # check if valid data received\n        if not (recv_data is None):\n            # extract unique port address and its respective data\n            unique_address, data = recv_data\n            # update the extracted data in the data dictionary\n            data_dict[unique_address] = data\n\n        if data_dict:\n            # print data just received from Client(s)\n            for key, value in data_dict.items():\n                print(\"Client at port {} said: {}\".format(key, value))\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5567\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n) \n\n# loop over\nwhile True:\n    # receive data from server\n    frame = client.recv()\n\n    # check for frame if None\n    if frame is None:\n        break\n\n    # {do something with frame here}\n\n    # Show output window\n    cv2.imshow(\"Client 5567 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n # !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5577\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # receive data from server\n    frame = client.recv()\n\n    # check for frame if None\n    if frame is None:\n        break\n\n    # {do something with frame here}\n\n    # Show output window\n    cv2.imshow(\"Client 5577 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# Open suitable video stream (webcam on first index in our case)\nstream = cv2.VideoCapture(0)\n\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=(5567, 5577),\n    protocol=\"tcp\",\n    pattern=2,\n    logging=True,\n    **options\n)\n\n# Define received data dictionary\ndata_dict = {}\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        (grabbed, frame) = stream.read()\n\n        # check for frame if not grabbed\n        if not grabbed:\n            break\n\n        # {do something with the frame here}\n\n        # send frame and also receive data from Client(s)\n        recv_data = server.send(frame)\n\n        # check if valid data received\n        if not (recv_data is None):\n            # extract unique port address and its respective data\n            unique_address, data = recv_data\n            # update the extracted data in the data dictionary\n            data_dict[unique_address] = data\n\n        if data_dict:\n            # print data just received from Client(s)\n            for key, value in data_dict.items():\n                print(\"Client at port {} said: {}\".format(key, value))\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_1","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5567\",\n    protocol=\"tcp\",\n    pattern=2,\n    receive_mode=True,\n    logging=True,\n    **options\n) \n\n# loop over\nwhile True:\n    # receive data from server\n    frame = client.recv()\n\n    # check for frame if None\n    if frame is None:\n        break\n\n    # {do something with frame here}\n\n    # Show output window\n    cv2.imshow(\"Client 5567 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_1","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5577\",\n    protocol=\"tcp\",\n    pattern=2,\n    receive_mode=True,\n    logging=True,\n    **options\n) \n\n# loop over\nwhile True:\n    # receive data from server\n    frame = client.recv()\n\n    # check for frame if None\n    if frame is None:\n        break\n\n    # {do something with frame here}\n\n    # Show output window\n    cv2.imshow(\"Client 5577 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-for-unidirectional-custom-data-transfer","title":"Using Multi-Clients Mode for Unidirectional Custom Data Transfer","text":"<p>Abstract</p> <p>With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to  a Server unidirectionally.</p> <p>In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>), and NOT with pattern <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>)!</p> <p>In this example, We will be transferring video-frames from a single Server (consisting of  Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end_2","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import NetGear\n\n# add various Picamera2 tweak parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=(5577, 5578),\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)  # !!! change following IP address '192.168.x.xxx' with yours !!!\n\n# Define received data dictionary\ndata_dict = {}\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame and also receive data from Client(s)\n        recv_data = server.send(frame)\n\n        # check if valid data received\n        if not (recv_data is None):\n            # extract unique port address and its respective data\n            unique_address, data = recv_data\n            # update the extracted data in the data dictionary\n            data_dict[unique_address] = data\n\n        if data_dict:\n            # print data just received from Client(s)\n            for key, value in data_dict.items():\n                print(\"Client at port {} said: {}\".format(key, value))\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import NetGear\n\n# add various Picamera tweak parameters to dictionary\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=(5577, 5578),\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)  # !!! change following IP address '192.168.x.xxx' with yours !!!\n\n# Define received data dictionary\ndata_dict = {}\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame and also receive data from Client(s)\n        recv_data = server.send(frame)\n\n        # check if valid data received\n        if not (recv_data is None):\n            # extract unique port address and its respective data\n            unique_address, data = recv_data\n            # update the extracted data in the data dictionary\n            data_dict[unique_address] = data\n\n        if data_dict:\n            # print data just received from Client(s)\n            for key, value in data_dict.items():\n                print(\"Client at port {} said: {}\".format(key, value))\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_2","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5577\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # prepare data to be sent\n    target_data = \"Hi, I am 5577 Client here.\"\n\n    # receive data from server and also send our data\n    frame = client.recv(return_data=target_data)\n\n    # check for frame if None\n    if frame is None:\n        break\n\n    # {do something with frame here}\n\n    # Show output window\n    cv2.imshow(\"Client 5577 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_2","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5578\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n) \n\n# loop over\nwhile True:\n\n    # prepare data to be sent\n    target_data = \"Hi, I am 5578 Client here.\"\n\n    # receive data from server and also send our data\n    frame = client.recv(return_data=target_data)\n\n    # check for frame if None\n    if frame is None:\n        break\n\n    # {do something with frame here}\n\n    # Show output window\n    cv2.imshow(\"Client 5578 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-with-bidirectional-mode","title":"Using Multi-Clients Mode with Bidirectional Mode","text":"<p>Abstract</p> <p>Multi-Clients Mode now also compatible with Bidirectional Mode, which lets you send additional data of any datatype<sup>1</sup>  along with frame in real-time bidirectionally between a single Server and all connected Client(s).</p> <p>Important Information</p> <ul> <li>Bidirectional data transfer ONLY works with pattern <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>), and NOT with pattern <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>)</li> <li>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its <code>message</code> parameter.</li> <li>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</li> </ul> New in v0.2.5 <p>This example was added in <code>v0.2.5</code>.</p> <p>In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from a single Server (In this case, Raspberry Pi with Camera Module) over the network to two independent Clients for displaying them both in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) back from both the Client(s) to our Server, which will be printed onto the terminal.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end_3","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import NetGear\nfrom libcamera import Transform\n\n# add various Picamera2 tweak parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of \n# all unique Server((5577,5578) in our case) and other parameters\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=(5577, 5578),\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)  # !!! change following IP address '192.168.x.xxx' with yours !!!\n\n# Define received data dictionary\ndata_dict = {}\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client(s)\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # check if valid data received\n        if not (recv_data is None):\n            # extract unique port address and its respective data\n            unique_address, data = recv_data\n            # update the extracted data in the data dictionary\n            data_dict[unique_address] = data\n\n        if data_dict:\n            # print data just received from Client(s)\n            for key, value in data_dict.items():\n                print(\"Client at port {} said: {}\".format(key, value))\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import NetGear\n\n# add various Picamera tweak parameters to dictionary\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of \n# all unique Server((5577,5578) in our case) and other parameters\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=(5577, 5578),\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)  # !!! change following IP address '192.168.x.xxx' with yours !!!\n\n# Define received data dictionary\ndata_dict = {}\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send frame &amp; data and also receive data from Client(s)\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # check if valid data received\n        if not (recv_data is None):\n            # extract unique port address and its respective data\n            unique_address, data = recv_data\n            # update the extracted data in the data dictionary\n            data_dict[unique_address] = data\n\n        if data_dict:\n            # print data just received from Client(s)\n            for key, value in data_dict.items():\n                print(\"Client at port {} said: {}\".format(key, value))\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_3","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5577\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # prepare data to be sent\n    target_data = \"Hi, I am 5577 Client here.\"\n\n    # receive data from server and also send our data\n    data = client.recv(return_data=target_data)\n\n    # check for data if None\n    if data is None:\n        break\n\n    # extract server_data &amp; frame from data\n    server_data, frame = data\n\n    # again check for frame if None\n    if frame is None:\n        break\n\n    # {do something with the extracted frame and data here}\n\n    # lets print extracted server data\n    if not (server_data is None):\n        print(server_data)\n\n    # Show output window\n    cv2.imshow(\"Client 5577 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_3","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5578\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n) \n\n# loop over\nwhile True:\n\n    # prepare data to be sent\n    target_data = \"Hi, I am 5578 Client here.\"\n\n    # receive data from server and also send our data\n    data = client.recv(return_data=target_data)\n\n    # check for data if None\n    if data is None:\n        break\n\n    # extract server_data &amp; frame from data\n    server_data, frame = data\n\n    # again check for frame if None\n    if frame is None:\n        break\n\n    # {do something with the extracted frame and data here}\n\n    # lets print extracted server data\n    if not (server_data is None):\n        print(server_data)\n\n    # Show output window\n    cv2.imshow(\"Client 5578 Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its <code>message</code> parameter.</p> <p>\u21a9</p> </li> </ol>"},{"location":"gears/netgear/advanced/multi_server/","title":"Multi-Servers Mode","text":""},{"location":"gears/netgear/advanced/multi_server/#multi-servers-mode-for-netgear-api","title":"Multi-Servers Mode for NetGear API","text":"NetGear's Multi-Servers Mode"},{"location":"gears/netgear/advanced/multi_server/#overview","title":"Overview","text":"<p>In Multi-Servers Mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer across multiple Publishers/Servers in the network at the same time. Each new server connects to a single client can be identified by its unique port address on the network. </p> <p>The supported patterns for this mode are Publish/Subscribe (<code>zmq.PUB/zmq.SUB</code>) and Request/Reply(<code>zmq.REQ/zmq.REP</code>) and can be easily activated in NetGear API through <code>multiserver_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Important Information regarding Multi-Servers Mode</p> <ul> <li> <p>A unique PORT address MUST be assigned to each Server on the network using its <code>port</code> parameter.</p> </li> <li> <p>A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its <code>port</code> parameter for a successful connection.</p> </li> <li> <p>Patterns <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>) and <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>) are the only supported values for this Mode. Therefore, calling any other pattern value with is mode will result in <code>ValueError</code>.</p> </li> <li> <p>Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw <code>ValueError</code>.</p> </li> <li> <p>The <code>address</code> parameter value of each Server MUST exactly match the Client. </p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#key-features","title":"Key Features","text":"<ul> <li> <p> Enables Multiple Server(s) connection with a single Client.</p> </li> <li> <p> Ability to send any additional data of any<sup>1</sup> datatype along with frames in real-time.</p> </li> <li> <p> Number of Servers can be extended to several numbers depending upon your system's hardware limit.</p> </li> <li> <p> Employs powerful Publish/Subscribe &amp; Request/Reply messaging patterns.</p> </li> <li> <p> Each new Server on the network can be identified at Client's end by their unique port addresses.</p> </li> <li> <p> NetGear API actively tracks the state of each connected Server.</p> </li> <li> <p> If all the connected servers on the network get disconnected, the client itself automatically exits to save resources.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#usage-examples","title":"Usage Examples","text":"<p>Example Assumptions</p> <ul> <li> <p>For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits.</p> </li> <li> <p>All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a live montage (multiple frames concatenated together).</p> </li> <li> <p>For building Frames Montage at Client's end, We are going to use <code>imutils</code> python library function to build montages, by concatenating  together frames received from different servers. Therefore, Kindly install this library with <code>pip install imutils</code> terminal command.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>In this example, we will capturing live video-frames on two independent sources (a.k.a Servers), each with a webcam connected to it. Afterwards, these frames will be sent over the network to a single system (a.k.a Client) using this Multi-Servers Mode in NetGear API in real time, and will be displayed as a live montage.</p> <p>This example is useful for building applications like Real-Time Security System with multiple cameras.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple \n# of all unique Server((5566,5567) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=(5566, 5567),\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    **options\n)\n\n# Define received frame dictionary\nframe_dict = {}\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # receive data from network\n        data = client.recv()\n\n        # check if data received isn't None\n        if data is None:\n            break\n\n        # extract unique port address and its respective frame\n        unique_address, frame = data\n\n        # {do something with the extracted frame here}\n\n        # get extracted frame's shape\n        (h, w) = frame.shape[:2]\n\n        # update the extracted frame in the received frame dictionary\n        frame_dict[unique_address] = frame\n\n        # build a montage using data dictionary\n        montages = build_montages(frame_dict.values(), (w, h), (2, 1))\n\n        # display the montage(s) on the screen\n        for (i, montage) in enumerate(montages):\n\n            cv2.imshow(\"Montage Footage {}\".format(i), montage)\n\n        # check for 'q' key if pressed\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord(\"q\"):\n            break\n\n    except KeyboardInterrupt:\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import CamGear\n\n# Open suitable video stream (webcam on first index in our case)\nstream = CamGear(source=0).start()\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\", port=\"5566\", protocol=\"tcp\", pattern=1, **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if not None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (also with a webcam connected to it at index <code>0</code>), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import CamGear\n\n# Open suitable video stream (webcam on first index in our case)\nstream = CamGear(source=0).start()\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\", port=\"5567\", protocol=\"tcp\", pattern=1, **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if not None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of all \n# unique Server((5566,5567) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=(5566, 5567),\n    protocol=\"tcp\",\n    pattern=2,\n    receive_mode=True,\n    **options\n)\n\n# Define received frame dictionary\nframe_dict = {}\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # receive data from network\n        data = client.recv()\n\n        # check if data received isn't None\n        if data is None:\n            break\n\n        # extract unique port address and its respective frame\n        unique_address, frame = data\n\n        # {do something with the extracted frame here}\n\n        # get extracted frame's shape\n        (h, w) = frame.shape[:2]\n\n        # update the extracted frame in the received frame dictionary\n        frame_dict[unique_address] = frame\n\n        # build a montage using data dictionary\n        montages = build_montages(frame_dict.values(), (w, h), (2, 1))\n\n        # display the montage(s) on the screen\n        for (i, montage) in enumerate(montages):\n\n            cv2.imshow(\"Montage Footage {}\".format(i), montage)\n\n        # check for 'q' key if pressed\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord(\"q\"):\n            break\n\n    except KeyboardInterrupt:\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_1","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# Open suitable video stream (webcam on first index in our case)\nstream = cv2.VideoCapture(0)\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameter\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\", port=\"5566\", protocol=\"tcp\", pattern=2, **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        (grabbed, frame) = stream.read()\n\n        # check for frame if not grabbed\n        if not grabbed:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.release()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_1","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (also with a webcam connected to it at index <code>0</code>), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# Open suitable video stream (webcam on first index in our case)\nstream = cv2.VideoCapture(0)\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\", port=\"5567\", protocol=\"tcp\", pattern=2, **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        (grabbed, frame) = stream.read()\n\n        # check for frame if not grabbed\n        if not grabbed:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.release()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-for-unidirectional-custom-data-transfer","title":"Using Multi-Servers Mode for Unidirectional Custom Data Transfer","text":"<p>Abstract</p> <p>With Multi-Servers Mode, you can send additional data of any datatype<sup>1</sup> along with frame with frame in real-time, from all connected Server(s) to a single Client unidirectionally.</p> <p>But <code>numpy.ndarray</code> data-type is NOT supported as data.</p> <p>In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module &amp; a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end_2","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=(5577, 5578),\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)  \n# Define received frame dictionary\nframe_dict = {}\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # receive data from network\n        data = client.recv()\n\n        # check if data received isn't None\n        if data is None:\n            break\n\n        # extract unique port address and its respective frame and received data\n        unique_address, extracted_data, frame = data\n\n        # {do something with the extracted frame and data here}\n        # let's display extracted data on our extracted frame\n        cv2.putText(\n            frame,\n            extracted_data,\n            (10, frame.shape[0] - 10),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            0.6,\n            (0, 255, 0),\n            2,\n        )\n\n        # get extracted frame's shape\n        (h, w) = frame.shape[:2]\n\n        # update the extracted frame in the frame dictionary\n        frame_dict[unique_address] = frame\n\n        # build a montage using data dictionary\n        montages = build_montages(frame_dict.values(), (w, h), (2, 1))\n\n        # display the montage(s) on the screen\n        for (i, montage) in enumerate(montages):\n\n            cv2.imshow(\"Montage Footage {}\".format(i), montage)\n\n        # check for 'q' key if pressed\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord(\"q\"):\n            break\n\n    except KeyboardInterrupt:\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_2","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import VideoGear\nimport cv2\n\n# Open suitable video stream (webcam on first index in our case)\nstream = VideoGear(source=0).start()\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5577\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with frame and data(to be sent) here}\n\n        # let's prepare a text string as data\n        target_data = \"I'm Server-1 at Port: 5577\"\n\n        # send frame and data through server\n        server.send(frame, message=target_data) # (1)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_2","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nfrom libcamera import Transform\nimport cv2\n\n# add various Picamera tweak parameters to dictionary\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.1.xxx\",\n    port=\"5578\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with frame and data(to be sent) here}\n\n        # let's prepare a text string as data\n        text = \"I'm Server-2 at Port: 5578\"\n\n        # send frame and data through server\n        server.send(frame, message=text)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream.\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nimport cv2\n\n# add various Picamera tweak parameters to dictionary\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.1.xxx\",\n    port=\"5578\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with frame and data(to be sent) here}\n\n        # let's prepare a text string as data\n        text = \"I'm Server-2 at Port: 5578\"\n\n        # send frame and data through server\n        server.send(frame, message=text)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream.\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-with-bidirectional-mode","title":"Using Multi-Servers Mode with Bidirectional Mode","text":"<p>Abstract</p> <p>Multi-Servers Mode now also compatible with Bidirectional Mode, which lets you send additional data of any datatype<sup>1</sup>  along with frame in real-time bidirectionally between a single Client and all connected Server(s).</p> <p>Important Information</p> <ul> <li>Bidirectional data transfer ONLY works with pattern <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>), and NOT with pattern <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>)</li> <li>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their <code>message</code> parameter.</li> <li>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</li> </ul> New in v0.2.5 <p>This example was added in <code>v0.2.5</code>.</p> <p>In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module &amp; a Laptop with webcam) to a single Client, and at same time sending back data (a Text String, for the sake of simplicity) to them over the network all in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end_3","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.x\",\n    port=(5577, 5578),\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)  \n# Define received frame dictionary\nframe_dict = {}\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # prepare data to be sent\n        target_data = \"Hi, I am a Client here.\"\n\n        # receive data from server(s) and also send our data\n        data = client.recv(return_data=target_data)\n\n        # check if data received isn't None\n        if data is None:\n            break\n\n        # extract unique port address and its respective frame and received data\n        unique_address, extracted_data, frame = recv_data\n\n        # {do something with the extracted frame and data here}\n        # let's display extracted data on our extracted frame\n        cv2.putText(\n            frame,\n            extracted_data,\n            (10, frame.shape[0] - 10),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            0.6,\n            (0, 255, 0),\n            2,\n        )\n\n        # get extracted frame's shape\n        (h, w) = frame.shape[:2]\n\n        # update the extracted frame in the frame dictionary\n        frame_dict[unique_address] = frame\n\n        # build a montage using data dictionary\n        montages = build_montages(frame_dict.values(), (w, h), (2, 1))\n\n        # display the montage(s) on the screen\n        for (i, montage) in enumerate(montages):\n\n            cv2.imshow(\"Montage Footage {}\".format(i), montage)\n\n        # check for 'q' key if pressed\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord(\"q\"):\n            break\n\n    except KeyboardInterrupt:\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_3","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import VideoGear\nimport cv2\n\n# Open suitable video stream (webcam on first index in our case)\nstream = VideoGear(source=0).start()\n\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.x.x\",\n    port=\"5577\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with frame and data(to be sent) here}\n\n        # let's prepare a text string as data\n        target_data = \"I'm Server-1 at Port: 5577\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_3","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nfrom libcamera import Transform\nimport cv2\n\n# add various Picamera2 tweak parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.1.xxx\",\n    port=\"5578\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with frame and data(to be sent) here}\n\n        # let's prepare a text string as data\n        target_data = \"I'm Server-2 at Port: 5578\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream.\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nimport cv2\n\n# add various Picamera tweak parameters to dictionary\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\n    address=\"192.168.1.xxx\",\n    port=\"5578\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until Keyboard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with frame and data(to be sent) here}\n\n        # let's prepare a text string as data\n        target_data = \"I'm Server-2 at Port: 5578\"\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = server.send(frame, message=target_data) # (1)\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream.\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their <code>message</code> parameter.</p> <p>\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/netgear/advanced/secure_mode/","title":"Secure Mode","text":""},{"location":"gears/netgear/advanced/secure_mode/#secure-mode-for-netgear-api","title":"Secure Mode for NetGear API","text":""},{"location":"gears/netgear/advanced/secure_mode/#overview","title":"Overview","text":"<p>Secure Mode provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network.</p> <p>Secure Mode uses a new wire protocol, ZMTP 3.0 that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ, that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. </p> <p>Secure Mode can be easily activated in NetGear API through <code>secure_mode</code> attribute of its <code>options</code> dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional <code>custom_cert_location</code> &amp; <code>overwrite_cert</code> like attribute too.</p> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#supported-zmq-security-layers","title":"Supported ZMQ Security Layers","text":"<p>Secure mode supports the two most powerful ZMQ security layers:</p> <ul> <li> <p>Stonehouse: which switches to the CURVE security protocol that provides strong encryption on data, and almost unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism.</p> </li> <li> <p>Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about except end-point attacks. This security layer enhanced security comes at a price of additional latency.</p> </li> </ul> <p> </p> <p>Important Information regarding Secure Mode</p> <ul> <li> <p>The <code>secure_mode</code> attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse, and NOT with StoneHouse).</p> </li> <li> <p>In Secure Mode, The Client's end MUST run before the Server's end to establish a secure connection.</p> </li> <li> <p>The Public+Secret Keypairs generated at the Server end MUST be made available at the Client's end too for successful authentication. If mismatched, connection failure will occur.</p> </li> <li> <p>By Default, the Public+Secret Keypairs will be generated/stored at the <code>$HOME/.vidgear/keys</code> directory of your machine (e.g. <code>/home/foo/.vidgear/keys</code> on Linux). But you can also use <code>custom_cert_location</code> attribute to set your own Custom-Path for a directory to generate/store these Keypairs.</p> </li> <li> <p>DO NOT share generated public+secret Keypairs with anyone else on the network to avoid any potential security breach. At the Server End, You can easily use the <code>'overwrite_cert'</code> attribute for regenerating New-Keypairs on initialization. But make sure those newly generated Keypairs at the Server-End MUST be made available at Client's End for successful authentication.</p> </li> <li> <p>IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to  ADDITIONAL LATENCY.</p> </li> <li> <p>Secure Mode only supports <code>libzmq</code> library version <code>&gt;= 4.0</code>.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#features","title":"Features","text":"<ul> <li> <p> Supports the two most powerful ZMQ security layers: StoneHouse &amp; IronHouse.</p> </li> <li> <p> Auto-generates, auto-validates &amp; auto-stores the required Public+Secret Keypairs safely.</p> </li> <li> <p> Compatible with all messaging pattern, primary and exclusive modes.</p> </li> <li> <p> Strong data encryption &amp; Unbreakable authentication.</p> </li> <li> <p> Able to protect against many man-in-the-middle (MITM) attacks.</p> </li> <li> <p> Minimum hassle and very easy to enable and integrate.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#exclusive-attributes","title":"Exclusive Attributes","text":"<p>For implementing Secure Mode, NetGear API currently provide following exclusive attribute for its <code>options</code> dictionary parameter:</p> <ul> <li> <p><code>secure_mode</code> (integer) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: <code>1</code>(StoneHouse) &amp; <code>2</code>(IronHouse), and its default value is <code>0</code>(Grassland(no security)). Its usage is as follows:</p> <pre><code>#activates IronHouse Security Mechanism\noptions = {'secure_mode':2}\n</code></pre> </li> <li> <p><code>custom_cert_location</code> (string): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create <code>.vidgear</code> folder (only if not available) at the assigned custom path (instead of home directory), and then use that directory for storing new Keypairs/Certificates. It can be used as follows:</p> <pre><code># set custom Keypair location to '/home/foo/foo1/foo2'\noptions = {\n    \"secure_mode\": 2,\n    \"custom_cert_location\": \"/home/foo/foo1/foo2\",\n} \n</code></pre> </li> <li> <p><code>overwrite_cert</code> (bool): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to <code>True</code> a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows:</p> <p><code>overwrite_cert</code> parameter is disabled for Client's end!</p> <pre><code># a new Keypair will be generated\noptions = {\"secure_mode\": 2, \"overwrite_cert\": True} \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#usage-examples","title":"Usage Examples","text":""},{"location":"gears/netgear/advanced/secure_mode/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with Secure Mode in NetGear API:</p> <p>In Secure Mode, Client's end MUST run before the Server's end to establish a secure connection!</p>"},{"location":"gears/netgear/advanced/secure_mode/#clients-end","title":"Client's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate StoneHouse security mechanism\noptions = {\"secure_mode\": 1}\n\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(pattern=1, receive_mode=True, logging=True, **options)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/advanced/secure_mode/#servers-end","title":"Server's End","text":"<p>Then open another terminal on the same system and execute the following python code to send the frames to our client:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n\n# activate StoneHouse security mechanism\noptions = {\"secure_mode\": 1}\n\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#using-secure-mode-with-variable-parameters","title":"Using Secure Mode with Variable Parameters","text":""},{"location":"gears/netgear/advanced/secure_mode/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>In Secure Mode, Client's end MUST run before the Server's end to establish a secure connection!</p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You need to paste the Public+Secret Keypairs (generated at the Server End) at the <code>$HOME/.vidgear/keys</code> directory of your Client machine for a successful authentication!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate IronHouse security mechanism\noptions = {\"secure_mode\": 2}\n\n# Define NetGear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=2,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You also need to copy the Public+Secret Keypairs (generated on running this example code) present in the <code>$HOME/.vidgear/keys</code> directory, and make available at Client's end for a successful authentication.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n\n# activate IronHouse security mechanism, and \n# [BEWARE!!!] generating new Keypairs for this example !!!\noptions = {\"secure_mode\": 2, \"overwrite_cert\": True}\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=2,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/","title":"SSH Tunneling Mode","text":""},{"location":"gears/netgear/advanced/ssh_tunnel/#ssh-tunneling-mode-for-netgear-api","title":"SSH Tunneling Mode for NetGear API","text":"NetGear's Bidirectional Mode"},{"location":"gears/netgear/advanced/ssh_tunnel/#overview","title":"Overview","text":"New in v0.2.2 <p>This document was added in <code>v0.2.2</code>.</p> <p>SSH Tunneling Mode allows you to connect NetGear client and server via secure SSH connection over the untrusted network and access its intranet services across firewalls. This mode works with pyzmq's <code>zmq.ssh</code> module for tunneling ZeroMQ connections over ssh.</p> <p>This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. Thereby, once you have established the tunnel, connections to local machine will actually be connections to remote machine as seen from the server.</p> Beware \u2620\ufe0f <p>Cybercriminals or malware could exploit SSH tunnels to hide their unauthorized communications, or to exfiltrate stolen data from the network. More information can be found here \u27b6</p> <p>All patterns are valid for this mode and it can be easily activated in NetGear API at server end through <code>ssh_tunnel_mode</code> string attribute of its <code>options</code> dictionary parameter during initialization.</p> <p>Important</p> <ul> <li>SSH tunneling mode can only be enabled on Server-end to establish remote SSH connection with Client.</li> <li>SSH tunneling mode requires Client's SSH Port(default <code>22</code>) to be TCP Port Forwarded by its Router, which allows Server machine to connect to it remotely.   </li> <li>SSH tunneling mode is NOT compatible with Multi-Servers and Multi-Clients Exclusive Modes yet.</li> </ul> <p>Useful Tips</p> <ul> <li>It is advise to use <code>pattern=2</code> to overcome random disconnection due to delays in network.</li> <li>SSH tunneling Mode is fully supports Bidirectional Mode, Secure Mode and JPEG-Frame Compression.</li> <li>It is advised to enable logging (<code>logging = True</code>) on the first run, to easily identify any runtime errors.</li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#prerequisites","title":"Prerequisites","text":"<p>SSH Tunnel Mode requires <code>pexpect</code> or <code>paramiko</code> as an additional dependency which is not part of standard VidGear package. It can be easily installed via pypi as follows:</p> PramikoPexpect <p><code>paramiko</code> is compatible with all platforms.</p> <p><code>paramiko</code> support is automatically enabled in ZeroMQ if installed.</p> <pre><code># install paramiko\npip install paramiko\n</code></pre> <p><code>pexpect</code> is NOT compatible with Windows Machines.</p> <pre><code># install pexpect\npip install pexpect\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#exclusive-attributes","title":"Exclusive Attributes","text":"<p>All these attributes will work on Server end only whereas Client end will simply discard them.</p> <p>For implementing SSH Tunneling Mode, NetGear API currently provide following exclusive attribute for its <code>options</code> dictionary parameter:</p> <ul> <li> <p><code>ssh_tunnel_mode</code> (string) : This attribute activates SSH Tunneling Mode and assigns the <code>\"&lt;ssh-username&gt;@&lt;client-public-ip-address&gt;:&lt;tcp-forwarded-port&gt;\"</code> SSH URL for tunneling at Server end. Its usage is as follows:</p> <p>On Server end, NetGear automatically validates if the <code>port</code> is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed), NetGear will throw <code>AssertionError</code>!</p> With Default PortWith Custom Port <p>The default port value in SSH URL is <code>22</code>, meaning Server assumes TCP Port <code>22</code> is forwarded on Client's end by default.</p> <pre><code># activate SSH Tunneling and assign SSH URL\noptions = {\"ssh_tunnel_mode\":\"userid@52.194.1.73\"}\n\n# i.e. only connections from the Public IP address `52.194.1.73` \n# on default port 22 are allowed.\n</code></pre> <p>But, you can also define your own custom TCP forwarded port instead:</p> <p>Here we're defining our own TCP Port <code>8080</code>, meaning Server assumes TCP Port <code>8080</code> is forwarded on Client's end.</p> <pre><code># activate SSH Tunneling and assign SSH URL\noptions = {\"ssh_tunnel_mode\":\"userid@52.194.1.73:8080\"}\n\n# i.e. only connections from the Public IP address `52.194.1.73` \n# on custom port 8080 are allowed.\n</code></pre> </li> <li> <p><code>ssh_tunnel_pwd</code> (string): This attribute sets the password required to authorize Host(client) for SSH Connection at Server end. This password grant access and controls SSH user can access what. It can be used as follows:</p> <pre><code># set password for our SSH conection\noptions = {\n    \"ssh_tunnel_mode\":\"userid@52.194.1.73\",\n    \"ssh_tunnel_pwd\":\"mypasswordstring\",\n} \n</code></pre> </li> <li> <p><code>ssh_tunnel_keyfile</code> (string): This attribute sets path to Host key that provide another way to authenticate Host(client) for SSH Connection at Server end. Its purpose is to prevent man-in-the-middle attacks. It allows device authentication keys to be rotated and managed conveniently and every connection to be secured. It can be used as follows:</p> <p>You can use Ssh-keygen tool for creating new authentication key pairs for SSH Tunneling.</p> <pre><code># set keyfile path for our SSH conection\noptions = {\n    \"ssh_tunnel_mode\":\"userid@52.194.1.73\",\n    \"ssh_tunnel_keyfile\":\"/home/foo/.ssh/id_rsa\",\n} \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#usage-example","title":"Usage Example","text":"Assumptions for this Example <p>In this particular example, we assume that:</p> <ul> <li> <p>Server: </p> <ul> <li> Server end is a Raspberry Pi with USB camera connected to it. </li> <li> Server is located at remote location and outside the Client's network.  </li> </ul> </li> <li> <p>Client:</p> <ul> <li> Client end is a Regular PC/Computer located at <code>52.155.1.89</code> public IP address for displaying frames received from the remote Server.</li> <li> Client's SSH Port(default <code>22</code>) is TCP Port Forwarded by its Router, which allows Server to connect to it remotely. This connection will then be tunneled back to our PC/Computer(Client) and makes TCP connection to it again via port <code>22</code> on localhost(<code>127.0.0.1</code>).</li> <li> Also, there's a username <code>test</code> present on the PC/Computer(Client) to SSH login with password <code>pas$wd</code>.</li> </ul> </li> <li> <p>Setup Diagram:</p> <p>Assumed setup can be visualized throw diagram as follows:</p> <p> Setup Diagram </p> </li> </ul>"},{"location":"gears/netgear/advanced/ssh_tunnel/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (A Regular PC where you want to display the input frames received from the Server) and execute the following python code: </p> Requirements for Client's End <p>To ensure a successful Remote NetGear Connection with Server:</p> <ul> <li> <p> Install OpenSSH Server: (Tested)</p>  Linux Windows MacOS <pre><code># Debian-based\nsudo apt-get install openssh-server\n\n# RHEL-based\nsudo yum install openssh-server\n</code></pre> <p>See this official Microsoft doc \u27b6</p> <pre><code>brew install openssh\n</code></pre> </li> <li> <p> Make sure to note down the Client's public IP address required by Server end.</p> </li> <li> <p> Make sure that Client's SSH Port(default <code>22</code>) is TCP Port Forwarded by its Router to expose it to the public Internet. Also, this forwarded TCP port value is needed at Server end.</p> </li> </ul> Finding Public IP Address <p>Only IPv4 IP-addresses are supported</p> Enabling Dynamic DNS <p>SSH tunneling requires public IP address to able to access host on public Internet. Thereby, if it's troublesome to remember Public IP address or your IP address change constantly, then you can use dynamic DNS services like https://www.noip.com/</p> <ul> <li>A Public IP address is a globally routable IP address that is assigned to a network device, allowing it direct access to the Internet. They are assigned to the device by its ISP, and each device has a unique public IP address.</li> <li>Determining the public IP address involves contacting a remote server over the HTTP/HTTPS or DNS protocol and obtaining the IP address from the remote server response.</li> <li>On Desktop machines, the easiest way to find out your public IP address is to google \"what is my IP\" in your browser:</li> </ul> <p></p> How to TCP Port Forward in your Router <p>For more information on Forwarding Port in Popular Home Routers. See this document \u27b6</p> Secsh channel X open FAILED: open failed: Administratively prohibited <p>Error: This error means that installed OpenSSH is preventing connections to forwarded ports from outside your Client Machine. </p> <p>Solution: You need to change <code>GatewayPorts no</code> option to <code>GatewayPorts yes</code> in the OpenSSH server configuration file <code>sshd_config</code> to allows anyone to connect to the forwarded ports on Client Machine. </p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n\n# Define NetGear Client at given IP address and define parameters \nclient = NetGear(\n    address=\"127.0.0.1\", # don't change this\n    port=\"5454\",\n    pattern=2,\n    receive_mode=True,\n    logging=True,\n)\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#servers-end","title":"Server's End","text":"<p>Now, Open the terminal on Remote Server System (A Raspberry Pi with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Make sure to replace the Client's Public IP Address and Forwarded TCP port(default is 22) in SSH URL with yours in the following example.</p> <p>On Server end, NetGear automatically validates if the <code>port</code> is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed), NetGear will throw <code>AssertionError</code>!</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n\n# activate SSH tunneling with SSH URL, and\n# [BEWARE!!!] Change SSH URL and SSH password with yours for this example !!!\noptions = {\n    \"ssh_tunnel_mode\": \"test@52.155.1.89\", # defaults to port 22\n    \"ssh_tunnel_pwd\": \"pas$wd\",\n}\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define NetGear server at given IP address and define parameters\nserver = NetGear(\n    address=\"127.0.0.1\", # don't change this\n    port=\"5454\",\n    pattern=2, \n    logging=True, \n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/overview/","title":"Overview","text":""},{"location":"gears/netgear_async/overview/#netgear_async-api","title":"NetGear_Async API","text":""},{"location":"gears/netgear_async/overview/#overview","title":"Overview","text":"<p>NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes.</p> <p>NetGear_Async is built on <code>zmq.asyncio</code>, and powered by a high-performance asyncio event loop called <code>uvloop</code> to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. </p> <p>NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network(see this doc example).</p> <p>NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code.</p> <p>In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> <p>NetGear_Async as of now supports four ZeroMQ messaging patterns:</p> <ul> <li> <code>zmq.PAIR</code> (ZMQ Pair Pattern)</li> <li> <code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern)</li> <li> <code>zmq.PUB/zmq.SUB</code> (ZMQ Publish/Subscribe Pattern) </li> <li> <code>zmq.PUSH/zmq.PULL</code> (ZMQ Push/Pull Pattern)</li> </ul> <p>Whereas supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> <li> <p>It is advised to comprehend NetGear API before using this API.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear_async/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through NetGear_Async Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/netgear_async/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/netgear_async/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/netgear_async/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/netgear_async/params/","title":"Parameters","text":""},{"location":"gears/netgear_async/params/#netgear_async-api-parameters","title":"NetGear_Async API Parameters","text":"<p>NetGear_Async provides a special internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/netgear_async/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide access to PiGear or CamGear APIs respectively. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#address","title":"<code>address</code>","text":"<p>This parameter sets the valid network address of the Server/Client. Network addresses unique identifiers across the network. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is based on selected primary mode, i.e <code>'localhost'</code> for Send Mode and <code>'*'</code> for Receive Mode.</p> <p>Usage:</p> <pre><code>NetGear_Async(address=\"192.168.0.145\")\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#port","title":"<code>port</code>","text":"<p>This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'5555'</code></p> <p>Usage:</p> <pre><code>NetGear_Async(port=\"5575\")\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#protocol","title":"<code>protocol</code>","text":"<p>This parameter sets the valid messaging protocol between Server/Client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: <code>'tcp'</code> and <code>'ipc'</code>.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'tcp'</code></p> <p>Usage:</p> <pre><code>NetGear_Async(protocol=\"ipc\")\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#pattern","title":"<code>pattern</code>","text":"<p>This parameter sets the supported messaging pattern(flow of communication) between Server/Client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> (i.e <code>zmq.PAIR</code>). </p> <p>All supported ZMQ patterns for NetGear_Async are:</p> <ul> <li><code>0</code> (.i.e. zmq.PAIR): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it.</li> <li><code>1</code> (.i.e. zmq.REQ/zmq.REP): In this pattern, it employs <code>ZMQ REQ</code> sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket <code>zmq.REQ</code> will block send unless it has successfully received a reply back and socket <code>zmq.REP</code> will block on recv() unless it has received a request.</li> <li><code>2</code> (.i.e. zmq.PUB/zmq.SUB): It is an another classic pattern where senders of messages, called publishers, do not program the messages to be sent directly to specific receivers, called subscribers. Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A <code>ZMQ.SUB</code> can connect to multiple <code>ZMQ.PUB</code> (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved.</li> <li><code>3</code> (.i.e. zmq.PUSH/zmq.PULL): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket.</li> </ul> <p>Usage:</p> <pre><code>NetGear_Async(pattern=1) # sets zmq.REQ/zmq.REP pattern\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#receive_mode","title":"<code>receive_mode</code>","text":"<p>This parameter select the Netgear's Mode of operation. It basically activates <code>Receive Mode</code>(if <code>True</code>) and <code>Send Mode</code>(if <code>False</code>). Furthermore, <code>recv()</code> method will only work when this flag is enabled(i.e. <code>Receive Mode</code>), whereas <code>send()</code> method will only work when this flag is disabled(i.e.<code>Send Mode</code>). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>(i.e. Send Mode is activated by default).</p> <p>Usage:</p> <pre><code>NetGear_Async(receive_mode=True) # activates Recieve Mode\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#timeout","title":"<code>timeout</code>","text":"<p>In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds), Otherwise <code>TimeoutError</code> will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter controls that  timeout value (i.e. the maximum waiting time (in seconds)) after which Client exit itself with a <code>TimeoutError</code> to save resources. Its minimum value is <code>0.0</code> but no max limit.</p> <p>Data-Type: Float/Integer</p> <p>Default Value: Its default value is <code>10.0</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(timeout=5.0) # sets 5secs timeout\n</code></pre>"},{"location":"gears/netgear_async/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the flexibility to alter various NetGear_Async API's internal properties and modes.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code></p> <p>Usage:</p> <p>Supported dictionary attributes for NetGear_Async API</p> <ul> <li> <p><code>bidirectional_mode</code> (boolean) : This internal attribute activates the exclusive Bidirectional Mode, if enabled(<code>True</code>).</p> <p>The desired attributes can be passed to NetGear_Async API as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n    \"bidirectional_mode\": True,\n}\n# assigning it\nNetGear_Async(logging=True, **options)\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in NetGear_Async.</p>"},{"location":"gears/netgear_async/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#options_1","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in NetGear_Async. Default is also <code>False</code>.</p>"},{"location":"gears/netgear_async/params/#source","title":"<code>source</code>","text":"<p>NetGear_Async API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>NetGear_Async(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>NetGear_Async(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>NetGear_Async(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>NetGear_Async(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/netgear_async/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>NetGear_Async(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>NetGear_Async(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nNetGear_Async(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in NetGear_Async.</p>"},{"location":"gears/netgear_async/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera index to be used as the source, allowing you to drive these multiple cameras simultaneously from within a single Python session. Its value can only be zero or greater, otherwise, NetGear_Async API will throw <code>ValueError</code> for any negative value.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code># select Camera Module at index `1`\nNetGear_Async(enablePiCamera=True, camera_num=1)\n</code></pre> <p>The complete usage example demonstrating the usage of the <code>camera_num</code> parameter is available here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter controls the resolution - a tuple (i.e. <code>(width,height)</code>) of two values giving the width and height of the output frames. </p> <p>Make sure both width and height values should be at least <code>64</code>.</p> <p>When using the Picamera2 backend, the <code>resolution</code> parameter will be OVERRIDDEN, if the user explicitly defines the <code>output_size</code> property of the <code>sensor</code> configurational parameter.</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter controls the framerate of the source.</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#options_3","title":"<code>options</code>","text":"<p>This dictionary parameter in the internal PiGear API backend allows you to control various camera settings for both the <code>picamera2</code> and legacy <code>picamera</code> backends and some internal API tasks. These settings include:</p>"},{"location":"gears/netgear_async/params/#a-configurational-camera-parameters","title":"A. Configurational Camera Parameters","text":"<ul> <li> These parameters are provided by the underlying backend library (depending upon backend in use), and must be applied to the camera system before the camera can be started.</li> <li> These parameter include: Brightness, Contrast, Saturation, Exposure, Colour Temperature, Colour Gains, etc. </li> <li> All supported parameters are listed in this Usage example \u27b6</li> </ul>"},{"location":"gears/netgear_async/params/#b-user-defined-parameters","title":"B. User-defined Parameters","text":"<ul> <li> These user-defined parameters control specific internal behaviors of the API and perform certain tasks on the camera objects.</li> <li> All supported User-defined Parameters are listed here \u27b6</li> </ul>"},{"location":"gears/netgear_async/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in NetGear_Async.</p>"},{"location":"gears/netgear_async/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>NetGear_Async(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/netgear_async/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the NetGear_Async API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/","title":"Usage Examples","text":""},{"location":"gears/netgear_async/usage/#netgear_async-api-usage-examples","title":"NetGear_Async API Usage Examples:","text":"<p>Helpful Tips</p> <ul> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> <li> <p>It is advised to comprehend NetGear API before using this API.</p> </li> </ul> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/netgear_async/usage/#requirement","title":"Requirement","text":"<p>NetGear_Async API is the part of <code>asyncio</code> package of VidGear, thereby you need to install VidGear with asyncio support as follows:</p> <pre><code>pip install vidgear[asyncio]\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with NetGear_Async API:</p>"},{"location":"gears/netgear_async/usage/#servers-end","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport asyncio\n\n# initialize Server with suitable source\nserver = NetGear_Async(source=\"/home/foo/foo1.mp4\").launch()\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#clients-end","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True).launch()\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # loop over Client's Asynchronous Frame Generator\n    async for frame in client.recv_generator():\n\n        # do something with received frames here\n\n        # Show output window\n        cv2.imshow(\"Output Frame\", frame)\n        key = cv2.waitKey(1) &amp; 0xFF\n\n        # await before continuing\n        await asyncio.sleep(0)\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n\n    # close all output window\n    cv2.destroyAllWindows()\n    # safely close client\n    client.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-variable-parameters","title":"Using NetGear_Async with Variable Parameters","text":""},{"location":"gears/netgear_async/usage/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours\nclient = NetGear_Async(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=2,\n    receive_mode=True,\n    logging=True,\n).launch()\n\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # loop over Client's Asynchronous Frame Generator\n    async for frame in client.recv_generator():\n\n        # do something with received frames here\n\n        # Show output window\n        cv2.imshow(\"Output Frame\", frame)\n        key = cv2.waitKey(1) &amp; 0xFF\n\n        # await before continuing\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n\n    # close all output window\n    cv2.destroyAllWindows()\n    # safely close client\n    client.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport asyncio\n\n# initialize Server with suitable source\nserver = NetGear_Async(\n    source=0,\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=2,\n    logging=True,\n).launch()\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-a-custom-sourceopencv","title":"Using NetGear_Async with a Custom Source(OpenCV)","text":"<p>NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to transform your frames before sending them onto the network. </p> <p>Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV:</p>"},{"location":"gears/netgear_async/usage/#servers-end_2","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# initialize Server without any source\nserver = NetGear_Async(source=None, logging=True)\n\n# !!! define your own video source here !!!\n# Open any video stream such as live webcam\n# video stream on first index(i.e. 0) device\nstream = cv2.VideoCapture(0)\n\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n\n    # loop over stream until its terminated\n    while True:\n\n        # read frames\n        (grabbed, frame) = stream.read()\n\n        # check if frame empty\n        if not grabbed:\n            break\n\n        # do something with the frame to be sent here\n\n        # yield frame\n        yield frame\n        # sleep for sometime\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    # Add your custom source generator to Server configuration\n    server.config[\"generator\"] = my_frame_generator()\n    # Launch the Server\n    server.launch()\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # close stream\n        stream.release()\n        # finally close the server\n        server.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#clients-end_2","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True, logging=True).launch()\n\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # loop over Client's Asynchronous Frame Generator\n    async for frame in client.recv_generator():\n\n        # {do something with received frames here}\n\n        # Show output window\n        cv2.imshow(\"Output Frame\", frame)\n        key = cv2.waitKey(1) &amp; 0xFF\n\n        # await before continuing\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n\n    # close all output window\n    cv2.destroyAllWindows()\n    # safely close client\n    client.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-other-gears","title":"Using NetGear_Async with Other Gears","text":"<p>NetGear_Async can be used with any other Gears without any compatibility issues. </p> <p>Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows:</p>"},{"location":"gears/netgear_async/usage/#servers-end_3","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport asyncio\n\n# initialize Server with suitable source and enable stabilization\nserver = NetGear_Async(\n    source=\"/home/foo/foo1.mp4\", stabilize=True, logging=True\n).launch()\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#clients-end_3","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears import WriteGear\nimport cv2, asyncio\n\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True).launch()\n\n# Define writer with output filename 'Output.mp4'\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # loop over Client's Asynchronous Frame Generator\n    async for frame in client.recv_generator():\n\n        # {do something with received frames here}\n\n        # write a modified frame to writer\n        writer.write(frame)\n\n        # Show output window\n        cv2.imshow(\"Output Frame\", frame)\n        key = cv2.waitKey(1) &amp; 0xFF\n\n        # await before continuing\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n\n    # close all output window\n    cv2.destroyAllWindows()\n    # safely close client\n    client.close()\n    # safely close writer\n    writer.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/","title":"Bidirectional Mode","text":""},{"location":"gears/netgear_async/advanced/bidirectional_mode/#bidirectional-mode-for-netgear_async-api","title":"Bidirectional Mode for NetGear_Async API","text":"NetGear_Async's Bidirectional Mode"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#overview","title":"Overview","text":"New in v0.2.2 <p>This document was added in <code>v0.2.2</code>.</p> <p>Bidirectional Mode enables seamless support for Bidirectional data transmission between Client and Sender along with video-frames through its synchronous messaging patterns such as <code>zmq.PAIR</code> (ZMQ Pair Pattern) &amp; <code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern) in NetGear_Async API.</p> <p>In Bidirectional Mode, we utilizes the NetGear_Async API's <code>transceive_data</code> method for transmitting data (at Client's end) and receiving data (in Server's end)  all while transferring frames in real-time. </p> <p>This mode can be easily activated in NetGear_Async through <code>bidirectional_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Important</p> <ul> <li> <p>In Bidirectional Mode, <code>zmq.PAIR</code>(ZMQ Pair) &amp; <code>zmq.REQ/zmq.REP</code>(ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in <code>ValueError</code>.</p> </li> <li> <p>Bidirectional Mode only works with User-defined Custom Source on Server end. Otherwise, NetGear_Async API will throw <code>ValueError</code>.</p> </li> <li> <p>Bidirectional Mode enables you to send data of ANY<sup>1</sup> Data-type along with frame bidirectionally.</p> </li> <li> <p>NetGear_Async API will throw <code>RuntimeError</code> if Bidirectional Mode is disabled at Server end or Client end but not both.</p> </li> <li> <p>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#exclusive-method-and-parameter","title":"Exclusive Method and Parameter","text":"<p>To send data bidirectionally, NetGear_Async API provides following exclusive method and parameter:</p> <p><code>transceive_data</code> only works when Bidirectional Mode is enabled.</p> <ul> <li> <p><code>transceive_data</code>: It's a bidirectional mode exclusive method to transmit data (in Receive mode) and receive data (in Send mode), all while transferring frames in real-time. </p> <ul> <li><code>data</code>: In <code>transceive_data</code> method, this parameter enables user to inputs data (of ANY<sup>1</sup> datatype) for sending back to Server at Client's end. </li> </ul> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#usage-examples","title":"Usage Examples","text":"<p>For Bidirectional Mode, NetGear_Async must need User-defined Custom Source at its Server end otherwise it will throw ValueError.</p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>Following is the bare-minimum code you need to get started with Bidirectional Mode over Custom Source Server built using OpenCV and NetGear_Async API:</p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# initialize Server without any source\nserver = NetGear_Async(source=None, logging=True, **options)\n\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n\n    # !!! define your own video source here !!!\n    # Open any valid video stream(for e.g `foo.mp4` file)\n    stream = cv2.VideoCapture(\"foo.mp4\")\n\n    # loop over stream until its terminated\n    while True:\n        # read frames\n        (grabbed, frame) = stream.read()\n\n        # check for empty frame\n        if not grabbed:\n            break\n\n        # {do something with the frame to be sent here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # receive data from Client\n        recv_data = await server.transceive_data()\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n        # send our frame &amp; data\n        yield (target_data, frame) # (1)\n\n        # sleep for sometime\n        await asyncio.sleep(0)\n\n    # safely close video stream\n    stream.release()\n\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    # Add your custom source generator to Server configuration\n    server.config[\"generator\"] = my_frame_generator()\n    # Launch the Server\n    server.launch()\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#client-end","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True, logging=True, **options).launch()\n\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # loop over Client's Asynchronous Frame Generator\n    async for (data, frame) in client.recv_generator():\n\n        # do something with receive data from server\n        if not (data is None):\n            # let's print it\n            print(data)\n\n        # {do something with received frames here}\n\n        # Show output window(comment these lines if not required)\n        cv2.imshow(\"Output Frame\", frame)\n        cv2.waitKey(1) &amp; 0xFF\n\n        # prepare data to be sent\n        target_data = \"Hi, I am a Client here.\"\n        # send our data to server\n        await client.transceive_data(data=target_data)\n\n        # await before continuing\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n\n    # close all output window\n    cv2.destroyAllWindows()\n\n    # safely close client\n    client.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","title":"Using Bidirectional Mode with Variable Parameters","text":""},{"location":"gears/netgear_async/advanced/bidirectional_mode/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear_Async Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear_Async(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # loop over Client's Asynchronous Frame Generator\n    async for (data, frame) in client.recv_generator():\n\n        # do something with receive data from server\n        if not (data is None):\n            # let's print it\n            print(data)\n\n        # {do something with received frames here}\n\n        # Show output window(comment these lines if not required)\n        cv2.imshow(\"Output Frame\", frame)\n        cv2.waitKey(1) &amp; 0xFF\n\n        # prepare data to be sent\n        target_data = \"Hi, I am a Client here.\"\n        # send our data to server\n        await client.transceive_data(data=target_data)\n\n        # await before continuing\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n\n    # close all output window\n    cv2.destroyAllWindows()\n\n    # safely close client\n    client.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end_1","title":"Server End","text":"<p>Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import libs\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears import VideoGear\nfrom libcamera import Transform\nimport cv2, asyncio\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# initialize Server without any source at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear_Async(\n    source=None,\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n\n    # !!! define your own video source below !!!\n\n    # define various Picamera2 tweak parameters\n    options = {\n        \"queue\": True,\n        \"buffer_count\": 4,\n        \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n        \"transform\": Transform(hflip=1),\n        \"auto_align_output_config\": True,  # auto-align camera configuration\n    }\n\n    # open pi video stream with defined parameters\n    stream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n    # loop over stream until its terminated\n    while True:\n        # read frames\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame to be sent here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # receive data from Client\n        recv_data = await server.transceive_data()\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n        # send our frame &amp; data\n        yield (target_data, frame) # (1)\n\n        # sleep for sometime\n        await asyncio.sleep(0)\n\n    # safely close video stream\n    stream.stop()\n\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    # Add your custom source generator to Server configuration\n    server.config[\"generator\"] = my_frame_generator()\n    # Launch the Server\n    server.launch()\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears import VideoGear\nimport cv2, asyncio\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# initialize Server without any source at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear_Async(\n    source=None,\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n\n    # !!! define your own video source below !!!\n\n    # define various Picamera tweak parameters\n    options = {\n        \"hflip\": True,\n        \"exposure_mode\": \"auto\",\n        \"iso\": 800,\n        \"exposure_compensation\": 15,\n        \"awb_mode\": \"horizon\",\n        \"sensor_mode\": 0,\n    }\n\n    # open pi video stream with defined parameters\n    stream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n    # loop over stream until its terminated\n    while True:\n        # read frames\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame to be sent here}\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # receive data from Client\n        recv_data = await server.transceive_data()\n\n        # print data just received from Client\n        if not (recv_data is None):\n            print(recv_data)\n\n        # send our frame &amp; data\n        yield (target_data, frame) # (1)\n\n        # sleep for sometime\n        await asyncio.sleep(0)\n\n    # safely close video stream\n    stream.stop()\n\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    # Add your custom source generator to Server configuration\n    server.config[\"generator\"] = my_frame_generator()\n    # Launch the Server\n    server.launch()\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","title":"Using Bidirectional Mode for Video-Frames Transfer","text":"<p>In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. </p> <p>This feature is great for building applications like Real-Time Video Chat.</p> <p>We're also using <code>reducer()</code> method for reducing frame-size on-the-go for additional performance.</p> <p>Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!</p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end_2","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both side anytime by pressing Ctrl+C on your keyboard!</p> <p>Server end can only send numpy.ndarray datatype as frame but not as data.</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears.asyncio.helper import reducer\nimport cv2, asyncio\nimport numpy as np\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# Define NetGear Server without any source and with defined parameters\nserver = NetGear_Async(source=None, pattern=1, logging=True, **options)\n\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n    # !!! define your own video source here !!!\n    # Open any valid video stream(for e.g `foo.mp4` file)\n    stream = cv2.VideoCapture(\"foo.mp4\")\n    # loop over stream until its terminated\n    while True:\n\n        # read frames\n        (grabbed, frame) = stream.read()\n\n        # check for empty frame\n        if not grabbed:\n            break\n\n        # reducer frames size if you want more performance, otherwise comment this line\n        frame = await reducer(frame, percentage=30)  # reduce frame by 30%\n\n        # {do something with the frame to be sent here}\n\n        # send frame &amp; data and also receive data from Client\n        recv_data = await server.transceive_data()\n\n        # receive data from Client\n        if not (recv_data is None):\n            # check data is a numpy frame\n            if isinstance(recv_data, np.ndarray):\n\n                # {do something with received numpy frame here}\n\n                # Let's show it on output window\n                cv2.imshow(\"Received Frame\", recv_data)\n                cv2.waitKey(1) &amp; 0xFF\n            else:\n                # otherwise just print data\n                print(recv_data)\n\n        # prepare data to be sent(a simple text in our case)\n        target_data = \"Hello, I am a Server.\"\n\n        # send our frame &amp; data to client\n        yield (target_data, frame) # (1)\n\n        # sleep for sometime\n        await asyncio.sleep(0)\n\n    # safely close video stream\n    stream.release()\n\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    # Add your custom source generator to Server configuration\n    server.config[\"generator\"] = my_frame_generator()\n    # Launch the Server\n    server.launch()\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#client-end_1","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears.asyncio.helper import reducer\nimport cv2, asyncio\n\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(pattern=1, receive_mode=True, logging=True, **options).launch()\n\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n    # !!! define your own video source here !!!\n    # again open the same video stream for comparison\n    stream = cv2.VideoCapture(\"foo.mp4\")\n    # loop over Client's Asynchronous Frame Generator\n    async for (server_data, frame) in client.recv_generator():\n\n        # check for server data\n        if not (server_data is None):\n\n            # {do something with the server data here}\n\n            # lets print extracted server data\n            print(server_data)\n\n        # {do something with received frames here}\n\n        # Show output window\n        cv2.imshow(\"Output Frame\", frame)\n        key = cv2.waitKey(1) &amp; 0xFF\n\n        # read frame target data from stream to be sent to server\n        (grabbed, target_data) = stream.read()\n        # check for frame\n        if grabbed:\n            # reducer frames size if you want more performance, otherwise comment this line\n            target_data = await reducer(\n                target_data, percentage=30\n            )  # reduce frame by 30%\n            # send our frame data\n            await client.transceive_data(data=target_data)\n\n        # await before continuing\n        await asyncio.sleep(0)\n\n    # safely close video stream\n    stream.release()\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n    try:\n        # run your main function task until it is complete\n        client.loop.run_until_complete(main())\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    # close all output window\n    cv2.destroyAllWindows()\n    # safely close client\n    client.close()\n</code></pre> <p> </p> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray datatype is ONLY SUPPORTED at Client's end with <code>transceive_data</code> method using its <code>data</code> parameter. Whereas Server end can only send numpy.ndarray datatype as frame but not as data.</p> <p>\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/pigear/overview/","title":"Overview","text":""},{"location":"gears/pigear/overview/#pigear-api","title":"PiGear API","text":"Raspberry Pi Camera Module"},{"location":"gears/pigear/overview/#overview","title":"Overview","text":"<p>PiGear is a specialized API similar to the CamGear API but optimized for Raspberry Pi  Boards, offering comprehensive support for camera modules (e.g., OmniVision OV5647, Sony IMX219), along with limited compatibility for USB cameras.</p> <p>PiGear implements a seamless and robust wrapper around the picamera2 python library, simplifying integration with minimal code changes and ensuring a smooth transition for developers already familiar with the Picamera2 API. PiGear leverages the <code>libcamera</code> API under the hood with multi-threading, providing high-performance , enhanced control and functionality for Raspberry Pi camera modules. </p> <p>PiGear handles common configuration parameters and non-standard settings for various camera types, simplifying the integration process. PiGear currently supports PiCamera2 API parameters such as <code>sensor</code>, <code>controls</code>, <code>transform</code>, and <code>format</code> etc., with internal type and sanity checks for robust performance.</p> <p>While primarily focused on Raspberry Pi camera modules, PiGear also provides basic functionality for USB webcams only with Picamera2 API, along with the ability to accurately differentiate between USB and Raspberry Pi cameras using metadata. </p> Backward compatibility with <code>picamera</code> library <p>PiGear seamlessly switches to the legacy <code>picamera</code> library if the <code>picamera2</code> library is unavailable, ensuring seamless backward compatibility. For this, PiGear also provides a flexible multi-threaded framework around complete <code>picamera</code> API, allowing developers to effortlessly exploit a wide range of parameters, such as <code>brightness</code>, <code>saturation</code>, <code>sensor_mode</code>, <code>iso</code>, <code>exposure</code>, and more. </p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <p>Furthermore, PiGear supports the use of multiple camera modules, including those found on Raspberry Pi Compute Module IO boards and USB cameras (only with Picamera2 API).</p> Threaded Internal Timer  <p>PiGear ensures proper resource release during the termination of the API, preventing potential issues or resource leaks. PiGear API internally implements a Threaded Internal Timer that silently keeps active track of any frozen-threads or hardware-failures and exits safely if any do occur. This means that if you're running the PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into a possible kernel panic, the API will exit safely to save resources.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this API, otherwise nothing will work.</p> <p>Helpful Tips</p> <ul> <li> <p>Follow PiCamera2 documentation and Picamera documentation which should help you quickly get started.</p> </li> <li> <p>If you're already familiar with OpenCV library, then see Switching from OpenCV \u27b6.</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/pigear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through PiGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/pigear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/pigear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/pigear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/pigear/params/","title":"Parameters","text":""},{"location":"gears/pigear/params/#pigear-api-parameters","title":"PiGear API Parameters","text":""},{"location":"gears/pigear/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera index to be used as the source, allowing you to drive these multiple cameras simultaneously from within a single Python session. Its value can only be zero or greater, otherwise, PiGear API will throw <code>ValueError</code> for any negative value.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code># select Camera Module at index `1`\nPiGear(camera_num=1)\n</code></pre> <p>The complete usage example demonstrating the usage of the <code>camera_num</code> parameter is available here \u27b6.</p> <p> </p>"},{"location":"gears/pigear/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter controls the resolution - a tuple (i.e. <code>(width,height)</code>) of two values giving the width and height of the output frames. </p> <p>Make sure both width and height values should be at least <code>64</code>.</p> <p>When using the Picamera2 backend, the <code>resolution</code> parameter will be OVERRIDDEN, if the user explicitly defines the <code>output_size</code> property of the <code>sensor</code> configurational parameter in PiGear API.</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>PiGear(resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter controls the framerate of the source.</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>PiGear(framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter controls the colorspace of the output frames. </p> <p>With the Picamera2 backend, you can also define a custom <code>format</code> (format of output frame pixels) in PiGear API. Checkout this bonus example \u27b6</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code> (i.e. Default <code>BGR</code> colorspace). </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are described here \u27b6</p> <pre><code>PiGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/pigear/params/#options","title":"<code>options</code>","text":"<p>This dictionary parameter in the PiGear API allows you to control various camera settings for both the <code>picamera2</code> and legacy <code>picamera</code> backends and some internal API tasks. These settings include:</p>"},{"location":"gears/pigear/params/#a-configurational-camera-parameters","title":"A. Configurational Camera Parameters","text":"<ul> <li> These parameters are provided by the underlying backend library (depending upon backend in use), and must be applied to the camera system before the camera can be started.</li> <li> These parameter include: Brightness, Contrast, Saturation, Exposure, Colour Temperature, Colour Gains, etc. </li> <li> All supported parameters are listed in this Usage example \u27b6</li> </ul>"},{"location":"gears/pigear/params/#b-user-defined-parameters","title":"B. User-defined Parameters","text":"<ul> <li> These user-defined parameters control specific internal behaviors of the API and perform certain tasks on the camera objects.</li> <li> <p> All supported User-defined Parameters are listed below:</p> <ul> <li> <p><code>enforce_legacy_picamera</code> (bool): This user-defined boolean parameter, if <code>True</code>, forces the use of the legacy <code>picamera</code> backend in PiGear API, even if the newer <code>picamera2</code> backend is available on the system. It's default value is <code>False</code>. Its usage is as follows:</p> <p>PiGear API will verify if the <code>picamera</code> Python library is installed before enabling the <code>enforce_legacy_picamera</code> parameter.</p> <pre><code>options = {\"enforce_legacy_picamera\": True}  # enforces `picamera` backend \n</code></pre> </li> <li> <p><code>enable_verbose_logs</code> (bool): [<code>picamera2</code> backend only] This <code>picamera2</code> backend specific parameter, if <code>True</code>, will set the logging level to output all debug messages from Picamera2 library. This parameter can be used in conjunction with enabling general logging (<code>logging=True</code>) in the PiGear API for even more granular control over logging output. It's default value is <code>False</code> (meaning only warning message will be outputted). Its usage is as follows:</p> <p>This parameter requires logging to be enabled (i.e. <code>logging=True</code>) in PiGear API, otherwise it will be discarded.</p> <pre><code>options = {\"enable_verbose_logs\": True}  # enables debug logs from `picamera2` backend\n</code></pre> </li> <li> <p><code>auto_align_output_size</code> (bool): [<code>picamera2</code> backend only] The Picamera2 backend in PiGear API has certain hardware restrictions and optimal frame size (or <code>resolution</code>) for efficient processing. Although user-specified frame sizes are allowed, Picamera2 can make minimal adjustments to the configuration if it detects an invalid or inefficient size. This parameter, if <code>True</code>, will request these optimal frame size adjustments from Picamera2. It's default value is <code>False</code> (meaning no changes will be made to user-specified resolution). Its usage is explained in detail below:</p> <p>This parameter may override any invalid or inefficient size inputted by user through <code>resolution</code> parameter in PiGear API.</p> <p><pre><code># auto-aligns output resolution to optimal\noptions = {\"auto_align_output_size\": True}\n\n# open pi video stream with user-specified resolution `(808, 606)`\nstream = PiGear(resolution=(808, 606), logging=True, **options).start()\n\n# read frame from stream\nframe = stream.read()\n\n# print final resolution of frame\nprint('width: ', frame.shape[1]) # height: 800 (changed)\nprint('height: ', frame.shape[0]) # height: 606\n# Picamera2 has decided an 800x606 image will be more efficient.\n</code></pre> Explanation: In the example code, Picamera2 adjusts the requested output resolution of <code>(808, 606)</code> to the more efficient <code>(800, 606)</code> size.</p> </li> <li> <p><code>HWFAILURE_TIMEOUT</code> (float): PiGear API provides a Threaded Internal Timer that silently keeps track of any frozen threads/hardware failures and exits safely if any occur at a timeout value. This parameter controls the timeout value, which is the maximum waiting time (in seconds) after which API exits itself with a <code>SystemError</code> to save resources. Its value can only be set between <code>1.0</code> (min) and <code>10.0</code> (max), with a default value of <code>2.0</code>. Its usage is as follows:</p> <pre><code>options = {\"HWFAILURE_TIMEOUT\": 2.5}  # sets timeout to 2.5 seconds\n</code></pre> </li> </ul> </li> </ul> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>The complete usage example demonstrating the usage of the <code>options</code> parameter is available here \u27b6.</p> <p>You can format these user-defined and configurational parameters as attributes of this <code>options</code> dictionary parameter as follows:</p> New Picamera2 backendLegacy Picamera backend <pre><code># formulate various Picamera2 API parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"exposure_compensation\": 15,\n    \"sensor\": {\"output_size\": (480, 320)},  # !!! will override `resolution` !!!\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <pre><code># formulate various Picamera API parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>PiGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>PiGear(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/","title":"Usage Examples","text":""},{"location":"gears/pigear/usage/#pigear-api-usage-examples","title":"PiGear API Usage Examples:","text":"<p>PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this API, otherwise nothing will work.</p> <p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/pigear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with PiGear API:</p> Under the hood, PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, PiGear API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> Disabling common <code>libcamera</code> API messages in silent mode. <p>The picamera2 backend can be a bit verbose with logging messages from the underlying <code>libcamera</code> library, even when logging is disabled (<code>logging=False</code>) in the PiGear API. </p> <ul> <li> To suppress these messages, you'll need to set <code>LIBCAMERA_LOG_LEVELS=2</code> environment variable before running your application. This will disable common <code>libcamera</code> API messages, keeping your console output cleaner.</li> <li> This can be done on various Operating Systems as follows:</li> </ul>  Linux Windows (Powershell) MacOS <pre><code>export LIBCAMERA_LOG_LEVELS=2\n</code></pre> <pre><code>$Env:LIBCAMERA_LOG_LEVELS=2\n</code></pre> <pre><code>export LIBCAMERA_LOG_LEVELS=2\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# open stream with default parameters\nstream = PiGear().start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/#using-pigear-with-variable-camera-properties","title":"Using PiGear with Variable Camera Properties","text":"New Picamera2 backendLegacy Picamera backend <p>PiGear provides a user-friendly interface for the underlying picamera2 library, offering access to almost all of its important configurational parameters. It simplifies configuration for developers with even basic knowledge of Raspberry Pi camera modules, allowing them to easily configure and control the camera functionality with just a few lines of code.</p> <p>This example doc showcases the capabilities of PiGear and demonstrates how it simplifies camera configuration with Picamera2 API backend.</p> All supported Picamera2 Library Configurational Parameters [IMPORTANT] <p>Following are the list of Picamera2 parameters, i.e. if supported, can be applied to the source stream in PiGear API through its <code>options</code> dictionary parameter by formatting them as its attributes.</p> Few Important points <ul> <li>These PiCamera2 parameters must be formatted as PiGear API's <code>options</code> dictionary parameter keys, and their values MUST strictly adhere to the specified data types (see table below). If the values do not follow the specified data types, they will be discarded.</li> <li>PiGear API only defines the default <code>main</code> stream configuration that is delivered to the PiCamera2 API. You CANNOT define other streams (such as <code>lores</code>, <code>raw</code>) manually.</li> <li>The <code>FrameDuration</code> and <code>FrameDurationLimits</code> properties of <code>control</code> configurational parameter are NOT supported and will be discarded, since camera FPS is handled by <code>framerate</code> parameter in PiGear API. </li> <li>The <code>resolution</code> parameter will be OVERRIDDEN, if the user explicitly defines the <code>output_size</code> property of the <code>sensor</code> configurational parameter in PiGear API.</li> </ul> Parameters Datatype Description Supported Supported on USB Cameras Remarks <code>buffer_count</code> <code>int</code>, <code>&gt;=1</code> number of sets of buffers to allocate for the camera system Read Docs here \u27b6 <code>queue</code> <code>bool</code> whether the system is allowed to queue up a frame ready for a capture request Read Docs here \u27b6 <code>controls</code> <code>dict</code> specify a set of runtime controls that can be regarded as part of the camera configuration Read Docs here \u27b6 <code>sensor</code> <code>dict</code> allow to select a particular mode of operation for the sensor Read Docs here \u27b6 <code>format</code> <code>str</code> Pixel formats Read Docs here \u27b6 and see Bonus example \u27b6 <code>transform</code> <code>Transform</code><sup>1</sup> The 2D plane transform that is applied to all images from all the configured streams. Read Docs here \u27b6 <code>colour_space</code> colour space of the output images Handled by <code>colorspace</code> parameter of PiGear API <code>size</code> A tuple of two values giving the width and height of the output image. (Both numbers should be no less than 64) Handled by <code>resolution</code>  parameter of PiGear API <code>display</code> name of the stream that will be displayed in the preview window. Not-Required <code>encode</code> name of the stream that will be used for video recording. Not-Required Limited support for USB Cameras <p>This example also works with USB Cameras, However:</p> <ul> <li>Users should assume that features such as: Camera controls (<code>\"controls\"</code>), Transformations (<code>\"transform\"</code>), Queue (<code>\"queue\"</code>) , and Buffer Count (<code>\"buffer_count\"</code>) that are supported on Raspberry Pi cameras, and so forth, are not available on USB Cameras. </li> <li>Hot-plugging of USB cameras is also NOT supported - PiGear API should be completely shut down and restarted when cameras are added or removed.</li> </ul> Enabling verbose logs for backend PiCamera2 Library <p>The PiGear API allows you to enable more detailed logging from the <code>picamera2</code> backend library using the <code>enable_verbose_logs</code> user-defined optional parameter attribute. This can be used in conjunction with enabling general logging (<code>logging=True</code>) in the PiGear API for even more granular control over logging output.</p> <p>PiGear also support changing parameter at runtime. Checkout this bonus example here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"sensor\": {\"output_size\": (480, 320)},  # !!! will override `resolution` !!!\n    \"auto_align_output_size\": True,  # auto-align output size\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>PiGear API switches to the legacy <code>picamera</code>backend if the <code>picamera2</code> library is unavailable.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <p>PiGear also supports almost every parameter available within <code>picamera</code> python library. These parameters can be easily applied to the source stream in PiGear API through its <code>options</code> dictionary parameter by formatting them as its attributes. The complete usage example is as follows:</p> <p>All supported parameters are listed in PiCamera Docs \u27b6</p> <p>PiGear also support changing parameter at runtime. Checkout this bonus example here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# formulate various Picamera API \n# configurational parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/#using-pigear-with-direct-colorspace-manipulation","title":"Using PiGear with Direct Colorspace Manipulation","text":"<p>PiGear API also supports Direct Colorspace Manipulation, which is ideal for changing source colorspace on the run. </p> <p>A more detailed  information on colorspace manipulation can be found here \u27b6</p> <p>In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY  colorspace when W key is pressed, and then LAB colorspace when E key is pressed, finally default colorspace (i.e. BGR) when S key is pressed. Also, quit when Q key is pressed:</p> <p>Any incorrect or None-Type value will immediately revert the colorspace to default (i.e. <code>BGR</code>).</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# open pi video stream with defined parameters and change colorspace to `HSV`\nstream = PiGear(\n    resolution=(640, 480),\n    framerate=60,\n    colorspace=\"COLOR_BGR2HSV\",\n    logging=True\n).start()\n\n\n# loop over\nwhile True:\n\n    # read HSV frames\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the HSV frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n\n    # check if 'w' key is pressed\n    if key == ord(\"w\"):\n        # directly change colorspace at any instant\n        stream.color_space = cv2.COLOR_BGR2GRAY  # Now colorspace is GRAY\n\n    # check for 'e' key is pressed\n    if key == ord(\"e\"):\n        stream.color_space = cv2.COLOR_BGR2LAB  # Now colorspace is CieLAB\n\n    # check for 's' key is pressed\n    if key == ord(\"s\"):\n        stream.color_space = None  # Now colorspace is default(ie BGR)\n\n    # check for 'q' key is pressed\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/#using-pigear-with-writegear-api","title":"Using PiGear with WriteGear API","text":"<p>PiGear can be easily used with WriteGear API directly without any compatibility issues. The suitable example is as follows:</p> New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import WriteGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"sensor\": {\"output_size\": (480, 320)},  # will override `resolution`\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # write gray frame to writer\n    writer.write(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> PiGear API switches to the legacy <code>picamera</code>backend if the <code>picamera2</code> library is unavailable. <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# formulate various Picamera API \n# configurational parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # write gray frame to writer\n    writer.write(gray)\n\n   # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <ol> <li> <p>A custom <code>libcamera</code> API class. Must be imported as <code>from libcamera import Transform</code>.\u00a0\u21a9</p> </li> </ol>"},{"location":"gears/screengear/overview/","title":"Overview","text":""},{"location":"gears/screengear/overview/#screengear-api","title":"ScreenGear API","text":"ScreenGear API in action"},{"location":"gears/screengear/overview/#overview","title":"Overview","text":"<p>ScreenGear is designed exclusively for targeting rapid Screencasting Capabilities, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends.</p> <p>ScreenGear API implements a multi-threaded wrapper around dxcam, pyscreenshot &amp; python-mss python library, and also flexibly supports its internal parameter. </p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/screengear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/screengear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/screengear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/screengear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/screengear/params/","title":"Parameters","text":""},{"location":"gears/screengear/params/#screengear-api-parameters","title":"ScreenGear API Parameters","text":""},{"location":"gears/screengear/params/#monitor","title":"<code>monitor</code>","text":"<p>This parameter enforces <code>dxcam</code> (if installed) and <code>mss</code> (otherwise) usage, and it is suitable for selecting index of a specific screen/monitor device (from where you want retrieve frames) in multi-monitor setup. For example, its value can be assign to <code>2</code>, to fetch frames from a secondary monitor screen.</p> <p>Implication of using <code>monitor</code> parameter</p> <p>Any value on <code>monitor</code> parameter other than <code>None</code> in ScreenGear API: </p> <ul> <li>Will enforce <code>dxcam</code> library backend on Windows platform (if installed), and <code>mss</code> library backend otherwise.</li> <li>Will discard any value on its <code>backend</code> parameter.</li> </ul> <p>Data-Type: Integer, Tuple (only if <code>dxcam</code> backend on Windows)</p> <p>Default Value: Its default value is <code>None</code> (i.e. disabled by default).</p> <p>Usage:</p> With <code>dxcam</code> on Windows With <code>mss</code> backend  Using GPU acceleration on Windows  <p>With  <code>dxcam</code> library backend, you can also assign which GPU devices ids to use along with monitor device ids as tuple <code>(monitor_idx, gpu_idx)</code>, as follows:</p> <pre><code># open video stream with defined parameters with \n# monitor at index `1` and GPU at index `0`.\nstream = ScreenGear(monitor=(1,0), logging=True).start()\n</code></pre> <p>Getting a complete list of monitor devices and GPUs</p> <p>To get a complete list of monitor devices and outputs(GPUs), you can use <code>dxcam</code> library itself: <pre><code>&gt;&gt;&gt; import dxcam\n&gt;&gt;&gt; dxcam.device_info()\n'Device[0]:&lt;Device Name:NVIDIA GeForce RTX 3090 Dedicated VRAM:24348Mb VendorId:4318&gt;\\n'\n&gt;&gt;&gt; dxcam.output_info()\n'Device[0] Output[0]: Res:(1920, 1080) Rot:0 Primary:True\\nDevice[0] Output[1]: Res:(1920, 1080) Rot:0 Primary:False\\n'\n</code></pre></p> <pre><code># open video stream with defined parameters \n# with monitor at index `1` selected\nScreenGear(monitor=1)\n</code></pre> <p>With <code>mss</code> library backend, You can also assign <code>monitor</code> value to <code>-1</code> to fetch frames from all connected multiple monitor screens with <code>mss</code> backend.</p> <p>With <code>mss</code> library backend, API will output <code>BGRA</code> colorspace frames instead of default <code>BGR</code>.</p> <pre><code># open video stream with defined parameters \n# with monitor at index `1` selected\nScreenGear(monitor=1)\n</code></pre> <p> </p>"},{"location":"gears/screengear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter enables <code>pyscreenshot</code> usage and select suitable backend for extracting frames in ScreenGear. The user have the authority of selecting suitable backend which generates best performance as well as the most compatible with their machines. The possible values are: <code>dxcam</code> (Windows only), <code>pil</code>, <code>mss</code>, <code>scrot</code>, <code>maim</code>, <code>imagemagick</code>, <code>pyqt5</code>, <code>pyqt</code>, <code>pyside2</code>, <code>pyside</code>, <code>wx</code>, <code>pygdk3</code>, <code>mac_screencapture</code>, <code>mac_quartz</code>, <code>gnome_dbus</code>, <code>gnome-screenshot</code>, <code>kwin_dbus</code>. </p> <p>Performance Benchmarking of all backend can be found here \u27b6 and here \u27b6</p> <p>Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API.</p> <p>Any value on <code>monitor</code> parameter will disable the <code>backend</code> parameter. You cannot use both parameters at same time.</p> <p>Backend defaults to <code>dxcam</code> library on Windows (if installed), and <code>pyscreenshot</code> otherwise.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>\"\"</code> (i.e. default backend).</p> <p>Usage:</p> <pre><code>ScreenGear(backend=\"pil\") # to enforce `pil` as backend for extracting frames.\n</code></pre> <p> </p>"},{"location":"gears/screengear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6.</p> <pre><code>ScreenGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/screengear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the flexibility to manually set the dimensions of capture screen area. </p> <p>Supported Dimensional Attributes</p> <p>ScreenGear API takes <code>left</code>, <code>top</code>, <code>width</code>, <code>height</code> coordinates of the bounding box of capture screen area(ROI), similar to PIL.ImageGrab.grab, defined below:</p> <p></p> <ul> <li><code>left</code>: the x-coordinate of the upper-left corner of the region</li> <li><code>top</code>: the y-coordinate of the upper-left corner of the region</li> <li><code>width</code>: the width of the complete region from left to the bottom-right corner of the region.</li> <li><code>height</code>: the height of the complete region from top to the bottom-right corner of the region.</li> </ul> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>The desired dimensional coordinates parameters can be passed to ScreenGear API by formatting them as attributes, as follows:</p> <pre><code># formatting dimensional parameters as dictionary attributes\noptions = {'top': 40, 'left': 0, 'width': 100, 'height': 100}\n# assigning it\nScreenGear(**options)\n</code></pre> <p> </p>"},{"location":"gears/screengear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>ScreenGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/","title":"Usage Examples","text":""},{"location":"gears/screengear/usage/#screengear-api-usage-examples","title":"ScreenGear API Usage Examples:","text":"<p>After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p>Recommended: Install DXcam library on Windows  Machines</p> <p>On Windows Machines, if installed, ScreenGear API uses <code>dxcam</code> backend machines for higher FPS performance. Thereby, it is highly recommended to install it via pip as follows:</p> <pre><code>pip install dxcam\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with ScreenGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# open video stream with default parameters\nstream = ScreenGear().start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-variable-screen-dimensions","title":"Using ScreenGear with Variable Screen Dimensions","text":"<p>ScreenGear API provides us the flexibility to directly set the dimensions of capturing-area of the screen. These dimensions can be easily applied to ScreenGear API through its <code>options</code> dictionary parameter by formatting them as its attributes. </p> Supported Dimensional Attributes <p>ScreenGear API takes <code>left</code>, <code>top</code>, <code>width</code>, <code>height</code> coordinates of the bounding box of capture screen area(ROI), similar to PIL.ImageGrab.grab, defined below:</p> <p></p> <ul> <li><code>left</code>: the x-coordinate of the upper-left corner of the region</li> <li><code>top</code>: the y-coordinate of the upper-left corner of the region</li> <li><code>width</code>: the width of the complete region from left to the bottom-right corner of the region.</li> <li><code>height</code>: the height of the complete region from top to the bottom-right corner of the region.</li> </ul> <p>The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# define dimensions of screen w.r.t to given monitor to be captured\noptions = {\"top\": 40, \"left\": 0, \"width\": 100, \"height\": 100}\n\n# open video stream with defined parameters\nstream = ScreenGear(logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-multiple-screens","title":"Using ScreenGear with Multiple Screens","text":"<p>ScreenGear API provides us the flexibility to select any connected display for fetching frames, with its <code>monitor</code> parameter:</p> <p>Implication of using <code>monitor</code> parameter</p> <p>Any value on <code>monitor</code> parameter other than <code>None</code> in ScreenGear API: </p> <ul> <li>Will enforce <code>dxcam</code> library backend on Windows platform (if installed), and <code>mss</code> library backend otherwise.</li> <li>Will discard any value on its <code>backend</code> parameter.</li> </ul> With <code>dxcam</code> on Windows With <code>mss</code> backend  Using GPU acceleration on Windows  <p>With  <code>dxcam</code> library backend, you can also assign which GPU devices ids to use along with monitor device ids as tuple <code>(monitor_idx, gpu_idx)</code>, as follows:</p> <pre><code># open video stream with defined parameters with \n# monitor at index `1` and GPU at index `0`.\nstream = ScreenGear(monitor=(1,0), logging=True).start()\n</code></pre> <p>Getting a complete list of monitor devices and GPUs</p> <p>To get a complete list of monitor devices and outputs(GPUs), you can use <code>dxcam</code> library itself: <pre><code>&gt;&gt;&gt; import dxcam\n&gt;&gt;&gt; dxcam.device_info()\n'Device[0]:&lt;Device Name:NVIDIA GeForce RTX 3090 Dedicated VRAM:24348Mb VendorId:4318&gt;\\n'\n&gt;&gt;&gt; dxcam.output_info()\n'Device[0] Output[0]: Res:(1920, 1080) Rot:0 Primary:True\\nDevice[0] Output[1]: Res:(1920, 1080) Rot:0 Primary:False\\n'\n</code></pre></p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# open video stream with defined parameters with monitor at index `1` selected\nstream = ScreenGear(monitor=1, logging=True).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>With <code>mss</code> library backend, You can also assign <code>monitor</code> value to <code>-1</code> to fetch frames from all connected multiple monitor screens with <code>mss</code> backend.</p> <p>With <code>mss</code> library backend, API will output <code>BGRA</code> colorspace frames instead of default <code>BGR</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# open video stream with defined parameters with monitor at index `1` selected\nstream = ScreenGear(monitor=1, logging=True).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-variable-backend","title":"Using ScreenGear with Variable Backend","text":"<p>With ScreenGear API, you can select from many different backends that generates best performance as well as the most compatible with our machine by employing its <code>backend</code> parameter that supports many different backends:</p> Supported <code>backend</code> values <p>Its possible values are: <code>dxcam</code> (Windows only), <code>pil</code>, <code>mss</code>, <code>scrot</code>, <code>maim</code>, <code>imagemagick</code>, <code>pyqt5</code>, <code>pyqt</code>, <code>pyside2</code>, <code>pyside</code>, <code>wx</code>, <code>pygdk3</code>, <code>mac_screencapture</code>, <code>mac_quartz</code>, <code>gnome_dbus</code>, <code>gnome-screenshot</code>, <code>kwin_dbus</code>. </p> <p>Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. More information on all these backends (except <code>dxcam</code>) can be found here \u27b6</p> <p>Backend defaults to <code>dxcam</code> library on Windows (if installed), and <code>pyscreenshot</code> otherwise.</p> <p>Any value on <code>monitor</code> parameter will disable the <code>backend</code> parameter. You cannot use them simultaneously.</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# open video stream with defined parameters and `mss` backend \n# for extracting frames.\nstream = ScreenGear(backend=\"mss\", logging=True).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-direct-colorspace-manipulation","title":"Using ScreenGear with Direct Colorspace Manipulation","text":"<p>ScreenGear API also supports Direct Colorspace Manipulation, which is ideal for changing source colorspace on the run. </p> <p>A more detailed  information on colorspace manipulation can be found here \u27b6</p> <p>In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY  colorspace when W key is pressed, and then LAB colorspace when E key is pressed, finally default colorspace (i.e. BGR) when S key is pressed. Also, quit when Q key is pressed:</p> <p>Any incorrect or None-type value, will immediately revert the colorspace to default i.e. <code>BGR</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# Change colorspace to `HSV`\nstream = ScreenGear(colorspace=\"COLOR_BGR2HSV\", logging=True).start()\n\n# loop over\nwhile True:\n\n    # read HSV frames\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the HSV frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n\n    # check if 'w' key is pressed\n    if key == ord(\"w\"):\n        # directly change colorspace at any instant\n        stream.color_space = cv2.COLOR_BGR2GRAY  # Now colorspace is GRAY\n\n    # check for 'e' key is pressed\n    if key == ord(\"e\"):\n        stream.color_space = cv2.COLOR_BGR2LAB  # Now colorspace is CieLAB\n\n    # check for 's' key is pressed\n    if key == ord(\"s\"):\n        stream.color_space = None  # Now colorspace is default(ie BGR)\n\n    # check for 'q' key is pressed\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-writegear-api","title":"Using ScreenGear with WriteGear API","text":"<p>ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n\n# define dimensions of screen w.r.t to given monitor to be captured\noptions = {\"top\": 40, \"left\": 0, \"width\": 100, \"height\": 100}\n\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n\n# open video stream with defined parameters\nstream = ScreenGear(monitor=1, logging=True, **options).start()\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # write gray frame to writer\n    writer.write(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/overview/","title":"Overview","text":""},{"location":"gears/stabilizer/overview/#stabilizer-class","title":"Stabilizer Class","text":"<p>VidGear's Stabilizer in Action(Video Credits @SIGGRAPH2013)</p> <p>This video is transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com</p>"},{"location":"gears/stabilizer/overview/#overview","title":"Overview","text":"<p>Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. </p> <p>The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies on Fixed-Size Python Queues for error-free &amp; ultra-fast frame handling. </p> <p>For more detailed information on Stabilizer working, See this blogpost \u27b6</p> <p> </p>"},{"location":"gears/stabilizer/overview/#features","title":"Features","text":"<ul> <li> <p> Real-time stabilization with low latency and no extra resources.</p> </li> <li> <p> Works exceptionally well with low-frequency jitter.</p> </li> <li> <p> Integrated with VideoGear, therefore, can be applied to any incoming stream.</p> </li> <li> <p> Also seamlessly works standalone.</p> </li> </ul> <p> </p> <p>Important</p> <ul> <li> <p>The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk!</p> </li> <li> <p> The stabilizer might be slower for High-Quality videos-frames.</p> </li> <li> <p>It is advised to enable logging on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/stabilizer/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/stabilizer/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/stabilizer/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/stabilizer/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/stabilizer/params/","title":"Parameters","text":""},{"location":"gears/stabilizer/params/#stabilizer-class-parameters","title":"Stabilizer Class Parameters","text":""},{"location":"gears/stabilizer/params/#smoothing_radius","title":"<code>smoothing_radius</code>","text":"<p>This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>25</code>. </p> <p>Usage: </p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(smoothing_radius=30)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#border_size","title":"<code>border_size</code>","text":"<p>This parameter enables and set the value for extended border size that compensates for reduction of black borders during stabilization. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>(no borders).</p> <p>Usage:</p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(border_size=10)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#crop_n_zoom","title":"<code>crop_n_zoom</code>","text":"<p>This parameter enables cropping and zooming of frames (to original size) to reduce the black borders from being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) during stabilization. It simply works in conjunction with the <code>border_size</code> parameter, i.e. when this parameter is enabled,  <code>border_size</code> will be used for cropping border instead of extending them. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(border_size=10, crop_n_zoom=True)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#border_type","title":"<code>border_type</code>","text":"<p>This parameter can be used to change the extended border type. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. </p> <p>Altering <code>border_type</code> parameter is DISABLED when <code>crop_n_zoom</code> is enabled!</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'black'</code>.</p> <p>Usage:</p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(border_type='reflect')\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>Stabilizer(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/","title":"Usage Examples","text":""},{"location":"gears/stabilizer/usage/#stabilizer-class-usage-examples","title":"Stabilizer Class Usage Examples:","text":"<p>The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk!</p> <p>The stabilizer might be slower  for High-Quality/Resolution  videos-frames.</p> <p>It is advised to enable logging on the first run for easily identifying any runtime errors.</p> <p>After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p> <p> </p>"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-videocapture-gears","title":"Bare-Minimum Usage with VideoCapture Gears","text":"<p>Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears:</p> <p>You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example.</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nfrom vidgear.gears import CamGear\nimport cv2\n\n# To open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n\n# initiate stabilizer object with default parameters\nstab = Stabilizer()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # send current frame to stabilizer for processing\n    stabilized_frame = stab.stabilize(frame)\n\n    # wait for stabilizer which still be initializing\n    if stabilized_frame is None:\n        continue\n\n    # {do something with the stabilized frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Stabilized Frame\", stabilized_frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# clear stabilizer resources\nstab.clean()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV:</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n\n# initiate stabilizer object with default parameters\nstab = Stabilizer()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # send current frame to stabilizer for processing\n    stabilized_frame = stab.stabilize(frame)\n\n    # wait for stabilizer which still be initializing\n    if stabilized_frame is None:\n        continue\n\n    # {do something with the stabilized frame here}\n\n    # Show output window\n    cv2.imshow(\"Stabilized Frame\", stabilized_frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# clear stabilizer resources\nstab.clean()\n\n# safely close video stream\nstream.release()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-variable-parameters","title":"Using Stabilizer with Variable Parameters","text":"<p>Stabilizer class provide certain parameters which you can use to tweak its internal properties. The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nfrom vidgear.gears import CamGear\nimport cv2\n\n# To open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n\n# initiate stabilizer object with defined parameters\nstab = Stabilizer(smoothing_radius=30, crop_n_zoom=True, border_size=5, logging=True)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # send current frame to stabilizer for processing\n    stabilized_frame = stab.stabilize(frame)\n\n    # wait for stabilizer which still be initializing\n    if stabilized_frame is None:\n        continue\n\n    # {do something with the stabilized frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Stabilized Frame\", stabilized_frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# clear stabilizer resources\nstab.clean()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-writegear","title":"Using Stabilizer with WriteGear","text":"<p>VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows:</p> <p>You can also add live audio input to WriteGear pipeline. See this bonus example  \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open suitable video stream\nstream = CamGear(source=\"unstabilized_stream.mp4\").start()\n\n# initiate stabilizer object with default parameters\nstab = Stabilizer()\n\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if not None-type\n    if frame is None:\n        break\n\n    # send current frame to stabilizer for processing\n    stabilized_frame = stab.stabilize(frame)\n\n    # wait for stabilizer which still be initializing\n    if stabilized_frame is None:\n        continue\n\n    # {do something with the stabilized frame here}\n\n    # write stabilized frame to writer\n    writer.write(stabilized_frame)\n\n    # Show output window\n    cv2.imshow(\"Stabilized Frame\", stabilized_frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# clear stabilizer resources\nstab.clean()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#using-videogear-with-stabilizer-backend","title":"Using VideoGear with Stabilizer backend","text":"<p>VideoGear API provides a special internal wrapper around Stabilizer class that enables easy stabilization for various video-streams (real-time or not)  with minimum effort and writing way fewer lines of code.</p> <p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/","title":"FFmpeg Installation","text":""},{"location":"gears/streamgear/ffmpeg_install/#ffmpeg-installation-instructions","title":"FFmpeg Installation Instructions","text":"<p>StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation:</p> <p>StreamGear API will throw RuntimeError, if it fails to detect valid FFmpeg executables on your system.</p> <p>Enable logging (<code>logging=True</code>) for debugging FFmpeg validation process.</p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/#linux-ffmpeg-installation","title":"Linux FFmpeg Installation","text":"<p>The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:</p>"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection","title":"A. Auto-Detection","text":"<p>This is a recommended approach on Linux Machines</p> <p>If StreamGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module. </p> <p>Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6</p>"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Linux Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Linux Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>)  or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the StreamGear API.</p> <p>If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/#windows-ffmpeg-installation","title":"Windows FFmpeg Installation","text":"<p>The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems.</p>"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-installation","title":"A. Auto-Installation","text":"<p>This is a recommended approach on Windows Machines</p> <p>If StreamGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. <code>C:\\Temp</code>) of your machine.</p> <p>Warning</p> <ul> <li> <p>The files downloaded to temporary directory (for e.g. <code>C:\\TEMP</code>), may get erased if your machine shutdowns/restarts.</p> </li> <li> <p>You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through <code>-ffmpeg_download_path</code> parameter.</p> </li> <li> <p>If binaries were found at the specified path, StreamGear automatically skips the auto-installation step.</p> </li> <li> <p>If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError!</p> </li> </ul>"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_1","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Windows Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Windows Static Binaries: https://ffmpeg.org/download.html#build-windows</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'C:/foo/Downloads/ffmpeg/bin'</code>) or path of <code>ffmpeg.exe</code> executable itself to the <code>custom_ffmpeg</code> parameter in the StreamGear API.</p> <p>If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/#macos-ffmpeg-installation","title":"MacOS FFmpeg Installation","text":"<p>The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.</p>"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection_1","title":"A. Auto-Detection","text":"<p>This is a recommended approach on MacOS Machines</p> <p>If StreamGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module.</p> <p>Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6</p>"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_2","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest macOS Static Binaries(only x64 Binaries) from the link below:</p> <p>MacOS Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>) or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the StreamGear API.</p> <p>If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError!</p> </li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/","title":"Introduction","text":""},{"location":"gears/streamgear/introduction/#streamgear-api","title":"StreamGear API","text":"StreamGear API's generalized workflow"},{"location":"gears/streamgear/introduction/#overview","title":"Overview","text":"<p>StreamGear streamlines and simplifies the transcoding workflow to generate Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats like MPEG-DASH and Apple HLS with just a few lines of Python code, allowing developers to focus on their application logic rather than dealing with the complexities of transcoding and chunking media files.</p> <p>StreamGear API provides a standalone, highly extensible, and flexible wrapper around the FFmpeg multimedia framework for generating chunk-encoded media segments from your multimedia content effortlessly.</p> <p>With StreamGear, you can transcode source video/audio files and real-time video frames into a sequence of multiple smaller chunks/segments of suitable lengths. These segments facilitate streaming at different quality levels (bitrates or spatial resolutions) and allow for seamless switching between quality levels during playback based on available bandwidth. You can serve these segments on a web server, making them easily accessible via standard HTTP GET requests.</p> <p>SteamGear currently supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)  and Apple HLS (HTTP Live Streaming). </p> <p>Additionally, StreamGear generates a manifest file (such as MPD for DASH) or a master playlist (such as M3U8 for Apple HLS) alongside the segments. These files contain essential segment information, including timing, URLs, and media characteristics like video resolution and adaptive bitrate. They are provided to the client before the streaming session begins.</p> <p>For streaming with older traditional protocols such as RTMP, RTSP/RTP you could use WriteGear API instead.</p> <p> </p> New in v0.2.2 <p>Apple HLS support was added in <code>v0.2.2</code>.</p> <p>Important</p> <ul> <li> <p>StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation.</p> </li> <li> <p> StreamGear API will throw RuntimeError, if it fails to detect valid FFmpeg executable on your system.</p> </li> <li> <p>It is advised to enable logging (<code>logging=True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p>Useful Links</p> <ul> <li>Checkout this detailed blogpost \u27b6 on how MPEG-DASH works.</li> <li>Checkout this detailed blogpost \u27b6 on how HLS works.</li> <li>Checkout this detailed blogpost \u27b6 for HLS vs. MPEG-DASH comparison.</li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/#mode-of-operations","title":"Mode of Operations","text":"<p>StreamGear primarily operates in following independent modes for transcoding:</p> Real-time Frames Mode itself is NOT Live-Streaming  <p>To enable live-streaming in Real-time Frames Mode, use the exclusive <code>-livestream</code> attribute of the <code>stream_params</code> dictionary parameter in the StreamGear API. Checkout this usage example \u27b6 for more information.</p> <ul> <li> <p>Single-Source Mode  : In this mode, StreamGear transcodes entire video file (as opposed to frame-by-frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) for streaming that required no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. </p> </li> <li> <p>Real-time Frames Mode  : In this mode, StreamGear directly transcodes frame-by-frame (as opposed to a entire video file), into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform <code>numpy.ndarray</code> frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, audio has to added manually (as separate source) for streams. </p> </li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/#watch-demo","title":"Watch Demo","text":"Watch MPEG-DASH StreamWatch APPLE HLS Stream <p>Watch StreamGear transcoded MPEG-DASH Stream:</p> <p> <p>Powered by clappr &amp; shaka-player</p></p> <p>This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com</p> <p>Video Credits: \"Tears of Steel\" - Project Mango Teaser</p> <p>Watch StreamGear transcoded APPLE HLS Stream:</p> <p> <p>Powered by clappr &amp; HlsjsPlayback</p></p> <p>This video assets (Playlist and segments) are hosted on GitHub Repository and served with raw.githack.com</p> <p>Video Credits: \"Sintel\" - Project Durian Teaser</p> <p> </p>"},{"location":"gears/streamgear/introduction/#recommended-players","title":"Recommended Players","text":"GUI PlayersCommand-Line PlayersOnline Players <ul> <li> MPV Player: (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. </li> <li> VLC Player: VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols.</li> <li> Parole: (UNIX only)  Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems. </li> </ul> <ul> <li> MP4Client: GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains.</li> <li> ffplay: FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs. </li> </ul> <p>To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list  \u27b6</p> <ul> <li> Clapper: Clappr is an extensible media player for the web.</li> <li> Shaka Player: Shaka Player is an open-source JavaScript library for playing adaptive media in a browser.</li> <li> MediaElementPlayer: MediaElementPlayer is a complete HTML/CSS audio/video player.</li> <li> Native MPEG-Dash + HLS Playback(Chrome Extension): Allow the browser to play HLS (m3u8) or MPEG-Dash (mpd) video urls 'natively' on chrome browsers.</li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/introduction/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/introduction/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/params/","title":"Parameters","text":""},{"location":"gears/streamgear/params/#streamgear-api-parameters","title":"StreamGear API Parameters","text":""},{"location":"gears/streamgear/params/#output","title":"<code>output</code>","text":"<p>This parameter sets the valid filename/path for storing the StreamGear assets, including Manifest file (such as MPD in case of DASH) or a Master Playlist (such as M3U8 in case of Apple HLS) and generated sequence of chunks/segments.</p> <p>StreamGear API will throw <code>ValueError</code> if the provided <code>output</code> is empty or invalid.</p> <p>Make sure to provide a valid filename with a valid file extension for the selected <code>format</code> value (such as <code>.mpd</code> for MPEG-DASH and <code>.m3u8</code> for APPLE-HLS), otherwise StreamGear will throw <code>AssertionError</code>.</p> <p>You can easily delete all previous assets at the <code>output</code> location by using the <code>-clear_prev_assets</code> attribute of the <code>stream_params</code> dictionary parameter.</p> <p>Data-Type: String</p> <p>Usage:</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p>Path to directory: Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for the Manifest file. This can be defined as follows:</p> DASHHLS <pre><code># Define streamer with output directory path for saving DASH assets \nstreamer = StreamGear(output = \"/home/foo/bar\") \n</code></pre> <pre><code># Define streamer with output directory path for saving HLS assets\nstreamer = StreamGear(output = \"/home/foo/bar\", format=\"hls\")  \n</code></pre> </li> <li> <p>Filename (with/without path): Valid filename (with a valid extension) of the output Manifest or Playlist file. If the filename is provided without a path, the current working directory will be used. This can be defined as follows:</p> DASHHLS <pre><code># Define streamer with output manifest filename\nstreamer = StreamGear(output = \"output_dash.mpd\") \n</code></pre> <pre><code># Define streamer with output playlist filename\nstreamer = StreamGear(output = \"output_hls.m3u8\", format=\"hls\") \n</code></pre> </li> <li> <p>URL: Valid URL of a network stream with a protocol supported by the installed FFmpeg (verify with the <code>ffmpeg -protocols</code> command). This is useful for directly storing assets to a network server. For example, you can use an <code>HTTP</code> protocol URL as follows:</p> DASHHLS <pre><code># Define streamer with output manifest URL\nstreamer = StreamGear(output = \"http://some_dummy_serverip/live/output_dash.mpd\") \n</code></pre> <pre><code># Define streamer with output playlist URL\nstreamer = StreamGear(output = \"http://some_dummy_serverip/live/output_hls.m3u8\", format=\"hls\")\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/streamgear/params/#format","title":"<code>format</code>","text":"<p>This parameter enables the adaptive HTTP streaming format. This parameter currently supported these formats: <code>dash</code> (i.e MPEG-DASH) and <code>hls</code> (i.e Apple HLS).</p> <p>Make sure to provide a valid filename with a valid file extension in the <code>output</code> parameter for the selected <code>format</code> value (i.e., <code>.mpd</code> for MPEG-DASH and <code>.m3u8</code> for APPLE-HLS), otherwise StreamGear will throw an <code>AssertionError</code>.</p> <p>Any improper value assigned to <code>format</code> parameter will result in a <code>ValueError</code>!</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>dash</code></p> <p>Usage:</p> DASHHLS <pre><code># Define streamer with DASH format\nStreamGear(output = \"output_dash.mpd\", format=\"dash\")\n</code></pre> <pre><code># Define streamer with HLS format\nStreamGear(output = \"output_hls.m3u8\", format=\"hls\")\n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located.</p> <p>Behavior on  Windows Systems</p> <p>On Windows, if a custom FFmpeg executable's path/directory is not provided through this <code>custom_ffmpeg</code> parameter, the StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at a suitable location on your Windows machine. More information can be found here \u27b6.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># Define streamer with custom ffmpeg binary\nStreamGear(output = 'output_foo.mpd', custom_ffmpeg=\"C://foo//bar//ffmpeg.exe\")\n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#stream_params","title":"<code>stream_params</code>","text":"<p>This parameter allows developers to leverage nearly all FFmpeg options, providing effortless and flexible control over its internal settings for transcoding and generating high-quality streams. All supported parameters can be formatted as attributes within this dictionary parameter.</p> <p>Please read the FFmpeg Documentation carefully before passing any additional values to the <code>stream_params</code> parameter. Incorrect values may cause errors or result in no output.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p>"},{"location":"gears/streamgear/params/#supported-parameters","title":"Supported Parameters","text":""},{"location":"gears/streamgear/params/#a-exclusive-parameters","title":"A. Exclusive Parameters","text":"<p>StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below:</p> <ul> <li> <p><code>-streams</code> (list of dicts): This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrate or spatial resolutions) for streaming. </p> Important Information about <code>-streams</code> attribute  <ul> <li>In addition to the user-defined Secondary Streams, StreamGear automatically generates a Primary Stream (at index <code>0</code>) with the same resolution as the input frames and at default framerate<sup>1</sup>, at the index <code>0</code>. </li> <li>You MUST define the <code>-resolution</code> value for each stream; otherwise, the stream will be discarded.</li> <li>You only need to define either the <code>-video_bitrate</code> or the <code>-framerate</code> for a valid stream. <ul> <li>If you specify the <code>-framerate</code>, the video bitrate will be calculated automatically.</li> <li>If you define both the <code>-video_bitrate</code> and the <code>-framerate</code>, the <code>-framerate</code> will get discard automatically.</li> </ul> </li> </ul> <p>To construct the additional stream dictionaries, you will need the following sub-attributes::</p> <ul> <li> <p><code>-resolution</code> (string): It is compulsory to define the required resolution/dimension/size for the stream, otherwise, the given stream will be rejected. Its value should be in the format <code>\"{width}x{height}\"</code>, as shown below:</p> <pre><code># produce a 1280x720 resolution/scale stream\n\"-streams\" = [{\"-resolution\": \"1280x720\"}]  \n</code></pre> </li> <li> <p><code>-video_bitrate</code> (string): This is an optional sub-attribute (can be ignored if the <code>-framerate</code> parameter is defined) that generally determines the bandwidth and quality of the stream. The higher the bitrate, the better the quality and the larger the bandwidth, which can place more strain on the network. Its value is typically in <code>k</code> (kilobits per second) or <code>M</code> (Megabits per second). Define this attribute as follows:</p> <pre><code># produce a 1280x720 resolution and 2000 kbps bitrate stream\n\"-streams\" : [{\"-resolution\": \"1280x720\", \"-video_bitrate\": \"2000k\"}] \n</code></pre> </li> <li> <p><code>-framerate</code> (float/int): This is another optional sub-attribute (can be ignored if the <code>-video_bitrate</code> parameter is defined) that defines the assumed framerate for the stream. Its value can be a float or integer, as shown below:</p> <pre><code># produce a 1280x720 resolution and 60fps framerate stream\n\"-streams\" : [{\"-resolution\": \"1280x720\", \"-framerate\": \"60.0\"}] \n</code></pre> </li> </ul> <p>Usage: You can easily define any number of streams using <code>-streams</code> attribute as follows:</p> <pre><code>stream_params = \n    {\"-streams\": \n        [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"}, # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30}, # Stream2: 1280x720 at 30fps\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps \n        ]\n    }\n</code></pre> <p>Its usage example can be found here \u27b6</p> </li> </ul> <p> </p> <ul> <li> <p><code>-video_source</code> (string): This attribute takes a valid video path as input and activates Single-Source Mode, for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value can be one of the following:</p> <ul> <li> <p>Video Filename: Valid path to a video file as follows:</p> <pre><code># set video source as `/home/foo/bar.mp4`\nstream_params = {\"-video_source\": \"/home/foo/bar.mp4\"}\n</code></pre> </li> <li> <p>Video URL: Valid URL of a network video stream as follows:</p> <p>Ensure the given video URL uses a protocol supported by the installed FFmpeg (verify with <code>ffmpeg -protocols</code> terminal command).</p> <pre><code># set video source as `http://livefeed.com:5050`\nstream_params = {\"-video_source\": \"http://livefeed.com:5050\"} \n</code></pre> </li> </ul> <p>Its usage example can be found here \u27b6</p> </li> </ul> <p> </p> <ul> <li> <p><code>-audio</code> (string/list): This attribute takes an external custom audio path (as a string) or an audio device name followed by a suitable demuxer (as a list) as the audio source input for all StreamGear streams. Its value can be one of the following:</p> <p>Ensure the provided <code>-audio</code> audio source is compatible with the input video source. Incompatibility can cause multiple errors or result in no output at all.</p> <ul> <li> <p>Audio Filename (string): Valid path to an audio file as follows:</p> <pre><code># set audio source as `/home/foo/foo1.aac`\nstream_params = {\"-audio\": \"/home/foo/foo1.aac\"} \n</code></pre> <p>Its usage examples can be found here \u27b6 and here \u27b6</p> </li> <li> <p>Audio URL (string): Valid URL of a network audio stream as follows:</p> <p>Ensure the given audio URL uses a protocol supported by the installed FFmpeg (verify with <code>ffmpeg -protocols</code> terminal command).</p> <pre><code># set input audio source as `https://exampleaudio.org/example-160.mp3`\nstream_params = {\"-audio\": \"https://exampleaudio.org/example-160.mp3\"} \n</code></pre> </li> <li> <p>Device name and Demuxer (list): Valid audio device name followed by a suitable demuxer as follows:</p> <pre><code># Assign appropriate input audio-source device (compatible with video source) and its demuxer\nstream_params = {\"-audio\":  [\n    \"-f\",\n    \"dshow\",\n    \"-i\",\n    \"audio=Microphone (USB2.0 Camera)\",\n]} \n</code></pre> <p>Its usage example can be found here \u27b6</p> </li> </ul> </li> </ul> <p> </p> <ul> <li> <p><code>-livestream</code> (bool): (optional) specifies whether to enable Low-latency Live-Streaming  in Real-time Frames Mode only, where chunks will contain information for new frames only and forget previous ones, or not. The default value is <code>False</code>. It can be used as follows: </p> <p>The <code>-livestream</code> optional parameter is NOT supported in Single-Source mode.</p> <pre><code>stream_params = {\"-livestream\": True} # enable live-streaming\n</code></pre> <p>Its usage example can be found here \u27b6</p> </li> </ul> <p> </p> <ul> <li> <p><code>-input_framerate</code> (float/int) :  (optional) This parameter specifies the assumed input video source framerate and only works in Real-time Frames Mode. Its default value is <code>25.0</code> fps. Its value can be a float or integer, as shown below:</p> <pre><code># set input video source framerate to 60fps\nstream_params = {\"-input_framerate\": 60.0} \n</code></pre> <p>Its usage example can be found here \u27b6</p> </li> </ul> <p> </p> <ul> <li> <p><code>-bpp</code> (float/int): (optional) This attribute controls the constant BPP (Bits-Per-Pixel) value, which helps ensure good quality in high motion scenes by determining the desired video bitrate for streams. A higher BPP value improves motion quality. The default value is <code>0.1</code>. Increasing the BPP value helps fill the gaps between the current bitrate and the upload limit/ingest cap. Its value can be anything above <code>0.001</code> and can be used as follows:</p> <p>Important points while tweaking BPP</p> <ul> <li>BPP is a sensitive value; start with <code>0.001</code> and make small increments (<code>0.0001</code>) to fine-tune.</li> <li>If your desired resolution/fps/audio combination is below the maximum service bitrate, raise BPP to match it for extra quality.</li> <li>It is generally better to lower resolution (and/or <code>fps</code>) and raise BPP than to raise resolution and lose BPP.</li> </ul> <pre><code># sets BPP to 0.05\nstream_params = {\"-bpp\": 0.05} \n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-gop</code> (float/int) : (optional) This parameter specifies the number of frames between two I-frames for accurate GOP (Group of Pictures) length. Increasing the GOP length reduces the number of I-frames per time frame, minimizing bandwidth consumption. For example, with complex subjects such as water sports or action scenes, a shorter GOP length (e.g., <code>15</code> or below) results in excellent video quality. For more static video, such as talking heads, much longer GOP sizes are not only sufficient but also more efficient. It can be used as follows:</p> <p>The larger the GOP size, the more efficient the compression and the less bandwidth you will need.</p> <p>By default, StreamGear automatically sets a recommended fixed GOP value (i.e., every two seconds) based on the input framerate and selected encoder.</p> <pre><code># set GOP length to 70\nstream_params = {\"-gop\": 70} \n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-clones</code> (list): (optional) This parameter sets special FFmpeg options that need to be repeated more than once in the command. For more information, see this issue. It accepts values as a list only. Usage is as follows:</p> <pre><code># sets special FFmpeg options repeated multiple times\nstream_params = {\"-clones\": ['-map', '0:v:0', '-map', '1:a?']}\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-ffmpeg_download_path</code> (string): (optional) This parameter sets a custom directory for downloading FFmpeg static binaries in Compression Mode during the Auto-Installation step on Windows machines only. If this parameter is not altered, the binaries will be saved to the default temporary directory (e.g., <code>C:/User/foo/temp</code>) on your Windows machine. It can be used as follows:</p> <pre><code># download FFmpeg static binaries to `C:/User/foo/bar`\nstream_params = {\"-ffmpeg_download_path\": \"C:/User/foo/bar\"} \n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-clear_prev_assets</code> (bool): (optional) This parameter specifies whether to remove/delete all previous copies of StreamGear assets files for selected <code>format</code> (i.e., manifest (<code>mpd</code>) in DASH, playlist (<code>mu38</code>) in HLS, and respective streaming chunks (<code>.ts</code>,<code>.m4s</code>), etc.) present at the path specified by the <code>output</code> parameter. The default value is <code>False</code>. It can be enabled as follows:</p> <p>Additional segments (such as <code>.webm</code>, <code>.mp4</code> chunks) are also removed automatically.</p> <pre><code># delete all previous assets\nstream_params = {\"-clear_prev_assets\": True} \n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-enable_force_termination</code> (bool): sets a special flag to enable the forced termination of the FFmpeg process, required only if StreamGear is getting frozen when terminated. Its usage is as follows:</p> <p>The <code>-enable_force_termination</code> flag can potentially cause unexpected behavior or corrupted output in certain scenarios. It is recommended to use this flag with caution.</p> <pre><code># enables forced termination of FFmpeg process\nstream_params = {\"-enable_force_termination\": True} \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/streamgear/params/#b-ffmpeg-parameters","title":"B. FFmpeg Parameters","text":"<p>Almost all FFmpeg parameters can be passed as dictionary attributes in <code>stream_params</code>. For example, to use the <code>libx264</code> encoder to produce a lossless output video, you can pass the required FFmpeg parameters as dictionary attributes as follows:</p> <p>Please check the H.264 documentation \u27b6 and FFmpeg Documentation \u27b6 for more information on following parameters.</p> <p>All FFmpeg parameters are case-sensitive. Double-check each parameter if any errors occur.</p> <p>In addition to these parameters, almost any FFmpeg parameter (supported by the installed FFmpeg) is also supported. Be sure to read the FFmpeg Documentation carefully first.</p> <pre><code># libx264 encoder and its supported parameters\nstream_params = {\"-vcodec\":\"libx264\", \"-crf\": 0, \"-preset\": \"fast\", \"-tune\": \"zerolatency\"} \n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#supported-encoders-and-decoders","title":"Supported Encoders and Decoders","text":"<p>All encoders and decoders compiled with the FFmpeg in use are supported by the StreamGear API. You can check the compiled encoders by running the following command in your terminal:</p> Faster Transcoding with Stream Copy in Single Source Mode <p>For faster transcoding of input video, utilize Stream copy (<code>-vcodec copy</code>) as the input video encoder in the Single-Source Mode for creating HLS/DASH chunks of the primary stream efficiently. However, consider the following points:</p> <ul> <li> Stream copy is NOT compatible with Real-time Frames Mode, as this mode necessitates re-encoding of incoming frames. Therefore, the <code>-vcodec copy</code> parameter will be ignored.</li> <li> Stream copying NOT compatible with Custom Streams (<code>-streams</code>), which also require re-encoding for each additional stream. Consequently, the <code>-vcodec copy</code> parameter will be ignored.</li> <li>When using the audio stream from the input video, the Audio Stream copy (<code>-acodec copy</code>) encoder will be automatically applied.</li> </ul> <pre><code># for checking encoder\nffmpeg -encoders           # use `ffmpeg.exe -encoders` on windows\n# for checking decoders\nffmpeg -decoders           # use `ffmpeg.exe -decoders` on windows\n</code></pre> <p>Similarly, supported audio/video demuxers and filters depend on the FFmpeg binaries in use.</p> <p> </p>"},{"location":"gears/streamgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>StreamGear(logging=True)\n</code></pre> <p> </p> <ol> <li> <p> In Real-time Frames Mode, the Primary Stream's framerate defaults to <code>-input_framerate</code> attribute value, if defined, else it will be 25fps.\u00a0\u21a9</p> </li> </ol>"},{"location":"gears/streamgear/rtfm/overview/","title":"Overview","text":""},{"location":"gears/streamgear/rtfm/overview/#streamgear-api-real-time-frames-mode","title":"StreamGear API: Real-time Frames Mode","text":"Real-time Frames Mode generalized workflow"},{"location":"gears/streamgear/rtfm/overview/#overview","title":"Overview","text":"<p>When no valid input is received on <code>-video_source</code> attribute of <code>stream_params</code> dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time <code>numpy.ndarray</code> video-frames (as opposed to a entire video file) into a sequence of multiple smaller chunks/segments for adaptive streaming. </p> <p>This mode works exceptionally well when you desire to flexibility manipulate or transform video-frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, StreamGear DOES NOT automatically maps video-source's audio to generated streams with this mode. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> <p>SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)  and Apple HLS (HTTP Live Streaming) with this mode.</p> <p>For this mode, StreamGear API provides exclusive <code>stream()</code> method for directly trancoding video-frames into streamable chunks. </p> <p> </p> New in v0.2.2 <p>Apple HLS support was added in <code>v0.2.2</code>.</p> <p>Real-time Frames Mode itself is NOT Live-Streaming </p> <p>To enable live-streaming in Real-time Frames Mode, use the exclusive <code>-livestream</code> attribute of the <code>stream_params</code> dictionary parameter in the StreamGear API. Checkout this usage example \u27b6 for more information.</p> <p>Please Remember </p> <ul> <li> <p>Using <code>transcode_source()</code> function instead of <code>stream()</code> in Real-time Frames Mode will immediately result in <code>RuntimeError</code>!</p> </li> <li> <p>NEVER assign anything to <code>-video_source</code> attribute of <code>stream_params</code> dictionary parameter, otherwise Single-Source Mode get activated, and as a result, using <code>stream()</code> function will throw <code>RuntimeError</code>!</p> </li> <li> <p>Input framerate defaults to <code>25.0</code> fps if <code>-input_framerate</code> attribute value not defined. </p> </li> </ul> <p> </p>"},{"location":"gears/streamgear/rtfm/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/streamgear/rtfm/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/rtfm/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/rtfm/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/rtfm/usage/","title":"Usage Examples","text":""},{"location":"gears/streamgear/rtfm/usage/#streamgear-api-usage-examples-real-time-frames-mode","title":"StreamGear API Usage Examples: Real-time Frames Mode","text":"<p>Real-time Frames Mode itself is NOT Live-Streaming </p> <p>To enable live-streaming in Real-time Frames Mode, use the exclusive <code>-livestream</code> attribute of the <code>stream_params</code> dictionary parameter in the StreamGear API. Checkout following usage example \u27b6 for more information.</p> <p>Important Information </p> <ul> <li> StreamGear API MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. API will throw RuntimeError, if it fails to detect valid FFmpeg executables on your system.</li> <li> In this mode, API by default generates a primary stream (at the index <code>0</code>) of same resolution as the input frames and at default framerate<sup>1</sup>.</li> <li> In this mode, API DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</li> <li> In this mode, Stream copy (<code>-vcodec copy</code>) encoder is unsupported as it requires re-encoding of incoming frames.</li> <li> Always use <code>close()</code> function at the very end of the main code.</li> </ul> DEPRECATION NOTICES for <code>v0.3.3</code> and above <ul> <li> The <code>terminate()</code> method in StreamGear is now deprecated and will be removed in a future release. Developers should use the new <code>close()</code> method instead, as it offers a more descriptive name, similar to the WriteGear API, for safely terminating StreamGear processes.</li> <li> The <code>rgb_mode</code> parameter in <code>stream()</code> method, which earlier used to support RGB frames in Real-time Frames Mode is now deprecated, and will be removed in a future version. Only BGR format frames will be supported going forward. Please update your code to handle BGR format frames.</li> </ul> <p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode:</p> <p>We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner.</p> <p>In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p>After running this bare-minimum example, StreamGear will produce a Manifest file (<code>dash.mpd</code>) with streamable chunks that contains information about a Primary Stream of same resolution and framerate<sup>1</sup> as input (without any audio).</p> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-controlled-input-framerate","title":"Bare-Minimum Usage with controlled Input-framerate","text":"<p>In Real-time Frames Mode, StreamGear API provides the exclusive <code>-input_framerate</code> attribute for the <code>stream_params</code> dictionary parameter, which allows you to set the assumed constant framerate for incoming frames.</p> <p>In this example, we will retrieve the framerate from a webcam video stream and set it as the value for the <code>-input_framerate</code> attribute in StreamGear.</p> <p>Remember, the input framerate defaults to 25.0 fps if the <code>-input_framerate</code> attribute value is not defined in Real-time Frames mode.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n\n# retrieve framerate from CamGear Stream and pass it as `-input_framerate` value\nstream_params = {\"-input_framerate\":stream.framerate}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n\n# retrieve framerate from CamGear Stream and pass it as `-input_framerate` value\nstream_params = {\"-input_framerate\":stream.framerate}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-live-streaming","title":"Bare-Minimum Usage with Live-Streaming","text":"<p>You can easily activate Low-latency Live-Streaming  in Real-time Frames Mode, where chunks will contain information for new frames only and forget previous ones, using the exclusive <code>-livestream</code> attribute of the <code>stream_params</code> dictionary parameter. The complete example is as follows:</p> <p>In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> DASHHLS <p>Controlling chunk size in DASH</p> <p>To control the number of frames kept in Chunks for the DASH stream (controlling latency), you can use the <code>-window_size</code> and <code>-extra_window_size</code> FFmpeg parameters. Lower values for these parameters will result in lower latency.</p> <p>After every few chunks (equal to the sum of <code>-window_size</code> and <code>-extra_window_size</code> values), all chunks will be overwritten while Live-Streaming. This means that newer chunks in the manifest will contain NO information from older chunks, and the resulting DASH stream will only play the most recent frames, reducing latency.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid video stream(from web-camera attached at index `0`)\nstream = CamGear(source=0).start()\n\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p>Controlling chunk size in HLS</p> <p>To control the number of frames kept in Chunks for the HLS stream (controlling latency), you can use the <code>-hls_init_time</code> &amp; <code>-hls_time</code> FFmpeg parameters. Lower values for these parameters will result in lower latency.</p> <p>After every few chunks (equal to the sum of <code>-hls_init_time</code> &amp; <code>-hls_time</code> values), all chunks will be overwritten while Live-Streaming. This means that newer chunks in the master playlist will contain NO information from older chunks, and the resulting HLS stream will only play the most recent frames, reducing latency.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid video stream(from web-camera attached at index `0`)\nstream = CamGear(source=0).start()\n\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>You can easily use the StreamGear API directly with any other Video Processing library (for e.g. OpenCV) in Real-time Frames Mode.</p> <p>The following is a complete StreamGear API usage example with OpenCV:</p> <p>This is a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature or example will work in a similar manner.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n      break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # send frame to streamer\n    streamer.stream(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n      break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # send frame to streamer\n    streamer.stream(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-additional-streams","title":"Usage with Additional Streams","text":"<p>Similar to Single-Source Mode, in addition to the Primary Stream, you can easily generate any number of additional Secondary Streams with variable bitrate or spatial resolution, using the exclusive <code>-streams</code> attribute of the <code>stream_params</code> dictionary parameter.</p> <p>To generate Secondary Streams, add each desired resolution and bitrate/framerate as a list of dictionaries to the <code>-streams</code> attribute. StreamGear will handle the rest automatically. The complete example is as follows:</p> <p>A more detailed information on <code>-streams</code> attribute can be found here \u27b6</p> <p>In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> Important Information about <code>-streams</code> attribute  <ul> <li>In addition to the user-defined Secondary Streams, StreamGear automatically generates a Primary Stream (at index <code>0</code>) with the same resolution as the input frames and at default framerate<sup>1</sup>.</li> <li> Ensure that your system, machine, server, or network can handle the additional resource requirements of the Secondary Streams. Exercise discretion when configuring multiple streams.</li> <li>You MUST define the <code>-resolution</code> value for each stream; otherwise, the stream will be discarded.</li> <li>You only need to define either the <code>-video_bitrate</code> or the <code>-framerate</code> for a valid stream. <ul> <li>If you specify the <code>-framerate</code>, the video bitrate will be calculated automatically.</li> <li>If you define both the <code>-video_bitrate</code> and the <code>-framerate</code>, the <code>-framerate</code> will get discard automatically.</li> </ul> </li> </ul> <p>Always use the <code>-streams</code> attribute to define additional streams safely. Duplicate or incorrect definitions can break the transcoding pipeline and corrupt the output chunks.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n\n# define various streams\nstream_params = {\n    \"-streams\": [\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream1: 1280x720 at 30fps framerate\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps framerate\n        {\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n    ],\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n\n# define various streams\nstream_params = {\n    \"-streams\": [\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream1: 1280x720 at 30fps framerate\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps framerate\n        {\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n    ],\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-file-audio-input","title":"Usage with File Audio-Input","text":"<p>In Real-time Frames Mode, if you want to add audio to your streams, you need to use the exclusive <code>-audio</code> attribute of the <code>stream_params</code> dictionary parameter.</p> <p>To add a audio source, provide the path to your audio file as a string to the <code>-audio</code> attribute. The API will automatically validate and map the audio to all generated streams. The complete example is as follows:</p> <p>Ensure the provided <code>-audio</code> audio source is compatible with the input video source. Incompatibility can cause multiple errors or result in no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>You can also assign a valid audio URL as input instead of a file path. More details can be found here \u27b6</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n\n# add various streams, along with custom audio\nstream_params = {\n    \"-streams\": [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n    ],\n    \"-input_framerate\": stream.framerate, # controlled framerate for audio-video sync !!! don't forget this line !!!\n    \"-audio\": \"/home/foo/foo1.aac\" # assign external audio-source\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n\n# add various streams, along with custom audio\nstream_params = {\n    \"-streams\": [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n    ],\n    \"-input_framerate\": stream.framerate, # controlled framerate for audio-video sync !!! don't forget this line !!!\n    \"-audio\": \"/home/foo/foo1.aac\" # assign external audio-source\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-device-audio-input","title":"Usage with Device Audio-Input","text":"<p>In Real-time Frames Mode, you can also use the exclusive <code>-audio</code> attribute of the <code>stream_params</code> dictionary parameter for streaming live audio from an external device.</p> <p>To stream live audio, format your audio device name followed by a suitable demuxer as a list, and assign it to the <code>-audio</code> attribute. The API will automatically validate and map the audio to all generated streams. The complete example is as follows:</p> <p>Example Assumptions </p> <ul> <li> You're running a Windows machine with all necessary audio drivers and software installed.</li> <li> There's an audio device named \"Microphone (USB2.0 Camera)\" connected to your Windows machine. Check instructions below to use device sources with the <code>-audio</code> attribute on different OS platforms.</li> </ul> Using devices sources with <code>-audio</code> attribute on different OS platforms <p>To use device sources with the <code>-audio</code> attribute on different OS platforms, follow these instructions:</p>  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details.</p> </li> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg -list_devices true -f dshow -i dummy\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source device and demuxer device and demuxer\nstream_params = {\"-audio\": [\"-f\",\"dshow\", \"-i\", \"audio=Microphone (USB2.0 Camera)\"]}\n</code></pre> </li> </ul> <p>If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel</p> <p>Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> Identify Sound Card: To get the list of all installed cards on your machine, you can type <code>arecord -l</code> or <code>arecord -L</code> (longer output).</p> <pre><code>arecord -l\n\n**** List of CAPTURE Hardware Devices ****\ncard 0: ICH5 [Intel ICH5], device 0: Intel ICH [Intel ICH5]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 1: Intel ICH - MIC ADC [Intel ICH5 - MIC ADC]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 2: Intel ICH - MIC2 ADC [Intel ICH5 - MIC2 ADC]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 3: Intel ICH - ADC2 [Intel ICH5 - ADC2]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: U0x46d0x809 [USB Device 0x46d:0x809], device 0: USB Audio [USB Audio]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <p>The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as <code>hw:0</code> or <code>hw:1</code></p> <pre><code># assign appropriate input audio-source device and demuxer device and demuxer \nstream_params = {\"-audio\": [\"-f\",\"alsa\", \"-i\", \"hw:1\"]}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines:</p> <ul> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>avfoundation</code> as follows:</p> <pre><code>ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source device and demuxer\nstream_params = {\"-audio\": [\"-f\",\"avfoundation\", \"-audio_device_index\", \"0\"]}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>It is advised to use this example with live-streaming enabled(<code>True</code>) by using StreamGear API's exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter.</p> <p>Ensure the provided <code>-audio</code> audio source is compatible with the video source device. Incompatibility can cause multiple errors or result in no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid DEVICE video stream\nstream = CamGear(source=0).start()\n\n# add various streams, along with custom audio\nstream_params = {\n    \"-streams\": [\n        {\n            \"-resolution\": \"640x360\",\n            \"-video_bitrate\": \"4000k\",\n        },  # Stream1: 640x360 at 4000kbs bitrate\n        {\"-resolution\": \"320x240\", \"-framerate\": 30.0},  # Stream2: 320x240 at 30fps\n    ],\n    \"-input_framerate\": stream.framerate,  # controlled framerate for audio-video sync !!! don't forget this line !!!\n    \"-livestream\": True,\n    \"-audio\": [\n        \"-f\",\n        \"dshow\",\n        \"-i\",\n        \"audio=Microphone (USB2.0 Camera)\",\n    ],  # assign appropriate input audio-source device(compatible with video source) and its demuxer\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# open any valid DEVICE video stream\nstream = CamGear(source=0).start()\n\n# add various streams, along with custom audio\nstream_params = {\n    \"-streams\": [\n        {\n            \"-resolution\": \"640x360\",\n            \"-video_bitrate\": \"4000k\",\n        },  # Stream1: 640x360 at 4000kbs bitrate\n        {\"-resolution\": \"320x240\", \"-framerate\": 30.0},  # Stream2: 320x240 at 30fps\n    ],\n    \"-input_framerate\": stream.framerate,  # controlled framerate for audio-video sync !!! don't forget this line !!!\n    \"-livestream\": True,\n    \"-audio\": [\n        \"-f\",\n        \"dshow\",\n        \"-i\",\n        \"audio=Microphone (USB2.0 Camera)\",\n    ],  # assign appropriate input audio-source device(compatible with video source) and its demuxer\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format=\"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-hardware-video-encoder","title":"Usage with Hardware Video-Encoder","text":"<p>In Real-time Frames Mode, you can easily change the video encoder according to your requirements by passing the <code>-vcodec</code> FFmpeg parameter as an attribute in the <code>stream_params</code> dictionary parameter. Additionally, you can specify additional properties, features, and optimizations for your system's GPU.</p> <p>In this example, we will be using <code>h264_vaapi</code> as our Hardware Encoder and specifying the device hardware's location and compatible video filters  by formatting them as attributes in the <code>stream_params</code> dictionary parameter.</p> <p>This example is just conveying the idea of how to use FFmpeg's hardware encoders with the StreamGear API in Real-time Frames Mode, which MAY OR MAY NOT suit your system. Please use suitable parameters based on your supported system and FFmpeg configurations only.</p> Checking VAAPI Support for Hardware Encoding <p>To use VAAPI (Video Acceleration API) as a hardware encoder in this example, follow these steps to ensure your FFmpeg supports VAAPI:</p> <pre><code>ffmpeg  -hide_banner -encoders | grep vaapi \n\n V..... h264_vaapi           H.264/AVC (VAAPI) (codec h264)\n V..... hevc_vaapi           H.265/HEVC (VAAPI) (codec hevc)\n V..... mjpeg_vaapi          MJPEG (VAAPI) (codec mjpeg)\n V..... mpeg2_vaapi          MPEG-2 (VAAPI) (codec mpeg2video)\n V..... vp8_vaapi            VP8 (VAAPI) (codec vp8)\n</code></pre> <p>Please read the FFmpeg Documentation carefully before passing any additional values to the <code>stream_params</code> parameter. Incorrect values may cause errors or result in no output.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = VideoGear(source=0).start() \n\n# add various streams with custom Video Encoder and optimizations\nstream_params = {\n    \"-streams\": [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n    ],\n    \"-vcodec\": \"h264_vaapi\", # define custom Video encoder\n    \"-vaapi_device\": \"/dev/dri/renderD128\", # define device location\n    \"-vf\": \"format=nv12,hwupload\",  # define video filters\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = VideoGear(source=0).start() \n\n# add various streams with custom Video Encoder and optimizations\nstream_params = {\n    \"-streams\": [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n    ],\n    \"-vcodec\": \"h264_vaapi\", # define custom Video encoder\n    \"-vaapi_device\": \"/dev/dri/renderD128\", # define device location\n    \"-vf\": \"format=nv12,hwupload\",  # define video pixformat\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p> <ol> <li> <p> In Real-time Frames Mode, the Primary Stream's framerate defaults to the value of the <code>-input_framerate</code> attribute, if defined. Otherwise, it will be set to 25 fps.\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/streamgear/ssm/overview/","title":"Overview","text":""},{"location":"gears/streamgear/ssm/overview/#streamgear-api-single-source-mode","title":"StreamGear API: Single-Source Mode","text":"Single-Source Mode generalized workflow"},{"location":"gears/streamgear/ssm/overview/#overview","title":"Overview","text":"<p>In this mode, StreamGear transcodes entire audio-video file (as opposed to frames-by-frame) into a sequence of multiple smaller chunks/segments for adaptive streaming. </p> <p>This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) files for streaming that requires no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing.</p> <p>SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)  and Apple HLS (HTTP Live Streaming) with this mode.</p> <p>For this mode, StreamGear API provides exclusive <code>transcode_source()</code> method to easily process audio-video files into streamable chunks.</p> <p>This mode can be easily activated by assigning suitable video path as input to <code>-video_source</code> attribute of <code>stream_params</code> dictionary parameter, during StreamGear initialization.</p> <p> </p> New in v0.2.2 <p>Apple HLS support was added in <code>v0.2.2</code>.</p> <p>Please Remember </p> <ul> <li>Using <code>stream()</code> function instead of <code>transcode_source()</code> in Single-Source Mode will instantly result in <code>RuntimeError</code>!</li> <li>Any invalid value to the <code>-video_source</code> attribute will result in <code>AssertionError</code>! </li> </ul> <p> </p>"},{"location":"gears/streamgear/ssm/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/streamgear/ssm/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/ssm/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/ssm/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/ssm/usage/","title":"Usage Examples","text":""},{"location":"gears/streamgear/ssm/usage/#streamgear-api-usage-examples-single-source-mode","title":"StreamGear API Usage Examples: Single-Source Mode","text":"<p>Important Information </p> <ul> <li> StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation. API will throw RuntimeError, if it fails to detect valid FFmpeg executables on your system.</li> <li> In this mode, API auto generates a primary stream of same resolution and framerate<sup>1</sup> as the input video  (at the index <code>0</code>).</li> <li> In this mode, if input video-source (i.e. <code>-video_source</code>) contains any audio stream/channel, then it automatically gets mapped to all generated streams.</li> <li> Always use <code>close()</code> function at the very end of the main code.</li> </ul> DEPRECATION NOTICES for <code>v0.3.3</code> and above <ul> <li> The <code>terminate()</code> method in StreamGear is now deprecated and will be removed in a future release. Developers should use the new <code>close()</code> method instead, as it offers a more descriptive name, similar to the WriteGear API, for safely terminating StreamGear processes.</li> <li> The <code>-livestream</code> optional parameter is NOT supported in this Single-Source Mode.</li> </ul> Faster Transcoding of Primary Stream with Stream Copy in Single Source Mode <p>For faster transcoding of input video in this mode, utilize Stream copy (<code>-vcodec copy</code>) as the input video encoder for creating HLS/DASH chunks of the primary stream efficiently. However, consider the following points:</p> <ul> <li> Stream copying NOT compatible with Custom Streams (<code>-streams</code>), which require re-encoding for each additional stream. Therefore, the <code>-vcodec copy</code> parameter will be ignored.</li> <li>When using the audio stream from the input video, the Audio Stream copy (<code>-acodec copy</code>) encoder will be automatically applied.</li> </ul> <p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode:</p> <p>If input video-source (i.e. <code>-video_source</code>) contains any audio stream/channel, then it automatically gets mapped to all generated streams.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode with valid video input\nstream_params = {\"-video_source\": \"foo.mp4\"}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <p>After running this bare-minimum example, StreamGear will produce a Manifest file (<code>dash_out.mpd</code>) with streamable chunks, containing information about a Primary Stream with the same resolution and framerate as the input.</p> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode with valid video input\nstream_params = {\"-video_source\": \"foo.mp4\"}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <p>After running this bare-minimum example, StreamGear will produce a Master Playlist file (<code>hls_out.mpd</code>) with streamable chunks, containing information about a Primary Stream with the same resolution and framerate as the input.</p> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#usage-with-additional-streams","title":"Usage with Additional Streams","text":"<p>In addition to the Primary Stream, you can easily generate any number of additional Secondary Streams with variable bitrate or spatial resolutions, using the exclusive <code>-streams</code> attribute of the <code>stream_params</code> dictionary parameter. </p> <p>To generate Secondary Streams, add each desired resolution and bitrate/framerate as a list of dictionaries to the <code>-streams</code> attribute. StreamGear will handle the rest automatically. The complete example is as follows:</p> <p>A more detailed information on <code>-streams</code> attribute can be found here \u27b6</p> <p>If input video-source (i.e. <code>-video_source</code>) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts.</p> Important Information about <code>-streams</code> attribute  <ul> <li>In addition to the user-defined Secondary Streams, StreamGear automatically generates a Primary Stream (at index <code>0</code>) with the same resolution and framerate as the input video-source (i.e. <code>-video_source</code>).</li> <li> Ensure that your system, machine, server, or network can handle the additional resource requirements of the Secondary Streams. Exercise discretion when configuring multiple streams.</li> <li>You MUST define the <code>-resolution</code> value for each stream; otherwise, the stream will be discarded.</li> <li>You only need to define either the <code>-video_bitrate</code> or the <code>-framerate</code> for a valid stream. <ul> <li>If you specify the <code>-framerate</code>, the video bitrate will be calculated automatically.</li> <li>If you define both the <code>-video_bitrate</code> and the <code>-framerate</code>, the <code>-framerate</code> will get discard automatically.</li> </ul> </li> </ul> <p>Always use the <code>-streams</code> attribute to define additional streams safely. Duplicate or incorrect definitions can break the transcoding pipeline and corrupt the output chunks.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode and also define various streams\nstream_params = {\n    \"-video_source\": \"foo.mp4\",\n    \"-streams\": [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps framerate\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps framerate\n        {\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n    ],\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode and also define various streams\nstream_params = {\n    \"-video_source\": \"foo.mp4\",\n    \"-streams\": [\n        {\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n        {\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps framerate\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps framerate\n        {\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n    ],\n}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#usage-with-custom-audio-input","title":"Usage with Custom Audio-Input","text":"<p>In single source mode, by default, if the input video source (i.e., <code>-video_source</code>) contains audio, it gets automatically mapped to all generated streams. However, if you want to add a custom audio source, you can use the exclusive <code>-audio</code> attribute of the <code>stream_params</code> dictionary parameter.</p> <p>To add a custom audio source, provide the path to your audio file as a string to the <code>-audio</code> attribute. The API will automatically validate and map the audio to all generated streams. The complete example is as follows:</p> <p>Ensure the provided <code>-audio</code> audio source is compatible with the input video source (<code>-video_source</code>). Incompatibility can cause multiple errors or result in no output at all.</p> <p>You can also assign a valid audio URL as input instead of a file path. More details can be found here \u27b6</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode and various streams, along with custom audio\nstream_params = {\n    \"-video_source\": \"foo.mp4\",\n    \"-streams\": [\n        {\"-resolution\": \"1280x720\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1280x720 at 4000kbs bitrate\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps\n    ],\n    \"-audio\": \"/home/foo/foo1.aac\", # define custom audio-source\n    \"-acodec\": \"copy\", # define copy audio encoder\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode and various streams, along with custom audio\nstream_params = {\n    \"-video_source\": \"foo.mp4\",\n    \"-streams\": [\n        {\"-resolution\": \"1280x720\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1280x720 at 4000kbs bitrate\n        {\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps\n    ],\n    \"-audio\": \"/home/foo/foo1.aac\",  # define custom audio-source\n    \"-acodec\": \"copy\", # define copy audio encoder\n}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#usage-with-variable-ffmpeg-parameters","title":"Usage with Variable FFmpeg Parameters","text":"<p>For fine-grained control over the transcoding process, StreamGear provides a highly extensible and flexible wrapper around FFmpeg library and access to almost all of its configurational parameter. </p> <p>In this example, we'll use the H.265/HEVC video encoder and AAC audio encoder, apply various optimal FFmpeg configurational parameters.</p> <p>This example assumes that the given input video source (<code>-video_source</code>) contains at least one audio stream.</p> <p>This example is just conveying the idea on how to use FFmpeg's internal encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner.</p> <p>Please read the FFmpeg Documentation carefully before passing any additional values to the <code>stream_params</code> parameter. Incorrect values may cause errors or result in no output.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\n# activate Single-Source Mode and various other parameters\nstream_params = {\n    \"-video_source\": \"foo.mp4\", # define Video-Source\n    \"-vcodec\": \"libx265\", # specify H.265/HEVC video encoder\n    \"-x265-params\": \"lossless=1\", # enables Lossless encoding\n    \"-bpp\": 0.15, # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes\n    \"-streams\": [\n        {\"-resolution\": \"640x360\", \"-video_bitrate\": \"4000k\"}, # Stream1: 1280x720 at 4000kbs bitrate\n        {\"-resolution\": \"320x240\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps\n    ],\n    \"-acodec\": \"aac\", # specify AAC audio encoder\n}\n\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", logging=True, **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n\nstream_params = {\n    \"-video_source\": \"foo.mp4\", # define Video-Source\n    \"-vcodec\": \"libx265\", # specify H.265/HEVC video encoder\n    \"-x265-params\": \"lossless=1\", # enables Lossless encoding\n    \"-bpp\": 0.15, # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes\n    \"-streams\": [\n        {\"-resolution\": \"640x360\", \"-video_bitrate\": \"4000k\"}, # Stream1: 1280x720 at 4000kbs bitrate\n        {\"-resolution\": \"320x240\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps\n    ],\n    \"-acodec\": \"aac\", # specify AAC audio encoder\n}\n\n# describe a suitable master playlist file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", logging=True, **stream_params)\n# transcode source\nstreamer.transcode_source()\n# close\nstreamer.close()\n</code></pre> <p> </p> <ol> <li> <p> In Real-time Frames Mode, the Primary Stream's framerate defaults to <code>-input_framerate</code> attribute value, if defined, else it will be 25fps.\u00a0\u21a9</p> </li> </ol>"},{"location":"gears/videogear/overview/","title":"Overview","text":""},{"location":"gears/videogear/overview/#videogear-api","title":"VideoGear API","text":"VideoGear API's generalized workflow"},{"location":"gears/videogear/overview/#overview","title":"Overview","text":"<p>VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. </p> <p>VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive <code>enablePiCamera</code> boolean flag.</p> <p>VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not)  with minimum effort and writing way fewer lines of code.</p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/videogear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through VideoGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/videogear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/videogear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/videogear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/videogear/params/","title":"Parameters","text":""},{"location":"gears/videogear/params/#videogear-api-parameters","title":"VideoGear API Parameters","text":"<p>VideoGear acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/videogear/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide direct access to PiGear or CamGear APIs respectively in VideoGear. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in VideoGear.</p>"},{"location":"gears/videogear/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>VideoGear(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/videogear/params/#options","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in VideoGear. Default is also <code>False</code>.</p>"},{"location":"gears/videogear/params/#source","title":"<code>source</code>","text":"<p>VideoGear API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>VideoGear(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>VideoGear(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>VideoGear(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>VideoGear(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/videogear/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the VideoGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend (<code>backend=cv2.CAP_GSTREAMER</code>) for any livestreams (such as Twitch).</p> <p>VideoGear automatically enforce GStreamer backend (backend=<code>cv2.CAP_GSTREAMER</code>) for YouTube-livestreams!</p> <p>VideoGear will exit with <code>RuntimeError</code> for YouTube livestreams, if OpenCV is not compiled with GStreamer(<code>&gt;=v1.0.0</code>) support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>VideoGear(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/videogear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>VideoGear(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#options_1","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nVideoGear(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in VideoGear.</p>"},{"location":"gears/videogear/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera index to be used as the source, allowing you to drive these multiple cameras simultaneously from within a single Python session. Its value can only be zero or greater, otherwise, VideoGear API will throw <code>ValueError</code> for any negative value.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code># select Camera Module at index `1`\nVideoGear(enablePiCamera=True, camera_num=1)\n</code></pre> <p>The complete usage example demonstrating the usage of the <code>camera_num</code> parameter is available here \u27b6.</p> <p> </p>"},{"location":"gears/videogear/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter controls the resolution - a tuple (i.e. <code>(width,height)</code>) of two values giving the width and height of the output frames. </p> <p>Make sure both width and height values should be at least <code>64</code>.</p> <p>When using the Picamera2 backend, the <code>resolution</code> parameter will be OVERRIDDEN, if the user explicitly defines the <code>output_size</code> property of the <code>sensor</code> configurational parameter.</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter controls the framerate of the source.</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#options_2","title":"<code>options</code>","text":"<p>This dictionary parameter in the internal PiGear API backend allows you to control various camera settings for both the <code>picamera2</code> and legacy <code>picamera</code> backends and some internal API tasks. These settings include:</p>"},{"location":"gears/videogear/params/#a-configurational-camera-parameters","title":"A. Configurational Camera Parameters","text":"<ul> <li> These parameters are provided by the underlying backend library (depending upon backend in use), and must be applied to the camera system before the camera can be started.</li> <li> These parameter include: Brightness, Contrast, Saturation, Exposure, Colour Temperature, Colour Gains, etc. </li> <li> All supported parameters are listed in this Usage example \u27b6</li> </ul>"},{"location":"gears/videogear/params/#b-user-defined-parameters","title":"B. User-defined Parameters","text":"<ul> <li> These user-defined parameters control specific internal behaviors of the API and perform certain tasks on the camera objects.</li> <li> All supported User-defined Parameters are listed here \u27b6</li> </ul> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>The complete usage example demonstrating the usage of the <code>options</code> parameter is available here \u27b6.</p> <p>You can format these user-defined and configurational parameters as attributes of this <code>options</code> dictionary parameter as follows:</p> New Picamera2 backendLegacy Picamera backend <pre><code># formulate various Picamera2 API parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"exposure_compensation\": 15,\n    \"sensor\": {\"output_size\": (480, 320)},  # !!! will override `resolution` !!!\n}\n\n# open pi video stream with defined parameters\nstream = VideoGear(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <pre><code># formulate various Picamera API parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = VideoGear(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in VideoGear.</p>"},{"location":"gears/videogear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>VideoGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/videogear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>VideoGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the VideoGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>VideoGear(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/","title":"Usage Examples","text":""},{"location":"gears/videogear/usage/#videogear-api-usage-examples","title":"VideoGear API Usage Examples:","text":"<p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-camgear-backend","title":"Bare-Minimum Usage with CamGear backend","text":"<p>VideoGear by default provides direct internal access to CamGear API.</p> <p>Following is the bare-minimum code you need to access CamGear API with VideoGear:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n\n\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = VideoGear(source=\"myvideo.avi\").start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-pigear-backend","title":"Bare-Minimum Usage with PiGear backend","text":"<p>VideoGear contains a special <code>enablePiCamera</code> flag that when <code>True</code> provides internal access to PiGear API.</p> <p>Following is the bare-minimum code you need to access PiGear API with VideoGear:</p> Under the hood, PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, PiGear API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this API, otherwise nothing will work.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n\n# enable enablePiCamera boolean flag to access PiGear API backend\nstream = VideoGear(enablePiCamera=True).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#using-videogear-with-video-stabilizer-backend","title":"Using VideoGear with Video Stabilizer backend","text":"<p>VideoGear API provides a special internal wrapper around VidGear's Exclusive Video Stabilizer class and provides easy way of activating stabilization for various video-streams (real-time or not) with its <code>stabilize</code> boolean parameter during initialization.</p> <p>The usage example is as follows:</p> <p>For a more detailed information on Video-Stabilizer Class, Read here \u27b6</p> <p>The stabilizer might be slower for High-Quality/Resolution videos-frames.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport numpy as np\nimport cv2\n\n# open any valid video stream with stabilization enabled(`stabilize = True`)\nstream_stab = VideoGear(source=\"test.mp4\", stabilize=True).start()\n\n# loop over\nwhile True:\n\n    # read stabilized frames\n    frame_stab = stream_stab.read()\n\n    # check for stabilized frame if None-type\n    if frame_stab is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Stabilized Output\", frame_stab)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close streams\nstream_stab.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#advanced-videogear-usage-with-camgear-backend","title":"Advanced VideoGear usage with CamGear Backend","text":"<p>VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API.</p> <p>The usage example of VideoGear API with Variable Camera Properties is as follows:</p> <p>This example demonstrates how to use the VideoGear API in a similar manner to the CamGear's example for controlling variable source properties. Any CamGear usage example can be implemented using the VideoGear API in a similar way.</p> <p>All the supported Source Tweak Parameters can be found here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n\n\n# define suitable tweak parameters for your stream.\noptions = {\n    \"CAP_PROP_FRAME_WIDTH\": 320, # resolution 320x240\n    \"CAP_PROP_FRAME_HEIGHT\": 240,\n    \"CAP_PROP_FPS\": 60, # framerate 60fps\n}\n\n# To open live video stream on webcam at first index(i.e. 0) \n# device and apply source tweak parameters\nstream = VideoGear(source=0, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#advanced-videogear-usage-with-pigear-backend","title":"Advanced VideoGear usage with PiGear Backend","text":"<p>VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API.</p> <p>The usage example of VideoGear API with Variable Camera Properties is as follows:</p> <p>This example demonstrates how to use the VideoGear API in a similar manner to the PiGear's example for using variable camera properties. Any PiGear usage example can be implemented using the VideoGear API in a similar way.</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = VideoGear(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n\n# formulate various Picamera API \n# configurational parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = VideoGear(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#using-videogear-with-colorspace-manipulation","title":"Using VideoGear with Colorspace Manipulation","text":"<p>VideoGear API also supports Colorspace Manipulation but NOT Direct like other VideoCapture Gears. </p> <p>Important: <code>color_space</code> global variable is NOT Supported in VideoGear API</p> <ul> <li><code>color_space</code> global variable is NOT Supported in VideoGear API, calling it will result in <code>AttribueError</code>. More details can be found here \u27b6</li> <li>Any incorrect or None-type value on <code>colorspace</code> parameter will be skipped automatically.</li> </ul> <p>In following example code, we will convert source colorspace to HSV on initialization:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n\n# Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV`\nstream = VideoGear(source=0, colorspace=\"COLOR_BGR2HSV\", logging=True).start()\n\n# loop over\nwhile True:\n\n    # read HSV frames\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the HSV frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n\n    # check for 'q' key is pressed\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#bonus-examples","title":"Bonus Examples","text":"<p>Checkout more advanced VideoGear examples with unusual configuration here \u27b6</p> <p> </p>"},{"location":"gears/webgear/advanced/","title":"Advanced Usages","text":""},{"location":"gears/webgear/advanced/#webgear-api-advanced-usage","title":"WebGear API Advanced Usage:","text":"<p>This is a continuation of the WebGear doc \u27b6. Thereby, It's advised to first get familiarize with this API, and its requirements.</p> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-variable-colorspace","title":"Using WebGear with Variable Colorspace","text":"<p>WebGear by default only supports \"BGR\" colorspace frames as input, but you can use <code>jpeg_compression_colorspace</code> string attribute through its options dictionary parameter to specify incoming frames colorspace. </p> <p>Let's implement a bare-minimum example using WebGear, where we will be sending GRAY frames to client browser:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6</p> <p>Supported <code>jpeg_compression_colorspace</code> colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n\n# various performance tweaks and enable grayscale input\noptions = {\n    \"frame_size_reduction\": 25,\n    \"jpeg_compression_colorspace\": \"GRAY\",  # set grayscale\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# initialize WebGear app and change its colorspace to grayscale\nweb = WebGear(\n    source=\"foo.mp4\", colorspace=\"COLOR_BGR2GRAY\", logging=True, **options\n)\n\n# run this app on Uvicorn server at address http://0.0.0.0:8000/\nuvicorn.run(web(), host=\"0.0.0.0\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address on your local machine.</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-a-custom-sourceopencv","title":"Using WebGear with a Custom Source(OpenCV)","text":"New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <p>WebGear allows you to easily define your own custom Source that you want to use to transform your frames before sending them onto the browser. </p> <p>JPEG Frame-Compression and all of its performance enhancing attributes are disabled with a Custom Source!</p> <p>Let's implement a bare-minimum example with a Custom Source using WebGear API and OpenCV:</p> <pre><code># import necessary libs\nimport uvicorn, asyncio, cv2\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\n\n# initialize WebGear app without any source\nweb = WebGear(logging=True)\n\n# create your own custom frame producer\nasync def my_frame_producer():\n\n    # !!! define your own video source here !!!\n    # Open any video stream such as live webcam \n    # video stream on first index(i.e. 0) device\n    stream = cv2.VideoCapture(0)\n    # loop over frames\n    while True:\n        # read frame from provided source\n        (grabbed, frame) = stream.read()\n        # break if NoneType\n        if not grabbed:\n            break\n\n        # do something with your OpenCV frame here\n\n        # reducer frames size if you want more performance otherwise comment this line\n        frame = await reducer(frame, percentage=30, interpolation=cv2.INTER_AREA)  # reduce frame by 30%\n        # handle JPEG encoding\n        encodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n        # yield frame in byte format\n        yield (b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\n        await asyncio.sleep(0)\n    # close stream\n    stream.release()\n\n\n# add your custom frame producer to config\nweb.config[\"generator\"] = my_frame_producer\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address.</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-mounting-points","title":"Using WebGear with Custom Mounting Points","text":"<p>With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows:</p> <pre><code># import libs\nimport uvicorn\nfrom starlette.routing import Mount\nfrom starlette.staticfiles import StaticFiles\nfrom vidgear.gears.asyncio import WebGear\n\n# various performance tweaks\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n}\n\n# initialize WebGear app\nweb = WebGear(\n    source=\"foo.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n\n# append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory\nweb.routes.append(\n    Mount(\"/test\", app=StaticFiles(directory=\"/home/foo/.vidgear/test\"), name=\"test\")\n)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script <code>jquery-3.3.1.slim.min.js</code> in this folder and  want to integrate it, then, we can do something like this:</p> <pre><code>&lt;script src=\"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\"&gt;&lt;/script&gt;\n</code></pre> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-webpage-routes","title":"Using WebGear with Custom Webpage Routes","text":"<p>With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts.</p> <p>Suppose we want to add a simple <code>hello world</code> webpage to our WebGear server. So let's create a bare-minimum <code>hello.html</code> file with HTML code as follows:</p> <pre><code>&lt;html&gt;\n   &lt;header&gt;\n      &lt;title&gt;This is Hello world page&lt;/title&gt;\n   &lt;/header&gt;\n   &lt;body&gt;\n      &lt;h1&gt;Hello World&lt;/h1&gt;\n      &lt;p&gt;how ya doing?&lt;/p&gt;\n   &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Then in our application code, we can integrate this webpage route, as follows:</p> <p><pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.templating import Jinja2Templates\nfrom starlette.routing import Route\nfrom vidgear.gears.asyncio import WebGear\n\n# Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located\ntemplate = Jinja2Templates(directory=\"/home/foo/.vidgear/custom_template\")\n\n# render and return our webpage template\nasync def hello_world(request):\n    page = \"hello.html\"\n    context = {\"request\": request}\n    return template.TemplateResponse(page, context)\n\n\n# add various performance tweaks as usual\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n}\n\n# initialize WebGear app with a valid source\nweb = WebGear(\n    source=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n\n# append new route to point our rendered webpage\nweb.routes.append(Route(\"/hello\", endpoint=hello_world))\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> And that's all, Now you can see output at <code>http://localhost:8000/hello</code> address.</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-middlewares","title":"Using WebGear with MiddleWares","text":"<p>WebGear natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>All supported middlewares can be found here \u27b6</p> <p>For this example, let's use <code>CORSMiddleware</code> for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows:</p> <p>The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context.</p> <p>Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6</p> <p><pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.cors import CORSMiddleware\nfrom vidgear.gears.asyncio import WebGear\n\n# add various performance tweaks as usual\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n}\n\n# initialize WebGear app with a valid source\nweb = WebGear(\n    source=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n\n# define and assign suitable cors middlewares\nweb.middleware = [\n    Middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n]\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> And that's all, Now you can see output at <code>http://localhost:8000</code> address.</p> <p> </p>"},{"location":"gears/webgear/advanced/#rules-for-altering-webgear-files-and-folders","title":"Rules for Altering WebGear Files and Folders","text":"<p>WebGear gives us complete freedom of altering data files generated in Auto-Generation Process, But you've to  keep the following rules in mind:</p>"},{"location":"gears/webgear/advanced/#rules-for-altering-data-files","title":"Rules for Altering Data Files","text":"<ul> <li> You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions.</li> <li> You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) present in <code>templates</code> folder inside the <code>webgear</code> directory at the default location, otherwise, it will trigger Auto-generation process, and it will overwrite the existing files with Server ones.</li> <li> You're allowed to add your own additional <code>.html</code>, <code>.css</code>, <code>.js</code>, etc. files in the respective folders at the default location and custom mounted Data folders.</li> </ul>"},{"location":"gears/webgear/advanced/#rules-for-altering-data-folders","title":"Rules for Altering Data Folders","text":"<ul> <li> You're allowed to add/mount any number of additional folder as shown in this example above.</li> <li> You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename <code>templates</code> folder in the <code>webgear</code> directory where critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) are located, otherwise, it will trigger Auto-generation process.</li> </ul>"},{"location":"gears/webgear/advanced/#bonus-examples","title":"Bonus Examples","text":"<p>Checkout more advanced WebGear examples with unusual configuration here \u27b6</p> <p> </p>"},{"location":"gears/webgear/overview/","title":"Overview","text":""},{"location":"gears/webgear/overview/#webgear-api","title":"WebGear API","text":"WebGear API's Video Server running at http://localhost:8000/ address."},{"location":"gears/webgear/overview/#overview","title":"Overview","text":"<p>WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser.</p> <p>WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.</p> <p>WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video.</p> <p>In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> <p> </p>"},{"location":"gears/webgear/overview/#data-files-auto-generation-workflow-for-webgear","title":"Data-Files Auto-Generation WorkFlow for WebGear","text":"Disabling Auto-Generation process in WebGear <p>Starting with vidgear <code>v0.3.0</code>, you can now completely disable Auto-Generation process in WebGear API using <code>skip_generate_webdata</code> optional boolean attribute. When <code>{skip_generate_webdata:True}</code>, no default data files will be downloaded or validated during initialization.</p> <p>Only <code>/video</code> route is available when <code>{skip_generate_webdata:True}</code> in WebGear API. All other default routes will be JSONResponses with <code>404</code>/<code>500</code> status codes.</p> Customizing default video endpoint path <p>Starting with vidgear <code>v0.3.1</code>, you can change default <code>/video</code> video endpoint path to any alphanumeric string value, using <code>custom_video_endpoint</code> optional string attribute. For example:</p> <p>Only alphanumeric string with no space in between are allowed as <code>custom_video_endpoint</code> value. Any other value will be discarded.</p> <p>WebGear's Default Theme which expects only default <code>/video</code> video endpoint path, will fail to work, if it is customized to any other value using this <code>custom_video_endpoint</code> attribute.</p> <p><pre><code># custom alphanumeric video endpoint string\noptions = {\"custom_video_endpoint\": \"xyz\"}\n\n# initialize WebGear app\nweb = WebGear(source=\"foo.mp4\", logging=True, **options)\n</code></pre> Hence, default video endpoint will now be available at <code>/xyz</code> path.</p> <p>On initializing WebGear API, it automatically checks for three critical data files(i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) inside the <code>templates</code> folder of the <code>webgear</code> directory at the default location which gives rise to the following two possible scenario:</p> <ul> <li> If data-files found: it will proceed normally for instantiating the Starlette application.</li> <li> If data-files not found: it will trigger the Auto-Generation process</li> </ul>"},{"location":"gears/webgear/overview/#default-location","title":"Default Location","text":"<ul> <li>A default location is the path of the directory where data files/folders are downloaded/generated/saved.</li> <li>By default, the <code>.vidgear</code> the folder at the home directory of your machine (for e.g <code>/home/foo/.vidgear</code> on Linux ) serves as the default location.</li> <li>But you can also use WebGear's <code>custom_data_location</code> dictionary attribute to change/alter default location path to somewhere else.</li> </ul> <p>Identifying Default location</p> <p>You can set <code>logging=True</code> during initialization, for easily identifying the selected default location, which will be something like this on a Linux  machine:</p> <pre><code>WebGear :: DEBUG :: `/home/foo/.vidgear` is the default location for saving WebGear data-files.\n</code></pre>"},{"location":"gears/webgear/overview/#auto-generation-process","title":"Auto-Generation process","text":"<p>Info</p> <ul> <li> <p>You can also force trigger the Auto-generation process to overwrite existing data-files using <code>overwrite_default_files</code> dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected.</p> </li> <li> <p>It is advised to enable logging(<code>logging=True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <ul> <li>On triggering this process, WebGear API creates <code>webgear</code> directory, and <code>templates</code> and <code>static</code> folders inside along with <code>js</code>, <code>css</code>, <code>img</code> sub-folders at the assigned default location.</li> <li> <p>Thereby at this default location, the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order:</p> <pre><code>.vidgear\n\u2514\u2500\u2500 webgear\n    \u251c\u2500\u2500 static\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 css\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 custom.css\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 img\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 favicon-32x32.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 js\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 custom.js\n    \u2514\u2500\u2500 templates\n        \u251c\u2500\u2500 404.html\n        \u251c\u2500\u2500 500.html\n        \u251c\u2500\u2500 base.html\n        \u2514\u2500\u2500 index.html\n6 directories, 7 files\n</code></pre> </li> <li> <p>Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.</p> </li> </ul> <p> </p>"},{"location":"gears/webgear/overview/#webgears-default-template","title":"WebGear's Default Template","text":"New in v0.2.1 <p>New Standalone WebGear's Default Theme was added in <code>v0.2.1</code>.</p> <p>The WebGear API by default uses simple &amp; elegant WebGear's Default Theme which looks like something as follows:</p>"},{"location":"gears/webgear/overview/#indexhtml","title":"Index.html","text":"<p>Can be accessed by visiting WebGear app server, running at http://localhost:8000/:</p>"},{"location":"gears/webgear/overview/#404html","title":"404.html","text":"<p>Appears when respective URL is not found, for example http://localhost:8000/ok:</p>"},{"location":"gears/webgear/overview/#500html","title":"500.html","text":"<p>Appears when an API Error is encountered:</p> <p>If <code>logging</code> is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response.</p> <p> </p>"},{"location":"gears/webgear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WebGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/webgear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/webgear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/webgear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/webgear/params/","title":"Parameters","text":""},{"location":"gears/webgear/params/#webgear-api-parameters","title":"WebGear API Parameters","text":"<p>WebGear provides a special internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/webgear/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#options","title":"<code>options</code>","text":"<p>This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p>"},{"location":"gears/webgear/params/#webgear-specific-attributes","title":"WebGear Specific attributes","text":"<ul> <li> <p><code>custom_data_location</code> (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows:</p> <pre><code># set default location to '/home/foo/foo1'\noptions = {\"custom_data_location\": \"/home/foo/foo1\"}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>custom_video_endpoint</code> (string) : Can be used to change/alter default <code>/video</code> video endpoint path to any alphanumeric string value. Its usage is as follows:</p> New in v0.3.1 <p><code>custom_video_endpoint</code> attribute was added in <code>v0.3.1</code>.</p> <p>Only alphanumeric string with no space in between are allowed as <code>custom_video_endpoint</code> value. Any other value will be discarded.</p> <p>WebGear's Default Theme which expects only default <code>/video</code> video endpoint path, will fail to work, if it is customized to any other value using this <code>custom_video_endpoint</code> attribute.</p> <p><pre><code># custom alphanumeric video endpoint string\noptions = {\"custom_video_endpoint\": \"xyz\"}\n# initialize WebGear app and assign it\nweb = WebGear(logging=True, **options)\n</code></pre> Hence, default video endpoint will now be available at <code>/xyz</code> path.</p> </li> <li> <p><code>overwrite_default_files</code> (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows:</p> <p>Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten.</p> <pre><code># force trigger the Auto-generation process\noptions = {\"overwrite_default_files\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>frame_size_reduction</code> (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the  most significant effect on performance. The value defaults to <code>25</code>, and must be no higher than <code>90</code> (fastest, max compression, Barely Visible frame-size) and no lower than <code>0</code> (slowest, no compression, Original frame-size). Its recommended value is between <code>40-60</code>. Its usage is as follows:</p> <pre><code># frame-size will be reduced by 50%\noptions = {\"frame_size_reduction\": 50} \n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_quality</code>: (int/float) This attribute controls the JPEG quantization factor. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. Its usage is as follows:</p> New in v0.2.2 <p><code>jpeg_compression_quality</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># activate jpeg encoding and set quality 95%\noptions = {\"jpeg_compression_quality\": 95}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_fastdct</code>: (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also <code>True</code>, and its usage is as follows:</p> New in v0.2.2 <p><code>jpeg_compression_fastdct</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># activate jpeg encoding and enable fast dct\noptions = {\"jpeg_compression_fastdct\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_fastupsample</code>: (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is <code>False</code>, and its usage is as follows:</p> New in v0.2.2 <p><code>jpeg_compression_fastupsample</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># activate jpeg encoding and enable fast upsampling\noptions = {\"jpeg_compression_fastupsample\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_colorspace</code>: (str) This internal attribute is used to specify incoming frames colorspace with compression. Its usage is as follows:</p> <p>Supported <code>jpeg_compression_colorspace</code> colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p> New in v0.2.2 <p><code>jpeg_compression_colorspace</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># Specify incoming frames are `grayscale`\noptions = {\"jpeg_compression\": \"GRAY\"}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>enable_infinite_frames</code> (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is <code>False</code>. Its usage is as follows:</p> New in v0.2.1 <p><code>enable_infinite_frames</code> attribute was added in <code>v0.2.1</code>.</p> <pre><code># emulate infinite frames\noptions = {\"enable_infinite_frames\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>skip_generate_webdata</code> (boolean) : Can be used to completely disable Data-Files Auto-Generation WorkFlow in WebGear API, and thereby no default data files will be downloaded or validated during its initialization. Its default value is <code>False</code>. Its usage is as follows:</p> New in v0.3.0 <p><code>skip_generate_webdata</code> attribute was added in <code>v0.3.0</code>.</p> <pre><code># completely disable Data-Files Auto-Generation WorkFlow\noptions = {\"skip_generate_webdata\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in WebGear.</p>"},{"location":"gears/webgear/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#options_1","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in WebGear. Default is also <code>False</code>.</p>"},{"location":"gears/webgear/params/#source","title":"<code>source</code>","text":"<p>WebGear API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>WebGear(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>WebGear(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>WebGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>WebGear(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>WebGear(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/webgear/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>WebGear(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>WebGear(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nWebGear(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in WebGear.</p>"},{"location":"gears/webgear/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera index to be used as the source, allowing you to drive these multiple cameras simultaneously from within a single Python session. Its value can only be zero or greater, otherwise, WebGear API will throw <code>ValueError</code> for any negative value.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code># select Camera Module at index `1`\nWebGear(enablePiCamera=True, camera_num=1)\n</code></pre> <p>The complete usage example demonstrating the usage of the <code>camera_num</code> parameter is available here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter controls the resolution - a tuple (i.e. <code>(width,height)</code>) of two values giving the width and height of the output frames. </p> <p>Make sure both width and height values should be at least <code>64</code>.</p> <p>When using the Picamera2 backend, the <code>resolution</code> parameter will be OVERRIDDEN, if the user explicitly defines the <code>output_size</code> property of the <code>sensor</code> configurational parameter.</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter controls the framerate of the source.</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#options_3","title":"<code>options</code>","text":"<p>This dictionary parameter in the internal PiGear API backend allows you to control various camera settings for both the <code>picamera2</code> and legacy <code>picamera</code> backends and some internal API tasks. These settings include:</p>"},{"location":"gears/webgear/params/#a-configurational-camera-parameters","title":"A. Configurational Camera Parameters","text":"<ul> <li> These parameters are provided by the underlying backend library (depending upon backend in use), and must be applied to the camera system before the camera can be started.</li> <li> These parameter include: Brightness, Contrast, Saturation, Exposure, Colour Temperature, Colour Gains, etc. </li> <li> All supported parameters are listed in this Usage example \u27b6</li> </ul>"},{"location":"gears/webgear/params/#b-user-defined-parameters","title":"B. User-defined Parameters","text":"<ul> <li> These user-defined parameters control specific internal behaviors of the API and perform certain tasks on the camera objects.</li> <li> All supported User-defined Parameters are listed here \u27b6</li> </ul> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>The complete usage example demonstrating the usage of the <code>options</code> parameter is available here \u27b6.</p> <p>You can format these user-defined and configurational parameters as attributes of this <code>options</code> dictionary parameter as follows:</p> New Picamera2 backendLegacy Picamera backend <pre><code># formulate various Picamera2 API parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"exposure_compensation\": 15,\n    \"sensor\": {\"output_size\": (480, 320)},  # !!! will override `resolution` !!!\n}\n\n# open pi video stream with defined parameters\nstream = WebGear(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <pre><code># formulate various Picamera API parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = WebGear(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in WebGear.</p>"},{"location":"gears/webgear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>WebGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/webgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WebGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the WebGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>WebGear(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/webgear/usage/","title":"Usage Examples","text":""},{"location":"gears/webgear/usage/#webgear-api-usage-examples","title":"WebGear API Usage Examples:","text":""},{"location":"gears/webgear/usage/#requirements","title":"Requirements","text":""},{"location":"gears/webgear/usage/#installation-with-asyncio-support","title":"Installation with Asyncio Support","text":"<p>WebGear API is the part of <code>asyncio</code> package of VidGear, thereby you need to install VidGear with asyncio support as follows:</p> <pre><code>pip install vidgear[asyncio]\n</code></pre>"},{"location":"gears/webgear/usage/#asgi-server","title":"ASGI Server","text":"<p>You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art <code>uvicorn</code> Server. But you can also use other ASGI server such as <code>daphne</code>, or <code>hypercorn</code> with it.</p> <p> </p>"},{"location":"gears/webgear/usage/#performance-enhancements","title":"Performance Enhancements","text":"<p>WebGear provides certain performance enhancing attributes for its <code>options</code> dictionary parameter to cope with performance-throttling.</p> <p>Performance Enhancing Attributes</p> <ul> <li> <p><code>frame_size_reduction</code>: (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to <code>20</code>, and must be no higher than <code>90</code> (fastest, max compression, Barely Visible frame-size) and no lower than <code>0</code> (slowest, no compression, Original frame-size). Its recommended value is between <code>40~60</code>. Its usage is as follows:</p> <pre><code>options={\"frame_size_reduction\": 50} #frame-size will be reduced by 50%\n</code></pre> </li> <li> <p>Various Encoding Parameters:</p> <p>In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image using <code>simplejpeg</code> library, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows:</p> <ul> <li> <p><code>jpeg_compression_quality</code>: (int/float) This attribute controls the JPEG quantization factor. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. Its usage is as follows:</p> <pre><code># activate jpeg encoding and set quality 95%\noptions = {\"jpeg_compression_quality\": 95}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastdct</code>: (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also <code>True</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast dct\noptions = {\"jpeg_compression_fastdct\": True}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastupsample</code>: (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is <code>False</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast upsampling\noptions = {\"jpeg_compression_fastupsample\": True}\n</code></pre> </li> </ul> </li> </ul> <p> </p>"},{"location":"gears/webgear/usage/#bare-minimum-usage-with-performance-enhancements","title":"Bare-Minimum Usage with Performance Enhancements","text":"<p>Let's implement our Bare-Minimum usage example with these Performance Enhancing Attributes \u27b6 for speeding up the output.</p>"},{"location":"gears/webgear/usage/#running-programmatically","title":"Running Programmatically","text":"<p>You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows:</p> <p>For accessing WebGear on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n\n# various performance tweaks\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n}\n\n# initialize WebGear app\nweb = WebGear(source=\"foo.mp4\", logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>which can be accessed on any browser on your machine at http://localhost:8000/.</p>"},{"location":"gears/webgear/usage/#running-from-terminal","title":"Running from Terminal","text":"<p>You can also access and run WebGear Server directly from the terminal commandline. The following command will run a WebGear VideoStreamer server at http://localhost:8000/:</p> <p>Make sure your <code>PYTHON_PATH</code> is set to python 3.7+ versions only.</p> <p>If you're using <code>--options/-op</code> flag, then kindly wrap your dictionary value in single <code>''</code> quotes.</p> <pre><code>python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"jpeg_compression_quality\": 80, \"jpeg_compression_fastdct\": True, \"jpeg_compression_fastupsample\": False}'\n</code></pre> <p>which can also be accessed on any browser on the network at http://localhost:8000/.</p> Advanced Usage from Terminal <p>You can run <code>python3 -m vidgear.gears.asyncio -h</code> help command to see all the advanced settings, as follows:</p> <pre><code>usage: python -m vidgear.gears.asyncio [-h] [-m MODE] [-s SOURCE] [-ep ENABLEPICAMERA] [-S STABILIZE]\n            [-cn CAMERA_NUM] [-yt stream_mode] [-b BACKEND] [-cs COLORSPACE]\n            [-r RESOLUTION] [-f FRAMERATE] [-td TIME_DELAY]\n            [-ip IPADDRESS] [-pt PORT] [-l LOGGING] [-op OPTIONS]\n\nRuns WebGear/WebGear_RTC Video Server through terminal.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -m {mjpeg,webrtc}, --mode {mjpeg,webrtc}\n                        Whether to use \"MJPEG\" or \"WebRTC\" mode for streaming.\n  -s SOURCE, --source SOURCE\n                        Path to input source for CamGear API.\n  -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA\n                        Sets the flag to access PiGear(if True) or otherwise\n                        CamGear API respectively.\n  -S STABILIZE, --stabilize STABILIZE\n                        Enables/disables real-time video stabilization.\n  -cn CAMERA_NUM, --camera_num CAMERA_NUM\n                        Sets the camera module index that will be used by\n                        PiGear API.\n  -yt STREAM_MODE, --stream_mode STREAM_MODE\n                        Enables YouTube Mode in CamGear API.\n  -b BACKEND, --backend BACKEND\n                        Sets the backend of the video source in CamGear API.\n  -cs COLORSPACE, --colorspace COLORSPACE\n                        Sets the colorspace of the output video stream.\n  -r RESOLUTION, --resolution RESOLUTION\n                        Sets the resolution (width,height) for camera module\n                        in PiGear API.\n  -f FRAMERATE, --framerate FRAMERATE\n                        Sets the framerate for camera module in PiGear API.\n  -td TIME_DELAY, --time_delay TIME_DELAY\n                        Sets the time delay(in seconds) before start reading\n                        the frames.\n  -ip IPADDRESS, --ipaddress IPADDRESS\n                        Uvicorn binds the socket to this ipaddress.\n  -pt PORT, --port PORT\n                        Uvicorn binds the socket to this port.\n  -l LOGGING, --logging LOGGING\n                        Enables/disables error logging, essential for\n                        debugging.\n  -op OPTIONS, --options OPTIONS\n                        Sets the parameters supported by APIs(whichever being\n                        accessed) to the input videostream, But make sure to\n                        wrap your dict value in single or double quotes.\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/advanced/","title":"Advanced Usages","text":""},{"location":"gears/webgear_rtc/advanced/#webgear_rtc-api-advanced-usage","title":"WebGear_RTC API Advanced Usage:","text":"<p>This is a continuation of the WebGear_RTC doc \u27b6. Thereby, It's advised to first get familiarize with this API, and its requirements.</p> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-as-real-time-broadcaster","title":"Using WebGear_RTC as Real-time Broadcaster","text":"<p>WebGear_RTC by default only supports one-to-one peer connection with a single consumer or client. But you can use <code>enable_live_broadcast</code> boolean attribute through its options dictionary parameter to easily enable live broadcast/stream to multiple peer consumers/clients at the same time.</p> <p>Let's implement a bare-minimum example using WebGear_RTC as Real-time Broadcaster:</p> <p><code>enable_infinite_frames</code> is enforced by default with this(<code>enable_live_broadcast</code>) attribute.</p> <p>For accessing WebGear_RTC on different Client Devices on the network, we use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various performance tweaks and enable live broadcasting\noptions = {\n    \"frame_size_reduction\": 25,\n    \"enable_live_broadcast\": True,\n}\n\n# initialize WebGear_RTC app\nweb = WebGear_RTC(source=\"foo.mp4\", logging=True, **options)\n\n# run this app on Uvicorn server at address http://0.0.0.0:8000/\nuvicorn.run(web(), host=\"0.0.0.0\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address on your local machine.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-a-custom-sourceopencv","title":"Using WebGear_RTC with a Custom Source(OpenCV)","text":"<p>WebGear_RTC provides <code>custom_stream</code> attribute with its <code>options</code> parameter that allows you to easily define your own Custom Streaming Class with suitable source that you want to use to transform your frames before sending them onto the browser. </p> <p>Let's implement a bare-minimum example with a Custom Source using WebGear_RTC API and OpenCV:</p> New in v0.2.4 <p>This implementation was added in <code>v0.2.4</code>.</p> <p>Auto-Reconnection or Auto-Refresh works out-of-the-box with this implementation.</p> <p>Make sure your Custom Streaming Class at-least implements <code>read()</code> and <code>stop()</code> methods as shown in following example, otherwise WebGear_RTC will throw ValueError!</p> Using Vidgear's VideoCapture APIs instead of OpenCV <p>You can directly replace Custom Streaming Class(<code>Custom_Stream_Class</code> in following example) with any VideoCapture APIs. These APIs implements <code>read()</code> and <code>stop()</code> methods by-default, so they're also supported out-of-the-box. </p> <p>See this example \u27b6 for more information.</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# create your own custom streaming class\nclass Custom_Stream_Class:\n    \"\"\"\n    Custom Streaming using OpenCV\n    \"\"\"\n\n    def __init__(self, source=0):\n\n        # !!! define your own video source here !!!\n        self.source = cv2.VideoCapture(source)\n\n        # define running flag\n        self.running = True\n\n    def read(self):\n\n        # don't forget this function!!!\n\n        # check if source was initialized or not\n        if self.source is None:\n            return None\n        # check if we're still running\n        if self.running:\n            # read frame from provided source\n            (grabbed, frame) = self.source.read()\n            # check if frame is available\n            if grabbed:\n\n                # do something with your OpenCV frame here\n\n                # lets convert frame to gray for this example\n                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n                # return our gray frame\n                return gray\n            else:\n                # signal we're not running now\n                self.running = False\n        # return None-type\n        return None\n\n    def stop(self):\n\n        # don't forget this function!!!\n\n        # flag that we're not running\n        self.running = False\n        # close stream\n        if not self.source is None:\n            self.source.release()\n\n# assign your Custom Streaming Class with adequate source (for e.g. foo.mp4) \n# to `custom_stream` attribute in options parameter\noptions = {\"custom_stream\": Custom_Stream_Class(source=\"foo.mp4\")}\n\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-custom-mounting-points","title":"Using WebGear_RTC with Custom Mounting Points","text":"<p>With our highly extensible WebGear_RTC API, you can add your own mounting points, where additional files located, as follows:</p> <pre><code># import libs\nimport uvicorn\nfrom starlette.routing import Mount\nfrom starlette.staticfiles import StaticFiles\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various performance tweaks\noptions = {\n    \"frame_size_reduction\": 25,\n}\n\n# initialize WebGear_RTC app\nweb = WebGear_RTC(\n    source=\"foo.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n\n# append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory\nweb.routes.append(\n    Mount(\"/test\", app=StaticFiles(directory=\"/home/foo/.vidgear/test\"), name=\"test\")\n)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script <code>jquery-3.3.1.slim.min.js</code> in this folder and  want to integrate it, then, we can do something like this:</p> <pre><code>&lt;script src=\"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\"&gt;&lt;/script&gt;\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-custom-webpage-routes","title":"Using WebGear_RTC with Custom Webpage Routes","text":"<p>With Webgear_RTC's flexible API, you can even add your additional HTML Static webpages without any extra efforts.</p> <p>Suppose we want to add a simple <code>hello world</code> webpage to our WebGear_RTC server. So let's create a bare-minimum <code>hello.html</code> file with HTML code as follows:</p> <pre><code>&lt;html&gt;\n   &lt;header&gt;\n      &lt;title&gt;This is Hello world page&lt;/title&gt;\n   &lt;/header&gt;\n   &lt;body&gt;\n      &lt;h1&gt;Hello World&lt;/h1&gt;\n      &lt;p&gt;how ya doing?&lt;/p&gt;\n   &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Then in our application code, we can integrate this webpage route, as follows:</p> <p><pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.templating import Jinja2Templates\nfrom starlette.routing import Route\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located\ntemplate = Jinja2Templates(directory=\"/home/foo/.vidgear/custom_template\")\n\n# render and return our webpage template\nasync def hello_world(request):\n    page = \"hello.html\"\n    context = {\"request\": request}\n    return template.TemplateResponse(page, context)\n\n\n# add various performance tweaks as usual\noptions = {\n    \"frame_size_reduction\": 25,\n}\n\n# initialize WebGear_RTC app with a valid source\nweb = WebGear_RTC(\n    source=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n\n# append new route to point our rendered webpage\nweb.routes.append(Route(\"/hello\", endpoint=hello_world))\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> And that's all, Now you can see output at <code>http://localhost:8000/hello</code> address.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-middlewares","title":"Using WebGear_RTC with MiddleWares","text":"<p>WebGear_RTC also natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>All supported middlewares can be found here \u27b6</p> <p>For this example, let's use <code>CORSMiddleware</code> for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows:</p> <p>The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context.</p> <p>Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6</p> <pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.cors import CORSMiddleware\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# add various performance tweaks as usual\noptions = {\n    \"frame_size_reduction\": 25,\n}\n\n# initialize WebGear_RTC app with a valid source\nweb = WebGear_RTC(\n    source=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n\n# define and assign suitable cors middlewares\nweb.middleware = [\n    Middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n]\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000</code> address.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-webgear_rtc-files-and-folders","title":"Rules for Altering WebGear_RTC Files and Folders","text":"<p>WebGear_RTC gives us complete freedom of altering data files generated in Auto-Generation Process, But you've to  keep the following rules in mind:</p>"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-data-files","title":"Rules for Altering Data Files","text":"<ul> <li> You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions.</li> <li> You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) present in <code>templates</code> folder inside the <code>webgear_rtc</code> directory at the default location, otherwise, it will trigger Auto-generation process, and it will overwrite the existing files with Server ones.</li> <li> You're allowed to add your own additional <code>.html</code>, <code>.css</code>, <code>.js</code>, etc. files in the respective folders at the default location and custom mounted Data folders.</li> </ul>"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-data-folders","title":"Rules for Altering Data Folders","text":"<ul> <li> You're allowed to add/mount any number of additional folder as shown in this example above.</li> <li> You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename <code>templates</code> folder in the <code>webgear_rtc</code> directory where critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) are located, otherwise, it will trigger Auto-generation process.</li> </ul>"},{"location":"gears/webgear_rtc/advanced/#bonus-examples","title":"Bonus Examples","text":"<p>Checkout more advanced WebGear_RTC examples with unusual configuration here \u27b6</p> <p> </p>"},{"location":"gears/webgear_rtc/overview/","title":"Overview","text":""},{"location":"gears/webgear_rtc/overview/#webgear_rtc-api","title":"WebGear_RTC API","text":"WebGear_RTC API's Video Server running at http://localhost:8000/ address."},{"location":"gears/webgear_rtc/overview/#overview","title":"Overview","text":"<p>WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms.</p> New in v0.2.1 <p>WebGear_RTC API was added in <code>v0.2.1</code>.</p> <p>WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.</p> <p>WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to seamlessly establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom streaming class with suitable source to transform frames easily before sending them across the network(see this doc example).</p> <p>WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. </p> <p>Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs.</p> <p> </p>"},{"location":"gears/webgear_rtc/overview/#data-files-auto-generation-workflow-for-webgear_rtc","title":"Data-Files Auto-Generation WorkFlow for WebGear_RTC","text":"<p>Same as WebGear, WebGear_RTC API automatically checks for three critical data files(i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) on initialization inside the <code>templates</code> folder of the <code>webgear_rtc</code> directory at the default location which gives rise to the following two possible scenario:</p> <ul> <li> If data-files found: it will proceed normally for instantiating the WebRTC media server through Starlette application.</li> <li> If data-files not found: it will trigger the Auto-Generation process</li> </ul>"},{"location":"gears/webgear_rtc/overview/#default-location","title":"Default Location","text":"<ul> <li>A default location is the path of the directory where data files/folders are downloaded/generated/saved.</li> <li>By default, the <code>.vidgear</code> the folder at the home directory of your machine (for e.g <code>/home/foo/.vidgear</code> on Linux ) serves as the default location.</li> <li>But you can also use WebGear_RTC's <code>custom_data_location</code> dictionary attribute to change/alter default location path to somewhere else.</li> </ul> <p>Identifying Default location</p> <p>You can set <code>logging=True</code> during initialization, for easily identifying the selected default location, which will be something like this on a Linux  machine:</p> <pre><code>WebGear_RTC :: DEBUG :: `/home/foo/.vidgear` is the default location for saving WebGear_RTC data-files.\n</code></pre>"},{"location":"gears/webgear_rtc/overview/#auto-generation-process","title":"Auto-Generation process","text":"<p>Info</p> <ul> <li> <p>You can also force trigger the Auto-generation process to overwrite existing data-files using <code>overwrite_default_files</code> dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected.</p> </li> <li> <p>It is advised to enable logging(<code>logging=True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <ul> <li>On triggering this process, WebGear_RTC API creates <code>webgear_rtc</code> directory, and <code>templates</code> and <code>static</code> folders inside along with <code>js</code>, <code>css</code>, <code>img</code> sub-folders at the assigned default location.</li> <li> <p>Thereby at this default location, the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order:</p> <pre><code>    .vidgear\n    \u2514\u2500\u2500 webgear_rtc\n        \u251c\u2500\u2500 static\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 css\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 custom.css\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 img\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 favicon-32x32.png\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 js\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 custom.js\n        \u2514\u2500\u2500 templates\n            \u251c\u2500\u2500 404.html\n            \u251c\u2500\u2500 500.html\n            \u251c\u2500\u2500 base.html\n            \u2514\u2500\u2500 index.html\n    6 directories, 7 files\n</code></pre> </li> <li> <p>Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.</p> </li> </ul> <p> </p>"},{"location":"gears/webgear_rtc/overview/#webgear_rtcs-default-template","title":"WebGear_RTC's Default Template","text":"<p>The WebGear_RTC API by default uses simple &amp; elegant WebGear_RTC's Default Theme which looks like something as follows:</p>"},{"location":"gears/webgear_rtc/overview/#indexhtml","title":"Index.html","text":"<p>Can be accessed by visiting WebGear_RTC app server, running at http://localhost:8000/:</p>"},{"location":"gears/webgear_rtc/overview/#404html","title":"404.html","text":"<p>Appears when respective URL is not found, for example http://localhost:8000/ok:</p>"},{"location":"gears/webgear_rtc/overview/#500html","title":"500.html","text":"<p>Appears when an API Error is encountered:</p> <p>If <code>logging</code> is enabled and an error occurs, then instead of displaying this 500 handler, WebGear_RTC will respond with a traceback response.</p> <p> </p>"},{"location":"gears/webgear_rtc/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WebGear_RTC Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/webgear_rtc/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/webgear_rtc/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/webgear_rtc/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/webgear_rtc/params/","title":"Parameters","text":""},{"location":"gears/webgear_rtc/params/#webgear_rtc-api-parameters","title":"WebGear_RTC API Parameters","text":"<p>WebGear_RTC provides a special internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear_RTC. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#options","title":"<code>options</code>","text":"<p>This parameter can be used to pass user-defined parameter to WebGear_RTC API by formatting them as this parameter's attribute. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p>"},{"location":"gears/webgear_rtc/params/#webgear_rtc-specific-attributes","title":"WebGear_RTC Specific attributes","text":"<ul> <li> <p><code>custom_stream</code> (class) : Can be used to easily define your own Custom Streaming Class with suitable custom source(such as OpenCV) that you want to use to transform your frames before sending them onto the browser. </p> <p>Make sure your Custom Streaming Class at-least implements <code>read()</code> and <code>stop()</code> methods, otherwise WebGear_RTC will throw ValueError!</p> New in v0.2.4 <p>This attribute was added in <code>v0.2.4</code>.</p> Using Vidgear's VideoCapture APIs instead of OpenCV <p>You can directly replace Custom Streaming Class with any VideoCapture APIs. These APIs implements <code>read()</code> and <code>stop()</code> methods by-default, so they're also supported out-of-the-box. </p> <p>See this example \u27b6 for more information.</p> <p>Its complete usage example is given here \u27b6.</p> <pre><code># set CamGear as custom streaming class with adequate parameters\noptions = {\"custom_stream\": CamGear(source=\"foo.mp4\", logging=True)}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>custom_data_location</code> (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows:</p> <pre><code># set default location to '/home/foo/foo1'\noptions = {\"custom_data_location\": \"/home/foo/foo1\"}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>overwrite_default_files</code> (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows:</p> <p>Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten.</p> <pre><code># force trigger the Auto-generation process\noptions = {\"overwrite_default_files\": True}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>frame_size_reduction</code> (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the  most significant effect on performance. The value defaults to <code>20</code>, and must be no higher than <code>90</code> (fastest, max compression, Barely Visible frame-size) and no lower than <code>0</code> (slowest, no compression, Original frame-size). Its recommended value is between <code>40-60</code>. Its usage is as follows:</p> <pre><code># frame-size will be reduced by 50%\noptions = {\"frame_size_reduction\": 50} \n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>enable_live_broadcast</code> (boolean) : WebGear_RTC by default only supports one-to-one peer connection with a single consumer/client, Hence this boolean attribute can be used to enable live broadcast to multiple peer consumers/clients at same time. Its default value is <code>False</code>. Its usage is as follows:</p> <p><code>enable_infinite_frames</code> is enforced by default when this attribute is enabled(<code>True</code>).</p> <p>For accessing WebGear_RTC on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> New in v0.2.2 <p><code>enable_live_broadcast</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># enable live boadcast to multiple consumers.\noptions = {\"enable_live_broadcast\": True}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> </li> <li> <p><code>enable_infinite_frames</code> (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is <code>False</code>. Its usage is as follows:</p> <p><code>enable_infinite_frames</code> is disabled when <code>enable_live_broadcast</code> attribute is enabled(<code>True</code>).</p> New in v0.2.1 <p><code>enable_infinite_frames</code> attribute was added in <code>v0.2.1</code>.</p> <pre><code># emulate infinite frames\noptions = {\"enable_infinite_frames\": True}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in WebGear_RTC. Default is also <code>False</code>.</p>"},{"location":"gears/webgear_rtc/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#options_1","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in WebGear_RTC.</p>"},{"location":"gears/webgear_rtc/params/#source","title":"<code>source</code>","text":"<p>WebGear_RTC API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>WebGear_RTC(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>WebGear_RTC(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>WebGear_RTC(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>WebGear_RTC(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/webgear_rtc/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>WebGear_RTC(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>WebGear_RTC(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nWebGear_RTC(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in WebGear_RTC.</p>"},{"location":"gears/webgear_rtc/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera index to be used as the source, allowing you to drive these multiple cameras simultaneously from within a single Python session. Its value can only be zero or greater, otherwise, WebGear_RTC API will throw <code>ValueError</code> for any negative value.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code># select Camera Module at index `1`\nWebGear_RTC(enablePiCamera=True, camera_num=1)\n</code></pre> <p>The complete usage example demonstrating the usage of the <code>camera_num</code> parameter is available here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter controls the resolution - a tuple (i.e. <code>(width,height)</code>) of two values giving the width and height of the output frames. </p> <p>Make sure both width and height values should be at least <code>64</code>.</p> <p>When using the Picamera2 backend, the <code>resolution</code> parameter will be OVERRIDDEN, if the user explicitly defines the <code>output_size</code> property of the <code>sensor</code> configurational parameter.</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter controls the framerate of the source.</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#options_3","title":"<code>options</code>","text":"<p>This dictionary parameter in the internal PiGear API backend allows you to control various camera settings for both the <code>picamera2</code> and legacy <code>picamera</code> backends and some internal API tasks. These settings include:</p>"},{"location":"gears/webgear_rtc/params/#a-configurational-camera-parameters","title":"A. Configurational Camera Parameters","text":"<ul> <li> These parameters are provided by the underlying backend library (depending upon backend in use), and must be applied to the camera system before the camera can be started.</li> <li> These parameter include: Brightness, Contrast, Saturation, Exposure, Colour Temperature, Colour Gains, etc. </li> <li> All supported parameters are listed in this Usage example \u27b6</li> </ul>"},{"location":"gears/webgear_rtc/params/#b-user-defined-parameters","title":"B. User-defined Parameters","text":"<ul> <li> These user-defined parameters control specific internal behaviors of the API and perform certain tasks on the camera objects.</li> <li> All supported User-defined Parameters are listed here \u27b6</li> </ul> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>The complete usage example demonstrating the usage of the <code>options</code> parameter is available here \u27b6.</p> <p>You can format these user-defined and configurational parameters as attributes of this <code>options</code> dictionary parameter as follows:</p> New Picamera2 backendLegacy Picamera backend <pre><code># formulate various Picamera2 API parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"exposure_compensation\": 15,\n    \"sensor\": {\"output_size\": (480, 320)},  # !!! will override `resolution` !!!\n}\n\n# open pi video stream with defined parameters\nstream = WebGear_RTC(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <pre><code># formulate various Picamera API parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = WebGear_RTC(enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options).start()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in WebGear_RTC.</p>"},{"location":"gears/webgear_rtc/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>WebGear_RTC(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WebGear_RTC(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the WebGear_RTC API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>WebGear_RTC(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/usage/","title":"Usage Examples","text":""},{"location":"gears/webgear_rtc/usage/#webgear_rtc-api-usage-examples","title":"WebGear_RTC API Usage Examples:","text":""},{"location":"gears/webgear_rtc/usage/#requirements","title":"Requirements","text":""},{"location":"gears/webgear_rtc/usage/#installation-with-asyncio-support","title":"Installation with Asyncio Support","text":"<p>WebGear_RTC API is the part of <code>asyncio</code> package of VidGear, thereby you need to install VidGear with asyncio support as follows:</p> <pre><code>pip install vidgear[asyncio]\n</code></pre>"},{"location":"gears/webgear_rtc/usage/#aiortc","title":"Aiortc","text":"<p>Must Required with WebGear_RTC API. You can easily install it via pip:</p> Microsoft Visual C++ 14.0 is required. <p>Installing <code>aiortc</code> on windows requires Microsoft Build Tools for Visual C++ libraries installed. You can easily fix this error by installing any ONE of these choices:</p> <p>While the error is calling for VC++ 14.0 - but newer versions of Visual C++ libraries works as well.</p> <ul> <li>Microsoft Build Tools for Visual Studio.</li> <li>Alternative link to Microsoft Build Tools for Visual Studio.</li> <li>Offline installer: vs_buildtools.exe</li> </ul> <p>Afterwards, Select: Workloads \u2192 Desktop development with C++, then for Individual Components, select only:</p> <ul> <li> Windows 10 SDK</li> <li> C++ x64/x86 build tools</li> </ul> <p>Finally, proceed installing <code>aiortc</code> via pip.</p> <pre><code>  pip install aiortc\n</code></pre>"},{"location":"gears/webgear_rtc/usage/#asgi-server","title":"ASGI Server","text":"<p>You'll also need to install an ASGI Server to run following WebGear_RTC usage examples, and by default WebGear_RTC ships the state-of-the-art <code>uvicorn</code> Server. But you can also use other ASGI server such as <code>daphne</code>, or <code>hypercorn</code> with it.</p> <p> </p>"},{"location":"gears/webgear_rtc/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Let's implement a Bare-Minimum usage example:</p>"},{"location":"gears/webgear_rtc/usage/#running-programmatically","title":"Running Programmatically","text":"<p>You can access and run WebGear_RTC VideoStreamer Server programmatically in your python script in just a few lines of code, as follows:</p> <p>For accessing WebGear_RTC on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> <p>We are using <code>frame_size_reduction</code> attribute for frame size reduction (in percentage) to be streamed with its <code>options</code> dictionary parameter to cope with performance-throttling in this example.</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various performance tweaks\noptions = {\n    \"frame_size_reduction\": 25,\n}\n\n# initialize WebGear_RTC app\nweb = WebGear_RTC(source=\"foo.mp4\", logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>which can be accessed on any browser on your machine at http://localhost:8000/.</p>"},{"location":"gears/webgear_rtc/usage/#running-from-terminal","title":"Running from Terminal","text":"<p>You can also access and run WebGear_RTC Server directly from the terminal commandline. The following command will run a WebGear_RTC VideoStreamer server at http://localhost:8000/:</p> <p>Make sure your <code>PYTHON_PATH</code> is set to python 3.7+ versions only.</p> <p>If you're using <code>--options/-op</code> flag, then kindly wrap your dictionary value in single <code>''</code> quotes.</p> <pre><code>python3 -m vidgear.gears.asyncio --mode webrtc --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}'\n</code></pre> <p>which can also be accessed on any browser on the network at http://localhost:8000/.</p> Advanced Usage from Terminal <p>You can run <code>python3 -m vidgear.gears.asyncio -h</code> help command to see all the advanced settings, as follows:</p> <pre><code>usage: python -m vidgear.gears.asyncio [-h] [-m MODE] [-s SOURCE] [-ep ENABLEPICAMERA] [-S STABILIZE]\n            [-cn CAMERA_NUM] [-yt stream_mode] [-b BACKEND] [-cs COLORSPACE]\n            [-r RESOLUTION] [-f FRAMERATE] [-td TIME_DELAY]\n            [-ip IPADDRESS] [-pt PORT] [-l LOGGING] [-op OPTIONS]\n\nRuns WebGear/WebGear_RTC Video Server through terminal.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -m {mjpeg,webrtc}, --mode {mjpeg,webrtc}\n                        Whether to use \"MJPEG\" or \"WebRTC\" mode for streaming.\n  -s SOURCE, --source SOURCE\n                        Path to input source for CamGear API.\n  -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA\n                        Sets the flag to access PiGear(if True) or otherwise\n                        CamGear API respectively.\n  -S STABILIZE, --stabilize STABILIZE\n                        Enables/disables real-time video stabilization.\n  -cn CAMERA_NUM, --camera_num CAMERA_NUM\n                        Sets the camera module index that will be used by\n                        PiGear API.\n  -yt STREAM_MODE, --stream_mode STREAM_MODE\n                        Enables YouTube Mode in CamGear API.\n  -b BACKEND, --backend BACKEND\n                        Sets the backend of the video source in CamGear API.\n  -cs COLORSPACE, --colorspace COLORSPACE\n                        Sets the colorspace of the output video stream.\n  -r RESOLUTION, --resolution RESOLUTION\n                        Sets the resolution (width,height) for camera module\n                        in PiGear API.\n  -f FRAMERATE, --framerate FRAMERATE\n                        Sets the framerate for camera module in PiGear API.\n  -td TIME_DELAY, --time_delay TIME_DELAY\n                        Sets the time delay(in seconds) before start reading\n                        the frames.\n  -ip IPADDRESS, --ipaddress IPADDRESS\n                        Uvicorn binds the socket to this ipaddress.\n  -pt PORT, --port PORT\n                        Uvicorn binds the socket to this port.\n  -l LOGGING, --logging LOGGING\n                        Enables/disables error logging, essential for\n                        debugging.\n  -op OPTIONS, --options OPTIONS\n                        Sets the parameters supported by APIs(whichever being\n                        accessed) to the input videostream, But make sure to\n                        wrap your dict value in single or double quotes.\n</code></pre> <p> </p>"},{"location":"gears/writegear/introduction/","title":"Introduction","text":""},{"location":"gears/writegear/introduction/#writegear-api","title":"WriteGear API","text":"WriteGear API generalized workflow"},{"location":"gears/writegear/introduction/#overview","title":"Overview","text":"<p>WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data.</p> <p>WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specifications (such as<code>bitrate, codec, framerate, resolution, subtitles,  etc.</code>). </p> <p>WriteGear also supports streaming with traditional protocols such as RTSP/RTP, RTMP. It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch, YouTube etc.) and Multiplexing Video-Audio with real-time frames in just few lines of code.</p> <p>Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc) without relying on any third-party API.</p> <p>In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.</p> <p> </p>"},{"location":"gears/writegear/introduction/#modes-of-operation","title":"Modes of Operation","text":"<p>WriteGear primarily operates in following modes:</p> <ul> <li> <p>Compression Mode: In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly.</p> </li> <li> <p>Non-Compression Mode: In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameter transformations available within OpenCV's VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc.</p> </li> </ul> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/introduction/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/writegear/compression/overview/","title":"Overview","text":""},{"location":"gears/writegear/compression/overview/#writegear-api-compression-mode","title":"WriteGear API: Compression Mode","text":"WriteGear API's Compression Mode generalized workflow"},{"location":"gears/writegear/compression/overview/#overview","title":"Overview","text":"<p>When <code>compression_mode</code> parameter is enabled (.i.e <code>compression_mode = True</code>), WriteGear API provides a complete, flexible &amp; robust wrapper around FFmpeg to encode lossless &amp; compressed multimedia files.</p> <p>This mode can process real-time video frames into a lossless compressed format with any suitable setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, and much more in just a few easy lines of code. It can also perform complex tasks such as Live-Streaming (such as for Twitch), multiplexing video with audio in real-time (see this usage example) while handling all errors robustly.</p> <p> </p> <p>Important Information</p> <ul> <li> <p>WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it automatically fallbacks to Non-Compression Mode.</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug any issues/errors easily and make suitable adjustments accordingly. </p> </li> </ul> <p>You can speed up the execution time by disabling logging (.i.e <code>logging = False</code>) for production use, and by tweaking FFmpeg parameters in <code>output_params</code> values. Look into FFmpeg docs \u27b6 for such hacks.</p> <p> </p>"},{"location":"gears/writegear/compression/overview/#custom-ffmpeg-commands-in-writegear-api","title":"Custom FFmpeg Commands in WriteGear API","text":"<p>WriteGear API now provides the <code>execute_ffmpeg_cmd</code> Function in Compression Mode, that enables the user to pass any custom CLI commands as an input to its internal FFmpeg Pipeline by formating it as a list. </p> <p>This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly.</p> <p>A complete guide on <code>execute_ffmpeg_cmd</code> Function can be found here \u27b6</p> <p> </p>"},{"location":"gears/writegear/compression/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/writegear/compression/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/writegear/compression/params/","title":"Parameters","text":""},{"location":"gears/writegear/compression/params/#writegear-api-parameters-compression-mode","title":"WriteGear API Parameters: Compression Mode","text":""},{"location":"gears/writegear/compression/params/#output","title":"<code>output</code>","text":"<p>This parameter sets the valid filename/path/URL for the video output.</p> <p>Warning</p> <p>WriteGear API will throw <code>ValueError</code> if <code>output</code> provided is empty or invalid.</p> <p>Data-Type: String</p> <p>Usage:</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p>Path to directory: Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename (with a default extension i.e.<code>.mp4</code>) as follows:</p> <pre><code>writer = WriteGear(output = '/home/foo/foo1') #Define writer \n</code></pre> </li> <li> <p>Filename (with/without path): Valid filename(with valid extension) of the output video file. In case filename is provided without path, then current working directory will be used.</p> <pre><code>writer = WriteGear(output = 'output.mp4') #Define writer \n</code></pre> <p>Make sure to provide valid filename with valid file-extension based on the encoder in use.</p> </li> <li> <p>URL: Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command <code>ffmpeg -protocols</code>) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a <code>rtmp</code> protocol URL as follows:</p> <pre><code>writer = WriteGear(output = 'rtmp://localhost/live/test') #Define writer \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/writegear/compression/params/#compression_mode","title":"<code>compression_mode</code>","text":"<p>This parameter selects the WriteGear's Primary Mode of Operation, i.e. if this parameter is enabled (.i.e <code>compression_mode = True</code>) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e <code>compression_mode = False</code>), the OpenCV's VideoWriter API will be used for encoding files/streams. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>True</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', compression_mode=True)\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only.</p> <p>Compression Mode Behavior on Windows</p> <p>In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through <code>custom_ffmpeg</code> parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine. More information can be found here \u27b6.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># if ffmpeg executables are located at \"/foo/foo1/FFmpeg\"\nWriteGear(output = 'output.mp4', custom_ffmpeg=\"/foo/foo1/FFmpeg\")\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/params/#output_params","title":"<code>output_params</code>","text":"<p>This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below:</p> <p>Kindly read FFmpeg Docs carefully, before passing any values to <code>output_param</code> dictionary parameter. Wrong values may result in undesired Errors or no output at all.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p>"},{"location":"gears/writegear/compression/params/#supported-parameters","title":"Supported Parameters","text":"<ul> <li> <p>FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in <code>output_param</code>. For example, for using <code>libx264 encoder</code> to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows:</p> <p>While providing additional av-source with <code>-i</code> FFmpeg parameter in <code>output_params</code> make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things!</p> <p>All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs.</p> <p>Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters</p> <pre><code> output_params = {\"-vcodec\":\"libx264\", \"-crf\": 0, \"-preset\": \"fast\", \"-tune\": \"zerolatency\"} \n</code></pre> </li> <li> <p>Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below:</p> <ul> <li> <p><code>-ffmpeg_download_path</code> (string): sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. <code>C:/User/temp</code>) on your windows machine. It can be used as follows: </p> <pre><code>output_params = {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"} # will be saved to \"C:/User/foo/foo1\"\n</code></pre> </li> <li> <p><code>-input_framerate</code> (float/int) : sets the constant framerate of the output. It can be used as follows: </p> <pre><code>output_params = {\"-input_framerate\": 60.0} # set the constant framerate to 60fps\n</code></pre> <p>Its usage example can be found here \u27b6</p> </li> <li> <p><code>-output_dimensions</code> (tuple/list) : sets the custom dimensions(size/resolution) of the output video (otherwise input video-frame size will be used). Its value can either be a tuple =&gt; <code>(width,height)</code> or a list =&gt; <code>[width, height]</code>, Its usage is as follows: </p> <pre><code>output_params = {\"-output_dimensions\": (1280,720)} # to produce a 1280x720 resolution/scale output video\n</code></pre> </li> <li> <p><code>-clones</code> (list): required to set special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue) or in cases where you want to preserve order of multiple FFmpeg parameters. This attribute only accepts list datatype as value. Its usage is as follows:</p> <p>Turn on logging(<code>logging = True</code>) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <p>WriteGear by automatically applies <code>-format</code> or <code>-f</code>, <code>-pix_fmt</code> and <code>-vcodec</code> or <code>-v:f</code> like critical input parameters for every stream. Therefore if you need multiple values for these parameter just define them with <code>-clones</code> attribute.</p> <pre><code>output_params = {\n    \"-i\": \"plug:dsnoopUSB\",\n    \"-f\": \"alsa\",\n    \"-ac\": \"1\",\n    \"-ar\": \"48000\",\n    \"-clones\": [\"-vcodec\", \"mpeg1video\", \"-f\", \"mpegts\"],\n}\n</code></pre> </li> <li> <p><code>-ffpreheaders</code> (list): required to set special FFmpeg parameters that are present at the starting of command(such as <code>-re</code>). This attribute only accepts list datatype as value. Its usage is as follows:</p> <p>This attribute is quite powerful and can break FFmpeg pipeline easily if not used correctly. User Discretion is advised!</p> <p>Turn on logging(<code>logging = True</code>) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <pre><code>output_params = {\n    \"-ffpreheaders\": [\"-re\"], # executes as `ffmpeg -re &lt;rest of command&gt;`\n}\n</code></pre> </li> <li> <p><code>-disable_ffmpeg_window</code> (bool): sets a special flag to enable detached subprocess creation on Windows OS, and can be useful while creating an <code>.exe</code> file for a python script that uses WriteGear API. On Windows, in certain cases, even after creating the <code>.exe</code> file in windowed mode or no-console mode, the FFmpeg commandline window would pop up while its being used by WriteGear API. Its usage is as follows:</p> New in v0.3.2 <p>This feature was added in <code>v0.3.2</code>.</p> <p><code>-disable_ffmpeg_window</code> is only available on Windows OS with logging disabled(<code>logging=False</code>) in compression mode.</p> <pre><code>output_params = {\"-disable_ffmpeg_window\": True} # disables FFmpeg creation window\n</code></pre> </li> <li> <p><code>-disable_force_termination</code> (bool): sets a special flag to manually disable the default forced termination of FFmpeg process in WriteGear API when <code>-i</code> FFmpeg parameter is used (For more details, see issue: #149). Its usage is as follows:</p> <p>The <code>-disable_force_termination</code> flag is a absolute necessity when video duration is too short(<code>&lt; 60sec</code>), otherwise WriteGear may produce invalid or no output.</p> <pre><code>output_params = {\"-disable_force_termination\": True} # disable the default forced-termination behaviour\n</code></pre> </li> </ul> </li> </ul>"},{"location":"gears/writegear/compression/params/#supported-encoders","title":"Supported Encoders","text":"<p>All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal:</p> <p>Similarily, supported demuxers and filters depends upons compiled FFmpeg in use.</p> <pre><code>ffmpeg -encoders           # use `ffmpeg.exe -encoders` on windows\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', logging=True)\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/","title":"Usage Examples","text":""},{"location":"gears/writegear/compression/usage/#writegear-api-usage-examples-compression-mode","title":"WriteGear API Usage Examples: Compression Mode","text":"<p>Important Information</p> <ul> <li> <p>WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it automatically fallbacks to Non-Compression Mode.</p> </li> <li> <p>DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with <code>ValueError</code>.</p> </li> <li> <p>While providing additional av-source with <code>-i</code> FFmpeg parameter in <code>output_params</code> make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things!</p> </li> <li> <p>Use <code>-disable_force_termination</code> flag when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> </li> <li> <p>Heavy resolution multimedia files take time to render which can last up to 0.1-1 seconds. Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead.</p> </li> <li> <p>Always use <code>writer.close()</code> at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.</p> </li> </ul> <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/writegear/compression/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = CamGear(source=\"myvideo.avi\").start()\n\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-in-rgb-mode","title":"Using Compression Mode in RGB Mode","text":"<p>In Compression Mode, WriteGear API contains <code>rgb_mode</code> boolean parameter for RGB Mode, which when enabled (i.e. <code>rgb_mode=True</code>), specifies that incoming frames are of RGB format (instead of default BGR format). This mode makes WriteGear directly compatible with libraries that only supports RGB format. </p> <p>The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # simulating RGB frame for example\n    frame_rgb = frame[:, :, ::-1]\n\n    # writing RGB frame to writer\n    writer.write(frame_rgb, rgb_mode=True)  # activate RGB Mode\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-controlled-framerate","title":"Using Compression Mode with controlled FrameRate","text":"<p>WriteGear API provides <code>-input_framerate</code>  attribute for its <code>options</code> dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. </p> Advanced Tip for setting constant framerate <p>If <code>-input_framerate</code> attribute doesn't works for you, then define it in conjunction with another <code>-r</code> FFmpeg parameter as attribute:</p> <pre><code># set output constant framerate to (say 60 fps)\noutput_params = {\"-input_framerate\":60, \"-r\":60}\n# assign that to WriteGear\nwriter = WriteGear(output=\"out.mp4\", logging =True, **output_params)\n</code></pre> <p>But make sure you MUST set value of <code>-r</code> and <code>-input_framerate</code> parameter less than or equal to your input source framerate.</p> <p>In this code we will retrieve framerate from video stream, and set it as <code>-input_framerate</code> attribute for <code>option</code> parameter in WriteGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n\n# retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter\noutput_params = {\"-input_framerate\": stream.framerate}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if None-type\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-for-live-streaming","title":"Using Compression Mode for live streaming","text":"<p>In Compression Mode, WriteGear also allows URL strings (as output) for live streaming realtime frames with its <code>output</code> parameter.  </p> <p>In this example, we will stream live camera frames directly to Twitch :</p> <p>For streaming with traditional protocols such as  RTSP/RTP, Checkout this WriteGear's Bonus Examples \u27b6.</p> <p> YouTube-Live Streaming example code also available in WriteGear's Bonus Examples \u27b6</p> <p>This example assume you already have a Twitch Account for publishing video.</p> <p>Make sure to change Twitch Stream Key with yours in following code before running!</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open live webcam video stream on first index(i.e. 0) device\nstream = CamGear(source=0, logging=True).start()\n\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n    \"-preset:v\": \"veryfast\",\n    \"-g\": 60,\n    \"-keyint_min\": 60,\n    \"-sc_threshold\": 0,\n    \"-bufsize\": \"2500k\",\n    \"-f\": \"flv\",\n}\n\n# [WARNING] Change your Twitch Stream Key here:\nTWITCH_KEY = \"live_XXXXXXXXXX~XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n# Define writer with defined parameters and\nwriter = WriteGear(\n    output=\"rtmp://live.twitch.tv/app/{}\".format(TWITCH_KEY),\n    logging=True,\n    **output_params\n)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-hardware-encoders","title":"Using Compression Mode with Hardware encoders","text":"<p>By default, WriteGear API uses <code>libx264</code> encoder for encoding output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing <code>-vcodec</code> FFmpeg parameter as an attribute with its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU  easily. </p> User Discretion Advised <p>This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your system hardware settings only.</p> <p>In this example, we will be using <code>h264_vaapi</code> as our hardware encoder and also optionally be specifying our device hardware's location (i.e. <code>'-vaapi_device':'/dev/dri/renderD128'</code>) and other features such as <code>'-vf':'format=nv12,hwupload'</code>:</p> Remember to check VAAPI support <p>To use <code>h264_vaapi</code> encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows:</p> <pre><code>ffmpeg  -hide_banner -encoders | grep vaapi \n\n V..... h264_vaapi           H.264/AVC (VAAPI) (codec h264)\n V..... hevc_vaapi           H.265/HEVC (VAAPI) (codec hevc)\n V..... mjpeg_vaapi          MJPEG (VAAPI) (codec mjpeg)\n V..... mpeg2_vaapi          MPEG-2 (VAAPI) (codec mpeg2video)\n V..... vp8_vaapi            VP8 (VAAPI) (codec vp8)\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open live webcam video stream on first index(i.e. 0) device\nstream = CamGear(source=0, logging=True).start()\n\n# define required FFmpeg parameters for your writer\noutput_params = {\n    \"-vcodec\": \"h264_vaapi\",\n    \"-vaapi_device\": \"/dev/dri/renderD128\",\n    \"-vf\": \"format=nv12,hwupload\",\n}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-opencv","title":"Using Compression Mode with OpenCV","text":"<p>You can easily use WriterGear API directly with any Video Processing library(For e.g OpenCV itself) in Compression Mode. The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # write gray frame to writer\n    writer.write(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-live-audio-input","title":"Using Compression Mode with Live Audio Input","text":"<p>In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of in its Compression Mode. Hence, combining audio with live video frames is pretty easy. </p> <p>In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic) to live frames incoming from the Video Source (for e.g external webcam), and save the output as a compressed video file, all in real time:</p> <p>Example Assumptions</p> <ul> <li>You're running are Linux machine.</li> <li>You already have appropriate audio driver and software installed on your machine.</li> </ul> Identifying and Specifying sound card on different OS platforms  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details.</p> </li> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg -list_devices true -f dshow -i dummy\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n    \"-f\": \"dshow\", # !!! warning: always keep this line above \"-i\" parameter !!!\n    \"-i\":\"audio=Microphone (USB2.0 Camera)\",\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-acodec\": \"aac\",\n    \"-ar\": \"44100\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel</p> <p>Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> Identify Sound Card: To get the list of all installed cards on your machine, you can type <code>arecord -l</code> or <code>arecord -L</code> (longer output).</p> <pre><code>arecord -l\n\n**** List of CAPTURE Hardware Devices ****\ncard 0: ICH5 [Intel ICH5], device 0: Intel ICH [Intel ICH5]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 1: Intel ICH - MIC ADC [Intel ICH5 - MIC ADC]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 2: Intel ICH - MIC2 ADC [Intel ICH5 - MIC2 ADC]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 3: Intel ICH - ADC2 [Intel ICH5 - ADC2]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: U0x46d0x809 [USB Device 0x46d:0x809], device 0: USB Audio [USB Audio]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <p>The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as <code>hw:0</code> or <code>hw:1</code></p> <pre><code># assign appropriate input audio-source\noutput_params = {\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-ar\": \"48000\",\n    \"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n    \"-i\": \"hw:1\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines:</p> <ul> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>avfoundation</code> as follows:</p> <pre><code>ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-ar\": \"48000\",\n    \"-f\": \"avfoundation\", # !!! warning: always keep this line above \"-audio_device_index\" parameter !!!\n    \"-audio_device_index\": \"0\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>Make sure this <code>-i</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer\noutput_params = {\n    \"-input_framerate\": stream.framerate,\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-ar\": \"48000\",\n    \"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n    \"-i\": \"hw:1\",\n}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/","title":"Custom FFmpeg Commands","text":""},{"location":"gears/writegear/compression/advanced/cciw/#custom-ffmpeg-commands-in-writegear-api","title":"Custom FFmpeg Commands in WriteGear API","text":"<p>WriteGear API now provides the <code>execute_ffmpeg_cmd</code> Method in Compression Mode that enables the user to pass any custom FFmpeg CLI (Command Line Interface) commands as input to its internal FFmpeg Pipeline by formating it as a list. </p> <p>This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly.</p> <p> </p> <p>Important Information</p> <ul> <li> <p>This Feature Requires WriteGear's Compression Mode enabled(<code>compression_mode = True</code>). Follow these dedicated Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>Only python list is a valid datatype as input for this function, any other value will throw <code>ValueError</code>.</p> </li> <li> <p>Kindly read FFmpeg Docs carefully, before passing any values to <code>output_param</code> dictionary parameter. Wrong values may result in undesired Errors or no output at all.</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#features","title":"Features","text":"<ul> <li> <p> Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline.</p> </li> <li> <p> Compatible with any FFmpeg terminal command.</p> </li> <li> <p> Standalone On-the-fly functioning.</p> </li> <li> <p> Can work without interfering with WriteGear API's Writer pipeline.</p> </li> <li> <p> Minimum hassle and extremely easy to enable and use. </p> </li> </ul> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#methods","title":"Methods","text":""},{"location":"gears/writegear/compression/advanced/cciw/#execute_ffmpeg_cmd","title":"<code>execute_ffmpeg_cmd</code>","text":"<p>This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: </p> <pre><code># format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list\nffmpeg_command = [\"-y\", \"-i\", source_video, \"-acodec\", \"copy\", \"input_audio.aac\"]\n\n# execute this list using this function\nexecute_ffmpeg_cmd(ffmpeg_command)\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#usage-examples","title":"Usage Examples","text":"<p>Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue.</p>"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-separate-audio-from-video","title":"Using WriteGear to separate Audio from Video","text":"<p>In this example, we will extract and save audio from a URL stream:</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n\n# define a valid url\nurl_to_stream = (\n    \"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\"\n)\n\n# Define writer with default parameters\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n\n# format command to convert stream audio as 'output_audio.aac' as list\nffmpeg_command_to_save_audio = [\n    \"-y\",\n    \"-i\",\n    url_to_stream,\n    \"output_audio.aac\",\n]  # `-y` parameter is to overwrite outputfile if exists\n\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command_to_save_audio)\n\n# safely close writer\nwriter.close()\n</code></pre> <p>After running this script, You will get the final <code>'output_audio.aac'</code> audio file.</p> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-merge-audio-with-video","title":"Using WriteGear to merge Audio with Video","text":"<p>In this example, we will merge audio with video:</p> <p>You can also directly add external audio input to video-frames in WriteGear. For more information, See this FAQ example \u27b6</p> <p>Example Assumptions</p> <ul> <li> <p>You already have a separate video(i.e <code>'input-video.mp4'</code>) and audio(i.e <code>'input-audio.aac'</code>) files.</p> </li> <li> <p>Both these Audio and Video files are compatible.</p> </li> </ul> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\nimport time\n\n# Open input video stream\nstream = VideoGear(source=\"input-video.mp4\").start()\n\n# set input audio stream path\ninput_audio = \"input-audio.aac\"\n\n# define your parameters\noutput_params = {\n    \"-input_framerate\": stream.framerate\n}  # output framerate must match source framerate\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n\n\n# sleep 1 sec as the above video might still be rendering\ntime.sleep(1)\n\n\n# format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4`\nffmpeg_command = [\n    \"-y\",\n    \"-i\",\n    \"Output.mp4\",\n    \"-i\",\n    input_audio,\n    \"-c:v\",\n    \"copy\",\n    \"-c:a\",\n    \"copy\",\n    \"-map\",\n    \"0:v:0\",\n    \"-map\",\n    \"1:a:0\",\n    \"-shortest\",\n    \"Output_with_audio.mp4\",\n]  # `-y` parameter is to overwrite outputfile if exists\n\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n</code></pre> <p>After running this script, You will get the final <code>'Output_with_audio.mp4'</code> file with both video and audio merged.</p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/","title":"FFmpeg Installation","text":""},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#ffmpeg-installation-instructions","title":"FFmpeg Installation Instructions","text":"<p>WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation:</p> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it automatically fallbacks to Non-Compression Mode.</p> <p> </p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#linux-ffmpeg-installation","title":"Linux FFmpeg Installation","text":"<p>The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection","title":"A. Auto-Detection","text":"<p>This is a recommended approach on Linux Machines</p> <p>If WriteGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module. </p> <p>Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Linux Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Linux Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>)  or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the WriteGear API.</p> <p>If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#windows-ffmpeg-installation","title":"Windows FFmpeg Installation","text":"<p>The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems.</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-installation","title":"A. Auto-Installation","text":"<p>This is a recommended approach on Windows Machines</p> <p>If WriteGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. <code>C:\\Temp</code>) of your machine.</p> <p>Warning</p> <ul> <li> <p>The files downloaded to temporary directory (for e.g. <code>C:\\TEMP</code>), may get erased if your machine shutdowns/restarts.</p> </li> <li> <p>You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through <code>-ffmpeg_download_path</code> parameter.</p> </li> <li> <p>If binaries were found at the specified path, WriteGear automatically skips the auto-installation step.</p> </li> <li> <p>If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode!</p> </li> </ul>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_1","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Windows Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Windows Static Binaries: https://ffmpeg.org/download.html#build-windows</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'C:/foo/Downloads/ffmpeg/bin'</code>) or path of <code>ffmpeg.exe</code> executable itself to the <code>custom_ffmpeg</code> parameter in the WriteGear API.</p> <p>If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#macos-ffmpeg-installation","title":"MacOS FFmpeg Installation","text":"<p>The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection_1","title":"A. Auto-Detection","text":"<p>This is a recommended approach on MacOS Machines</p> <p>If WriteGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module.</p> <p>Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_2","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest macOS Static Binaries(only x64 Binaries) from the link below:</p> <p>MacOS Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>) or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the WriteGear API.</p> <p>If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/non_compression/overview/","title":"Overview","text":""},{"location":"gears/writegear/non_compression/overview/#writegear-api-non-compression-mode","title":"WriteGear API: Non-Compression Mode","text":"WriteGear API's Non-Compression Mode generalized workflow"},{"location":"gears/writegear/non_compression/overview/#overview","title":"Overview","text":"<p>When <code>compression_mode</code> parameter is disabled (.i.e <code>compression_mode = False</code>), WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression.</p> <p>This mode provides flexible access to OpenCV's VideoWriter API,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. which are only available in Compression Mode. Thereby, the resultant output video-file size will be many times larger as compared to Compression Mode.</p> <p> </p> <p>Important Information</p> <ul> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode.</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/non_compression/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/writegear/non_compression/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/writegear/non_compression/params/","title":"Parameters","text":""},{"location":"gears/writegear/non_compression/params/#writegear-api-parameters-non-compression-mode","title":"WriteGear API Parameters: Non-Compression Mode","text":""},{"location":"gears/writegear/non_compression/params/#output","title":"<code>output</code>","text":"<p>This parameter sets the valid output Video filename/path for the output video.</p> <p>WriteGear API will throw <code>RuntimeError</code> if <code>output</code> provided is empty or invalid.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <p>Make sure to provide valid filename with valid file-extension based on the encoder in use (default is <code>.mp4</code>).</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p>Path to directory: Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename (with a default extension i.e.<code>.mp4</code>) as follows:</p> <pre><code>writer = WriteGear(output = '/home/foo/foo1', compression_mode=False) # Define writer \n</code></pre> </li> <li> <p>Filename (with/without path): Valid filename(with valid extension) of the output video file. In case filename is provided without path, then current working directory will be used.</p> <pre><code>writer = WriteGear(output = 'output.mp4', compression_mode=False) # Define writer \n</code></pre> </li> <li> <p>GStreamer Pipeline: </p> <p>WriteGear API also supports GStreamer Pipeline as input to its <code>output</code> parameter in Non-Compression Mode, when GStreamer Pipeline Mode is enabled. It can be used as follows:</p> <p>Requirement for GStreamer Pipelining</p> <p>GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> New in v0.2.5 <p>This feature was added in <code>v0.2.5</code>.</p> <pre><code># enable GStreamer Pipeline Mode for writer\noutput_params = {\"-gst_pipeline_mode\": True}\n# Define writer\nwriter = WriteGear(\noutput=\"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location=foo.mp4\", compression_mode=False) \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/writegear/non_compression/params/#compression_mode","title":"<code>compression_mode</code>","text":"<p>This parameter selects the WriteGear's Primary Mode of Operation, i.e. if this parameter is enabled (.i.e <code>compression_mode = True</code>) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e <code>compression_mode = False</code>), the OpenCV's VideoWriter API will be used for encoding files/streams. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>True</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', compression_mode=False)\n</code></pre> <p> </p>"},{"location":"gears/writegear/non_compression/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>Not supported in Non-Compression Mode!</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#output_params","title":"<code>output_params</code>","text":"<p>This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below:</p> <p>Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc., which are available with WriteGear's Compression Mode only.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#supported-attributes","title":"Supported Attributes","text":"<p>Non-Compression Mode only gives access to a limited number of Parameters through its <code>output_params</code> parameter's attributes, which are as follows:</p>"},{"location":"gears/writegear/non_compression/params/#a-opencv-parameters","title":"A. OpenCV Parameters","text":"<p>WriteGear provides access to all available OpenCV's VideoWriter API parameters in Non-Compression Mode.</p> Parameters Description <code>-fourcc</code> 4-character code of codec used to encode frames <code>-fps</code> controls the framerate of output video(Default value: 25) <code>-backend</code> (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are <code>CAP_FFMPEG</code> or <code>CAP_GSTREAMER</code>(if enabled) <code>-color</code> (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) <p><code>-height</code> and <code>-width</code> parameter are no longer supported and are automatically derived from the input frames.</p>"},{"location":"gears/writegear/non_compression/params/#b-exclusive-parameters","title":"B. Exclusive Parameters","text":"<p>In addition to OpenCV Parameters, WriteGear API also provides few exclusive attribute, which are as follows: </p> <ul> <li> <p><code>-gst_pipeline_mode</code>: a boolean attribute to enable GStreamer Pipeline Mode to supports GStreamer Pipeline as input to its <code>output</code> parameter in Non-Compression Mode.</p> <p>Enabling <code>-gst_pipeline_mode</code> will enforce <code>-backend</code> parameter value to <code>\"CAP_GSTREAMER\"</code></p> New in v0.2.5 <p><code>-gst_pipeline_mode</code> attribute was added in <code>v0.2.5</code>.</p> <p>Its usage example can be found here \u27b6.</p> </li> </ul> <p>Usage:</p> <p>To assign desired parameters in Non-Compression Mode, you can format it as dictionary attribute and pass through this(<code>output_params</code>) parameter as follows:</p> <pre><code># format parameter as dictionary attribute\noutput_params = {\"-fps\":30} \n# and then, assign it\nWriteGear(output = 'output.mp4', compression_mode=False, **output_params)\n</code></pre> <p>Its usage example can be found here \u27b6.</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#supported-fourcc-codecs","title":"Supported FOURCC Codecs","text":"<p>FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression.</p> <p>List of all supported FOURCC codecs can found here \u27b6</p> <p>Usage:</p> <p>To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this(<code>output_params</code>) parameter. For example, using <code>MJPG</code> as codec, we can:</p> <pre><code># format codec as dictionary attribute\noutput_params = {\"-fourcc\":\"MJPG\"} \n# and then, assign it\nWriteGear(output = 'output.mp4', compression_mode=False, **output_params)\n</code></pre> <p>Its usage example can be found here \u27b6.</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', compression_mode=False, logging=True)\n</code></pre> <p> </p>"},{"location":"gears/writegear/non_compression/usage/","title":"Usage Examples","text":""},{"location":"gears/writegear/non_compression/usage/#writegear-api-usage-examples-non-compression-mode","title":"WriteGear API Usage Examples: Non-Compression Mode","text":"<p>Important Information</p> <ul> <li> <p>DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with <code>ValueError</code>.</p> </li> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode.</p> </li> <li> <p>Always use <code>writer.close()</code> at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.</p> </li> </ul> <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = CamGear(source=\"myvideo.avi\").start()\n\n# Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", compression_mode=False)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-videocapture-gears","title":"Using Non-Compression Mode with VideoCapture Gears","text":"<p>In Non-Compression mode, WriteGear API provides flexible control over OpenCV's VideoWriter API parameters through its <code>output_param</code> dictionary parameter by formating them as dictionary attributes. Moreover, WriteGear API can be used in conjunction with any other Gears/APIs effortlessly. </p> <p>All supported attributes for <code>output_param</code> can be found  here \u27b6</p> <p>The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# define suitable tweak parameters for writer\noutput_params = {\"-fourcc\": \"MJPG\", \"-fps\": 30}\n\n# open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0, logging=True).start()\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(\n    output=\"Output.mp4\", compression_mode=False, logging=True, **output_params\n)\n\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # write gray frame to writer\n    writer.write(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-opencv","title":"Using Non-Compression Mode with OpenCV","text":"<p>You can easily use WriterGear API directly with any Video Processing library(For e.g OpenCV itself) in Non-Compression Mode. The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# define suitable tweak parameters for writer\noutput_params = {\"-fourcc\": \"MJPG\", \"-fps\": 30}\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(\n    output=\"Output.mp4\", compression_mode=False, logging=True, **output_params\n)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # {do something with the frame here}\n    # lets convert frame to gray for this example\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # write gray frame to writer\n    writer.write(gray)\n\n    # Show output window\n    cv2.imshow(\"Output Gray Frame\", gray)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-gstreamer-pipeline","title":"Using Non-Compression Mode with GStreamer Pipeline","text":"<p>WriteGear API's Non-Compression Mode also supports GStreamer Pipeline as input to its <code>output</code> parameter, when GStreamer Pipeline Mode is enabled. This provides flexible way to write video frames to file or network stream with controlled framerate and bitrate. The complete usage example is as follows:</p> <p>Requirement for GStreamer Pipelining</p> <p>GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> New in v0.2.5 <p>This example was added in <code>v0.2.5</code>.</p> <p>In this example we will be constructing GStreamer pipeline to write video-frames into a file(<code>foo.mp4</code>) at 1M video-bitrate.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# enable GStreamer Pipeline Mode for writer\noutput_params = {\"-gst_pipeline_mode\": True}\n\n# open live video stream on webcam at first index(i.e. 0) device\nstream = cv2.VideoCapture(0)\n\n# gst pipeline to write to a file `foo.mp4` at 1M video-bitrate\nGSTPipeline = \"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location={}\".format(\n    \"foo.mp4\"\n)\n\n# Define writer with defined parameters and with our Gstreamer pipeline\nwriter = WriteGear(\n    output=GSTPipeline, compression_mode=False, logging=True, **output_params\n)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.release()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/camgear_ex/","title":"Bonus Examples","text":""},{"location":"help/camgear_ex/#camgear-examples","title":"CamGear Examples","text":""},{"location":"help/camgear_ex/#synchronizing-two-sources-in-camgear","title":"Synchronizing Two Sources in CamGear","text":"<p>In this example both streams and corresponding frames will be processed synchronously i.e. with no delay:</p> <p>Using same source with more than one instances of CamGear can lead to Global Interpreter Lock (GIL) that degrades performance even when it is not a bottleneck.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\nimport time\n\n# define and start the stream on first source ( For e.g #0 index device)\nstream1 = CamGear(source=0, logging=True).start() \n\n# define and start the stream on second source ( For e.g #1 index device)\nstream2 = CamGear(source=1, logging=True).start() \n\n# infinite loop\nwhile True:\n\n    frameA = stream1.read()\n    # read frames from stream1\n\n    frameB = stream2.read()\n    # read frames from stream2\n\n    # check if any of two frame is None\n    if frameA is None or frameB is None:\n        #if True break the infinite loop\n        break\n\n    # do something with both frameA and frameB here\n    cv2.imshow(\"Output Frame1\", frameA)\n    cv2.imshow(\"Output Frame2\", frameB)\n    # Show output window of stream1 and stream 2 separately\n\n    key = cv2.waitKey(1) &amp; 0xFF\n    # check for 'q' key-press\n    if key == ord(\"q\"):\n        #if 'q' key-pressed break out\n        break\n\n    if key == ord(\"w\"):\n        #if 'w' key-pressed save both frameA and frameB at same time\n        cv2.imwrite(\"Image-1.jpg\", frameA)\n        cv2.imwrite(\"Image-2.jpg\", frameB)\n        #break   #uncomment this line to break out after taking images\n\ncv2.destroyAllWindows()\n# close output window\n\n# safely close both video streams\nstream1.stop()\nstream2.stop()\n</code></pre> <p> </p>"},{"location":"help/camgear_ex/#using-variable-yt_dlp-parameters-in-camgear","title":"Using variable <code>yt_dlp</code> parameters in CamGear","text":"<p>CamGear provides exclusive attributes <code>STREAM_RESOLUTION</code> (for specifying stream resolution) &amp; <code>STREAM_PARAMS</code> (for specifying underlying API(e.g. <code>yt_dlp</code>) parameters) with its <code>options</code> dictionary parameter. </p> <p>The complete usage example is as follows: </p> <p>More information on <code>STREAM_RESOLUTION</code> &amp; <code>STREAM_PARAMS</code> attributes can be found here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n\n# specify attributes\noptions = {\"STREAM_RESOLUTION\": \"720p\", \"STREAM_PARAMS\": {\"nocheckcertificate\": True}}\n\n# Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\n    source=\"https://youtu.be/bvetuLwJIkA\", stream_mode=True, logging=True, **options\n).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/camgear_ex/#using-camgear-for-capturing-rtsprtmp-urls","title":"Using CamGear for capturing RTSP/RTMP URLs","text":"<p>You can open any network stream (such as RTSP/RTMP) just by providing its URL directly to CamGear's <code>source</code> parameter. </p> <p>Here's a high-level wrapper code around CamGear API to enable auto-reconnection during capturing: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> Enforcing UDP stream <p>You can easily enforce UDP for RTSP streams inplace of default TCP, by putting following lines of code on the top of your existing code:</p> <pre><code># import required libraries\nimport os\n\n# enforce UDP\nos.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;udp\"\n</code></pre> <p>Finally, use <code>backend</code> parameter value as <code>backend=cv2.CAP_FFMPEG</code> in CamGear.</p> <pre><code>from vidgear.gears import CamGear\nimport cv2\nimport datetime\nimport time\n\n\nclass Reconnecting_CamGear:\n    def __init__(self, cam_address, reset_attempts=50, reset_delay=5):\n        self.cam_address = cam_address\n        self.reset_attempts = reset_attempts\n        self.reset_delay = reset_delay\n        self.source = CamGear(source=self.cam_address).start()\n        self.running = True\n\n    def read(self):\n        if self.source is None:\n            return None\n        if self.running and self.reset_attempts &gt; 0:\n            frame = self.source.read()\n            if frame is None:\n                self.source.stop()\n                self.reset_attempts -= 1\n                print(\n                    \"Re-connection Attempt-{} occured at time:{}\".format(\n                        str(self.reset_attempts),\n                        datetime.datetime.now().strftime(\"%m-%d-%Y %I:%M:%S%p\"),\n                    )\n                )\n                time.sleep(self.reset_delay)\n                self.source = CamGear(source=self.cam_address).start()\n                # return previous frame\n                return self.frame\n            else:\n                self.frame = frame\n                return frame\n        else:\n            return None\n\n    def stop(self):\n        self.running = False\n        self.reset_attempts = 0\n        self.frame = None\n        if not self.source is None:\n            self.source.stop()\n\n\nif __name__ == \"__main__\":\n    # open any valid video stream\n    stream = Reconnecting_CamGear(\n        cam_address=\"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\",\n        reset_attempts=20,\n        reset_delay=5,\n    )\n\n    # loop over\n    while True:\n\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # Show output window\n        cv2.imshow(\"Output\", frame)\n\n        # check for 'q' key if pressed\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord(\"q\"):\n            break\n\n    # close output window\n    cv2.destroyAllWindows()\n\n    # safely close video stream\n    stream.stop()\n</code></pre> <p> </p>"},{"location":"help/camgear_faqs/","title":"FAQs","text":""},{"location":"help/camgear_faqs/#camgear-faqs","title":"CamGear FAQs","text":""},{"location":"help/camgear_faqs/#what-is-camgear-api-and-what-does-it-do","title":"What is CamGear API and what does it do?","text":"<p>Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rtsp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-camgear-api","title":"I'm only familiar with OpenCV, how to get started with CamGear API?","text":"<p>Answer: Answer: First, refer to the Switching from OpenCV guide, then go through CamGear documentation \u27b6. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-change-opencv-source-backend-in-camgear-api","title":"How to change OpenCV source backend in CamGear API?","text":"<p>Answer: See its Parameters \u27b6. Its, <code>backend</code>(int) parameter sets the backend of the source. Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> in case of Direct Show.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-get-framerate-of-the-source-in-camgear-api","title":"How to get framerate of the source in CamGear API?","text":"<p>Answer: CamGear's <code>framerate</code> global variable can be used to retrieve framerate of the input video stream.  See this example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-compile-opencv-with-gstreamer-support","title":"How to compile OpenCV with GStreamer support?","text":"<p>Answer: For compiling OpenCV with GSstreamer(<code>&gt;=v1.0.0</code>) support:</p>  Linux Windows MacOS <ul> <li> <p> Compile manually: Follow this tutorial \u27b6</p> </li> <li> <p> Compile using Pip: Follow this GitHub issue \u27b6</p> </li> </ul> <ul> <li> Compile manually: Follow this tutorial \u27b6</li> </ul> <ul> <li> Compile manually: Follow this tutorial \u27b6</li> </ul> <p> </p>"},{"location":"help/camgear_faqs/#how-to-change-quality-and-parameters-of-youtube-streams-with-camgear","title":"How to change quality and parameters of YouTube Streams with CamGear?","text":"<p>Answer: CamGear provides exclusive attributes <code>STREAM_RESOLUTION</code> (for specifying stream resolution) &amp; <code>STREAM_PARAMS</code> (for specifying underlying API(e.g. <code>yt_dlp</code>) parameters) with its <code>options</code> dictionary parameter. See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-open-rtsp-network-streams-with-camgear","title":"How to open RTSP network streams with CamGear?","text":"<p>Answer: You can open any local network stream (such as RTSP) just by providing its URL directly to CamGear's <code>source</code> parameter. See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-set-camera-settings-with-camgear","title":"How to set Camera Settings with CamGear?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#can-i-play-4k8k-video-with-camgear-api","title":"Can I play 4K/8k video with CamGear API?","text":"<p>Answer: Yes, you can if your System Hardware supports it.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-synchronize-between-two-cameras","title":"How to synchronize between two cameras?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#can-i-use-gpu-to-decode-the-video-source","title":"Can I use GPU to decode the video source?","text":"<p>Answer: See this issue comment \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#why-camgear-is-throwing-warning-that-threaded-queue-mode-is-disabled","title":"Why CamGear is throwing warning that Threaded Queue Mode is disabled?","text":"<p>Answer: That's a normal behavior. Please read about Threaded Queue Mode \u27b6</p> <p> </p>"},{"location":"help/general_faqs/","title":"General FAQs","text":""},{"location":"help/general_faqs/#general-faqs","title":"General FAQs","text":""},{"location":"help/general_faqs/#im-new-to-python-programming-or-its-usage-in-opencv-library-how-to-use-vidgear-in-my-projects","title":"\"I'm new to Python Programming or its usage in OpenCV Library\", How to use vidgear in my projects?","text":"<p>Answer: Before using vidgear, It's recommended to first go through the following dedicated blog sites and learn how OpenCV-Python syntax works (with examples):</p> <ul> <li> <p>PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs, and books at PyImageSearch.com. Highly recommended!</p> </li> <li> <p>learnopencv.com \u27b6  Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students, and self-starters interested in Computer Vision and Machine Learning.</p> </li> <li> <p>There's also the official OpenCV Tutorials \u27b6 curated by the OpenCV developers.</p> </li> </ul> <p>Once done, visit Switching from OpenCV \u27b6 to easily replace OpenCV APIs with suitable Gears \u27b6 in your project. All the best! </p> <p>If you run into any trouble or have any questions, then refer our Help section.</p> <p> </p>"},{"location":"help/general_faqs/#vidgear-is-using-multi-threading-but-python-is-notorious-for-its-poor-performance-in-multithreading","title":"\"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\"","text":"<p>Answer: Refer vidgear's Threaded-Queue-Mode \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#modulenotfounderror-no-module-named-vidgeargears-vidgear-is-not-a-package","title":"ModuleNotFoundError: No module named 'vidgear.gears'. 'vidgear' is not a package?","text":"<p>Answer: This error means you either have a file named <code>vidgear.py</code> in your python path or you've named your python script <code>vidgear.py</code>. Replace <code>vidgear</code> name with anything else to fix this error.</p> <p> </p>"},{"location":"help/general_faqs/#how-to-log-to-a-file-in-vidgear","title":"How to log to a file in VidGear?","text":"<p>Answer: VidGear provides exclusive <code>VIDGEAR_LOGFILE</code> environment variable to enable logging to a file while logging is enabled (i.e. <code>logging=True</code>) on respective Gear. You just have to set directory pathname (automatically creates <code>vidgear.log</code> file) or a log file pathname itself as value for this  environment variable. This can be done on various Operating Systems as follows:</p> <p>Remember enabling this logging to a file will completely disable any output on the terminal.</p>  Linux Windows (Powershell) MacOS <pre><code># path to file\nexport VIDGEAR_LOGFILE=\"$HOME/foo.log\"\n\n# or just directory path \n# !!! Make sure `foo` path already exists !!!\nexport VIDGEAR_LOGFILE=\"$HOME/foo\"\n\n# to remove\nunset VIDGEAR_LOGFILE\n</code></pre> <pre><code># path to file\n$Env:VIDGEAR_LOGFILE = \"D:\\foo.log\"\n\n# or just directory path \n# !!! Make sure `foo` path already exists !!!\n$Env:VIDGEAR_LOGFILE = \"D:\\foo\"\n\n# to remove\n$Env:VIDGEAR_LOGFILE = \"\"\n</code></pre> <pre><code># path to file\nexport VIDGEAR_LOGFILE=\"$HOME/foo.log\"\n\n# or just directory path \n# !!! Make sure `foo` path already exists !!!\nexport VIDGEAR_LOGFILE=\"$HOME/foo\"\n\n# to remove\nunset VIDGEAR_LOGFILE\n</code></pre> <p> </p>"},{"location":"help/general_faqs/#can-i-perform-deep-learning-task-with-vidgear","title":"Can I perform Deep Learning task with VidGear?","text":"<p>Answer: VidGear is a powerful Video Processing library (similar to OpenCV, FFmpeg, etc.) that can read, write, process, send &amp; receive a sequence of video-frames in an optimized manner. But for Deep Learning or Machine Learning tasks, you have to use a third-party library. That being said, all VidGear's APIs can be used with any third-party Library(such as PyTorch, Tensorflow, etc.) that can leverage the overall performance if you're processing video/audio streams/frames in your application with Deep Learning tasks. Also, it eases the workflow since you have to write way fewer lines of code to read/store/process output videos.</p> <p> </p>"},{"location":"help/general_faqs/#can-i-ask-my-question-directly-without-raising-an-issue","title":"Can I ask my question directly without raising an issue?","text":"<p>Answer: Yes, please join our Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/general_faqs/#how-to-contribute-to-vidgear-development","title":"How to contribute to VidGear development?","text":"<p>Answer: See our Contribution Guidelines \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#what-oses-are-supported-by-vidgear","title":"What OSes are supported by VidGear?","text":"<p>Answer: See Supported Systems \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#what-python-versions-are-supported-by-vidgear","title":"What Python versions are supported by VidGear?","text":"<p>Answer: See Supported Python legacies \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#can-i-include-vidgear-in-my-project-commercially-or-not","title":"Can I include VidGear in my project commercially or not?","text":"<p>Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#i-love-using-vidgear-for-my-projects-how-can-i-support-it","title":"\"I Love using VidGear for my projects\", How can I support it?","text":"<p>Answer: See Helping VidGear \u27b6 </p> <p> </p>"},{"location":"help/get_help/","title":"Getting Help","text":""},{"location":"help/get_help/#getting-help","title":"Getting Help","text":"Courtesy - Pinterest <p>Would you like to get help with VidGear?</p> <p>There are several ways such as:</p> <p> </p>"},{"location":"help/get_help/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Got a question related to VidGear Working?  </p> <p>Checkout the Frequently Asked Questions - a curated list of all the questions with adequate answer that we commonly receive for quickly troubleshooting your problems:</p> <ul> <li>General FAQs \u27b6</li> <li>CamGear FAQs \u27b6</li> <li>PiGear FAQs \u27b6</li> <li>ScreenGear FAQs \u27b6</li> <li>StreamGear FAQs \u27b6</li> <li>WriteGear FAQs \u27b6</li> <li>NetGear FAQs \u27b6</li> <li>WebGear FAQs \u27b6</li> <li>WebGear_RTC FAQs \u27b6</li> <li>VideoGear FAQs \u27b6</li> <li>NetGear_Async FAQs \u27b6</li> <li>Stabilizer Class FAQs \u27b6</li> </ul> <p> </p>"},{"location":"help/get_help/#bonus-examples","title":"Bonus Examples","text":"<p>How we do this with that API?  </p> <p>Checkout the Bonus Examples - a curated list of all experimental examples with unusual configuration that aren't included in general usage examples:</p> <ul> <li>CamGear Examples \u27b6</li> <li>PiGear Examples \u27b6</li> <li>ScreenGear Examples \u27b6</li> <li>StreamGear Examples \u27b6</li> <li>WriteGear Examples \u27b6</li> <li>NetGear Examples \u27b6</li> <li>WebGear Examples \u27b6</li> <li>WebGear_RTC Examples \u27b6</li> <li>VideoGear Examples \u27b6</li> <li>NetGear_Async Examples \u27b6</li> <li>Stabilizer Class Examples \u27b6</li> </ul> <p> </p>"},{"location":"help/get_help/#join-our-gitter-community-channel","title":"Join our Gitter Community channel","text":"<p>Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems</p> <p>Join and chat on our Gitter Community channel: </p> <p>There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas &amp; information, etc. </p> <p> </p>"},{"location":"help/get_help/#this-is-what-you-do-when","title":"This is what you do when...","text":"<ul> <li> Got a question or problem?</li> <li> Found a typo?</li> <li> Found a bug?</li> <li> Missing a feature/improvement?</li> </ul>"},{"location":"help/get_help/#reporting-an-issues","title":"Reporting an issues","text":"<p>Want to report a bug? Suggest a new feature?</p> <p>Before you do, please read our guidelines \u27b6</p> <p> </p>"},{"location":"help/get_help/#preparing-a-pull-request","title":"Preparing a Pull Request","text":"<p>Interested in contributing to VidGear?</p> <p>Before you do, please read our guidelines \u27b6</p> <p> </p>"},{"location":"help/netgear_async_ex/","title":"Bonus Examples","text":""},{"location":"help/netgear_async_ex/#netgear_async-examples","title":"NetGear_Async Examples","text":""},{"location":"help/netgear_async_ex/#using-netgear_async-with-webgear","title":"Using NetGear_Async with WebGear","text":"<p>The complete usage example is as follows: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p>"},{"location":"help/netgear_async_ex/#client-webgear-server","title":"Client + WebGear Server","text":"<p>Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code:</p> <p>After running this code, Make sure to open Browser immediately otherwise NetGear_Async will soon exit with <code>TimeoutError</code>. You can also try setting <code>timeout</code> parameter to a higher value to extend this timeout.</p> <p>Make sure you use different <code>port</code> value for NetGear_Async and WebGear API.</p> <p>High CPU utilization may occur on Client's end. User discretion is advised.</p> <p>Note down the IP-address of this system (required at Server's end) by executing the  <code>hostname -I</code> command and also replace it in the following code.\"</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\nimport uvicorn, asyncio, cv2\n\n# Define NetGear_Async Client at given IP address and define parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear_Async(\n    receive_mode=True,\n    pattern=1,\n    logging=True,\n).launch()\n\n# create your own custom frame producer\nasync def my_frame_producer():\n\n    # loop over Client's Asynchronous Frame Generator\n    async for frame in client.recv_generator():\n\n        # {do something with received frames here}\n\n        # reducer frames size if you want more performance otherwise comment this line\n        frame = await reducer(\n            frame, percentage=30, interpolation=cv2.INTER_AREA\n        )  # reduce frame by 30%\n\n        # handle JPEG encoding\n        encodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n        # yield frame in byte format\n        yield (b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\n        await asyncio.sleep(0)\n\n\nif __name__ == \"__main__\":\n    # Set event loop to client's\n    asyncio.set_event_loop(client.loop)\n\n    # initialize WebGear app without any source\n    web = WebGear(logging=True)\n\n    # add your custom frame producer to config with adequate IP address\n    web.config[\"generator\"] = my_frame_producer\n\n    # run this app on Uvicorn server at address http://localhost:8000/\n    uvicorn.run(web(), host=\"localhost\", port=8000)\n\n    # safely close client\n    client.close()\n\n    # close app safely\n    web.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.</p>"},{"location":"help/netgear_async_ex/#server","title":"Server","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index 0), and execute the following python code:</p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n\n# initialize Server without any source\nserver = NetGear_Async(\n    source=None,\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n)\n\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n\n    # !!! define your own video source here !!!\n    # Open any video stream such as live webcam\n    # video stream on first index(i.e. 0) device\n    stream = cv2.VideoCapture(0)\n\n    # loop over stream until its terminated\n    while True:\n\n        # read frames\n        (grabbed, frame) = stream.read()\n\n        # check if frame empty\n        if not grabbed:\n            break\n\n        # do something with the frame to be sent here\n\n        # yield frame\n        yield frame\n        # sleep for sometime\n        await asyncio.sleep(0)\n\n    # close stream\n    stream.release()\n\n\nif __name__ == \"__main__\":\n    # set event loop\n    asyncio.set_event_loop(server.loop)\n    # Add your custom source generator to Server configuration\n    server.config[\"generator\"] = my_frame_generator()\n    # Launch the Server\n    server.launch()\n    try:\n        # run your main function task until it is complete\n        server.loop.run_until_complete(server.task)\n    except (KeyboardInterrupt, SystemExit):\n        # wait for interrupts\n        pass\n    finally:\n        # finally close the server\n        server.close()\n</code></pre> <p> </p>"},{"location":"help/netgear_async_faqs/","title":"FAQs","text":""},{"location":"help/netgear_async_faqs/#netgear_async-faqs","title":"NetGear_Async FAQs","text":""},{"location":"help/netgear_async_faqs/#what-is-netgear_async-api-and-what-does-it-do","title":"What is NetGear_Async API and what does it do?","text":"<p>Answer: NetGear_Async is an asyncio videoframe messaging framework, built on <code>zmq.asyncio</code>, and powered by high-performance asyncio event loop called <code>uvloop</code> to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6</p> <p> </p>"},{"location":"help/netgear_async_faqs/#how-to-get-started-with-netgear_async-api","title":"How to get started with NetGear_Async API?","text":"<p>Answer: Answer: Answer: First, refer to the Switching from OpenCV guide, then go through NetGear_Async documentation \u27b6. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p>See NetGear_Async doc \u27b6. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/netgear_async_faqs/#netgear_async-is-throwing-modulenotfounderror-on-importing-why","title":"\"NetGear_Async is throwing <code>ModuleNotFoundError</code> on importing\", Why?","text":"<p>Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6.</p> <p> </p>"},{"location":"help/netgear_async_faqs/#what-is-the-key-difference-between-netgear_async-and-netgear-apis","title":"What is the key difference between NetGear_Async and NetGear APIs?","text":"<p>Answer: </p> <ul> <li> <p>NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. </p> </li> <li> <p>NetGear_Async: is an asyncio videoframe messaging framework, built on <code>zmq.asyncio</code>, and powered by high-performance asyncio event loop called <code>uvloop</code> to high-speed and lag-free video streaming over the network with minimal resource constraints.</p> </li> </ul> <p>Key Difference: NetGear_Async is highly memory efficient, but has less features as compared to NetGear API which is marginally faster too. </p> <p> </p>"},{"location":"help/netgear_async_faqs/#can-i-use-multi-server-bi-directional-like-modes-in-netgear_async","title":"Can I use Multi-Server, Bi-Directional like modes in NetGear_Async?","text":"<p>Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet.</p> <p> </p>"},{"location":"help/netgear_async_faqs/#how-to-use-netgear_async-with-custom-server-source-from-opencv","title":"How to use NetGear_Async with custom Server Source from OpenCV?","text":"<p>Answer: See this usage example \u27b6. </p> <p> </p>"},{"location":"help/netgear_async_faqs/#why-netgear_async-is-running-slow","title":"Why NetGear_Async is running slow?","text":"<p>Answer: Checkout tips suggested in this answer \u27b6</p> <p> </p>"},{"location":"help/netgear_ex/","title":"Bonus Examples","text":""},{"location":"help/netgear_ex/#netgear-examples","title":"NetGear Examples","text":""},{"location":"help/netgear_ex/#using-netgear-with-webgear","title":"Using NetGear with WebGear","text":"<p>The complete usage example is as follows: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p>"},{"location":"help/netgear_ex/#client-webgear-server","title":"Client + WebGear Server","text":"<p>Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code:</p> <p>After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with <code>RuntimeError</code>. You can also try setting <code>max_retries</code> and <code>request_timeout</code> like attributes to a higher value to avoid this.</p> <p>Make sure you use different <code>port</code> value for NetGear and WebGear API.</p> <p>High CPU utilization may occur on Client's end. User discretion is advised.</p> <p>Note down the local IP-address of this system (required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <pre><code># import necessary libs\nimport uvicorn, asyncio, cv2\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\n\n# initialize WebGear app without any source\nweb = WebGear(logging=True)\n\n\n# activate jpeg encoding and specify other related parameters\noptions = {\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# create your own custom frame producer\nasync def my_frame_producer():\n    # initialize global params\n    # Define NetGear Client at given IP address and define parameters\n    # !!! change following IP address '192.168.x.xxx' with yours !!!\n    client = NetGear(\n        receive_mode=True,\n        address=\"192.168.x.xxx\",\n        port=\"5454\",\n        protocol=\"tcp\",\n        pattern=1,\n        logging=True,\n        **options,\n    )\n\n    # loop over frames\n    while True:\n        # receive frames from network\n        frame = client.recv()\n\n        # if NoneType\n        if frame is None:\n            break\n\n        # do something with your OpenCV frame here\n\n        # reducer frames size if you want more performance otherwise comment this line\n        frame = await reducer(\n            frame, percentage=30, interpolation=cv2.INTER_AREA\n        )  # reduce frame by 30%\n\n        # handle JPEG encoding\n        encodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n        # yield frame in byte format\n        yield (b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\n        await asyncio.sleep(0)\n    # close stream\n    client.close()\n\n\n# add your custom frame producer to config with adequate IP address\nweb.config[\"generator\"] = my_frame_producer\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.</p>"},{"location":"help/netgear_ex/#server","title":"Server","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index 0), and execute the following python code:</p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate jpeg encoding and specify other related parameters\noptions = {\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/netgear_ex/#using-netgear-with-webgear_rtc","title":"Using NetGear with WebGear_RTC","text":"<p>The complete usage example is as follows: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p>"},{"location":"help/netgear_ex/#client-webgear_rtc-server","title":"Client + WebGear_RTC Server","text":"<p>Open a terminal on Client System where you want to display the input frames (and setup WebGear_RTC server) received from the Server and execute the following python code:</p> <p>After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with <code>RuntimeError</code>. You can also try setting <code>max_retries</code> and <code>request_timeout</code> like attributes to a higher value to avoid this.</p> <p>Make sure you use different <code>port</code> value for NetGear and WebGear_RTC API.</p> <p>High CPU utilization may occur on Client's end. User discretion is advised.</p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>For VideoCapture APIs you also need to implement <code>start()</code> in addition to <code>read()</code> and <code>stop()</code> methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work!</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# create your own custom streaming class\nclass Custom_Stream_Class:\n    \"\"\"\n    Custom Streaming using NetGear Receiver\n    \"\"\"\n\n    def __init__(\n        self,\n        address=None,\n        port=\"5454\",\n        protocol=\"tcp\",\n        pattern=1,\n        logging=True,\n        **options,\n    ):\n        # initialize global params\n        # Define NetGear Client at given IP address and define parameters\n        self.client = NetGear(\n            receive_mode=True,\n            address=address,\n            port=port,\n            protocol=protocol,\n            pattern=pattern,\n            logging=logging,\n            **options\n        )\n        self.running = False\n\n    def start(self):\n\n        # don't forget this function!!!\n        # This function is specific to VideoCapture APIs only\n\n        if not self.source is None:\n            self.source.start()\n\n    def read(self):\n\n        # don't forget this function!!!\n\n        # check if source was initialized or not\n        if self.source is None:\n            return None\n        # check if we're still running\n        if self.running:\n            # receive frames from network\n            frame = self.client.recv()\n            # check if frame is available\n            if not (frame is None):\n\n                # do something with your OpenCV frame here\n\n                # reducer frames size if you want more performance otherwise comment this line\n                frame = reducer(frame, percentage=20)  # reduce frame by 20%\n\n                # return our gray frame\n                return frame\n            else:\n                # signal we're not running now\n                self.running = False\n        # return None-type\n        return None\n\n    def stop(self):\n\n        # don't forget this function!!!\n\n        # flag that we're not running\n        self.running = False\n        # close stream\n        if not (self.client is None):\n            self.client.close()\n            self.client = None\n\n\n# activate jpeg encoding and specify NetGear related parameters\noptions = {\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# assign your Custom Streaming Class with adequate NetGear parameters\n# to `custom_stream` attribute in options parameter of WebGear_RTC.\noptions = {\n    \"custom_stream\": Custom_Stream_Class(\n        address=\"192.168.x.xxx\",\n        port=\"5454\",\n        protocol=\"tcp\",\n        pattern=1,\n        logging=True,\n        **options\n    )\n}\n\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.</p>"},{"location":"help/netgear_ex/#server_1","title":"Server","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index 0), and execute the following python code:</p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n\n# activate jpeg encoding and specify other related parameters\noptions = {\n    \"jpeg_compression\": True,\n    \"jpeg_compression_quality\": 90,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": True,\n}\n\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/netgear_faqs/","title":"FAQs","text":""},{"location":"help/netgear_faqs/#netgear-faqs","title":"NetGear FAQs","text":""},{"location":"help/netgear_faqs/#what-is-netgear-api-and-what-does-it-do","title":"What is NetGear API and what does it do?","text":"<p>Answer: NetGear is exclusively designed to transfer video frames &amp; data synchronously (Pair &amp; Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-get-started-with-netgear-api","title":"How to get started with NetGear API?","text":"<p>Answer: First, refer to the Switching from OpenCV guide, then go through NetGear documentation \u27b6. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/netgear_faqs/#what-exclusive-modes-are-compatible-with-each-other-in-netgear-api","title":"What Exclusive Modes are compatible with each other in NetGear API?","text":"<p>Here's the compatibility chart for NetGear's Exclusive Modes:</p> Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional SSH Tunneling Multi-Servers - No (throws error) Yes Yes No (throws error) Multi-Clients No (throws error) - Yes Yes No (throws error) Secure Yes Yes - Yes Yes Bidirectional Yes Yes Yes - Yes SSH Tunneling No (throws error) No (throws error) Yes Yes - <p> </p>"},{"location":"help/netgear_faqs/#why-netgear-is-running-slow","title":"Why NetGear is running slow?","text":"<p>Answer: Here are few tips to troubleshoot performance on your machine:</p> <ul> <li> <p>Update ZMQ to latest: Update your <code>pyzmq</code> lib as follows:</p> <pre><code>sudo pip3 install -U pyzmq\n</code></pre> </li> <li> <p>Install testing branch: The <code>testing</code> branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing <code>testing</code> branch directly \u27b6.</p> </li> <li> <p>Use PUB/SUB pattern if you're live streaming:  Try different <code>pattern</code> values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. <code>pattern=2</code>) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario.</p> </li> <li> <p>Use Wired connection instead of Wireless connection: Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely.</p> </li> <li> <p>Enable all Performance Attributes with Frame Compression: You can also try enabling Frame Compression with its all Performance Attributes for NetGear API.</p> </li> <li> <p>Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer(<code>reducer</code>) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6). Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency!</p> </li> <li> <p>Systematically, check for Hardware/Network Issues \u27b6</p> </li> <li> <p>Finally, if nothing works then, checkout NetGear_Async API \u27b6</p> </li> </ul> <p> </p>"},{"location":"help/netgear_faqs/#how-to-find-local-ip-address-on-different-os-platforms","title":"How to find local IP-address on different OS platforms?","text":"<p>Answer: For finding local IP-address of your machine:</p> On Linux OSOn Windows OSOn MAC OS <ul> <li> Follow this tutorial \u27b6</li> </ul> <ul> <li> Follow this tutorial \u27b6</li> </ul> <ul> <li> Follow this tutorial \u27b6</li> </ul> <p> </p>"},{"location":"help/netgear_faqs/#how-to-send-data-along-with-frames-in-multi-servers-and-multi-clients-modes","title":"How to send data along with frames in Multi-Servers and Multi-Clients Modes?","text":"<p>Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-use-enable-encryption-and-authentication-in-netgear-api","title":"How to use enable Encryption and Authentication in NetGear API?","text":"<p>Answer: See its Secure Mode doc \u27b6.</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-send-custom-data-along-with-frames-bidirectionally-in-netgear-api","title":"How to send custom data along with frames bidirectionally in NetGear API?","text":"<p>Answer: See its Bidirectional Mode doc \u27b6.</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-access-netgear-api-outside-network-or-remotely","title":"How to access NetGear API outside network or remotely?","text":"<p>Answer: See its SSH Tunneling Mode doc \u27b6.</p> <p> </p>"},{"location":"help/netgear_faqs/#are-there-any-side-effect-of-sending-data-with-frames","title":"Are there any side-effect of sending data with frames?","text":"<p>Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised.</p> <p> </p>"},{"location":"help/netgear_faqs/#why-netgear-api-not-working-correctly","title":"Why NetGear API not working correctly?","text":"<p>Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-solve-zmqerrorzmqerror-errors","title":"How to solve <code>zmq.error.ZMQError</code> errors?","text":"<p>Answer: For those used to the idea that a \"server\" provides their address to a client, then you should recheck your preconceptions! Please read the Netgear instructions carefully, and you will note that it is the client device that defines the IP that is provided to the server config. If you get this the wrong way (using the server IP on the client), then you will get a <code>zmq.error.ZMQError</code> error. Make sure it is the client's IP shared across the two systems.</p> <p> </p>"},{"location":"help/pigear_ex/","title":"Bonus Examples","text":""},{"location":"help/pigear_ex/#pigear-examples","title":"PiGear Examples","text":""},{"location":"help/pigear_ex/#changing-output-pixel-format-in-pigear-api-with-picamera2-backend","title":"Changing Output Pixel Format in PiGear API with Picamera2 Backend","text":"<p>With the Picamera2 backend, you can also define a custom <code>format</code> (format of output frame pixels) in PiGear API. </p> Handling output frames with a custom pixel format correctly <p>While defining custom <code>format</code> as an optional parameter, it is advised to also define the <code>colorspace</code> parameter in the PiGear API. This is required only under TWO conditions:</p> <ul> <li>If <code>format</code> value is not MPEG for USB cameras.</li> <li>If <code>format</code> value is not BGR (i.e., <code>RGB888</code>) or BGRA (i.e., <code>XRGB8888</code>) for Raspberry Pi camera modules.</li> </ul> <p> Otherwise, output frames might NOT be compatible with OpenCV functions, and you need to handle these frames manually!</p> Picamera2 library has an unconventional naming convention for its pixel formats. <p>Please note that, Picamera2 takes its pixel format naming from <code>libcamera</code>, which in turn takes them from certain underlying Linux components. The results are not always the most intuitive. For example, OpenCV users will typically want each pixel to be a (<code>B</code>, <code>G</code>, <code>R</code>) triple for which the <code>RGB888</code> format should be chosen, and not <code>BGR888</code>. Similarly, OpenCV users wanting an alpha channel should select <code>XRGB8888</code>. </p> <p>For more information, refer Picamera2 docs \u27b6</p> YUV420/YVU420YUYV <p>For reducing the size of frames in memory it is advised to use the <code>YUV420</code> pixels format.</p> <p>In this example we will be defining custom <code>YUV420</code> (or <code>YVU420</code>) pixels format of output frame, and converting it back to <code>BGR</code> to be able to display with OpenCV.</p> <p>You could also instead define <code>colorspace=\"COLOR_YUV420p2RGB\"</code> parameter in PiGear API for converting it back to <code>BGR</code> similarly.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# formulate `format` Picamera2 API \n# configurational parameters\noptions = {\n    \"format\": \"YUV420\" # or use `YVU420`\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    yuv420_frame = stream.read()\n\n    # check for frame if Nonetype\n    if yuv420_frame is None:\n        break\n\n    # {do something with the `YUV420` frame here}\n\n    # convert `YUV420` to `BGR`\n    bgr = cv2.cvtColor(yuv420_frame, cv2.COLOR_YUV420p2BGR)\n\n    # {do something with the `BGR` frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", bgr)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p><code>YUYV</code> is a one packed <code>4:2:2</code> YUV format that is popularly used by USB cameras.</p> <p>Make sure <code>YUYV</code> pixel format is supported by your USB camera.</p> <p>In this example we will be defining custom <code>YUYV</code> pixels format of output frame, and converting it back to <code>BGR</code> to be able to display with OpenCV.</p> <p>You could also instead define <code>colorspace=\"COLOR_YUV2BGR_YUYV\"</code> parameter in PiGear API for converting it back to <code>BGR</code> similarly.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# formulate `format` Picamera2 API \n# configurational parameters\noptions = {\n    \"format\": \"YUYV\"\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    yuv420_frame = stream.read()\n\n    # check for frame if Nonetype\n    if yuv420_frame is None:\n        break\n\n    # {do something with the `YUV420` frame here}\n\n    # convert `YUV420` to `BGR`\n    bgr = cv2.cvtColor(yuv420_frame, cv2.COLOR_YUV2BGR_YUYV)\n\n    # {do something with the `BGR` frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", bgr)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/pigear_ex/#dynamically-adjusting-raspberry-pi-camera-parameters-at-runtime-in-pigear-api","title":"Dynamically Adjusting Raspberry Pi Camera Parameters at Runtime in PiGear API","text":"New Picamera2 backendLegacy Picamera backend <p>With the <code>picamera2</code> backend, using <code>stream</code> global parameter in the PiGear API, you can change all camera controls (except output resolution and format) at runtime after the camera has started.</p> Accessing all available camera controls <p>A complete list of all the available camera controls can be found in the <code>picamera2</code> docs \u27b6, and also by inspecting the <code>camera_controls</code> property of the Picamera2 object available with  <code>stream</code> global parameter in PiGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\n\n# open any pi video stream\nstream = PiGear()\n\n#display all available camera controls\nprint(stream.stream.camera_controls)\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>This returns a dictionary with the control names as keys, and each value being a tuple of (<code>min</code>, <code>max</code>, <code>default</code>) values for that control.  The default value should be interpreted with some caution as in many cases libcamera's default value will be overwritten by the camera tuning as soon as the camera is started.</p> <p>In this example, we will set the initial Camera Module's brightness value to <code>-0.5</code> (dark), and will change it to <code>0.5</code> (bright) when the Z key is pressed at runtime:</p> <p>Delay in setting runtime controls</p> <p>There will be a delay of several frames before the controls take effect. This is because there is perhaps quite a large number of requests for camera frames already in flight, and for some controls (<code>exposure time</code> and <code>analogue gain</code> specifically), the camera may actually take several frames to apply the updates.</p> Using <code>with</code> construct for Guaranteed Camera Control Updates at Runtime <p>While directly modifying using <code>set_controls</code> method might seem convenient, it doesn't guarantee that all camera control settings are applied within the same frame at runtime. The <code>with</code> construct provides a structured approach to managing camera control updates in real-time. Here's how to use it:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\n\n# formulate initial configurational parameters\noptions = \"controls\": {\"ExposureTime\": 5000, \"AnalogueGain\": 0.5}\n\n# open pi video stream with these parameters\nstream = PiGear(logging=True, **options).start() \n\n# Enter context manager and set runtime controls\n# Within this block, the controls are guaranteed to be applied atomically\nwith stream.stream.controls as controls:  \n    controls.ExposureTime = 10000  # Set new exposure time\n    controls.AnalogueGain = 1.0     # Set new analogue gain\n\n# ...rest of code goes here...\n\n# safely close video stream\nstream.stop()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# formulate initial configurational parameters\n# set brightness to -0.5 (dark)\noptions = {\"controls\": {\"Brightness\": -0.5}}\n\n# open pi video stream with these parameters\nstream = PiGear(logging=True, **options).start() \n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n    # check for 'z' key if pressed\n    if key == ord(\"z\"):\n        # change brightness to 0.5 (bright)\n        stream.stream.set_controls({\"Brightness\": 0.5})\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>You can also use the <code>stream</code> global parameter in PiGear with the<code>picamera</code> backend to feed any <code>picamera</code> parameters at runtime after the camera has started.</p> PiGear API switches to the legacy <code>picamera</code>backend if the <code>picamera2</code> library is unavailable. <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> optional parameter boolean attribute.</p> <p>In this example we will set initial Camera Module's <code>brightness</code> value <code>80</code> (brighter), and will change it <code>30</code> (darker) when Z key is pressed at runtime:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# formulate initial configurational parameters \n# set brightness to `80` (bright)\noptions = {\"brightness\": 80} \n\n# open pi video stream with these parameters\nstream = PiGear(logging=True, **options).start() \n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n\n    # {do something with the frame here}\n\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n    # check for 'z' key if pressed\n    if key == ord(\"z\"):\n        # change brightness to `30` (darker)\n        stream.stream.brightness = 30\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre>"},{"location":"help/pigear_ex/#accessing-multiple-camera-through-its-index-in-pigear-api","title":"Accessing Multiple Camera through its Index in PiGear API","text":"<p>With the <code>camera_num</code> parameter in the PiGear API, you can easily select the camera index to be used as the source, allowing you to drive these multiple cameras simultaneously from within a single Python session. </p> <p>The <code>camera_num</code> value can only be zero or greater, otherwise, PiGear API will throw <code>ValueError</code> for any negative value.</p> New Picamera2 backendLegacy Picamera backend <p>With the <code>picamera2</code> backend, you can use the <code>camera_num</code> parameter in PiGear to select the camera index to be used as the source if you have multiple Raspberry Pi camera modules (such as CM4) and/or USB cameras connected simultaneously to your Raspberry Pi.</p> Accessing metadata about connected cameras. <p>You can call the <code>global_camera_info()</code> method of the Picamera2 object available with <code>stream</code> global parameter in PiGear API to find out what cameras are attached. This returns a list containing one dictionary for each camera, ordered according the camera number you would pass to the <code>camera_num</code> parameter in PiGear API to open that device. The dictionary contains:</p> <ul> <li><code>Model</code> : the model name of the camera, as advertised by the camera driver.</li> <li><code>Location</code> : a number reporting how the camera is mounted, as reported by <code>libcamera</code>.</li> <li><code>Rotation</code> : how the camera is rotated for normal operation, as reported by <code>libcamera</code>.</li> <li><code>Id</code> : an identifier string for the camera, indicating how the camera is connected. </li> </ul> <p>You should always check this list to discover which camera is which as the order can change when the system boots or USB cameras are re-connected as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\n\n# open any pi video stream\nstream = PiGear()\n\n#display all available cameras metadata\nprint(stream.stream.global_camera_info())\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>The PiGear API can accurately differentiate between USB and Raspberry Pi camera modules by utilizing the camera's metadata.</p> <p>In this example, we will select the USB Camera connected at index <code>1</code> on the Raspberry Pi as the primary source for extracting frames in PiGear API:</p> Limited support for USB Cameras <p>This example also works with USB Cameras, However:</p> <ul> <li>Users should assume that features such as: Camera controls (<code>\"controls\"</code>), Transformations (<code>\"transform\"</code>), Queue (<code>\"queue\"</code>) , and Buffer Count (<code>\"buffer_count\"</code>) that are supported on Raspberry Pi cameras, and so forth, are not available on USB Cameras. </li> <li>Hot-plugging of USB cameras is also NOT supported - PiGear API should be completely shut down and restarted when cameras are added or removed.</li> </ul> <p>This example assumes a USB Camera is connected at index <code>1</code>, and some other camera connected at index <code>0</code> on your Raspberry Pi.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters for USB camera\noptions = {\n    \"sensor\": {\"output_size\": (480, 320)},  # will override `resolution`\n    \"format\": \"RGB888\" # BGR format for this example\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream at index `1` with defined parameters\nstream = PiGear(camera_num=1, resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p>With the Picamera backend, you should not change the <code>camera_num</code> parameter unless you are using the Raspberry Pi 3/3+/4 Compute Module IO Boards or third party Arducam Camarray Multiple Camera Solutions, which supports attaching multiple camera modules to the same Raspberry Pi board using appropriate I/O connections.</p> <p>You can use the <code>camera_num</code> parameter in PiGear with the <code>picamera</code> backend to select the camera index to be used as the source if you have multiple Raspberry Pi camera modules connected.</p> PiGear API switches to the legacy <code>picamera</code>backend if the <code>picamera2</code> library is unavailable. <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> optional parameter boolean attribute.</p> <p>In this example, we will select the Camera Module connected at index <code>1</code> on the Raspberry Pi as the primary source for extracting frames in PiGear API:</p> <p>This example assumes a Camera Module is connected at index <code>1</code> on your Raspberry Pi.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n\n# formulate various Picamera API \n# configurational parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream at index `1` with defined parameters\nstream = PiGear(camera_num=1, resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/pigear_faqs/","title":"FAQs","text":""},{"location":"help/pigear_faqs/#pigear-faqs","title":"PiGear FAQs","text":""},{"location":"help/pigear_faqs/#what-is-pigear-api-and-what-does-it-do","title":"What is PiGear API and what does it do?","text":"<p>Answer: PiGear is a specialized API similar to the CamGear API but optimized for Raspberry Pi Boards, offering comprehensive support for camera modules (e.g., OmniVision OV5647, Sony IMX219), along with limited compatibility for USB cameras. For more info. see PiGear doc \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-pigear-api","title":"I'm only familiar with OpenCV, how to get started with PiGear API?","text":"<p>Answer: First, refer to the Switching from OpenCV guide, then go through PiGear documentation. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/pigear_faqs/#why-my-camera-module-is-not-detected-by-pigear","title":"Why my camera module is not detected by PiGear?","text":"<p>Answer: Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using PiGear API. Also, recheck/change your Camera Module's ribbon-cable and Camera Module itself, if it damaged or got broken somehow.</p> <p> </p>"},{"location":"help/pigear_faqs/#how-to-select-camera-index-on-pi-compute-io-board-with-two-cameras-attached","title":"How to select camera index on Pi Compute IO board with two Cameras attached?","text":"<p>Answer: Refer this bonus example \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#why-pigear-is-throwing-systemerror","title":"Why PiGear is throwing <code>SystemError</code>?","text":"<p>Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both. </p> <p> </p>"},{"location":"help/pigear_faqs/#how-to-assign-various-configurational-settings-for-camera-module-with-pigear","title":"How to assign various configurational settings for Camera Module with PiGear?","text":"<p>Answer: See this usage example \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#video-output-is-too-dark-with-pigear-why","title":"\"Video output is too dark with PiGear\", Why?","text":"<p>Answer: The camera configuration settings might be incorrect. Check this usage example \u27b6 and try tinkering parameters like <code>sensor_mode</code>, <code>shutter_speed</code>, and <code>exposure_mode</code>. Additionally, if your <code>framerate</code> parameter value is too high, try lowering it.</p> <p> </p>"},{"location":"help/pigear_faqs/#how-to-dynamically-adjust-raspberry-pi-camera-parameters-at-runtime-with-pigear","title":"How to dynamically adjust Raspberry Pi Camera Parameters at runtime with PiGear?","text":"<p>Answer: See this bonus example \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#is-it-possible-to-change-output-frames-pixel-format-in-pigear-api","title":"Is it possible to change output frames Pixel Format in PiGear API?","text":"<p>Answer: Yes it is possible with Picamera2 Backend. See this bonus example \u27b6</p> <p> </p>"},{"location":"help/screengear_ex/","title":"Bonus Examples","text":""},{"location":"help/screengear_ex/#screengear-examples","title":"ScreenGear Examples","text":""},{"location":"help/screengear_ex/#using-screengear-with-netgear-and-writegear","title":"Using ScreenGear with NetGear and WriteGear","text":"<p>The complete usage example is as follows: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p>"},{"location":"help/screengear_ex/#client-writegear","title":"Client + WriteGear","text":"<p>Open a terminal on Client System (where you want to save the input frames received from the Server) and execute the following python code: </p> <p>Note down the IP-address of this system(required at Server's end) by executing the command: <code>hostname -I</code> and also replace it in the following code.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    receive_mode=True,\n    logging=True,\n    **options\n)\n\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n\n# loop over\nwhile True:\n\n    # receive frames from network\n    frame = client.recv()\n\n    # check for received frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close client\nclient.close()\n\n# safely close writer\nwriter.close()\n</code></pre>"},{"location":"help/screengear_ex/#server-screengear","title":"Server + ScreenGear","text":"<p>Now, Open the terminal on another Server System (with a montior/display attached to it), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears import NetGear\n\n# define dimensions of screen w.r.t to given monitor to be captured\noptions = {\"top\": 40, \"left\": 0, \"width\": 100, \"height\": 100}\n\n# open stream with defined parameters\nstream = ScreenGear(logging=True, **options).start()\n\n# define various netgear tweak flags\noptions = {\"flag\": 0, \"copy\": True, \"track\": False}\n\n# Define Netgear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\n    address=\"192.168.x.xxx\",\n    port=\"5454\",\n    protocol=\"tcp\",\n    pattern=1,\n    logging=True,\n    **options\n)\n\n# loop over until KeyBoard Interrupted\nwhile True:\n\n    try:\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if Nonetype\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # send frame to server\n        server.send(frame)\n\n    except KeyboardInterrupt:\n        break\n\n# safely close video stream\nstream.stop()\n\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/screengear_ex/#using-screengear-with-webgear_rtc","title":"Using ScreenGear with WebGear_RTC","text":"<p>The complete usage example is as follows: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> Bare-MinimumAdvanced <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# assign your ScreenGear class with adequate parameters \n# to `custom_stream` attribute in options parameter\noptions = {\"custom_stream\": ScreenGear(logging=True)}\n\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>For VideoCapture APIs you also need to implement <code>start()</code> in addition to <code>read()</code> and <code>stop()</code> methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work!</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears.helper import reducer\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# create your own custom streaming class\nclass Custom_Stream_Class:\n    \"\"\"\n    Custom Streaming using ScreenGear\n    \"\"\"\n\n    def __init__(self, backend=\"mss\", logging=False):\n\n        # !!! define your own video source here !!!\n        self.source = ScreenGear(backend=backend, logging=logging)\n\n        # define running flag\n        self.running = True\n\n    def start(self):\n\n        # don't forget this function!!!\n        # This function is specific to VideoCapture APIs only\n\n        if not self.source is None:\n            self.source.start()\n\n    def read(self):\n\n        # don't forget this function!!!\n\n        # check if source was initialized or not\n        if self.source is None:\n            return None\n        # check if we're still running\n        if self.running:\n            # read frame from provided source\n            frame = self.source.read()\n            # check if frame is available\n            if not(frame is None):\n\n                # do something with your OpenCV frame here\n\n                # reducer frames size if you want more performance otherwise comment this line\n                frame = reducer(frame, percentage=20)  # reduce frame by 20%\n\n                # return our gray frame\n                return frame\n            else:\n                # signal we're not running now\n                self.running = False\n        # return None-type\n        return None\n\n    def stop(self):\n\n        # don't forget this function!!!\n\n        # flag that we're not running\n        self.running = False\n        # close stream\n        if not self.source is None:\n            self.source.stop()\n\n\n# assign your Custom Streaming Class with adequate ScreenGear parameters\n# to `custom_stream` attribute in options parameter\noptions = {\"custom_stream\": Custom_Stream_Class(backend=\"pil\", logging=True)}\n\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/screengear_faqs/","title":"FAQs","text":""},{"location":"help/screengear_faqs/#screengear-faqs","title":"ScreenGear FAQs","text":""},{"location":"help/screengear_faqs/#what-is-screengear-api-and-what-does-it-do","title":"What is ScreenGear API and what does it do?","text":"<p>Answer: ScreenGear is designed exclusively for targeting rapid Screencasting Capabilities, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. For more info. see ScreenGear doc \u27b6</p> <p> </p>"},{"location":"help/screengear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-screengear-api","title":"I'm only familiar with OpenCV, how to get started with ScreenGear API?","text":"<p>Answer: First, refer to the Switching from OpenCV guide, then go through ScreenGear documentation. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/screengear_faqs/#screengear-is-slow","title":"ScreenGear is Slow?","text":"<p>Answer: This maybe due to selected <code>backend</code> for ScreenGear API is not compatible with your machine. See this usage example to change backend \u27b6. Try different backends, and select which works the best for your machine.</p> <p> </p>"},{"location":"help/screengear_faqs/#how-to-define-area-on-screen-to-record-with-screengear","title":"How to define area on screen to record with ScreenGear?","text":"<p>Answer: See this usage example \u27b6</p> <p> </p>"},{"location":"help/screengear_faqs/#how-to-record-video-from-all-connected-screens","title":"How to record video from all connected screens?","text":"<p>Answer: With <code>mss</code> backend, see ScreenGear's <code>monitor</code> parameter that sets the index of the monitor to grab a frame from. If its value is <code>-1</code>, it will record from all monitors. More information can be found here  \u27b6</p> <p> </p>"},{"location":"help/screengear_faqs/#im-getting-attributeerror-dxcamera-object-has-no-attribute-is_capturing-error","title":"I'm getting \"AttributeError: 'DXCamera' object has no attribute 'is_capturing'\" Error?","text":"<p>Answer: This is a well-known error in backend <code>dxcam</code> library which occurs when you've multiple GPUs on your Windows machine. To workaround this, you need select Internal GPU in settings as follows:</p> On  Windows 11On  Windows 10 <p>In Settings, go to <code>System &gt; Display &gt; Graphics</code> and add your <code>Python.exe</code> as \"Desktop App\", then select \"Power saving\" as follows:  </p> <p>And finally press Save button.  </p> <p>In Settings, go to <code>Graphics Settings</code> and add your <code>Python.exe</code> as \"Desktop App\", then select \"Power saving\" as follows:</p> <p> </p> <p>And finally press Save button.  </p> <p> </p>"},{"location":"help/stabilizer_ex/","title":"Bonus Examples","text":""},{"location":"help/stabilizer_ex/#stabilizer-class-examples","title":"Stabilizer Class Examples","text":""},{"location":"help/stabilizer_ex/#saving-stabilizer-class-output-with-live-audio-input","title":"Saving Stabilizer Class output with Live Audio Input","text":"<p>In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic input) with Stabilized frames incoming from the Stabilizer Class (which is also using same Webcam video input through OpenCV), and save the final output as a compressed video file, all in real time:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>Example Assumptions</p> <ul> <li>You're running are Linux machine.</li> <li>You already have appropriate audio driver and software installed on your machine.</li> </ul> Identifying and Specifying sound card on different OS platforms Windows Linux MacOS  <p>Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details.</p> </li> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg -list_devices true -f dshow -i dummy\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n    \"-f\": \"dshow\", # !!! warning: always keep this line above \"-i\" parameter !!!\n    \"-i\":\"audio=Microphone (USB2.0 Camera)\",\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-acodec\": \"aac\",\n    \"-ar\": \"44100\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel</p> <p>Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> Identify Sound Card: To get the list of all installed cards on your machine, you can type <code>arecord -l</code> or <code>arecord -L</code> (longer output).</p> <pre><code>arecord -l\n\n**** List of CAPTURE Hardware Devices ****\ncard 0: ICH5 [Intel ICH5], device 0: Intel ICH [Intel ICH5]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 1: Intel ICH - MIC ADC [Intel ICH5 - MIC ADC]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 2: Intel ICH - MIC2 ADC [Intel ICH5 - MIC2 ADC]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 3: Intel ICH - ADC2 [Intel ICH5 - ADC2]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: U0x46d0x809 [USB Device 0x46d:0x809], device 0: USB Audio [USB Audio]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <p>The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as <code>hw:0</code> or <code>hw:1</code></p> <pre><code># assign appropriate input audio-source\noutput_params = {\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-ar\": \"48000\",\n    \"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n    \"-i\": \"hw:1\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines:</p> <ul> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>avfoundation</code> as follows:</p> <pre><code>ffmpeg -f qtkit -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-ar\": \"48000\",\n    \"-f\": \"avfoundation\", # !!! warning: always keep this line above \"-audio_device_index\" parameter !!!\n    \"-audio_device_index\": \"0\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>Make sure this <code>-i</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nfrom vidgear.gears.stabilizer import Stabilizer\nimport cv2\n\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n\n# initiate stabilizer object with defined parameters\nstab = Stabilizer(smoothing_radius=30, crop_n_zoom=True, border_size=5, logging=True)\n\n# change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer\noutput_params = {\n    \"-input_framerate\": stream.get(cv2.CAP_PROP_FPS),\n    \"-thread_queue_size\": \"512\",\n    \"-ac\": \"2\",\n    \"-ar\": \"48000\",\n    \"-f\": \"alsa\", # (1)\n    \"-i\": \"hw:1\",\n}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # send current frame to stabilizer for processing\n    stabilized_frame = stab.stabilize(frame)\n\n    # wait for stabilizer which still be initializing\n    if stabilized_frame is None:\n        continue\n\n    # {do something with the stabilized frame here}\n\n    # write stabilized frame to writer\n    writer.write(stabilized_frame)\n\n\n# clear stabilizer resources\nstab.clean()\n\n# safely close video stream\nstream.release()\n\n# safely close writer\nwriter.close()\n</code></pre> <ol> <li> Always keep this line above <code>-i</code> parameter!</li> </ol> <p> </p>"},{"location":"help/stabilizer_ex/#saving-stabilizer-class-output-with-file-audio-input","title":"Saving Stabilizer Class output with File Audio Input","text":"<p>In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time:</p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <p>Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>Use <code>-disable_force_termination</code> flag when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nfrom vidgear.gears.stabilizer import Stabilizer\nimport cv2\n\n# Give suitable video file path to be stabilized\nunstabilized_videofile = \"test.mp4\"\n\n# open stream on given path\nstream = cv2.VideoCapture(unstabilized_videofile)\n\n# initiate stabilizer object with defined parameters\nstab = Stabilizer(smoothing_radius=30, crop_n_zoom=True, border_size=5, logging=True)\n\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n    \"-i\": unstabilized_videofile,\n    \"-c:a\": \"aac\",\n    \"-input_framerate\": stream.get(cv2.CAP_PROP_FPS),\n    \"-clones\": [\"-shortest\"],\n    # !!! Uncomment following line if video duration is too short(&lt;60sec). !!!\n    #\"-disable_force_termination\": True,\n}\n\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    (grabbed, frame) = stream.read()\n\n    # check for frame if not grabbed\n    if not grabbed:\n        break\n\n    # send current frame to stabilizer for processing\n    stabilized_frame = stab.stabilize(frame)\n\n    # wait for stabilizer which still be initializing\n    if stabilized_frame is None:\n        continue\n\n    # {do something with the stabilized frame here}\n\n    # write stabilized frame to writer\n    writer.write(stabilized_frame)\n\n\n# clear stabilizer resources\nstab.clean()\n\n# safely close video stream\nstream.release()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/stabilizer_faqs/","title":"FAQs","text":""},{"location":"help/stabilizer_faqs/#stabilizer-class-faqs","title":"Stabilizer Class FAQs","text":""},{"location":"help/stabilizer_faqs/#what-is-stabilizer-class-and-what-does-it-do","title":"What is Stabilizer Class and what does it do?","text":"<p>Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6</p> <p> </p>"},{"location":"help/stabilizer_faqs/#how-much-latency-you-would-typically-expect-with-stabilizer-class","title":"How much latency you would typically expect with Stabilizer Class?","text":"<p>Answer: The stabilizer will be Slower for High-Quality videos-frames. Try reducing frames size (Use <code>reducer()</code> method) before feeding them for reducing latency. Also, see <code>smoothing_radius</code> parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. The larger its value, the less will be panning, more will be latency, and vice-versa.</p> <p> </p>"},{"location":"help/stabilizer_faqs/#how-to-remove-black-borders-in-output-video-after-stabilizing-it","title":"How to remove black borders in output video after stabilizing it?","text":"<p>Answer: See <code>crop_n_zoom</code> parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects). It works in conjunction with the <code>border_size</code> parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is <code>False</code>.</p> <p> </p>"},{"location":"help/stabilizer_faqs/#can-i-use-stabilizer-directly-with-opencv","title":"Can I use Stabilizer directly with OpenCV?","text":"<p>Answer: Yes, see this usage example \u27b6.</p> <p> </p>"},{"location":"help/stabilizer_faqs/#why-stabilization-is-not-working-properly-for-my-video","title":"Why stabilization is not working properly for my video?","text":"<p>Answer: The Stabilizer may not perform well against High-frequency jitter in video. But,you can check if increasing <code>smoothing_radius</code> parameter value helps but it will add latency too.</p> <p> </p>"},{"location":"help/streamgear_ex/","title":"Bonus Examples","text":""},{"location":"help/streamgear_ex/#streamgear-examples","title":"StreamGear Examples","text":""},{"location":"help/streamgear_ex/#streamgear-live-streaming-usage-with-pigear","title":"StreamGear Live-Streaming Usage with PiGear","text":"<p>In this example, we will be Live-Streaming video-frames from Raspberry Pi (with Camera Module connected)  using PiGear API and StreamGear API's Real-time Frames Mode:</p> <p>Use <code>-window_size</code> &amp; <code>-extra_window_size</code> FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency.</p> <p>After every few chunks (equal to the sum of <code>-window_size</code> &amp; <code>-extra_window_size</code> values), all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames.</p> <p>In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> <p>PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using the PiGear API, otherwise nothing will work.</p> DASHHLS New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import StreamGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> Under the hood, PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, PiGear API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# formulate various Picamera API \n# configurational parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> New Picamera2 backendLegacy Picamera backend <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import StreamGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters\noptions = {\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> Under the hood, PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, PiGear API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import StreamGear\nimport cv2\n\n# formulate various Picamera API \n# configurational parameters\noptions = {\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # send frame to streamer\n    streamer.stream(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close streamer\nstreamer.close()\n</code></pre> <p> </p>"},{"location":"help/streamgear_faqs/","title":"FAQs","text":""},{"location":"help/streamgear_faqs/#streamgear-faqs","title":"StreamGear FAQs","text":""},{"location":"help/streamgear_faqs/#what-is-streamgear-api-and-what-does-it-do","title":"What is StreamGear API and what does it do?","text":"<p>Answer: StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. For more info. see StreamGear doc \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-get-started-with-streamgear-api","title":"How to get started with StreamGear API?","text":"<p>Answer: First, refer to the Switching from OpenCV guide, then go through StreamGear documentation. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/streamgear_faqs/#what-is-mpd-file-created-with-streamgear","title":"What is <code>.mpd</code> file created with StreamGear?","text":"<p>Answer: SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session.</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-play-streaming-assets-created-with-streamgear-api","title":"How to play Streaming Assets created with StreamGear API?","text":"<p>Answer: You can easily feed Manifest file(<code>.mpd</code>) to DASH Supported Players Input but sure encoded chunks are present along with it. See this list of recommended players \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#what-adaptive-streaming-formats-are-supported-yet","title":"What Adaptive Streaming Formats are supported yet?","text":"<p>Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon.</p> <p> </p>"},{"location":"help/streamgear_faqs/#is-drm-encryption-supported-in-streamgear-api","title":"Is DRM Encryption supported in StreamGear API?","text":"<p>Answer: No, DRM Encryption is NOT supported yet.</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-create-additional-streams-in-streamgear-api","title":"How to create additional streams in StreamGear API?","text":"<p>Answer: See this example \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-opencv","title":"How to use StreamGear API with OpenCV?","text":"<p>Answer: See this example \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-real-time-frames","title":"How to use StreamGear API with real-time frames?","text":"<p>Answer: See Real-time Frames Mode \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-use-hardwaregpu-encoder-for-transcoding-in-streamgear-api","title":"How to use Hardware/GPU encoder for transcoding in StreamGear API?","text":"<p>Answer: See this example \u27b6</p> <p> </p>"},{"location":"help/videogear_ex/","title":"Bonus Examples","text":""},{"location":"help/videogear_ex/#videogear-examples","title":"VideoGear Examples","text":""},{"location":"help/videogear_ex/#using-videogear-with-rosrobot-operating-system","title":"Using VideoGear with ROS(Robot Operating System)","text":"<p>We will be using <code>cv_bridge</code> to convert OpenCV frames to ROS image messages and vice-versa. </p> <p>In this example, we'll create a node that convert OpenCV frames into ROS image messages, and then publishes them over ROS.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example is vidgear implementation of this wiki example.</p> <pre><code># import roslib\nimport roslib\n\nroslib.load_manifest(\"my_package\")\n\n# import other required libraries\nimport sys\nimport rospy\nimport cv2\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom vidgear.gears import VideoGear\n\n# custom publisher class\nclass image_publisher:\n    def __init__(self, source=0, logging=False):\n        # create CV bridge\n        self.bridge = CvBridge()\n        # define publisher topic\n        self.image_pub = rospy.Publisher(\"image_topic_pub\", Image)\n        # open stream with given parameters\n        self.stream = VideoGear(source=source, logging=logging).start()\n        # define publisher topic\n        rospy.Subscriber(\"image_topic_sub\", Image, self.callback)\n\n    def callback(self, data):\n\n        # {do something with received ROS node data here}\n\n        # read frames\n        frame = self.stream.read()\n        # check for frame if None-type\n        if not (frame is None):\n\n            # {do something with the frame here}\n\n            # publish our frame\n            try:\n                self.image_pub.publish(self.bridge.cv2_to_imgmsg(frame, \"bgr8\"))\n            except CvBridgeError as e:\n                # catch any errors\n                print(e)\n\n    def close(self):\n        # stop stream\n        self.stream.stop()\n\n\ndef main(args):\n    # !!! define your own video source here !!!\n    # Open any video stream such as live webcam\n    # video stream on first index(i.e. 0) device\n\n    # define publisher\n    ic = image_publisher(source=0, logging=True)\n    # initiate ROS node on publisher\n    rospy.init_node(\"image_publisher\", anonymous=True)\n    try:\n        # run node\n        rospy.spin()\n    except KeyboardInterrupt:\n        print(\"Shutting down\")\n    finally:\n        # close publisher\n        ic.close()\n\n\nif __name__ == \"__main__\":\n    main(sys.argv)\n</code></pre> <p> </p>"},{"location":"help/videogear_ex/#using-videogear-for-capturing-rtsprtmp-urls","title":"Using VideoGear for capturing RTSP/RTMP URLs","text":"<p>Here's a high-level wrapper code around VideoGear API to enable auto-reconnection during capturing, plus stabilization is enabled (<code>stabilize=True</code>) in order to stabilize captured frames on-the-go: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> Enforcing UDP stream <p>You can easily enforce UDP for RTSP streams inplace of default TCP, by putting following lines of code on the top of your existing code:</p> <pre><code># import required libraries\nimport os\n\n# enforce UDP\nos.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;udp\"\n</code></pre> <p>Finally, use <code>backend</code> parameter value as <code>backend=cv2.CAP_FFMPEG</code> in VideoGear.</p> <pre><code>from vidgear.gears import VideoGear\nimport cv2\nimport datetime\nimport time\n\n\nclass Reconnecting_VideoGear:\n    def __init__(self, cam_address, stabilize=False, reset_attempts=50, reset_delay=5):\n        self.cam_address = cam_address\n        self.stabilize = stabilize\n        self.reset_attempts = reset_attempts\n        self.reset_delay = reset_delay\n        self.source = VideoGear(\n            source=self.cam_address, stabilize=self.stabilize\n        ).start()\n        self.running = True\n\n    def read(self):\n        if self.source is None:\n            return None\n        if self.running and self.reset_attempts &gt; 0:\n            frame = self.source.read()\n            if frame is None:\n                self.source.stop()\n                self.reset_attempts -= 1\n                print(\n                    \"Re-connection Attempt-{} occured at time:{}\".format(\n                        str(self.reset_attempts),\n                        datetime.datetime.now().strftime(\"%m-%d-%Y %I:%M:%S%p\"),\n                    )\n                )\n                time.sleep(self.reset_delay)\n                self.source = VideoGear(\n                    source=self.cam_address, stabilize=self.stabilize\n                ).start()\n                # return previous frame\n                return self.frame\n            else:\n                self.frame = frame\n                return frame\n        else:\n            return None\n\n    def stop(self):\n        self.running = False\n        self.reset_attempts = 0\n        self.frame = None\n        if not self.source is None:\n            self.source.stop()\n\n\nif __name__ == \"__main__\":\n    # open any valid video stream\n    stream = Reconnecting_VideoGear(\n        cam_address=\"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\",\n        reset_attempts=20,\n        reset_delay=5,\n    )\n\n    # loop over\n    while True:\n\n        # read frames from stream\n        frame = stream.read()\n\n        # check for frame if None-type\n        if frame is None:\n            break\n\n        # {do something with the frame here}\n\n        # Show output window\n        cv2.imshow(\"Output\", frame)\n\n        # check for 'q' key if pressed\n        key = cv2.waitKey(1) &amp; 0xFF\n        if key == ord(\"q\"):\n            break\n\n    # close output window\n    cv2.destroyAllWindows()\n\n    # safely close video stream\n    stream.stop()\n</code></pre> <p> </p>"},{"location":"help/videogear_ex/#using-videogear-for-real-time-stabilization-with-audio-encoding","title":"Using VideoGear for Real-time Stabilization with Audio Encoding","text":"<p>In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time:</p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <p>Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>Use <code>-disable_force_termination</code> flag when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nfrom vidgear.gears import VideoGear\nimport cv2\n\n# Give suitable video file path to be stabilized\nunstabilized_videofile = \"test.mp4\"\n\n# open any valid video path with stabilization enabled(`stabilize = True`)\nstream_stab = VideoGear(source=unstabilized_videofile, stabilize=True, logging=True).start()\n\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n    \"-i\": unstabilized_videofile,\n    \"-c:a\": \"aac\",\n    \"-input_framerate\": stream_stab.framerate,\n    \"-clones\": [\"-shortest\"],\n    # !!! Uncomment following line if video duration is too short(&lt;60sec). !!!\n    #\"-disable_force_termination\": True,\n}\n\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame_stab = stream_stab.read()\n\n    # check for frame if not grabbed\n    if frame_stab is None:\n        break\n\n    # {do something with the stabilized frame here}\n\n    # write stabilized frame to writer\n    writer.write(frame_stab)\n\n# safely close streams\nstream_stab.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/videogear_faqs/","title":"FAQs","text":""},{"location":"help/videogear_faqs/#videogear-faqs","title":"VideoGear FAQs","text":""},{"location":"help/videogear_faqs/#what-is-videogear-api-and-what-does-it-do","title":"What is VideoGear API and what does it do?","text":"<p>Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special <code>enablePiCamera</code> boolean flag. For more info. see VideoGear doc \u27b6</p> <p> </p>"},{"location":"help/videogear_faqs/#whats-the-need-of-videogear-api","title":"What's the need of VideoGear API?","text":"<p>Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not)  with minimum efforts and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async.</p> <p> </p>"},{"location":"help/videogear_faqs/#which-apis-are-accessible-with-videogear-api","title":"Which APIs are accessible with VideoGear API?","text":"<p>Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class.</p> <p> </p>"},{"location":"help/videogear_faqs/#can-we-access-writegear-api-or-netgear-api-too-with-videogear","title":"Can we access WriteGear API or NetGear API too with VideoGear?","text":"<p>Answer: No, only selected VideoCapture APIs (anwsered above) are accessible.</p> <p> </p>"},{"location":"help/videogear_faqs/#does-using-videogear-instead-of-camgear-api-directly-affects-performance","title":"Does using VideoGear instead of CamGear API directly, affects performance?","text":"<p>Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API and without any modifications in-between.</p> <p> </p>"},{"location":"help/webgear_ex/","title":"Bonus Examples","text":""},{"location":"help/webgear_ex/#webgear-examples","title":"WebGear Examples","text":""},{"location":"help/webgear_ex/#using-webgear-with-raspberrypi-camera-module","title":"Using WebGear with RaspberryPi Camera Module","text":"<p>Because of WebGear API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs.</p> <p>Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear, CamGear and PiGear parameters directly in WebGear API in the similar manner.</p> <p>Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in few lines of python code:</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import libs\nimport uvicorn\nfrom libcamera import Transform\nfrom vidgear.gears.asyncio import WebGear\n\n# various WebGear_RTC performance \n# and Picamera2 API tweaks\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# initialize WebGear app\nweb = WebGear(\n    enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n\n# various webgear performance and Picamera API tweaks\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# initialize WebGear app\nweb = WebGear(\n    enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_ex/#using-webgear-with-real-time-video-stabilization-enabled","title":"Using WebGear with real-time Video Stabilization enabled","text":"<p>Here's an example of using WebGear API with real-time Video Stabilization enabled:</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n\n# various webgear performance tweaks\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n}\n\n# initialize WebGear app  with a raw source and enable video stabilization(`stabilize=True`)\nweb = WebGear(source=\"foo.mp4\", stabilize=True, logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_ex/#display-two-sources-simultaneously-in-webgear","title":"Display Two Sources Simultaneously in WebGear","text":"<p>In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear API by defining two separate frame generators: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>Step-1 (Trigger Auto-Generation Process): Firstly, run this bare-minimum code to trigger the Auto-generation process, this will create <code>.vidgear</code> directory at current location (directory where you'll run this code):</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n\n# provide current directory to save data files\noptions = {\"custom_data_location\": \"./\"}\n\n# initialize WebGear app\nweb = WebGear(source=0, logging=True, **options)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>Step-2 (Replace HTML file): Now, go inside <code>.vidgear</code> <code>webgear</code> <code>templates</code> directory at current location of your machine, and there replace content of <code>index.html</code> file with following:</p> <pre><code>{% extends \"base.html\" %}\n{% block content %}\n  &lt;h1 class=\"glow\"&gt;WebGear Video Feed&lt;/h1&gt;\n   &lt;div class=\"rows\"&gt;\n     &lt;img src=\"/video\" alt=\"Feed\"/&gt;\n     &lt;img src=\"/video2\" alt=\"Feed\"/&gt;\n   &lt;/div&gt;\n{% endblock %}\n</code></pre> <p>Step-3 (Build your own Frame Producers): Now, create a python script code with OpenCV source, as follows:</p> <pre><code># import necessary libs\nimport uvicorn, asyncio, cv2\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\nfrom starlette.responses import StreamingResponse\nfrom starlette.routing import Route\n\n# provide current directory to load data files\noptions = {\"custom_data_location\": \"./\"}\n\n# initialize WebGear app without any source\nweb = WebGear(logging=True, **options)\n\n# create your own custom frame producer\nasync def my_frame_producer1():\n\n   # !!! define your first video source here !!!\n   # Open any video stream such as \"foo1.mp4\"\n   stream = cv2.VideoCapture(\"foo1.mp4\")\n   # loop over frames\n   while True:\n       # read frame from provided source\n       (grabbed, frame) = stream.read()\n       # break if NoneType\n       if not grabbed:\n           break\n\n       # do something with your OpenCV frame here\n\n       # reducer frames size if you want more performance otherwise comment this line\n       frame = await reducer(frame, percentage=30)  # reduce frame by 30%\n       # handle JPEG encoding\n       encodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n       # yield frame in byte format\n       yield (b\"--frame\\r\\nContent-Type:video/jpeg2000\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\n       await asyncio.sleep(0.00001)\n   # close stream\n   stream.release()\n\n\n# create your own custom frame producer\nasync def my_frame_producer2():\n\n   # !!! define your second video source here !!!\n   # Open any video stream such as \"foo2.mp4\"\n   stream = cv2.VideoCapture(\"foo2.mp4\")\n   # loop over frames\n   while True:\n       # read frame from provided source\n       (grabbed, frame) = stream.read()\n       # break if NoneType\n       if not grabbed:\n           break\n\n       # do something with your OpenCV frame here\n\n       # reducer frames size if you want more performance otherwise comment this line\n       frame = await reducer(frame, percentage=30)  # reduce frame by 30%\n       # handle JPEG encoding\n       encodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n       # yield frame in byte format\n       yield (b\"--frame\\r\\nContent-Type:video/jpeg2000\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\n       await asyncio.sleep(0.00001)\n   # close stream\n   stream.release()\n\n\nasync def custom_video_response(scope):\n   \"\"\"\n   Return a async video streaming response for `my_frame_producer2` generator\n   \"\"\"\n   assert scope[\"type\"] in [\"http\", \"https\"]\n   await asyncio.sleep(0.00001)\n   return StreamingResponse(\n       my_frame_producer2(),\n       media_type=\"multipart/x-mixed-replace; boundary=frame\",\n   )\n\n\n# add your custom frame producer to config\nweb.config[\"generator\"] = my_frame_producer1\n\n# append new route i.e. new custom route with custom response\nweb.routes.append(\n    Route(\"/video2\", endpoint=custom_video_response)\n    )\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.</p> <p> </p>"},{"location":"help/webgear_faqs/","title":"FAQs","text":""},{"location":"help/webgear_faqs/#webgear-faqs","title":"WebGear FAQs","text":""},{"location":"help/webgear_faqs/#what-is-webgear-api-and-what-does-it-do","title":"What is WebGear API and what does it do?","text":"<p>Answer: WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser. For more info. see WebGear doc \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#how-to-get-started-with-webgear-api","title":"How to get started with WebGear API?","text":"<p>Answer: First, refer to the Switching from OpenCV guide, then go through WebGear documentation. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/webgear_faqs/#webgear-is-throwing-modulenotfounderror-on-importing-why","title":"\"WebGear is throwing <code>ModuleNotFoundError</code> on importing\", Why?","text":"<p>Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-webgear-always-need-active-internet-connection","title":"Can WebGear always need Active Internet Connection?","text":"<p>Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server, otherwise you can also add your own custom files. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#is-it-possible-to-stream-on-a-different-device-on-the-network-with-webgear","title":"Is it possible to stream on a different device on the network with WebGear?","text":"<p>If you set <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine, then you must still use http://localhost:8000/ to access stream on that same host machine browser.</p> <p>For accessing WebGear on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. Then type the IP-address of source machine followed by the defined <code>port</code> value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000) to access the stream.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-i-manually-place-default-files-for-webgear","title":"Can I manually place default files for WebGear?","text":"<p>Answer: Yes, you can either download default files from Github Server, and manually place at default location, OR, you can yourself create the require three critical files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>)  inside <code>templates</code> folder at the default location, thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#how-to-send-opencv-frames-directly-to-webgear-server","title":"How to send OpenCV frames directly to Webgear Server?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#how-can-i-add-my-custom-webpage-to-webgear","title":"How can I add my custom WebPage to WebGear?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#how-can-to-add-cors-headers-to-webgear","title":"How can to add CORS headers to WebGear?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-i-change-the-default-location","title":"Can I change the default location?","text":"<p>Answer: Yes, you can use WebGear's <code>custom_data_location</code> attribute of <code>option</code> parameter in WebGear API, to change default location to somewhere else.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-i-deleterename-the-webgear-default-data","title":"Can I delete/rename the WebGear default data?","text":"<p>Answer: Yes, but you've to follow these rules \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#what-web-browser-are-supported-by-webgear-api","title":"What Web browser are supported by WebGear API?","text":"<p>Answer: All modern browser with Javascript support are supported by WebGear. If not, then discuss with us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/webgear_rtc_ex/","title":"Bonus Examples","text":""},{"location":"help/webgear_rtc_ex/#webgear_rtc_rtc-examples","title":"WebGear_RTC_RTC Examples","text":""},{"location":"help/webgear_rtc_ex/#using-webgear_rtc-with-raspberrypi-camera-module","title":"Using WebGear_RTC with RaspberryPi Camera Module","text":"<p>Because of WebGear_RTC API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs.</p> <p>Following usage examples are just an idea of what can be done with WebGear_RTC API, you can try various VideoGear, CamGear and PiGear parameters directly in WebGear_RTC API in the similar manner.</p> <p>Here's a bare-minimum example of using WebGear_RTC API with the Raspberry Pi camera module while tweaking its various properties in just one-liner:</p> <p>Backend PiGear API now fully supports the newer <code>picamera2</code> python library under the hood for Raspberry Pi  camera modules. Follow this guide \u27b6 for its installation.</p> <p>Make sure to complete Raspberry Pi Camera Hardware-specific settings prior using this backend, otherwise nothing will work.</p> New Picamera2 backendLegacy Picamera backend <pre><code># import libs\nimport uvicorn\nfrom libcamera import Transform\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various WebGear_RTC performance \n# and Picamera2 API tweaks\noptions = {\n    \"frame_size_reduction\": 25,\n    \"queue\": True,\n    \"buffer_count\": 4,\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"auto_align_output_config\": True,  # auto-align camera configuration\n}\n\n# initialize WebGear app\nweb = WebGear_RTC(\n    enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> Under the hood, Backend PiGear API (version <code>0.3.3</code> onwards) prioritizes the new <code>picamera2</code> API backend. <p>However, the API seamlessly switches to the legacy <code>picamera</code> backend, if the <code>picamera2</code> library is unavailable or not installed.</p> <p>It is advised to enable logging(<code>logging=True</code>) to see which backend is being used.</p> <p>The <code>picamera</code> library is built on the legacy camera stack that is NOT (and never has been) supported on 64-bit OS builds.</p> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various WebGear_RTC performance and Picamera API tweaks\noptions = {\n    \"frame_size_reduction\": 25,\n    \"hflip\": True,\n    \"exposure_mode\": \"auto\",\n    \"iso\": 800,\n    \"exposure_compensation\": 15,\n    \"awb_mode\": \"horizon\",\n    \"sensor_mode\": 0,\n}\n\n# initialize WebGear app\nweb = WebGear_RTC(\n    enablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_rtc_ex/#using-webgear_rtc-with-real-time-video-stabilization-enabled","title":"Using WebGear_RTC with real-time Video Stabilization enabled","text":"<p>Here's an example of using WebGear_RTC API with real-time Video Stabilization enabled:</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various webgear_rtc performance tweaks\noptions = {\n    \"frame_size_reduction\": 25,\n}\n\n# initialize WebGear_RTC app  with a raw source and enable video stabilization(`stabilize=True`)\nweb = WebGear_RTC(source=\"foo.mp4\", stabilize=True, logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_rtc_ex/#display-two-sources-simultaneously-in-webgear_rtc","title":"Display Two Sources Simultaneously in WebGear_RTC","text":"<p>In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear_RTC API by simply concatenating frames in real-time: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nimport numpy as np\nfrom vidgear.gears.helper import reducer\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True)\n\n# frame concatenator\ndef get_conc_frame(frame1, frame2):\n    h1, w1 = frame1.shape[:2]\n    h2, w2 = frame2.shape[:2]\n\n    # create empty matrix\n    vis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)\n\n    # combine 2 frames\n    vis[:h1, :w1, :3] = frame1\n    vis[:h2, w1 : w1 + w2, :3] = frame2\n\n    return vis\n\n\n# create your own custom streaming class\nclass Custom_Stream_Class:\n    \"\"\"\n    Custom Streaming using two OpenCV sources\n    \"\"\"\n\n    def __init__(self, source1=None, source2=None):\n\n        # !!! define your own video source here !!!\n        # check is source are provided\n        if source1 is None or source2 is None:\n            raise ValueError(\"Provide both source\")\n\n        # initialize global params\n        # define both source here\n        self.stream1 = cv2.VideoCapture(source1)\n        self.stream2 = cv2.VideoCapture(source2)\n\n        # define running flag\n        self.running = True\n\n    def read(self):\n\n        # don't forget this function!!!\n\n        # check if sources were initialized or not\n        if self.stream1 is None or self.stream2 is None:\n            return None\n\n        # check if we're still running\n        if self.running:\n            # read video frame\n            (grabbed1, frame1) = self.stream1.read()\n            (grabbed2, frame2) = self.stream2.read()\n\n            # if NoneType\n            if not grabbed1 or not grabbed2:\n\n                # do something with your OpenCV frame here\n\n                # concatenate frame\n                frame = get_conc_frame(frame1, frame2)\n\n                # reducer frames size if you want more performance otherwise comment this line\n                # frame = await reducer(frame, percentage=30)  # reduce frame by 30%\n\n                # return our gray frame\n                return frame\n            else:\n                # signal we're not running now\n                self.running = False\n        # return None-type\n        return None\n\n    def stop(self):\n\n        # don't forget this function!!!\n\n        # flag that we're not running\n        self.running = False\n        # close stream\n        if not (self.stream1 is None):\n            self.stream1.release()\n            self.stream1 = None\n\n        if not (self.stream2 is None):\n            self.stream2.release()\n            self.stream2 = None\n\n\n# assign your Custom Streaming Class with adequate two sources\n# to `custom_stream` attribute in options parameter\noptions = {\n    \"custom_stream\": Custom_Stream_Class(\n        source1=\"foo1.mp4\", source2=\"foo2.mp4\"\n    )\n}\n\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/","title":"FAQs","text":""},{"location":"help/webgear_rtc_faqs/#webgear_rtc-faqs","title":"WebGear_RTC FAQs","text":""},{"location":"help/webgear_rtc_faqs/#what-is-webgear_rtc-api-and-what-does-it-do","title":"What is WebGear_RTC API and what does it do?","text":"<p>Answer: WebGear_RTC utilizes WebRTC technology under the hood, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. For more info. see WebGear_RTC doc \u27b6</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-to-get-started-with-webgear_rtc-api","title":"How to get started with WebGear_RTC API?","text":"<p>Answer: First, refer to the Switching from OpenCV guide, then go through WebGear_RTC documentation. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-webgear_rtc-is-different-to-webgear-api-which-should-i-choose","title":"How WebGear_RTC is different to WebGear API, which should I choose?","text":"<p>Answer: WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG. You can choose any API according to your application, but the quality would be better on WebGear API, on-the-other-hand latency would be better on WebGear_RTC API. Also, WebRTC protocol accepts a wide range of devices, whereas WebGear is limited only to modern browsers. </p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#webgear_rtc-is-throwing-modulenotfounderror-on-importing-why","title":"\"WebGear_RTC is throwing <code>ModuleNotFoundError</code> on importing\", Why?","text":"<p>Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-webgear_rtc-always-need-active-internet-connection","title":"Can WebGear_RTC always need Active Internet Connection?","text":"<p>Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server, otherwise you can also add your own custom files. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#is-it-possible-to-stream-on-a-different-device-on-the-network-with-webgear_rtc","title":"Is it possible to stream on a different device on the network with WebGear_RTC?","text":"<p>If you set <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine, then you must still use http://localhost:8000/ to access stream on your host machine browser.</p> <p>For accessing WebGear_RTC on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. Then type the IP-address of source machine followed by the defined <code>port</code> value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000) to access the stream.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-i-manually-place-default-files-for-webgear_rtc","title":"Can I manually place default files for WebGear_RTC?","text":"<p>Answer: Yes, you can either download default files from Github Server, and manually place at default location, OR, you can yourself create the require three critical files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>)  inside <code>templates</code> folder at the default location, thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-to-stream-webgear_rtc-server-output-to-multiple-clients","title":"How to stream Webgear_RTC Server output to multiple clients?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-to-send-opencv-frames-directly-to-webgear_rtc-server","title":"How to send OpenCV frames directly to Webgear_RTC Server?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-can-i-add-my-custom-webpage-to-webgear_rtc","title":"How can I add my custom WebPage to WebGear_RTC?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-can-to-add-cors-headers-to-webgear_rtc","title":"How can to add CORS headers to WebGear_RTC?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-i-change-the-default-location","title":"Can I change the default location?","text":"<p>Answer: Yes, you can use WebGear_RTC's <code>custom_data_location</code> attribute of <code>option</code> parameter in WebGear_RTC API, to change default location to somewhere else.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-i-deleterename-the-webgear_rtc-default-data","title":"Can I delete/rename the WebGear_RTC default data?","text":"<p>Answer: Yes, but you've to follow these rules \u27b6</p> <p> </p>"},{"location":"help/writegear_ex/","title":"Bonus Examples","text":""},{"location":"help/writegear_ex/#writegear-examples","title":"WriteGear Examples","text":""},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-rtsprtp-live-streaming","title":"Using WriteGear's Compression Mode for RTSP/RTP Live-Streaming","text":"<p>In Compression Mode, you can use WriteGear for livestreaming with traditional protocols such as RTSP/RTP. The example to achieve that is as follows:   </p> New in v0.2.6 <p>This example was added in <code>v0.2.6</code>.</p> Creating your own RTSP Server locally <p>If you want to create your RTSP Server locally, then checkout MediaMTX (formerly rtsp-simple-server) - ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams.</p> <p>This example assume you already have a RTSP Server running at specified RTSP address with format <code>rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH]</code> for publishing video frames.</p> <p>Make sure to change RTSP address <code>rtsp://localhost:8554/mystream</code> with yours in following code before running!</p> <pre><code># import required libraries\nimport cv2\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\n\n# open any valid video stream(for e.g `foo.mp4` file)\nstream = CamGear(source=\"foo.mp4\").start()\n\n# define required FFmpeg parameters for your writer\noutput_params = {\"-f\": \"rtsp\", \"-rtsp_transport\": \"tcp\"}\n\n# Define writer with defined parameters and RTSP address\n# [WARNING] Change your RTSP address `rtsp://localhost:8554/mystream` with yours!\nwriter = WriteGear(\n    output=\"rtsp://localhost:8554/mystream\", logging=True, **output_params\n)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-youtube-live-streaming","title":"Using WriteGear's Compression Mode for YouTube-Live Streaming","text":"<p>In Compression Mode, you can also use WriteGear for Youtube-Livestreaming. The example is as follows:   </p> New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <p>This example assume you already have a YouTube Account with Live-Streaming enabled for publishing video.</p> <p>Make sure to change YouTube-Live Stream Key with yours in following code before running!</p> Without AudioWith Audio <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# define and open video source\nstream = CamGear(source=\"/home/foo/foo.mp4\", logging=True).start()\n\n# define required FFmpeg parameters for your writer\noutput_params = {\n    \"-clones\": [\"-f\", \"lavfi\", \"-i\", \"anullsrc\"],\n    \"-vcodec\": \"libx264\",\n    \"-preset\": \"medium\",\n    \"-b:v\": \"4500k\",\n    \"-bufsize\": \"512k\",\n    \"-pix_fmt\": \"yuv420p\",\n    \"-f\": \"flv\",\n}\n\n# [WARNING] Change your YouTube-Live Stream Key here:\nYOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\"\n\n# Define writer with defined parameters\nwriter = WriteGear(\n    output=\"rtmp://a.rtmp.youtube.com/live2/{}\".format(YOUTUBE_STREAM_KEY),\n    logging=True,\n    **output_params\n)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p>This code assume given input video source contains valid audio stream.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# define video source(with audio) here\nVIDEO_SOURCE = \"/home/foo/foo.mp4\"\n\n# Open stream\nstream = CamGear(source=VIDEO_SOURCE, logging=True).start()\n\n# define required FFmpeg parameters for your writer\n# [NOTE]: Added VIDEO_SOURCE as audio-source\noutput_params = {\n    \"-i\": VIDEO_SOURCE,\n    \"-acodec\": \"aac\",\n    \"-ar\": 44100,\n    \"-b:a\": 712000,\n    \"-vcodec\": \"libx264\",\n    \"-preset\": \"medium\",\n    \"-b:v\": \"4500k\",\n    \"-bufsize\": \"512k\",\n    \"-pix_fmt\": \"yuv420p\",\n    \"-f\": \"flv\",\n}\n\n# [WARNING] Change your YouTube-Live Stream Key here:\nYOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\"\n\n# Define writer with defined parameters\nwriter = WriteGear(\n    output=\"rtmp://a.rtmp.youtube.com/live2/{}\".format(YOUTUBE_STREAM_KEY),\n    logging=True,\n    **output_params\n)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-with-v4l2loopback-virtual-cameras","title":"Using WriteGear's Compression Mode with v4l2loopback Virtual Cameras","text":"<p>With WriteGear's Compression Mode, you can directly feed video-frames to <code>v4l2loopback</code> generated Virtual Camera devices on Linux Machines. The complete usage example is as follows:</p> New in v0.3.0 <p>This example was added in <code>v0.3.0</code>.</p> Example Assumptions <ul> <li>You're running are a Linux machine.</li> <li>WriteGear API's backend FFmpeg binaries are compiled with <code>v4l2/v4l2loopback</code> demuxer support.</li> <li>You already have <code>v4l2loopback</code> Virtual Camera device running at address: <code>/dev/video0</code></li> </ul> Creating your own Virtual Camera device with <code>v4l2loopback</code> module. <p>To install and create a v4l2loopback virtual camera device on Linux Mint OS/Ubuntu (may slightly differ for other distros), run following two terminal commands:</p> <pre><code>$ sudo apt-get install v4l2loopback-dkms v4l2loopback-utils linux-modules-extra-$(uname -r)\n\n$ sudo modprobe v4l2loopback devices=1 video_nr=0 exclusive_caps=1 card_label='VCamera'\n</code></pre> <p>For further information on parameters used, checkout v4l2loopback docs</p> <p>Finally, You can check the loopback device you just created by listing contents of <code>/sys/devices/virtual/video4linux</code> directory with terminal command:</p> <pre><code>$ sudo ls -1 /sys/devices/virtual/video4linux\n\nvideo0 \n</code></pre> <p>Now you can use <code>/dev/video0</code> Virtual Camera device path in WriteGear API.</p> v4l2: open /dev/videoX: Permission denied <p>If you got this error, then you must add your username to the <code>video</code> group by running following commands: <pre><code>$ sudo adduser $(whoami) video\n$ sudo usermod -a -G video $(whoami)\n</code></pre> Afterwards, restart your computer to finialize these changes.</p> <p>Note: If the problem still persists, then try to run your python script as superuser with <code>sudo</code> command.</p> Default <code>libx264</code> encoder is incompatible with <code>v4l2loopback</code> module. <p>Kindly use other encoders such as <code>libxvid</code>, <code>mpeg4</code> etc.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# open any valid video stream(for e.g `foo.mp4` file)\nstream = CamGear(source=\"foo.mp4\").start()\n\n# define required FFmpeg parameters for your writer\n# also retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter\noutput_params = {\n    \"-input_framerate\": stream.framerate,\n    \"-vcodec\": \"libxvid\",\n    \"-f\": \"v4l2\",\n    \"-pix_fmt\": \"yuv420p\",\n}\n\n# Define writer with \"/dev/video0\" as source and user-defined parameters \nwriter = WriteGear(output=\"/dev/video0\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if None-type\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p>The data sent to the v4l2loopback device <code>/dev/video0</code> in this example with WriteGear API, can then be read by any v4l2-capable application (such as OpenCV, VLC, ffplay etc.)</p> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-creating-mp4-segments","title":"Using WriteGear's Compression Mode for creating MP4 segments","text":"<p>In Compression Mode, you can also use WriteGear for creating MP4 segments from almost any video source. The example is as follows:   </p> New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# Open any video source `foo.mp4`\nstream = VideoGear(\n    source=\"foo.mp4\", logging=True\n).start()\n\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n    \"-c:v\": \"libx264\",\n    \"-crf\": 22,\n    \"-map\": 0,\n    \"-segment_time\": 9,\n    \"-g\": 9,\n    \"-sc_threshold\": 0,\n    \"-force_key_frames\": \"expr:gte(t,n_forced*9)\",\n    \"-clones\": [\"-f\", \"segment\"],\n}\n\n# Define writer with defined parameters\nwriter = WriteGear(output=\"output%03d.mp4\", logging=True, **output_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-to-add-external-audio-file-input-to-video-frames","title":"Using WriteGear's Compression Mode to add external audio file input to video frames","text":"<p>You can also use WriteGear for merging external audio with live video-source:  </p> New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <p>Make sure this <code>-i</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n\n# open any valid video stream(for e.g `foo_video.mp4` file)\nstream = CamGear(source=\"foo_video.mp4\").start()\n\n# add various parameters, along with custom audio\nstream_params = {\n    \"-input_framerate\": stream.framerate,  # controlled framerate for audio-video sync !!! don't forget this line !!!\n    \"-i\": \"foo_audio.aac\",  # assigns input audio-source: \"foo_audio.aac\"\n}\n\n# Define writer with defined parameters\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **stream_params)\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # write frame to writer\n    writer.write(frame)\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) &amp; 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-generating-timely-accurate-video","title":"Using WriteGear's Compression Mode for generating Timely Accurate Video","text":"<p>If you need timely accurate video with exactly same speed as real-time input, then you need to use FFmpeg directly through its <code>execute_ffmpeg_cmd</code> method: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <p>In this example we are capturing video from desktop screen in a Timely Accurate manner.</p> Windows Linux MacOS  <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n\n# Define writer with defined parameters and with some dummy name\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n\n# format FFmpeg command to generate time accurate video\nffmpeg_command = [\n    \"-y\",\n    \"-f\",\n    \"gdigrab\",\n    \"-framerate\",\n    \"30\",\n    \"-i\",\n    \"desktop\",\n    \"Output.mkv\",\n]  # `-y` parameter is to overwrite outputfile if exists\n\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n\n# safely close writer\nwriter.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n\n# Define writer with defined parameters and with some dummy name\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n\n# format FFmpeg command to generate time accurate video\nffmpeg_command = [\n    \"-y\",\n    \"-f\",\n    \"x11grab\",\n    \"-framerate\",\n    \"30\",\n    \"-i\",\n    \"default\",\n    \"Output.mkv\",\n]  # `-y` parameter is to overwrite outputfile if exists\n\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n\n# safely close writer\nwriter.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n\n# Define writer with defined parameters and with some dummy name\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n\n# format FFmpeg command to generate time accurate video\nffmpeg_command = [\n    \"-y\",\n    \"-f\",\n    \"avfoundation\",\n    \"-framerate\",\n    \"30\",\n    \"-i\",\n    \"default\",\n    \"Output.mkv\",\n]  # `-y` parameter is to overwrite outputfile if exists\n\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegear-with-rosrobot-operating-system","title":"Using WriteGear with ROS(Robot Operating System)","text":"<p>We will be using <code>cv_bridge</code> to convert OpenCV frames to ROS image messages and vice-versa. </p> <p>In this example, we'll create a node that listens to a ROS image message topic, converts the received images messages into OpenCV frames, draws a circle on it, and then process these frames into a lossless compressed file format in real-time.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example is vidgear implementation of this wiki example.</p> <pre><code># import roslib\nimport roslib\n\nroslib.load_manifest(\"my_package\")\n\n# import other required libraries\nimport sys\nimport rospy\nimport cv2\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom vidgear.gears import WriteGear\n\n# custom publisher class\nclass image_subscriber:\n    def __init__(self, output=\"Output.mp4\"):\n        # create CV bridge\n        self.bridge = CvBridge()\n        # define publisher topic\n        self.image_pub = rospy.Subscriber(\"image_topic_sub\", Image, self.callback)\n        # Define writer with default parameters\n        self.writer = WriteGear(output=output)\n\n    def callback(self, data):\n        # convert received data to frame\n        try:\n            cv_image = self.bridge.imgmsg_to_cv2(data, \"bgr8\")\n        except CvBridgeError as e:\n            print(e)\n\n        # check if frame is valid\n        if cv_image:\n\n            # {do something with the frame here}\n            # let's add a circle\n            (rows, cols, channels) = cv_image.shape\n            if cols &gt; 60 and rows &gt; 60:\n                cv2.circle(cv_image, (50, 50), 10, 255)\n\n            # write frame to writer\n            self.writer.write(cv_image)\n\n        def close(self):\n            # safely close video stream\n            self.writer.close()\n\n\ndef main(args):\n    # define publisher with suitable output filename\n    # such as `Output.mp4` for saving output\n    ic = image_subscriber(output=\"Output.mp4\")\n    # initiate ROS node on publisher\n    rospy.init_node(\"image_subscriber\", anonymous=True)\n    try:\n        # run node\n        rospy.spin()\n    except KeyboardInterrupt:\n        print(\"Shutting down\")\n    finally:\n        # close publisher\n        ic.close()\n\n\nif __name__ == \"__main__\":\n    main(sys.argv)\n</code></pre> <p> </p>"},{"location":"help/writegear_faqs/","title":"FAQs","text":""},{"location":"help/writegear_faqs/#writegear-faqs","title":"WriteGear FAQs","text":""},{"location":"help/writegear_faqs/#what-is-writegear-api-and-what-does-it-do","title":"What is WriteGear API and what does it do?","text":"<p>Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-writegear-api","title":"I'm only familiar with OpenCV, how to get started with WriteGear API?","text":"<p>Answer: Answer: First, refer to the Switching from OpenCV guide, then go through WriteGear documentation. If you still have doubts, ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/writegear_faqs/#why-writegear-is-throwing-valueerror","title":"Why WriteGear is throwing <code>ValueError</code>?","text":"<p>Answer: WriteGear will exit with <code>ValueError</code> if you feed frames of different dimensions or channels.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-install-and-configure-ffmpeg-correctly-for-writegear-on-my-machine","title":"How to install and configure FFmpeg correctly for WriteGear on my machine?","text":"<p>Answer: Follow these Installation Instructions \u27b6 for its installation.</p> <p> </p>"},{"location":"help/writegear_faqs/#can-i-use-writegear-directly-with-opencv","title":"Can I use WriteGear directly with OpenCV?","text":"<p>Answer: Yes,</p> <ul> <li>For Compression Mode: See this usage example \u27b6.</li> <li>For  Non-Compression Mode: See this usage example \u27b6</li> </ul> <p> </p>"},{"location":"help/writegear_faqs/#what-ffmpegs-encoders-and-parameters-are-supported-by-writegear-in-compression-mode","title":"What FFmpeg's encoders and parameters are supported by WriteGear in compression mode?","text":"<p>Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#what-opencvs-fourcc-and-parameters-are-supported-by-writegear-in-non-compression-mode","title":"What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode?","text":"<p>Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#why-this-fourcc-is-not-working-for-me","title":"Why this FOURCC is not working for me?","text":"<p>Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error.</p> <p> </p>"},{"location":"help/writegear_faqs/#can-i-pass-my-custom-ffmpeg-commands-directly-in-writegear-api","title":"Can I pass my custom FFmpeg commands directly in WriteGear API?","text":"<p>Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-use-specific-hardware-encoder-in-writegear","title":"How to use specific Hardware Encoder in WriteGear?","text":"<p>Answer: See this usage example \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-add-live-audio-to-writegear","title":"How to add live audio to WriteGear?","text":"<p>Answer: See this doc \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-separate-and-merge-audio-fromto-video","title":"How to separate and merge audio from/to video?","text":"<p>Answer: See these usage examples \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#can-i-live-stream-to-twitch-with-writegear-api","title":"Can I live stream to Twitch with WriteGear API?","text":"<p>Answer: Yes, See this usage example \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#is-youtube-live-streaming-possible-with-writegear","title":"Is YouTube-Live Streaming possible with WriteGear?","text":"<p>Answer: Yes, See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-live-streaming-using-rtsprtp-protocol-with-writegear","title":"How to Live-Streaming using RTSP/RTP protocol with WriteGear?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-create-mp4-segments-from-a-video-stream-with-writegear","title":"How to create MP4 segments from a video stream with WriteGear?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-add-external-audio-file-input-to-video-frames","title":"How add external audio file input to video frames?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#why-this-ffmpeg-parameter-is-not-working-for-me-in-compression-mode","title":"Why this FFmpeg parameter is not working for me in compression mode?","text":"<p>Answer: If some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6, and if that doesn't help, then finally report an issue \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#why-writegear-is-switching-to-non-compression-mode-even-if-it-is-not-enable","title":"Why WriteGear is switching to Non-compression Mode, even if it is not enable?","text":"<p>Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it will automatically fallback to Non-Compression Mode. Follow Installation Instructions \u27b6 for FFmpeg installation.</p> <p> </p>"},{"location":"installation/pip_install/","title":"Install using pip","text":""},{"location":"installation/pip_install/#install-using-pip","title":"Install using pip","text":"<p>Best option for easily getting stable VidGear installed.</p>"},{"location":"installation/pip_install/#prerequisites","title":"Prerequisites","text":"<p>When installing VidGear with pip, you need to manually install following prerequisites:</p>  Upgrade your <code>pip</code> <p>It strongly advised to upgrade to latest <code>pip</code> before installing vidgear to avoid any undesired installation error(s).</p> <p>There are two mechanisms to upgrade <code>pip</code>:</p> <code>pip</code><code>ensurepip</code> <p>You can use existing <code>pip</code> to upgrade itself:</p> Install <code>pip</code> if not present <ul> <li>Download the script, from https://bootstrap.pypa.io/get-pip.py.</li> <li>Open a terminal/command prompt, <code>cd</code> to the folder containing the <code>get-pip.py</code> file and run:</li> </ul>  Linux /  MacOS Windows <pre><code>python get-pip.py\n</code></pre> <pre><code>py get-pip.py\n</code></pre> <p>More details about this script can be found in pypa/get-pip\u2019s README.</p>  Linux /  MacOS Windows <pre><code>python -m pip install pip --upgrade\n</code></pre> <pre><code>py -m pip install pip --upgrade\n</code></pre> <p>Python also comes with an <code>ensurepip</code> module<sup>1</sup>, which can easily upgrade/install <code>pip</code> in any Python environment.</p>  Linux /  MacOS Windows <pre><code>python -m ensurepip --upgrade\n</code></pre> <pre><code>py -m ensurepip --upgrade\n</code></pre> <p> </p>"},{"location":"installation/pip_install/#critical-prerequisites","title":"Critical Prerequisites","text":""},{"location":"installation/pip_install/#opencv","title":"OpenCV","text":"<p>Must require OpenCV(3.0+) python binaries installed for all core functions. You easily install it directly via pip:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       \n</code></pre>"},{"location":"installation/pip_install/#api-specific-prerequisites","title":"API Specific Prerequisites","text":""},{"location":"installation/pip_install/#ffmpeg","title":"FFmpeg","text":"<p>Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode. </p> <p>FFmpeg Installation</p> <ul> <li>For WriteGear API's Compression Mode: Follow this dedicated FFmpeg Installation doc for its installation.</li> <li>For StreamGear API: Follow this dedicated FFmpeg Installation doc for its installation.</li> </ul>"},{"location":"installation/pip_install/#picamera2","title":"Picamera2","text":"<p>Required only if you're using Raspberry Pi  Camera Modules (or USB webcams) with the PiGear API. Here's how to install Picamera2 python library:</p> Using Legacy <code>picamera</code> library with PiGear (<code>v0.3.3</code> and above) <p>PiGear API (version <code>0.3.3</code> onwards) prioritizes the newer Picamera2 library under the hood for Raspberry Pi  camera modules. However, if your operating system doesn't support Picamera2, you can still use the legacy <code>picamera</code> library. Here's how to easily install it using pip:</p> <pre><code>pip install picamera\n</code></pre> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> Picamera2 is only supported on Raspberry Pi OS Bullseye (or later) images, both 32 and 64-bit. <p>Picamera2 is NOT supported on:</p> <ul> <li> Images based on Buster or earlier releases.</li> <li> Raspberry Pi OS Legacy images.</li> <li> Bullseye (or later) images where the legacy camera stack has been re-enabled.</li> </ul> Installation using <code>apt</code> (Recommended)Installation using <code>pip</code> As of September 2022, Picamera2 is pre-installed on images downloaded from Raspberry Pi. So you don't have to install it manually. <ul> <li> On Raspberry Pi OS images, Picamera2 is now installed with all the GUI (Qt and OpenGL) dependencies.</li> <li> <p> On Raspberry Pi OS Lite, it is installed without the GUI dependencies, although preview images can still be displayed using DRM/KMS. If these users wish to use the additional X-Windows GUI features, they will need to run:</p> <pre><code>sudo apt install -y python3-pyqt5 python3-opengl\n</code></pre> </li> </ul> <p>If Picamera2 is not already installed, then your image is presumably older and you should start with system upgrade: <pre><code>sudo apt update &amp;&amp; upgrade\n</code></pre></p> <p>If you have installed Picamera2 previously using pip, then you should also uninstall this (<code>pip3 uninstall picamera2</code>).</p> <p>Thereafter, you can install Picamera2 with all the GUI (Qt and OpenGL) dependencies using:</p> <pre><code>sudo apt install -y python3-picamera2\n</code></pre> <p>Or, If you DON'T want the GUI dependencies, use:</p> <pre><code>sudo apt install -y python3-picamera2 --no-install-recommends\n</code></pre> <p>This is NOT the recommended way to install Picamera2.</p> <p>However, if you wish to install Picamera2 with all the GUI (Qt and OpenGL) dependencies with pip, use:</p> <pre><code>sudo apt install -y python3-libcamera python3-kms++\nsudo apt install -y python3-pyqt5 python3-prctl \nsudo apt install -y libatlas-base-dev ffmpeg python3-pip\npip3 install numpy --upgrade\npip3 install picamera2[gui]\n</code></pre> <p>Or, If you DON'T want the GUI dependencies, use:</p> <pre><code>sudo apt install -y python3-libcamera python3-kms++\nsudo apt install -y python3-prctl libatlas-base-dev\nsudo apt install -y ffmpeg libopenjp2-7 python3-pip\npip3 install numpy --upgrade\npip3 install picamera2\n</code></pre>"},{"location":"installation/pip_install/#uvloop","title":"Uvloop","text":"<p>Required only if you're using the NetGear_Async API on UNIX machines for maximum performance. You can easily install it via pip:</p> <p>uvloop is NOT yet supported on Windows  Machines.</p> <pre><code>pip install uvloop\n</code></pre>"},{"location":"installation/pip_install/#dxcam","title":"DXcam","text":"<p>Required only if you're using the ScreenGear API on Windows machines for better FPS performance. You can easily install it via pip:</p> <p>FYI, DXcam is ONLY supported on Windows  Machines.</p> <pre><code>pip install dxcam\n</code></pre>"},{"location":"installation/pip_install/#installation","title":"Installation","text":"Installation command with <code>pip</code> has been changed in <code>v0.2.4</code> <p>The legacy <code>pip install vidgear</code> command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use <code>pip install vidgear[core]</code> command instead.</p> <code>v0.2.4</code> and newerOlder <pre><code># Install latest stable release with all Core dependencies\npip install -U vidgear[core]\n</code></pre> <p><code>[core]</code> keyword isn't available in versions older than <code>v0.2.4</code></p> <pre><code># Install older stable release with all Core dependencies\npip install vidgear&lt;0.2.4\n</code></pre> <p>Similarly in your python project files like <code>setup.py</code> or <code>requirements.txt</code> or <code>setup.cfg</code>, use vidgear dependency as <code>vidgear[core]&gt;=0.2.4</code>  instead.</p> <p>This change does not affects <code>pip install vidgear[asyncio]</code> command.</p> <p>Installation is as simple as:</p> Installing vidgear with only selective dependencies <p>Starting with version <code>v0.2.2</code>, you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). </p> <p>This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system:</p> <ul> <li> <p>Install bare-minimum vidgear as follows:</p> <code>v0.2.4</code> and newerOlder <pre><code># Install stable release with bare-minimum dependencies\npip install -U vidgear\n</code></pre> <pre><code># Install stable without any dependencies\npip install --no-deps vidgear&lt;0.2.4\n</code></pre> </li> <li> <p>Then, you must install Critical dependencies(if not already):</p> <code>v0.2.4</code> and newerOlder <pre><code># Install opencv(only if not installed previously)\npip install opencv-python \n</code></pre> <pre><code># Install critical dependencies\npip install cython, numpy, requests, tqdm, colorlog\n\n# Install opencv(only if not installed previously)\npip install opencv-python \n</code></pre> </li> <li> <p>Finally, manually install your API-specific dependencies as required by your API(in use):</p> <pre><code># Just copy-&amp;-paste from table below\npip install &lt;API-specific dependencies&gt;\n</code></pre> <code>v0.2.4</code> and newerOlder APIs Dependencies CamGear <code>yt_dlp</code> PiGear <code>picamera</code>, <code>picamera2</code> (see this for its installation) VideoGear Based on CamGear or PiGear backend in use ScreenGear <code>dxcam</code>, <code>mss</code>, <code>pyscreenshot</code>, <code>Pillow</code> WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear <code>pyzmq</code>, <code>simplejpeg</code> WebGear <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code>, <code>simplejpeg</code> WebGear_RTC <code>aiortc</code>, <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code> NetGear_Async <code>pyzmq</code>, <code>msgpack</code>, <code>msgpack_numpy</code>, <code>uvloop</code> Stabilizer Class - APIs Dependencies CamGear <code>pafy</code>, <code>yt_dlp</code>, <code>streamlink</code> PiGear <code>picamera</code> VideoGear Based on CamGear or PiGear backend in use ScreenGear <code>mss</code>, <code>pyscreenshot</code>, <code>Pillow</code> WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear <code>pyzmq</code>, <code>simplejpeg</code> WebGear <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code>, <code>simplejpeg</code> WebGear_RTC <code>aiortc</code>, <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code> NetGear_Async <code>pyzmq</code>, <code>msgpack</code>, <code>msgpack_numpy</code>, <code>uvloop</code> Stabilizer Class - </li> </ul>  Windows Installation <p>If you are using Windows, some of the commands given below, may not work out-of-the-box.</p> <p>A quick solution may be to preface every Python command with <code>python -m</code> like this:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install -U vidgear[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install -U vidgear[asyncio]\n</code></pre> <p>And, If you don't have the privileges to the directory you're installing package. Then use <code>--user</code> flag, that makes pip install packages in your home directory instead:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install --upgrade --user vidgear[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install --upgrade --user vidgear[asyncio]\n</code></pre> <p>Or, If you're using <code>py</code> as alias for installed python, then:</p> <pre><code># Install latest stable release with all Core dependencies\npy -m pip install --upgrade --user vidgear[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npy -m pip install --upgrade --user vidgear[asyncio]\n</code></pre> <pre><code># Install latest stable release with all Core dependencies\npip install -U vidgear[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install -U vidgear[asyncio]\n</code></pre> <p>And if you prefer to install VidGear directly from the repository:</p> <pre><code># Install latest stable release with all Core dependencies\npip install git+git://github.com/abhiTronix/vidgear@master#egg=vidgear[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install git+git://github.com/abhiTronix/vidgear@master#egg=vidgear[asyncio]\n</code></pre> <p>Or you can also download its wheel (<code>.whl</code>) package from our repository's releases section, and thereby can be installed as follows:</p> <pre><code># Install latest stable release with all Core dependencies\npip install vidgear-0.3.3-py3-none-any.whl[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install vidgear-0.3.3-py3-none-any.whl[asyncio]\n</code></pre> <p> </p> <ol> <li> <p> The <code>ensurepip</code> module is missing/disabled on Ubuntu. Use <code>pip</code> method only.\u00a0\u21a9</p> </li> </ol>"},{"location":"installation/source_install/","title":"Install from source","text":""},{"location":"installation/source_install/#install-from-source","title":"Install from source","text":"<p>Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions).</p>"},{"location":"installation/source_install/#prerequisites","title":"Prerequisites","text":"<p>When installing VidGear from source, following are some API specific prerequisites you may need to install manually:</p> <p>What about rest of the prerequisites?</p> <p>Any other python prerequisites (Critical/API specific) will be automatically installed based on your OS/System specifications.</p>  Upgrade your <code>pip</code> <p>It strongly advised to upgrade to latest <code>pip</code> before installing vidgear to avoid any undesired installation error(s).</p> <p>There are two mechanisms to upgrade <code>pip</code>:</p> <code>pip</code><code>ensurepip</code> <p>You can use existing <code>pip</code> to upgrade itself:</p> Install <code>pip</code> if not present <ul> <li>Download the script, from https://bootstrap.pypa.io/get-pip.py.</li> <li>Open a terminal/command prompt, <code>cd</code> to the folder containing the <code>get-pip.py</code> file and run:</li> </ul> Linux/MacOSWindows <pre><code>python get-pip.py\n</code></pre> <pre><code>py get-pip.py\n</code></pre> <p>More details about this script can be found in pypa/get-pip\u2019s README.</p> Linux/MacOSWindows <pre><code>python -m pip install pip --upgrade\n</code></pre> <pre><code>py -m pip install pip --upgrade\n</code></pre> <p>Python also comes with an <code>ensurepip</code> module<sup>1</sup>, which can easily upgrade/install <code>pip</code> in any Python environment.</p> Linux/MacOSWindows <pre><code>python -m ensurepip --upgrade\n</code></pre> <pre><code>py -m ensurepip --upgrade\n</code></pre>"},{"location":"installation/source_install/#api-specific-prerequisites","title":"API Specific Prerequisites","text":""},{"location":"installation/source_install/#ffmpeg","title":"FFmpeg","text":"<p>Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode. </p> <p>FFmpeg Installation</p> <ul> <li>For WriteGear API's Compression Mode: Follow this dedicated FFmpeg Installation doc for its installation.</li> <li>For StreamGear API: Follow this dedicated FFmpeg Installation doc for its installation.</li> </ul>"},{"location":"installation/source_install/#picamera2","title":"Picamera2","text":"<p>Required only if you're using Raspberry Pi  Camera Modules (or USB webcams) with the PiGear API. Here's how to install Picamera2 python library:</p> Using Legacy <code>picamera</code> library with PiGear (<code>v0.3.3</code> and above) <p>PiGear API (version <code>0.3.3</code> onwards) prioritizes the newer Picamera2 library under the hood for Raspberry Pi  camera modules. However, if your operating system doesn't support Picamera2, you can still use the  legacy <code>picamera</code> library. Here's how to easily install it using pip:</p> <pre><code>pip install picamera\n</code></pre> <p>You could also enforce the legacy picamera API backend in PiGear by using the <code>enforce_legacy_picamera</code> user-defined optional parameter boolean attribute.</p> Picamera2 is only supported on Raspberry Pi OS Bullseye (or later) images, both 32 and 64-bit. <p>Picamera2 is NOT supported on:</p> <ul> <li> Images based on Buster or earlier releases.</li> <li> Raspberry Pi OS Legacy images.</li> <li> Bullseye (or later) images where the legacy camera stack has been re-enabled.</li> </ul> Installation using <code>apt</code> (Recommended)Installation using <code>pip</code> As of September 2022, Picamera2 is pre-installed on images downloaded from Raspberry Pi. So you don't have to install it manually. <ul> <li> On Raspberry Pi OS images, Picamera2 is now installed with all the GUI (Qt and OpenGL) dependencies.</li> <li> <p> On Raspberry Pi OS Lite, it is installed without the GUI dependencies, although preview images can still be displayed using DRM/KMS. If these users wish to use the additional X-Windows GUI features, they will need to run:</p> <pre><code>sudo apt install -y python3-pyqt5 python3-opengl\n</code></pre> </li> </ul> <p>If Picamera2 is not already installed, then your image is presumably older and you should start with system upgrade: <pre><code>sudo apt update &amp;&amp; upgrade\n</code></pre></p> <p>If you have installed Picamera2 previously using pip, then you should also uninstall this (<code>pip3 uninstall picamera2</code>).</p> <p>Thereafter, you can install Picamera2 with all the GUI (Qt and OpenGL) dependencies using:</p> <pre><code>sudo apt install -y python3-picamera2\n</code></pre> <p>Or, If you DON'T want the GUI dependencies, use:</p> <pre><code>sudo apt install -y python3-picamera2 --no-install-recommends\n</code></pre> <p>This is NOT the recommended way to install Picamera2.</p> <p>However, if you wish to install Picamera2 with all the GUI (Qt and OpenGL) dependencies with pip, use:</p> <pre><code>sudo apt install -y python3-libcamera python3-kms++\nsudo apt install -y python3-pyqt5 python3-prctl \nsudo apt install -y libatlas-base-dev ffmpeg python3-pip\npip3 install numpy --upgrade\npip3 install picamera2[gui]\n</code></pre> <p>Or, If you DON'T want the GUI dependencies, use:</p> <pre><code>sudo apt install -y python3-libcamera python3-kms++\nsudo apt install -y python3-prctl libatlas-base-dev\nsudo apt install -y ffmpeg libopenjp2-7 python3-pip\npip3 install numpy --upgrade\npip3 install picamera2\n</code></pre>"},{"location":"installation/source_install/#installation","title":"Installation","text":"<p>If you want to checkout the latest beta <code>testing</code> branch , you can do so with the following commands:</p> <p>This can be useful if you want to provide feedback for a new feature or bug fix in the <code>testing</code> branch.</p> <p>DO NOT clone or install any other branch other than <code>testing</code> unless advised, as it is not tested with CI environments and possibly very unstable or unusable.</p> Installing vidgear with only selective dependencies <p>Starting with version <code>v0.2.2</code>, you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). </p> <p>This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system:</p> <ul> <li> <p>To clone and install bare-minimum vidgear without any dependencies do as follows:</p> <pre><code># clone the repository and get inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest testing branch\ngit checkout testing\n\n# Install stable release with bare-minimum dependencies\npip install .\n</code></pre> </li> <li> <p>Then, you must install Critical dependencies(if not already):</p> <pre><code># Install opencv(only if not installed previously)\npip install opencv-python \n</code></pre> </li> <li> <p>Finally, manually install your API-specific dependencies as required by your API(in use):</p> <pre><code># Just copy-&amp;-paste from table below\npip install &lt;API-specific dependencies&gt;\n</code></pre> APIs Dependencies CamGear <code>yt_dlp</code> PiGear <code>picamera</code>, <code>picamera2</code> (see this for its installation) VideoGear Based on CamGear or PiGear backend in use ScreenGear <code>dxcam</code>, <code>mss</code>, <code>pyscreenshot</code>, <code>Pillow</code> WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear <code>pyzmq</code>, <code>simplejpeg</code> WebGear <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code>, <code>simplejpeg</code> WebGear_RTC <code>aiortc</code>, <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code> NetGear_Async <code>pyzmq</code>, <code>msgpack</code>, <code>msgpack_numpy</code>, <code>uvloop</code> Stabilizer Class - </li> </ul>  Windows Installation <p>If you are using Windows, some of the commands given below, may not work out-of-the-box.</p> <p>A quick solution may be to preface every Python command with <code>python -m</code> like this:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install -U .[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install -U .[asyncio]\n</code></pre> <p>And, If you don't have the privileges to the directory you're installing package. Then use <code>--user</code> flag, that makes pip install packages in your home directory instead:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install --upgrade --user .[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install --upgrade --user .[asyncio]\n</code></pre> <p>Or, If you're using <code>py</code> as alias for installed python, then:</p> <pre><code># Install latest stable release with all Core dependencies\npy -m pip install --upgrade --user .[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npy -m pip install --upgrade --user .[asyncio]\n</code></pre> <pre><code># clone the repository and get inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest testing branch\ngit checkout testing\n\n# Install latest stable release with all Core dependencies\npip install -U .[core]\n\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install -U .[asyncio]\n</code></pre> <p> </p> <ol> <li> <p> The <code>ensurepip</code> module is missing/disabled on Ubuntu. Use <code>pip</code> method only.\u00a0\u21a9</p> </li> </ol>"}]}