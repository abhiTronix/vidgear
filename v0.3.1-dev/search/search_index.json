{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>VidGear is a cross-platform High-Performance Video-Processing Framework for building complex real-time media applications in python </p> <p>VidGear provides an easy-to-use, highly extensible, Multi-Threaded + Asyncio API Framework on top of many state-of-the-art specialized libraries like OpenCV, FFmpeg, ZeroMQ, picamera, starlette, yt_dlp, pyscreenshot, aiortc and python-mss at its backend, and enable us to flexibly exploit their internal parameters and methods, while silently delivering robust error-handling and real-time performance \u26a1\ufe0f.</p> <p>\"Write Less and Accomplish More\" \u2014 VidGear's Motto</p> <p>VidGear focuses on simplicity, and thereby lets programmers and software developers to easily integrate and perform Complex Video Processing Tasks without going through hefty documentation and in just a few lines of code.</p> <p> </p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>In case you're run into any problems, consult the Help section.</p> <ul> <li> <p> If this is your first time using VidGear, head straight to the Installation to install VidGear.</p> </li> <li> <p> Once you have VidGear installed, Checkout its Function-Specific Gears.</p> </li> <li> <p> Also, if you're already familar with OpenCV library, then see Switching from OpenCV Library.</p> </li> </ul> <p>If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6</p> <p> </p>"},{"location":"#gears","title":"Gears","text":"<p>VidGear is built with multiple Gears each with some unique functionality.</p> <p>Each Gear is designed exclusively to handle/control/process different data-specific &amp; device-specific video streams, network streams, and media encoders/decoders.</p> <p>These Gears can be classified as follows:</p>"},{"location":"#videocapture-gears","title":"VideoCapture Gears","text":"<ul> <li>CamGear: Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs.</li> <li>PiGear: Multi-Threaded API targeting various Raspberry-Pi Camera Modules.</li> <li>ScreenGear: Multi-Threaded API targeting ultra-fast Screencasting.    </li> <li>VideoGear: Common Video-Capture API with internal Video Stabilizer wrapper.</li> </ul>"},{"location":"#videowriter-gears","title":"VideoWriter Gears","text":"<ul> <li>WriteGear: Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.</li> </ul>"},{"location":"#streaming-gears","title":"Streaming Gears","text":"<ul> <li> <p>StreamGear: Handles Transcoding of High-Quality, Dynamic &amp; Adaptive Streaming Formats.</p> </li> <li> <p>Asynchronous I/O Streaming Gear:</p> <ul> <li>WebGear: ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network.</li> <li>WebGear_RTC: Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.</li> </ul> </li> </ul>"},{"location":"#network-gears","title":"Network Gears","text":"<ul> <li> <p>NetGear: Handles High-Performance Video-Frames &amp; Data Transfer between interconnecting systems over the network.</p> </li> <li> <p>Asynchronous I/O Network Gear:</p> <ul> <li>NetGear_Async: Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework. </li> </ul> </li> </ul> <p> </p>"},{"location":"#contributions","title":"Contributions","text":"<p>Contributions are welcome, and greatly appreciated!  </p> <p>Please see our Contribution Guidelines for more details.</p> <p> </p>"},{"location":"#community-channel","title":"Community Channel","text":"<p>If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6</p> <p> </p>"},{"location":"#become-a-stargazer","title":"Become a Stargazer","text":"<p>You can be a Stargazer  by starring us on Github, it helps us a lot and you're making it easier for others to find &amp; trust this library. Thanks!</p> <p> </p>"},{"location":"#donations","title":"Donations","text":"<p>VidGear is free and open source and will always remain so. </p> <p>It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference </p> kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); <p> </p>"},{"location":"#citation","title":"Citation","text":"<p>Here is a Bibtex entry you can use to cite this project in a publication:</p> <p></p> <pre><code>@software{vidgear,\nauthor       = {Abhishek Thakur and\n                  Zoe Papakipos and\n                  Christian Clauss and\n                  Christian Hollinger and\n                  Ian Max Andolina and\n                  Vincent Boivin and\n                  enarche-ahn and\n                  freol35241 and\n                  Benjamin Lowe and\n                  Micka\u00ebl Schoentgen and\n                  Renaud Bouckenooghe},\ntitle        = {abhiTronix/vidgear: VidGear v0.3.0},\nmonth        = jan,\nyear         = 2023,\npublisher    = {Zenodo},\nversion      = {vidgear-0.3.0},\ndoi          = {10.5281/zenodo.7571405},\nurl          = {https://doi.org/10.5281/zenodo.7571405}\n}\n</code></pre> <p> </p>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#v030-2023-01-26","title":"v0.3.0 (2023-01-26)","text":"New Features <ul> <li> WriteGear: <ul> <li>Added support for user-defined and higher than 8-bit depth input frames pixel-format.<ul> <li>Added support for higher than 8-bit depth frames with datatypes of unsigned integer(<code>uint</code>) kind and element size <code>2</code>.</li> <li>Added <code>dtype</code> parameter to internal <code>Preprocess</code> method for passing input frames datatype.</li> <li>Implemented auto-calculation of input pixel-format based on number of channels in higher than 8-bit depth frames.</li> <li>Added various known working pixel-formats(based on number of channels), supported by all prominent computer vision libraries.</li> <li>Added support for up to 1-channel(<code>gray16-le/be</code>) to all the way up to 4-channels(<code>bgra64-le/be</code>) in input frames.</li> <li>Added endianness little(<code>le</code>) or big(<code>be</code>) at the suffix of pixel-format based on byte-order of input frames datatypes.</li> <li>Extended support for higher RGB 8-bit depth frames through RGB mode.</li> </ul> </li> <li>Added support for user-defined custom input pixel-format.<ul> <li>Added new <code>-input_pixfmt</code> attribute to <code>output_params</code> dictionary parameter for easily specifying custom input pixel-format.</li> <li>Added newly implemented <code>get_supported_pixfmts</code> method import for verifying user-defined input pixel-format against Installed FFmpeg supported pixel-formats. Unsupported values will be discarded. </li> <li>Implemented runtime datatype validation check, such that all input frames must have same datatype.</li> </ul> </li> <li>Added support for Context Managers for proper handling of resources via <code>with</code> statement for allocating and releasing resources precisely. (Suggested by @sueskind)<ul> <li>Implement the <code>__enter__()</code> and <code>__exit__()</code> methods.</li> <li>Added <code>__enter__</code> method that returns reference to the WriteGear Class.</li> <li>Added <code>__exit__</code> method that automatically executes <code>close()</code> for performing the cleanup operations and handling exception gracefully. </li> </ul> </li> </ul> </li> <li> StreamGear: <ul> <li>Added support for Context Managers for proper handling of resources via <code>with</code> statement for allocating and releasing resources precisely. (Suggested by @sueskind)<ul> <li>Implement the <code>__enter__()</code> and <code>__exit__()</code> methods.</li> <li>Added <code>__enter__</code> method that returns reference to the StreamGear Class.</li> <li>Added <code>__exit__</code> method that automatically executes <code>close()</code> for performing the cleanup operations and handling exception gracefully. </li> </ul> </li> </ul> </li> <li> WebGear:<ul> <li>Added way to completely disable Data-Files Auto-Generation WorkFlow.<ul> <li>Added new <code>skip_generate_webdata</code> boolean optional attribute(<code>False</code> by default) to completely disable Data-Files Auto-Generation WorkFlow.</li> <li>This flag enables only <code>/video</code> route for disabled Data-Files Auto-Generation WorkFlow.</li> <li>Implemented JSONResponse as placeholder response instead of Index, <code>404</code> and <code>500</code> HTML pages, when workflow is disabled. (Note: Index HTML page will throw <code>404</code> status code.)</li> <li>Added necessary imports.</li> </ul> </li> </ul> </li> <li> Helper:<ul> <li>Added more robust implementation of validate_audio method.<ul> <li>Added new more robust regex pattern for extracting audio-samplerate.</li> <li>Added new <code>validate_audio</code> method for calculating accurate bitrate(in kbps) from audio samplerate, channels, bit-depth values.</li> <li>Implemented new patterns and logic for accurately extracting audio channels and bit-depth from given metadata.</li> </ul> </li> <li>Added support for Linux video device path (such as <code>/dev/video0</code>).</li> </ul> </li> <li> Maintenance: <ul> <li>Logging current vidgear version when vidgear APIs are called, not at import.<ul> <li>Added <code>logcurr_vidgear_ver</code> helper function to facilitate logging current vidgear version, when called within a API.</li> <li>Implemented <code>ver_is_logged</code> global variable in helper to log version only once, which can modifiable with <code>logcurr_vidgear_ver</code> method only. Followed recommendation given in official python docs: https://docs.python.org/3/faq/programming.html#how-do-i-share-global-variables-across-modules</li> <li>Current version can only be logged by VidGear APIs with the logging turned on (i.e. <code>logging=True</code>).</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added new WriteGear Bonus Example:<ul> <li>Added \"Using WriteGear's Compression Mode with <code>v4l2loopback</code> Virtual Cameras bonus python example.</li> <li>Added related prerequisites and dependencies for creating <code>v4l2loopback</code> Virtual Cameras on Linux machines.</li> <li>Added both With/Without-Audio cases for \"Using WriteGear's Compression Mode for YouTube-Live Streaming\".</li> </ul> </li> <li>Added <code>content.code.copy</code> and <code>content.tabs.link</code> features.</li> <li>Added docs related to <code>skip_generate_webdata</code> optional attribute.</li> <li>Added feedback features to mkdocs.yml.</li> <li>Added <code>404.html</code> static template to <code>mkdocs.yml</code>.</li> </ul> </li> <li> CI:<ul> <li>Added v4l2loopback support for testing <code>/dev/video0</code> device on Linux machines.</li> <li>Added test cases for newer implementation of <code>validate_audio</code> method.</li> <li>Added <code>test_skip_generate_webdata</code> to test <code>skip_generate_webdata</code> optional attribute.</li> <li>Added tests for user-defined and higher than 8-bit depth input frames pixel-format.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> WriteGear: <ul> <li>Completely revamped code structure and comments.<ul> <li>Updated comments, description, and logging messages to more sensible and developer friendly.</li> <li>Implemented operator short-circuiting to cleanup code as much as possible.</li> <li>Renamed <code>startFFmpeg_Process</code> internal class method to <code>start_FFProcess</code>.</li> <li>Renamed <code>Preprocess</code> internal class method to <code>PreprocessFFParams</code>.</li> <li>Renamed <code>startCV_Process</code> internal class method to <code>start_CVProcess</code>.</li> <li>Renamed <code>initiate</code> internal class parameter to <code>initiate_process</code>.</li> <li>Renamed <code>force_termination</code> internal class parameter to <code>forced_termination</code>.</li> <li>Enabled <code>output_params</code> parameters logging in both modes.</li> <li>Improved <code>compression</code> and <code>logging</code> parameters boolean value handling.</li> <li>Impelemented <code>stdout</code> closing to cleanup pipeline before terminating.</li> </ul> </li> </ul> </li> <li> Helper:<ul> <li>Updated <code>validate_audio</code> method with improved and more robust regex patterns for identifying audio bitrate in ay audio file.</li> </ul> </li> <li> Setup.py:<ul> <li>Bumped version to <code>0.3.0</code>.</li> <li>Replaced <code>&gt;=</code> comparsion operator with more flexible <code>~=</code>.</li> <li>Replaced <code>distutils.version.LooseVersion</code> with <code>pkg_resources.parse_version</code>.</li> </ul> </li> <li> Maintenance: <ul> <li>Replaced depreciated <code>LooseVersion</code> with <code>parse_version</code>.</li> <li>Updated <code>Retry</code> package to be imported from <code>requests.adapters</code>.</li> <li>Moved terminal and python code text area to Question GitHub Form Schema.</li> <li>Removed unnecessary imports.</li> <li>Removed redundant code.</li> <li>Improved logging messages.</li> <li>Updated code comments.</li> <li>Updated method descriptions.</li> <li>Refactored code.</li> <li>Increased coverage.</li> </ul> </li> <li> Bash Script:<ul> <li>Updated FFmpeg Static Binaries links to latest date/version tag to <code>12-07-2022</code>.</li> <li>Removed depreciated binaries download links and code.</li> </ul> </li> <li> Docs:<ul> <li>Replaced all <code>raw.githubusercontent.com</code> GIF URLs with <code>user-images.githubusercontent.com</code>.</li> <li>Reformatted <code>custom.css</code> and added missing comments.</li> <li>Updated sponsor block.</li> <li>Enabled Code Highlights.</li> <li>Updated announcement bar.</li> <li>Updated <code>changelog.md</code>.</li> <li>Reduced <code>webgear_rtc.gif</code> size.</li> <li>Updated Zenodo badge and the BibTeX entry.</li> </ul> </li> <li> CI:<ul> <li>Added more flexible formats to <code>return_testvideo_path</code> function.</li> <li>Updated <code>test_write</code> test for higher than 8-bit depth input frames pixel-format in WriteGear's Compression Mode.</li> <li>Updated <code>actions/checkout</code> to <code>v3</code>.</li> <li>Updated <code>actions/setup-python</code> to <code>v4</code>.</li> <li>Updated <code>codecov/codecov-action</code> to <code>v3</code>.</li> <li>Moved <code>test_colorspaces</code> test to CamGear tests.</li> <li>Added deffcode library import.</li> </ul> </li> <li>Re-stuctured yaml code.</li> </ul> Breaking Updates/Changes <ul> <li> WriteGear: <ul> <li>Renamed <code>output_filename</code> string parameter to <code>output</code>.<ul> <li>Since WriteGear API accepts all sorts of streams (such as valid filename/path/URL) for encoding, thereby changing parameter name to <code>output</code> will be more true to its purpose.</li> <li>Renaming <code>output_filename</code> to <code>output</code> in WriteGear API will also help user to not accidentally assume WriteGear supports only encoding of video files.</li> <li>It matches the <code>output</code> parameter in StreamGear which basically does the same thing.</li> </ul> </li> <li>Renamed <code>cmd</code> parameter in <code>execute_ffmpeg_cmd()</code> class method to more sensible <code>command</code>.</li> <li><code>ValueError</code> will be raised if datatype of input frames mismatches Writegear API</li> </ul> </li> </ul> Bug-fixes <ul> <li> Camgear: <ul> <li>Fixed <code>CamGear.read()</code> blocked unnecessarily.<ul> <li>\ud83d\udcac When <code>THREADED_QUEUE_MODE</code> is enabled <code>CamGear.read()</code> blocks for an excessive duration when attempting to read past the end of a stream.</li> <li>Added <code>None</code> frame to the queue at the end to signal we're done.</li> <li>Added <code>terminate</code> Event check before continuing.</li> </ul> </li> <li>Fixed deadlock on exit.<ul> <li>\ud83d\udcac The deadlock is due to <code>self.__queue.get(timeout=self.__thread_timeout)</code> line in <code>read()</code> method, which still waits for timeout(thread_timeout) to happen when main <code>update()</code> thread was already terminated on exit and queue was empty. Since there was no way to signal queue that stream is already ended, the blocking <code>queue.get()</code> keeps on waiting until timeout occurs.</li> <li>The solution was to signal <code>queue.get()</code> that stream is already ended by putting <code>None</code> in queue on exiting the main <code>update()</code> thread.</li> </ul> </li> </ul> </li> <li> ScreenGear: <ul> <li>Fixed <code>ScreenGear.read()</code> blocked during cold startup.</li> <li>\ud83d\udcac During startup, <code>ScreenGear.read()</code> doesn't checks if queue is empty before continuing.</li> </ul> </li> <li> WriteGear: <ul> <li>Fixed gstpipeline_mode not activating when wrongly assuming <code>output</code> value as valid path.</li> <li>Fixed name 'compression' is not defined bug.</li> <li>Fixed <code>AttributeError</code>.</li> </ul> </li> <li> Helper:<ul> <li>Fixed <code>fltp</code> keyword in regex pattern causing non-ftlp streams to be not recognized.</li> <li>Fixed response.headers returning <code>content-length</code> as Nonetype since it may not necessarily have the Content-Legth header set.<ul> <li>Reason: The response from gitlab.com  contains a Transfer-Encoding field as <code>'Transfer-Encoding': 'chunked'</code>, which means data is sent in a series of chunks, so the Content-Length header is emitted. More info: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding#Directives</li> </ul> </li> <li>Fixed Linux video device paths still not working. <ul> <li>Moved <code>helper.py</code> logic to WriteGear and StreamGear APIs resp.</li> </ul> </li> <li>Fixed KeyError for empty metadata.</li> </ul> </li> <li> Setup:<ul> <li>Pinned <code>pyzmq==24.0.1</code> working version.</li> <li>Removed redundant patch for the issue.</li> </ul> </li> <li> Maintaince:<ul> <li>Fixed missing pkg name <code>import_dependency_safe</code> functions calls.</li> </ul> </li> <li> Bash Script: <ul> <li>Fixed gstreamer installation.</li> </ul> </li> <li> CI:<ul> <li>Fixed missing v4l2loopback apt dependency on Linux envs.</li> <li>Added fix for RTCPeerConnection fails to create RTCDtlsTransport (Related issue: aiortc/aiortc#804)<ul> <li>Pinned <code>cryptography==38.0.4</code> in dependencies.</li> </ul> </li> <li>Pinned Linux image to <code>ubuntu-20.04</code> in github actions.</li> <li>Fixed No module named 'httpx' bug.<ul> <li>Added <code>httpx</code> library import.</li> </ul> </li> <li>Fixed F821 undefined name bug.</li> <li>Fixed Gstreamer bug.</li> </ul> </li> <li> Docs:<ul> <li>Fixed hyperlinks to new GitHub's form schemas. </li> <li>Fixed non-rendering images in README.md <ul> <li>Replaced all relative image/gifs paths with absolute URLs in README.md.</li> </ul> </li> <li>Fixed badges/shields#8671 badge issue in README.md</li> <li>Fixed GitLab CDN links throwing blocked by CORS policy bug.<ul> <li>Replaced gitlab GitHack CDN links with with bitbucket.</li> </ul> </li> <li>Fixed DASH playback failing by setting the <code>maxAttempts</code> to Infinity.</li> <li>Removed <code>x-sign</code> glow-text effect CSS.</li> <li>Fixed several typos (suggested by @timgates42)</li> <li>Fixed coverage badge.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #346</li> <li>PR #348</li> <li>PR #349</li> <li>PR #350</li> <li>PR #351</li> </ul>"},{"location":"changelog/#v026-2022-07-05","title":"v0.2.6 (2022-07-05)","text":"New Features <ul> <li> Docs:<ul> <li>Added new bonus example for RTSP/RTP Live-Streaming using WriteGear's Compression Mode.</li> <li>Added \"How to resolve zmq.error.ZMQError\" FAQ for NetGear API.(PR by @iandol)</li> <li>Added new ko-fi button to README.md</li> <li>Added new contributors block to changelog.md</li> </ul> </li> <li> Maintenance: <ul> <li>Added new patterns to <code>.gitignore</code> to ignore pypi's <code>build</code> directory and <code>egg-info</code> files.</li> </ul> </li> <li> CI:<ul> <li>Switched to new Issue GitHub's form schema using YAML<ul> <li>Added new <code>bug_report.yaml</code>.</li> <li>Added new <code>question.yaml</code>.</li> <li>Added new <code>proposal.yaml</code>.</li> <li>Deleted depreciated markdown files.</li> <li>Polished forms.</li> </ul> </li> </ul> </li> </ul> Updates/Improvements <ul> <li> Setup.py:<ul> <li>Bumped version to <code>0.2.6</code>.</li> <li>Updated logic operators and dependency.<ul> <li>Replaced <code>&gt;=</code> comparsion operator with more flexible <code>~=</code>.</li> <li>Replaced <code>distutils.version.LooseVersion</code> with <code>pkg_resources.parse_version</code>.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Updated Site Navigation.<ul> <li>Added new notices to inform users more effectively about bonus examples.</li> <li>Added new <code>Bonus</code> section to navigation and moved suitable pages under it.</li> <li>Updated headings and URLs.</li> </ul> </li> <li>Redesigned and Rewritten Donation and Contribution section to README.md</li> <li>Updated Zenodo badge and bibtex entry.</li> <li>Updated Admonition Icon, FAQs and site-links.</li> <li>Reformatted code and its comments.</li> <li>Updated <code>changelog.md</code>.</li> </ul> </li> <li> API:<ul> <li>Updated depreciated tostring() to tobytes(). <code>tostring</code> was renamed to <code>tobytes</code> for the purposes for clarity in Python 3.2. https://docs.python.org/3/library/array.html#array.array.tobytes</li> </ul> </li> <li> CI:<ul> <li>Added more paths and files to skip commits.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> <code>-input_framerate</code> parameter now accepts any positive value for WriteGear and StreamGear APIs.</li> </ul> Bug-fixes <ul> <li> API:<ul> <li>Fixed <code>-input_framerate</code> less than 5 does not get used in WriteGear and StreamGear APIs.(PR by @freol35241)</li> </ul> </li> <li> CamGear: Fixed Yt-dlp generated HTTP DASH Segments URLs not supported by OpenCV's VideoCapture(PR by @DynamiteC)</li> <li> StreamGear: <ul> <li>Fixed <code>hls_segment_type</code> not working bug. (PR by @enarche-ahn)</li> <li>Fixed critical logging parameter bug<ul> <li>Fixed debug logs even when <code>logging=False</code> in StreamGear's Real-time Mode. (patch suggested by @enarche-ahn)</li> <li>Added length check to <code>-video_source</code> attribute to correctly infers it as empty(or invalid).</li> </ul> </li> </ul> </li> <li> CI:<ul> <li>Xfailed RTSP CamGear CI test.</li> <li>Fixed pinned version syntax bug in docs_deployer workflow.</li> <li>Fixed typos in Github forms and its context.</li> <li>Added missing dependency.</li> </ul> </li> <li> Docs:<ul> <li>Fixed jinja2 <code>3.1.0</code> or above breaks mkdocs.<ul> <li><code>jinja2&gt;=3.1.0</code> breaks mkdocs (mkdocs/mkdocs#2799), therefore pinned jinja2 version to <code>&lt;3.1.0</code>.</li> </ul> </li> <li>Fixed support for new <code>mkdocstring</code> versions<ul> <li>Replaced rendering sub-value with options.</li> <li>Removed pinned <code>mkdocstrings==0.17.0</code> version.</li> </ul> </li> <li>Fixed Netgear+Webgear bonus example code bugs.(PR by @iandol)<ul> <li>Added a missing import.</li> <li>Removed <code>self.</code> typo.</li> <li>Replaced the <code>return</code> value with <code>break</code> in the async as it triggers an error. </li> </ul> </li> <li>Fixed external bug that causing \"Home\" tab to irresponsive randomly when accessed from other tabs.</li> <li>Fixed indentation and spacing.</li> <li>Fixed typos and updated context.</li> <li>Removed dead code.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #288</li> <li>PR #290</li> <li>PR #293</li> <li>PR #295</li> <li>PR #307</li> <li>PR #313</li> <li>PR #320</li> </ul> New Contributors <ul> <li>@iandol</li> <li>@freol35241</li> <li>@enarche-ahn</li> <li>@DynamiteC</li> </ul>"},{"location":"changelog/#v025-2021-02-11","title":"v0.2.5 (2021-02-11)","text":"New Features <ul> <li> WriteGear: <ul> <li>Add support for GStreamer pipeline in WriteGear API's Non-Compression mode:<ul> <li>Implemented GStreamer Pipeline Mode to accept GStreamer pipeline as string to its output_filename parameter.</li> <li>Added new special <code>-gst_pipeline_mode</code> attribute for its output_params parameter.</li> <li>This feature provides flexible way to directly write video frames into GStreamer Pipeline with controlled bitrate. </li> <li>Added new docs and updated existing docs with related changes.</li> </ul> </li> <li>Added new <code>-ffpreheaders</code> special attribute to WriteGear's options parameter:<ul> <li>This attribute is specifically required to set special FFmpeg parameters in Compression Mode that are present at the starting of command(such as <code>-re</code>).</li> <li>This attribute only accepts list datatype as value.</li> <li>Added related docs.</li> </ul> </li> </ul> </li> <li> NetGear: <ul> <li>Added bidirectional data transfer support by extending Bidirectional mode support to exclusive Multi-Clients and Multi-Servers modes:<ul> <li>Users will now able to send data bidirectionally in both Multi-Clients and Multi-Servers exclusive modes.</li> <li>Bidirectional mode will no longer disables automatically when Multi-Clients and Multi-Servers modes already enabled.</li> <li>Added new docs and updated existing docs with related changes.</li> </ul> </li> </ul> </li> <li> Maintenance: <ul> <li>Added official support for Python-3.10 legacies.</li> <li>Added <code>float</code> value support to <code>THREAD_TIMEOUT</code> optional parameter.</li> <li>Added info about dropped support for Python-3.6 legacies through announcement bar.</li> <li>Added <code>config.md</code> file for Issue templates.</li> <li>Added title to Issue templates.</li> </ul> </li> <li> Docs:<ul> <li>Added new Code Annotations</li> <li>Added new icons to headings.</li> <li>Added Advanced VideoGear usage example with CamGear backend.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Setup.py:<ul> <li>Dropped support for Python-3.6 and below legacies.</li> <li>Updated logging formatting.</li> <li>Updated python_requires to <code>&gt;=3.7</code>.</li> <li>Bumped version to <code>0.2.5</code>.</li> </ul> </li> <li> Helper:<ul> <li>Vidgear will now report current version on every run.</li> </ul> </li> <li> Docs: <ul> <li>Updated SSH tunneling docs context.</li> <li>Excluded <code>docs</code> directory from CI envs.</li> <li>Updated Zenodo badge and BibTeX entry.</li> <li>Updated dark theme hue to <code>260</code>.</li> <li>Updated Admonitions.</li> <li>Additional warnings against pushing PR against VidGear's <code>testing</code> branch only.</li> <li>Updated code comments.</li> </ul> </li> <li> CI:<ul> <li>Removed support for Python-3.6 legacies from all workflows.</li> <li>Updated NetGear's Exclusive Mode tests.</li> <li>Added GStreamer Pipeline Mode tests.</li> </ul> </li> <li> Maintenance: <ul> <li>Updated Issue and PR templates.</li> <li>Updated metadata.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Dropped support for Python-3.6 legacies from vidgear.</li> </ul> Bug-fixes <ul> <li> NetGear: Fixed bidirectional mode overriding multi-clients mode's data.</li> <li> WriteGear: <ul> <li>Fixed wrongly defined ffmpeg_preheaders.</li> <li>Fixed condition logic bugs.</li> <li>Fixed UnboundLocalError bug.</li> </ul> </li> <li> Setup: Fixed uvicorn and aiortc dropped support for Python-3.6 legacies.</li> <li> CI: <ul> <li>Fixed GitHub Actions interprets <code>3.10</code> as <code>3.1</code> if used without strings.</li> <li>Fixed naming error in azure YAML.</li> </ul> </li> <li> Docs:<ul> <li>Fixed codecov badge URL in README.md</li> <li>Fixed hyperlinks in README.</li> <li>Fixed indentation and spacing.</li> <li>Fixed typos and updated context.</li> <li>Removed dead code.</li> </ul> </li> <li> Maintenance: <ul> <li>Removed depreciated condition checks.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #283</li> <li>PR #284</li> </ul>"},{"location":"changelog/#v024-2021-12-05","title":"v0.2.4 (2021-12-05)","text":"New Features <ul> <li> CamGear: <ul> <li>Added a new YT_backend Internal Class with YT-DLP backend:<ul> <li>Implemented <code>YT_backend</code> a new CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs.</li> <li>Added support for pipeling (live) video-frames from all yt-dlp supported streaming sites: https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites</li> <li>Implemented algorithm from scratch for auto-extracting resolution specific streamable URLs for pipelineing.</li> <li>Implemented logic for auto-calculating <code>best</code> and <code>worst</code> resolutions.</li> <li>Added new <code>ytv_metadata</code> global parameter to CamGear for accessing video's metadata(such as duration, title, description) on-the-go.</li> <li>\u26a0\ufe0f Playlists are still unsupported.</li> </ul> </li> </ul> </li> <li> WebGear_RTC: <ul> <li>Implemented a new easy way of defining Custom Streaming Class with suitable source(such as OpenCV):<ul> <li>Added new <code>custom_stream</code> attribute with WebGear_RTC <code>options</code> parameter that allows you to easily define your own Custom Streaming Class with suitable source(such as OpenCV).</li> <li>This implementation supports repeated Auto-Reconnection or Auto-Refresh out-of-the-box.</li> <li>This implementation is more user-friendly and easy to integrate within complex APIs.</li> <li>This implementation requires at-least <code>read()</code> and <code>stop()</code> methods implemented within Custom Streaming Class, otherwise WebGear_RTC will throw ValueError.</li> <li>This implementation supports all vidgear's VideoCapture APIs readily as input.</li> </ul> </li> </ul> </li> <li> Maintenance:<ul> <li>Added new <code>.gitignore</code>  for specifying intentionally untracked files to ignore<ul> <li>Added more files entries to <code>.gitignore</code>.</li> </ul> </li> <li>Added new <code>.gitattributes</code> to manage how Git reads line endings.<ul> <li>Enabled <code>auto</code> default behavior, in case people don't have <code>core.autocrlf</code> set.</li> <li>Enforced LF line-endings for selective files types.</li> <li>Added Binary data files that specifies they are not text, and git should not try to change them.</li> <li>Added Language aware diff headers.</li> <li>Added Linguist language overrides.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added bonus example to add real-time file audio encoding with VideoGear and Stabilizer class.</li> <li>Added complete usage docs with new CamGear's Internal Class with YT-DLP backend.</li> <li>Added instructions to extract video's metadata in CamGear.</li> <li>Added donation link in page footer with bouncing heart animation through pure CSS.</li> <li>Added info about critical changes in <code>v0.2.4</code> and above installation through new announcement bar.</li> <li>Added related usage docs for new WebGear_RTC custom streaming class.</li> <li>Added changes for upgrading mkdocs-material from <code>v7.x</code> to newer <code>v8.x</code>.</li> <li>Added outdated version warning block.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> CamGear:<ul> <li>Added <code>is_livestream</code> global YT_backend parameters.</li> <li>Added default options for yt-dlp for extracting info_dict(metadata) of the video as a single JSON line.</li> <li>Completely removed old logic for extracting streams using pafy.</li> <li>Removed all dead code related to streamlink backend.</li> </ul> </li> <li> Setup.py:<ul> <li>Moved all API specific dependencies to <code>extra_requires</code> under the name <code>\"core\"</code>. [PR #268 by @zpapakipos]</li> <li>Added rule to replace GitHub heading links in description.</li> <li>Updated <code>extra_require</code> dependencies.</li> <li>Removed <code>streamlink</code> dependency.</li> <li>Removed <code>pafy</code> dependency.</li> <li>Removed <code>pyzmq</code> from latest_version group.</li> <li>Updated SEO Keywords.</li> </ul> </li> <li> Docs: <ul> <li>Re-written <code>pip</code> and <code>source</code> installation docs. </li> <li>Added warning for using <code>-disable_force_termination</code> flag for short duration videos.</li> <li>Added <code>permalink_title</code> entry to mkdocs.yml.</li> <li>Updated CamGear parameters.</li> <li>Updated Admonitions with related information.</li> <li>Updated Functional Block Diagram(<code>gears_fbd.png</code>) image.</li> <li>Updated installation instructions.</li> <li>Updated Advanced examples using WebGear_RTC's custom streaming class.</li> <li>Updated code highlighting.</li> <li>Updated zenodo badge.</li> <li>Updated BibTex for project citation.</li> <li>Replaced incorrect API parameter docs.</li> <li>Updated WebGear_RTC parameters.</li> </ul> </li> <li> CI:<ul> <li>Updated CI tests for new WebGear_RTC custom streaming class.</li> <li>Restored <code>test_stream_mode</code> CamGear test.</li> <li>Updated Streaming Sites test links.</li> <li>Added more tests cases.</li> </ul> </li> <li> Maintenance: <ul> <li>Updated spacing in logger formatting.</li> <li>Renamed Asyncio Helper logger name.</li> <li>Changed logging colors.</li> <li>Updated logging messages.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Installation command with <code>pip</code> has been changed in <code>v0.2.4</code>:<ul> <li>The legacy <code>pip install vidgear</code> command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use <code>pip install vidgear[core]</code> command instead.</li> </ul> </li> <li> CamGear:<ul> <li>Removed <code>streamlink</code> backend support from <code>stream_mode</code> in favor of more reliable CamGear's Internal YT-DLP backend class for extracting metadata from Streaming URLs.<ul> <li>CamGear will raise <code>ValueError</code> if streaming site URL is unsupported by yt-dlp backend.</li> <li>CamGear will raise <code>ValueError</code> if <code>yt-dlp</code> isn't installed and <code>stream_mode</code> is enabled.</li> </ul> </li> <li>Removed automatic enforcing of GStreamer backend for YouTube-livestreams and made it optional.<ul> <li>The CamGear will not raise ValueError if GStreamer support is missing in OpenCV backends.</li> </ul> </li> </ul> </li> <li> WebGear_RTC:<ul> <li>Removed support for assigning Custom Media Server Class(inherited from aiortc's VideoStreamTrack) in WebGear_RTC through its <code>config</code> global parameter.</li> <li>WebGear_RTC API will now throws ValueError if <code>source</code> parameter is NoneType as well as <code>custom_stream</code> attribute is undefined.</li> </ul> </li> <li> Helper: <ul> <li>Removed <code>restore_levelnames</code> method.</li> <li>Removed <code>youtube_url_validator</code> helper method.</li> </ul> </li> </ul> Bug-fixes <ul> <li> CamGear:<ul> <li>Fixed KeyError Bug for missing attributed in meta_data json in some streaming sites.</li> </ul> </li> <li> Helper: <ul> <li>Removed unused imports.</li> </ul> </li> <li> Docs:<ul> <li>Removed slugify from mkdocs which was causing invalid hyperlinks in docs.</li> <li>Fixed GitHub hyperlinks in README.md.</li> <li>Fixed hyperlink in announcement bar.</li> <li>Fixed content tabs failing to work.</li> <li>Fixed line-endings and usage example code.</li> <li>Removed any <code>pafy</code> and <code>streamlink</code> references.</li> <li>Fixed context and typos.</li> </ul> </li> <li> CI: <ul> <li>Fixed NameError bugs in WebGear_RTC CI test.</li> </ul> </li> <li> Maintenance: <ul> <li>Removed dead logger code causing Python's Built-in logging module to hide logs.</li> <li>Removed unused <code>logging</code> import.</li> <li>Updated code comments.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #268</li> <li>PR #272</li> <li>PR #274</li> </ul> New Contributors <ul> <li>@zpapakipos</li> </ul>"},{"location":"changelog/#v023-2021-10-27","title":"v0.2.3 (2021-10-27)","text":"New Features <ul> <li> CamGear: <ul> <li>Added support for <code>4K</code> Streaming URLs.</li> </ul> </li> <li> Helper: <ul> <li>Implemented logging ColorFormatter string alignment.<ul> <li>Center aligned logging Level-name and Class-name.</li> <li>Changed <code>%</code> formatting style with modern <code>{</code>.</li> <li>Re-added <code>asctime</code> value to Formatter string.</li> <li>Re-arranged parameter positions in Formatter string.</li> </ul> </li> </ul> </li> <li> Maintenance:<ul> <li>Added new <code>.gitignore</code>  for specifying intentionally untracked files to ignore<ul> <li>Added more files entries to <code>.gitignore</code>.</li> </ul> </li> <li>Added new <code>.gitattributes</code> to manage how Git reads line endings.<ul> <li>Enabled <code>auto</code> default behavior, in case people don't have <code>core.autocrlf</code> set.</li> <li>Enforced LF line-endings for selective files types.</li> <li>Added Binary data files that specifies they are not text, and git should not try to change them.</li> <li>Added Language aware diff headers.</li> <li>Added Linguist language overrides.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added new ScreenGear with WebGear_RTC API bonus example.</li> <li>Added support for <code>hl_lines</code> argument for highlighting specific code lines.</li> <li>Added drop-shadow effects for its <code>slate</code> theme to improve visibility.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> CamGear:<ul> <li>Replaced <code>youtube-dl</code> with <code>yt-dlp</code> as pafy backend for YouTube videos pipelining.<ul> <li>Implemented hack to trick pafy into assuming <code>yt-dlp</code> as <code>youtube-dl</code>.</li> <li>Using <code>sys.modules</code> to present <code>yt-dlp</code> as <code>youtube-dl</code>.</li> <li><code>yt-dlp</code> python API functions exactly similar to <code>youtube-dl</code>.</li> <li>Replaced <code>youtube-dl</code> dependency with <code>yt-dlp</code>.</li> <li>Replaced <code>youtube-dl</code> imports with <code>yt-dlp</code>.</li> </ul> </li> </ul> </li> <li> StreamGear: <ul> <li>Updated default <code>stream_count</code> internal dict key value to 1.</li> </ul> </li> <li> Maintenance:<ul> <li>Introduced python short-circuiting for handling logging logic.</li> <li>Enabled logging for <code>check_WriteAccess</code> method in WriteGear, StreamGear and NetGear APIs.</li> </ul> </li> <li> Docs:<ul> <li>Added warning for ScreenGear outputting RGBA frames instead of default BGR frames with <code>mss</code> backend.</li> <li>Added warnings for properly formatting <code>output_params</code> when assigning external audio-source in WriteGear.</li> <li>Added depreciation notice for Python 3.6 legacies.</li> <li>Restructured docs to make it more user-friendly.</li> <li>Updated, Extended and Improved context.</li> <li>Improved code comments.</li> <li>Updated docs admonitions.</li> <li>Updated <code>Zenodo</code> badge.</li> </ul> </li> <li> CI: <ul> <li>Migrated to new Codecov Uploader in Azure Pipelines.<ul> <li>Support for the Bash Uploader will be deprecated on February 1st, 2022. See: https://docs.codecov.com/docs/about-the-codecov-bash-uploader</li> <li>Added commands for signature and SHASUM verification to ensure integrity of the Uploader before use.</li> <li>Replaced related bash commands.</li> </ul> </li> <li>Replaced <code>env</code> with <code>export</code> in ci_linux.yml.</li> <li>Replaced <code>bubkoo/needs-more-info@v1</code> with <code>wow-actions/needs-more-info@v1</code>.</li> <li>Added codecov secret token through <code>env</code> variable. </li> <li>Added wildcard to skip CI tests for doc(<code>.md</code>) files.</li> <li>Added <code>.md</code> files to Codecov ignore list.</li> <li>Update vidgear's banner image.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> <code>check_WriteAccess</code> will now return as invalid path if writing directory does not exists. This will effect output file handling in WriteGear and StreamGear APIs.</li> </ul> Bug-fixes <ul> <li> StreamGear:<ul> <li>Fixed StreamGear Malformed URI Error with HLS Segments [PR #243 by @Vboivin]<ul> <li>Removed the extra <code>'%'</code> character from the naming convention for segment files.</li> <li>Used <code>stream_count</code> internal dict variable to alter template for HLS segment filenames.</li> </ul> </li> </ul> </li> <li> WriteGear: <ul> <li>Fixed bug in disable_force_termination logic which accidentally disables force termination.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Fixed <code>name 'VideoStreamTrack' is not defined</code> bug.</li> </ul> </li> <li> Setup.py: <ul> <li>Fixed <code>TypeError</code> bug.</li> <li>Fixed invalid <code>latest_version</code> retrieval.</li> </ul> </li> <li> Helper:<ul> <li>Fixed <code>check_WriteAccess</code> failing to recognize correct permission for writing the output file on windows platform. <ul> <li>Implemented separate logic for <code>Windows</code> and <code>*nix</code> platforms.</li> <li>Added new <code>stat</code> import.</li> <li>Improved warnings and error handling.</li> <li>Added logging parameter to <code>check_WriteAccess</code>.</li> </ul> </li> <li>Fixed bug in check_WriteAccess that throws <code>OSError</code> while handling URLs.</li> </ul> </li> <li> Docs:<ul> <li>Fixed bugs in WriteGear's Compression Mode with Live Audio Input example.</li> <li>Fixed \"drop-shadow\" property via <code>filter</code> function conflicting with sidecard button.<ul> <li>Added new CSS classes for image, admonitions and code highlight in dark theme.</li> </ul> </li> <li>Several internal and external webpage links typos fixed.</li> <li>Fixed several language typos.</li> </ul> </li> <li> CI: <ul> <li>Fixed Azure Pipeline coverage upload bugs.</li> <li>Fixed random errors in CamGear <code>stream_mode</code> test.</li> </ul> </li> <li> Bash:<ul> <li>Removed the Windows carriage returns from the shell scripts to be able to execute them on Linux. </li> </ul> </li> <li> Fixed logging comments.</li> </ul> Pull Requests <ul> <li>PR #249</li> <li>PR #262</li> </ul> New Contributors <ul> <li>@Vboivin</li> </ul>"},{"location":"changelog/#v022-2021-09-02","title":"v0.2.2 (2021-09-02)","text":"New Features <ul> <li> StreamGear: <ul> <li>Native Support for Apple HLS Multi-Bitrate Streaming format:<ul> <li>Added support for new Apple HLS (HTTP Live Streaming) HTTP streaming format in StreamGear.</li> <li>Implemented default workflow for auto-generating primary HLS stream of same resolution and framerate as source.</li> <li>Added HLS support in Single-Source and Real-time Frames Modes.</li> <li>Implemented inherit support for <code>fmp4</code> and <code>mpegts</code> HLS segment types.</li> <li>Added adequate default parameters required for trans-coding HLS streams.</li> <li>Added native support for HLS live-streaming.</li> <li>Added <code>\"hls\"</code> value to <code>format</code> parameter for easily selecting HLS format.</li> <li>Added HLS support in <code>-streams</code> attribute for transcoding additional streams.</li> <li>Added support for <code>.m3u8</code> and <code>.ts</code> extensions in <code>clear_prev_assets</code> workflow.</li> <li>Added validity check for <code>.m3u8</code> extension in output when HLS format is used.</li> <li>Separated DASH and HLS command handlers.</li> <li>Created HLS format exclusive parameters.</li> <li>Implemented <code>-hls_base_url</code> FFMpeg parameter support.</li> </ul> </li> <li>Added support for audio input from external device:<ul> <li>Implemented support for audio input from external device.</li> <li>Users can now easily add audio device and decoder by formatting them as python list.</li> <li>Modified <code>-audio</code> parameter to support <code>list</code> data type as value.</li> <li>Modified <code>validate_audio</code> helper function to validate external audio devices.</li> </ul> </li> <li>Added <code>-seg_duration</code> to control segment duration.</li> </ul> </li> <li> NetGear:<ul> <li>New SSH Tunneling Mode for remote connection:<ul> <li>New SSH Tunneling Mode for connecting ZMQ sockets across machines via SSH tunneling.</li> <li>Added new <code>ssh_tunnel_mode</code> attribute to enable ssh tunneling at provide address at server end only.</li> <li>Implemented new <code>check_open_port</code> helper method to validate availability of host at given open port.</li> <li>Added new attributes <code>ssh_tunnel_keyfile</code> and <code>ssh_tunnel_pwd</code> to easily validate ssh connection.</li> <li>Extended this feature to be compatible with bi-directional mode and auto-reconnection.</li> <li>Disabled support for exclusive Multi-Server and Multi-Clients modes.</li> <li>Implemented logic to automatically enable <code>paramiko</code> support if installed.</li> <li>Reserved port-<code>47</code> for testing.</li> </ul> </li> <li>Additional colorspace support for input frames with Frame-Compression enabled:<ul> <li>Allowed to manually select colorspace on-the-fly with JPEG frame compression.</li> <li>Updated <code>jpeg_compression</code> dict parameter to support colorspace string values.</li> <li>Added all supported colorspace values by underline <code>simplejpeg</code> library.</li> <li>Server enforced frame-compression colorspace on client(s).</li> <li>Enable \"BGR\" colorspace by default.</li> <li>Added Example for changing incoming frames colorspace with NetGear's Frame Compression.</li> <li>Updated Frame Compression parameters in NetGear docs.</li> <li>Updated existing CI tests to cover new frame compression functionality.</li> </ul> </li> </ul> </li> <li> NetGear_Async:<ul> <li>New exclusive Bidirectional Mode for bidirectional data transfer:<ul> <li>NetGear_Async's first-ever exclusive Bidirectional mode with pure asyncio implementation.</li> <li>Bidirectional mode is only available with User-defined Custom Source(i.e. <code>source=None</code>)</li> <li>Added support for <code>PAIR</code> &amp; <code>REQ/REP</code> bidirectional patterns for this mode.</li> <li>Added powerful <code>asyncio.Queues</code> for handling user data and frames in real-time.</li> <li>Implemented new <code>transceive_data</code> method  to Transmit (in Recieve mode) and Receive (in Send mode) data in real-time.</li> <li>Implemented <code>terminate_connection</code> internal asyncio method to safely terminate ZMQ connection and queues.</li> <li>Added <code>msgpack</code> automatic compression encoding and decoding of data and frames in bidirectional mode.</li> <li>Added support for <code>np.ndarray</code> video frames.</li> <li>Added new <code>bidirectional_mode</code> attribute for enabling this mode.</li> <li>Added 8-digit random alphanumeric id generator for each device.</li> <li>NetGear_Async will throw <code>RuntimeError</code> if bidirectional mode is disabled at server or client but not both.</li> </ul> </li> <li>Added new <code>disable_confirmation</code> used to force disable termination confirmation from client in <code>terminate_connection</code>.</li> <li>Added <code>task_done()</code> method after every <code>get()</code> call to gracefully terminate queues.</li> <li>Added new <code>secrets</code> and <code>string</code> imports.</li> </ul> </li> <li> WebGear: <ul> <li>Updated JPEG Frame compression with <code>simplejpeg</code>:<ul> <li>Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality.</li> <li>Utilized <code>encode_jpeg</code> and <code>decode_jpeg</code> methods to implement turbo-JPEG transcoding with <code>simplejpeg</code>.</li> <li>Added new options to control JPEG frames quality, enable fastest dct, fast upsampling  to boost performance.</li> <li>Added new <code>jpeg_compression</code>, <code>jpeg_compression_quality</code>, <code>jpeg_compression_fastdct</code>, <code>jpeg_compression_fastupsample</code> attributes.</li> <li>Enabled fast dct by default with JPEG frames at <code>90%</code>.</li> <li>Incremented default frame reduction to <code>25%</code>.</li> <li>Implemented automated grayscale colorspace frames handling.</li> <li>Updated old and added new usage examples.</li> <li>Dropped support for depreciated attributes from WebGear and added new attributes.</li> </ul> </li> <li>Added new WebGear Theme: (Checkout at https://github.com/abhiTronix/vidgear-vitals)<ul> <li>Added responsive image scaling according to screen aspect ratios.</li> <li>Added responsive text scaling.</li> <li>Added rounded border and auto-center to image tag.</li> <li>Added bootstrap css properties to implement auto-scaling.</li> <li>Removed old <code>resize()</code> hack.</li> <li>Improved text spacing and weight.</li> <li>Integrated toggle full-screen to new implementation.</li> <li>Hide Scrollbar both in WebGear_RTC and WebGear Themes.</li> <li>Beautify files syntax and updated files checksum.</li> <li>Refactor files and removed redundant code.</li> <li>Bumped theme version to <code>v0.1.2</code>.</li> </ul> </li> </ul> </li> <li> WebGear_RTC:<ul> <li>Added native support for middlewares:<ul> <li>Added new global <code>middleware</code> variable for easily defining Middlewares as list.</li> <li>Added validity check for Middlewares.</li> <li>Added tests for middlewares support.</li> <li>Added example for middlewares support.</li> <li>Extended middlewares support to WebGear API too.</li> <li>Added related imports.</li> </ul> </li> <li>Added new WebGear_RTC Theme:  (Checkout at https://github.com/abhiTronix/vidgear-vitals)<ul> <li>Implemented new responsive video scaling according to screen aspect ratios.</li> <li>Added bootstrap CSS properties to implement auto-scaling.</li> <li>Removed old <code>resize()</code> hack.</li> <li>Beautify files syntax and updated files checksum.</li> <li>Refactored files and removed redundant code.</li> <li>Bumped theme version to <code>v0.1.2</code></li> </ul> </li> </ul> </li> <li> Helper: <ul> <li>New automated interpolation selection for gears:<ul> <li>Implemented <code>retrieve_best_interpolation</code> method to automatically select best available interpolation within OpenCV.</li> <li>Added support for this method in WebGear, WebGear_RTC and Stabilizer Classes/APIs.</li> <li>Added new CI tests for this feature.</li> </ul> </li> <li>Implemented <code>get_supported_demuxers</code> method to get list of supported demuxers.</li> </ul> </li> <li> CI:<ul> <li>Added new <code>no-response</code> work-flow for stale issues.</li> <li>Added new CI tests for SSH Tunneling Mode.</li> <li>Added <code>paramiko</code> to CI dependencies.</li> <li>Added support for <code>\"hls\"</code> format in existing CI tests.</li> <li>Added new functions <code>check_valid_m3u8</code> and <code>extract_meta_video</code> for validating HLS files.</li> <li>Added new <code>m3u8</code> dependency to CI workflows.</li> <li>Added complete CI tests for NetGear_Async's new Bidirectional Mode:<ul> <li>Implemented new exclusive <code>Custom_Generator</code> class for testing bidirectional data dynamically on server-end.</li> <li>Implemented new exclusive <code>client_dataframe_iterator</code> method for testing bidirectional data on client-end.</li> <li>Implemented <code>test_netgear_async_options</code> and <code>test_netgear_async_bidirectionalmode</code> two new tests.</li> <li>Added <code>timeout</code> value on server end in CI tests.</li> </ul> </li> </ul> </li> <li> Setup.py:<ul> <li>Added new <code>cython</code> and <code>msgpack</code> dependency.</li> <li>Added <code>msgpack</code> and <code>msgpack_numpy</code> to auto-install latest.</li> </ul> </li> <li> BASH: <ul> <li>Added new <code>temp_m3u8</code> folder for generating M3U8 assets in CI tests.</li> </ul> </li> <li> Docs:<ul> <li>Added docs for new Apple HLS StreamGear format:<ul> <li>Added StreamGear HLS transcoding examples for both StreamGear modes.</li> <li>Updated StreamGear parameters to w.r.t new HLS configurations.</li> <li>Added open-sourced \"Sintel\" - project Durian Teaser Demo with StreamGear's HLS stream using <code>Clappr</code> and raw.githack.com.</li> <li>Added new HLS chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear</li> <li>Added support for HLS video in Clappr within <code>custom.js</code> using HlsjsPlayback plugin.</li> <li>Added support for Video Thumbnail preview for HLS video in Clappr within <code>custom.js</code></li> <li>Added <code>hlsjs-playback.min.js</code> JS script and suitable configuration for HlsjsPlayback plugin.</li> <li>Added custom labels for quality levels selector in <code>custom.js</code>.</li> <li>Added new docs content related to new Apple HLS format.</li> <li>Updated DASH chunk folder at https://github.com/abhiTronix/vidgear-docs-additionals.</li> <li>Added example for audio input support from external device in StreamGear.</li> <li>Added steps for using <code>-audio</code> attribute on different OS platforms in StreamGear.</li> </ul> </li> <li>Added usage examples for NetGear_Async's Bidirectional Mode:<ul> <li>Added new Usage examples and Reference doc for NetGear_Async's Bidirectional Mode.</li> <li>Added new image asset for NetGear_Async's Bidirectional Mode.</li> <li>Added NetGear_Async's <code>option</code> parameter reference.</li> <li>Updated NetGear_Async definition in docs.</li> <li>Changed font size for Helper methods.</li> <li>Renamed <code>Bonus</code> section to <code>References</code> in <code>mkdocs.yml</code>.</li> </ul> </li> <li>Added Gitter sidecard embed widget:<ul> <li>Imported gitter-sidecar script to <code>main.html</code>.</li> <li>Updated <code>custom.js</code> to set global window option.</li> <li>Updated Sidecard UI in <code>custom.css</code>.</li> </ul> </li> <li>Added bonus examples to help section:<ul> <li>Implemented a curated list of more advanced examples with unusual configuration for each API.</li> </ul> </li> <li>Added several new contents and updated context.</li> <li>Added support for search suggestions, search highlighting and search sharing (i.e. deep linking)</li> <li>Added more content to docs to make it more user-friendly.</li> <li>Added warning that JPEG Frame-Compression is disabled with Custom Source in WebGear.</li> <li>Added steps for identifying and specifying sound card on different OS platforms in WriteGear.</li> <li>Added Zenodo DOI badge and its reference in BibTex citations.</li> <li>Added <code>extra.homepage</code> parameter, which allows for setting a dedicated URL for <code>site_url</code>.</li> <li>Added <code>pymdownx.striphtml</code> plugin for stripping comments.</li> <li>Added complete docs for SSH Tunneling Mode.</li> <li>Added complete docs for NetGear's SSH Tunneling Mode.</li> <li>Added <code>pip</code> upgrade related docs.</li> <li>Added docs for installing vidgear with only selective dependencies</li> <li>Added new <code>advance</code>/<code>experiment</code> admonition with new background color.</li> <li>Added new icons SVGs for <code>advance</code> and <code>warning</code> admonition.</li> <li>Added new usage example and related information.</li> <li>Added new image assets for ssh tunneling example.</li> <li>Added new admonitions</li> <li>Added new FAQs.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> VidGear Core: <ul> <li>New behavior to virtually isolate optional API specific dependencies by silencing <code>ImportError</code> on all VidGear's APIs import.</li> <li>Implemented algorithm to cache all imports on startup but silence any <code>ImportError</code> on missing optional dependency.</li> <li>Now <code>ImportError</code> will be raised only any certain API specific dependency is missing during given API's initialization.</li> <li>New <code>import_dependency_safe</code> to imports specified dependency safely with <code>importlib</code> module.</li> <li>Replaced all APIs imports with <code>import_dependency_safe</code>.</li> <li>Added support for relative imports in <code>import_dependency_safe</code>.</li> <li>Implemented <code>error</code> parameter to by default <code>ImportError</code> with a meaningful message if a dependency is missing, Otherwise if <code>error = log</code> a warning will be logged and on <code>error = silent</code> everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified.</li> <li>Implemented behavior that if a dependency is present, but older than <code>min_version</code> specified, an error is raised always.</li> <li>Implemented <code>custom_message</code> to display custom message on error instead of default one.</li> <li>Implemented separate <code>import_core_dependency</code> function to import and check for specified core dependency. </li> <li><code>ImportError</code> will be raised immediately if core dependency not found.</li> </ul> </li> <li> StreamGear: <ul> <li>Replaced depreciated <code>-min_seg_duration</code> flag with <code>-seg_duration</code>.</li> <li>Removed redundant <code>-re</code> flag from RTFM.</li> <li>Improved Live-Streaming performance by disabling SegmentTimline</li> <li>Improved DASH assets detection for removal by using filename prefixes.</li> </ul> </li> <li> NetGear:<ul> <li>Replaced <code>np.newaxis</code> with <code>np.expand_dims</code>.</li> <li>Replaced <code>random</code> module with <code>secrets</code> while generating system ID.</li> <li>Update array indexing with <code>np.copy</code>.</li> </ul> </li> <li> NetGear_Async:<ul> <li>Improved custom source handling.</li> <li>Removed deprecated <code>loop</code> parameter from asyncio methods.</li> <li>Re-implemented <code>skip_loop</code> parameter in <code>close()</code> method.</li> <li><code>run_until_complete</code> will not used if <code>skip_loop</code> is enabled.</li> <li><code>skip_loop</code> now will create asyncio task instead and will enable <code>disable_confirmation</code> by default.</li> <li>Replaced <code>create_task</code> with <code>ensure_future</code> to ensure backward compatibility with python-3.6 legacies.</li> <li>Simplified code for <code>transceive_data</code> method.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Improved handling of failed ICE connection.</li> <li>Made <code>is_running</code> variable globally available for internal use.</li> </ul> </li> <li> Helper: <ul> <li>Added <code>4320p</code> resolution support to <code>dimensions_to_resolutions</code> method.</li> <li>Implemented new <code>delete_file_safe</code> to safely delete files at given path.</li> <li>Replaced <code>os.remove</code> calls with <code>delete_file_safe</code>.</li> <li>Added support for filename prefixes in <code>delete_ext_safe</code> method.</li> <li>Improved and simplified <code>create_blank_frame</code> functions frame channels detection.</li> <li>Added <code>logging</code> parameter to capPropId function to forcefully discard any error(if required).</li> </ul> </li> <li> Setup.py: <ul> <li>Added patch for <code>numpy</code> dependency, <code>numpy</code> recently dropped support for python 3.6.x legacies. See https://github.com/numpy/numpy/releases/tag/v1.20.0</li> <li>Removed version check on certain dependencies.</li> <li>Re-added <code>aiortc</code> to auto-install latest version.</li> </ul> </li> <li> Asyncio: <ul> <li>Changed <code>asyncio.sleep</code> value to <code>0</code>.<ul> <li>The amount of time sleep is irrelevant; the only purpose await asyncio.sleep() serves is to force asyncio to suspend execution to the event loop, and give other tasks a chance to run. Also, <code>await asyncio.sleep(0)</code> will achieve the same effect. https://stackoverflow.com/a/55782965/10158117</li> </ul> </li> </ul> </li> <li> License: <ul> <li>Dropped publication year range to avoid confusion. (Signed and Approved by @abhiTronix)</li> <li>Updated Vidgear license's year of first publication of the work in accordance with US copyright notices defined by Title 17, Chapter 4(Visually perceptible copies): https://www.copyright.gov/title17/92chap4.html</li> <li>Reflected changes in all copyright notices.</li> </ul> </li> <li> CI: <ul> <li>Updated macOS VM Image to latest in azure devops.</li> <li>Updated VidGear Docs Deployer Workflow.</li> <li>Updated WebGear_RTC CI tests.</li> <li>Removed redundant code from CI tests.</li> <li>Updated tests to increase coverage.</li> <li>Enabled Helper tests for python 3.8+ legacies.</li> <li>Enabled logging in <code>validate_video</code> method.</li> <li>Added <code>-hls_base_url</code> to streamgear tests.</li> <li>Update <code>mpegdash</code> dependency to <code>0.3.0-dev2</code> version in Appveyor.</li> <li>Updated CI tests for new HLS support</li> <li>Updated CI tests from scratch for new native HLS support in StreamGear.</li> <li>Updated test patch for StreamGear.</li> <li>Added exception for RunTimeErrors in NetGear CI tests.</li> <li>Added more directories to Codecov ignore list.</li> <li>Imported relative <code>logger_handler</code> for asyncio tests.</li> </ul> </li> <li> Docs:<ul> <li>Re-positioned few docs comments at bottom for easier detection during stripping.</li> <li>Updated to new extra <code>analytics</code> parameter in Material Mkdocs.</li> <li>Updated dark theme to <code>dark orange</code>.</li> <li>Changed fonts =&gt; text: <code>Muli</code> &amp; code: <code>Fira Code</code></li> <li>Updated fonts to <code>Source Sans Pro</code>.</li> <li>Updated <code>setup.py</code> update-link for modules.</li> <li>Re-added missing StreamGear Code docs.</li> <li>Several minor tweaks and typos fixed.</li> <li>Updated <code>404.html</code> page.</li> <li>Updated admonitions colors and beautified <code>custom.css</code>.</li> <li>Replaced VideoGear &amp; CamGear with OpenCV in CPU intensive examples.</li> <li>Updated <code>mkdocs.yml</code> with new changes and URLs.</li> <li>Moved FAQ examples to bonus examples.</li> <li>Moved StreamGear primary modes to separate sections for better readability.</li> <li>Implemented separate overview and usage example pages for StreamGear primary modes.</li> <li>Improved StreamGear docs context and simplified language.</li> <li>Renamed StreamGear <code>overview</code> page to <code>introduction</code>.</li> <li>Re-written Threaded-Queue-Mode from scratch with elaborated functioning.</li> <li>Replace Paypal with Liberpay in <code>FUNDING.yml</code>.</li> <li>Updated FFmpeg Download links.</li> <li>Reverted UI change in CSS.</li> <li>Updated <code>changelog.md</code> and fixed clutter.</li> <li>Updated <code>README.md</code> and <code>mkdocs.yml</code> with new additions</li> <li>Updated context for CamGear example.</li> <li>Restructured and added more content to docs.</li> <li>Updated comments in source code.</li> <li>Removed redundant data table tweaks from <code>custom.css</code>.</li> <li>Re-aligned badges in README.md.</li> <li>Beautify <code>custom.css</code>.</li> <li>Updated <code>mkdocs.yml</code>.</li> <li>Updated context and fixed typos.</li> <li>Added missing helper methods in Reference.</li> <li>Updated Admonitions.</li> <li>Updates images assets.</li> <li>Bumped CodeCov.</li> </ul> </li> <li> Logging:<ul> <li>Improved logging level-names.</li> <li>Updated logging messages.</li> </ul> </li> <li> Minor tweaks to <code>needs-more-info</code> template.</li> <li> Updated issue templates and labels.</li> <li> Removed redundant imports.</li> </ul> Breaking Updates/Changes <ul> <li> Virtually isolated all API specific dependencies, Now <code>ImportError</code> for API-specific dependencies will be raised only when any of them is missing at API's initialization.</li> <li> Renamed <code>delete_safe</code> to <code>delete_ext_safe</code>.</li> <li> Dropped support for <code>frame_jpeg_quality</code>, <code>frame_jpeg_optimize</code>, <code>frame_jpeg_progressive</code> attributes from WebGear.</li> </ul> Bug-fixes <ul> <li> CamGear:<ul> <li>Hot-fix for Live Camera Streams:<ul> <li>Added new event flag to keep check on stream read.</li> <li>Implemented event wait for  <code>read()</code> to block it when source stream is busy.</li> <li>Added and Linked <code>THREAD_TIMEOUT</code> with event wait timout.</li> <li>Improved backward compatibility of new additions.</li> </ul> </li> <li>Enforced logging for YouTube live.</li> </ul> </li> <li> NetGear: <ul> <li>Fixed Bidirectional Video-Frame Transfer broken with frame-compression:<ul> <li>Fixed <code>return_data</code> interfering with return JSON-data in receive mode.</li> <li>Fixed logic.</li> </ul> </li> <li>Fixed color-subsampling interfering with colorspace.</li> <li>Patched external <code>simplejpeg</code> bug. Issue: https://gitlab.com/jfolz/simplejpeg/-/issues/11<ul> <li>Added <code>np.squeeze</code> to drop grayscale frame's 3rd dimension on Client's end.</li> </ul> </li> <li>Fixed bug that cause server end frame dimensions differ from client's end when frame compression enabled.</li> </ul> </li> <li> NetGear_Async: <ul> <li>Fixed bug related asyncio queue freezing on calling <code>join()</code>.</li> <li>Fixed ZMQ connection bugs in bidirectional mode.</li> <li>Fixed several critical bugs in event loop handling.</li> <li>Fixed several bugs in bidirectional mode implementation.</li> <li>Fixed missing socket termination in both server and client end.</li> <li>Fixed <code>timeout</code> parameter logic.</li> <li>Fixed typos in error messages.</li> </ul> </li> <li> WebGear_RTC: <ul> <li>Fixed stream freezes after web-page reloading:<ul> <li>Implemented new algorithm to continue stream even when webpage is reloaded.</li> <li>Inherit and modified <code>next_timestamp</code> VideoStreamTrack method for generating accurate timestamps.</li> <li>Implemented <code>reset_connections</code> callable to reset all peer connections and recreate Video-Server timestamps. (Implemented by @kpetrykin)</li> <li>Added <code>close_connection</code> endpoint in JavaScript to inform server page refreshing.(Thanks to @kpetrykin)</li> <li>Added exclusive reset connection node <code>/close_connection</code> in routes.</li> <li>Added <code>reset()</code> method to Video-Server class for manually resetting timestamp clock.</li> <li>Added <code>reset_enabled</code> flag to keep check on reloads.</li> <li>Fixed premature webpage auto-reloading.</li> <li>Added additional related imports.</li> </ul> </li> <li>Fixed web-page reloading bug after stream ended:<ul> <li>Disable webpage reload behavior handling for Live broadcasting.</li> <li>Disable reload CI test on Windows machines due to random failures.</li> <li>Improved handling of failed ICE connection.</li> </ul> </li> <li>Fixed Assertion error bug:<ul> <li>Source must raise MediaStreamError when stream ends instead of returning None-type.</li> </ul> </li> </ul> </li> <li> WebGear<ul> <li>Removed format specific OpenCV decoding and encoding support for WebGear.</li> </ul> </li> <li> Helper: <ul> <li>Regex bugs fixed:<ul> <li>New improved regex for discovering supported encoders in <code>get_supported_vencoders</code>.</li> <li>Re-implemented check for extracting only valid output protocols in <code>is_valid_url</code>.</li> <li>Minor tweaks for better regex compatibility.</li> </ul> </li> <li>Bugfix related to OpenCV import:<ul> <li>Bug fixed for OpenCV import comparison test failing with Legacy versions and throwing <code>ImportError</code>.</li> <li>Replaced <code>packaging.parse_version</code> with more robust <code>distutils.version</code>.</li> </ul> </li> <li>Fixed bug with <code>create_blank_frame</code> that throws error with gray frames:<ul> <li>Implemented automatic output channel correction inside <code>create_blank_frame</code> function.</li> <li>Extended automatic output channel correction support to asyncio package.</li> </ul> </li> <li>Implemented <code>RTSP</code> protocol validation as demuxer, since it's not a protocol but a demuxer.</li> <li>Removed redundant <code>logger_handler</code>, <code>mkdir_safe</code>, <code>retrieve_best_interpolation</code>, <code>capPropId</code> helper functions from asyncio package. Relatively imported helper functions from non-asyncio package.</li> <li>Removed unused <code>aiohttp</code> dependency.</li> <li>Removed <code>asctime</code> formatting from logging.</li> </ul> </li> <li> StreamGear: <ul> <li>Fixed Multi-Bitrate HLS VOD streams:<ul> <li>Re-implemented complete workflow for Multi-Bitrate HLS VOD streams.</li> <li>Extended support to both Single-Source and Real-time Frames Modes.</li> </ul> </li> <li>Fixed bugs with audio-video mapping.</li> <li>Fixed master playlist not generating in output.</li> <li>Fixed improper <code>-seg_duration</code> value resulting in broken pipeline.</li> <li>Fixed expected aspect ratio not calculated correctly for additional streams.</li> <li>Fixed stream not terminating when provided input from external audio device.</li> <li>Fixed bugs related to external audio not mapped correctly in HLS format.</li> <li>Fixed OPUS audio fragments not supported with MP4 video in HLS.</li> <li>Fixed unsupported high audio bit-rate bug.</li> </ul> </li> <li> Setup.py: <ul> <li>Fixed <code>latest_version</code> returning incorrect version for some PYPI packages.</li> <li>Removed <code>latest_version</code> variable support from <code>simplejpeg</code>.</li> <li>Fixed <code>streamlink</code> only supporting requests==2.25.1 on Windows.</li> <li>Removed all redundant dependencies like <code>colorama</code>, <code>aiofiles</code>, <code>aiohttp</code>.</li> <li>Fixed typos in dependencies.</li> </ul> </li> <li> Setup.cfg: <ul> <li>Replaced dashes with underscores to remove warnings.</li> </ul> </li> <li> CI:<ul> <li>Replaced buggy <code>starlette.TestClient</code> with <code>async-asgi-testclient</code> in WebGear_RTC</li> <li>Removed <code>run()</code> method and replaced with pure asyncio implementation.</li> <li>Added new <code>async-asgi-testclient</code> CI dependency.</li> <li>Fixed <code>fake_picamera</code> class logger calling <code>vidgear</code> imports prematurely before importing <code>picamera</code> class in tests.<ul> <li>Implemented new <code>fake_picamera</code> class logger inherently with <code>logging</code> module.</li> <li>Moved <code>sys.module</code> logic for faking to <code>init.py</code>.</li> <li>Added <code>__init__.py</code> to ignore in Codecov.</li> </ul> </li> <li>Fixed event loop closing prematurely while reloading:<ul> <li>Internally disabled suspending event loop while reloading.</li> </ul> </li> <li>Event Policy Loop patcher added for WebGear_RTC tests.</li> <li>Fixed <code>return_assets_path</code> path bug.</li> <li>Fixed typo in <code>TimeoutError</code> exception import.</li> <li>Fixed eventloop is already closed bug.</li> <li>Fixed eventloop bugs in Helper CI tests.</li> <li>Fixed several minor bugs related to new CI tests.</li> <li>Fixed bug in PiGear tests. </li> </ul> </li> <li> Docs:<ul> <li>Fixed 404 page does not work outside the site root with mkdocs.</li> <li>Fixed markdown files comments not stripped when converted to HTML.</li> <li>Fixed missing heading in VideoGear.</li> <li>Typos in links and code comments fixed.</li> <li>Several minor tweaks and typos fixed.</li> <li>Fixed improper URLs/Hyperlinks and related typos.</li> <li>Fixed typos in usage examples.</li> <li>Fixed redundant properties in CSS.</li> <li>Fixed bugs in <code>mkdocs.yml</code>.</li> <li>Fixed docs contexts and typos.</li> <li>Fixed <code>stream.release()</code> missing in docs.</li> <li>Fixed several typos in code comments.</li> <li>Removed dead code from docs.</li> </ul> </li> <li> Refactored Code and reduced redundancy.</li> <li> Fixed shutdown in <code>main.py</code>.</li> <li> Fixed logging comments.</li> </ul> Pull Requests <ul> <li>PR #210</li> <li>PR #215</li> <li>PR #222</li> <li>PR #223</li> <li>PR #227</li> <li>PR #231</li> <li>PR #233</li> <li>PR #237 </li> <li>PR #239 </li> <li>PR #243 </li> </ul> New Contributors <ul> <li>@kpetrykin</li> </ul>"},{"location":"changelog/#v021-2021-04-25","title":"v0.2.1 (2021-04-25)","text":"New Features <ul> <li> WebGear_RTC:<ul> <li>A new API that is similar to WeGear API in all aspects but utilizes WebRTC standard instead of Motion JPEG for streaming.</li> <li>Now it is possible to share data and perform teleconferencing peer-to-peer, without requiring that the user install plugins or any other third-party software.</li> <li>Added a flexible backend for <code>aiortc</code> - a python library for Web Real-Time Communication (WebRTC).</li> <li>Integrated all functionality and parameters of WebGear into WebGear_RTC API.</li> <li>Implemented JSON Response with a WebRTC Peer Connection of Video Server.</li> <li>Added a internal <code>RTC_VideoServer</code> server on WebGear_RTC, a inherit-class to aiortc's VideoStreamTrack API.</li> <li>New Standalone UI Default theme v0.1.1 for WebGear_RTC from scratch without using 3rd-party assets. (by @abhiTronix)</li> <li>New <code>custom.js</code> and <code>custom.css</code> for custom responsive behavior.</li> <li>Added WebRTC support to <code>custom.js</code> and ensured compatibility with WebGear_RTC.</li> <li>Added example support for ICE framework and STUN protocol like WebRTC features to <code>custom.js</code>.</li> <li>Added <code>resize()</code> function to <code>custom.js</code> to automatically adjust <code>video</code> &amp; <code>img</code> tags for smaller screens.</li> <li>Added WebGear_RTC support in main.py for easy access through terminal using <code>--mode</code> flag.</li> <li>Integrated all WebGear_RTC enhancements to WebGear Themes.</li> <li>Added CI test for WebGear_RTC.</li> <li>Added complete docs for WebGear_RTC API.</li> <li>Added bare-minimum as well as advanced examples usage code.</li> <li>Added new theme images.</li> <li>Added Reference and FAQs.</li> </ul> </li> <li> CamGear API:<ul> <li>New Improved Pure-Python Multiple-Threaded Implementation:<ul> <li>Optimized Threaded-Queue-Mode Performance. (PR by @bml1g12)</li> <li>Replaced regular <code>queue.full</code> checks followed by sleep with implicit sleep with blocking <code>queue.put</code>.</li> <li>Replaced regular <code>queue.empty</code> checks followed by queue.</li> <li>Replaced <code>nowait_get</code> with a blocking <code>queue.get</code> natural empty check.</li> <li>Up-to 2x performance boost than previous implementations. </li> </ul> </li> <li>New <code>THREAD_TIMEOUT</code> attribute to prevent deadlocks:<ul> <li>Added support for <code>THREAD_TIMEOUT</code> attribute to its <code>options</code> parameter.</li> <li>Updated CI Tests and docs.</li> </ul> </li> </ul> </li> <li> WriteGear API:<ul> <li>New more robust handling of default video-encoder in compression mode:<ul> <li>Implemented auto-switching of default video-encoder automatically based on availability.</li> <li>API now selects Default encoder based on priority: <code>\"libx264\" &gt; \"libx265\" &gt; \"libxvid\" &gt; \"mpeg4\"</code>.</li> <li>Added <code>get_supported_vencoders</code> Helper method to enumerate Supported Video Encoders.</li> <li>Added common handler for <code>-c:v</code> and <code>-vcodec</code> flags.</li> </ul> </li> </ul> </li> <li> NetGear API:<ul> <li>New Turbo-JPEG compression with simplejpeg<ul> <li>Implemented JPEG compression algorithm for 4-5% performance boost at cost of minor loss in quality.</li> <li>Utilized <code>encode_jpeg</code> and <code>decode_jpeg</code> methods to implement turbo-JPEG transcoding with <code>simplejpeg</code>.</li> <li>Added options to control JPEG frames quality, enable fastest dct, fast upsampling  to boost performance.</li> <li>Added new <code>jpeg_compression</code>, <code>jpeg_compression_quality</code>, <code>jpeg_compression_fastdct</code>, <code>jpeg_compression_fastupsample</code> attributes.</li> <li>Enabled fast dct by default with JPEG frames at 90%.</li> <li>Added Docs for JPEG Frame Compression.</li> </ul> </li> </ul> </li> <li> WebGear API: <ul> <li>New modular and flexible configuration for Custom Sources:<ul> <li>Implemented more convenient approach for handling custom source configuration.</li> <li>Added new <code>config</code> global variable for this new behavior.</li> <li>Now None-type <code>source</code> parameter value is allowed for defining own custom sources.</li> <li>Added new Example case and Updates Docs for this feature.</li> <li>Added new CI Tests.</li> </ul> </li> <li>New Browser UI Updates:<ul> <li>New Standalone UI Default theme v0.1.0 for browser (by @abhiTronix)</li> <li>Completely rewritten theme from scratch with only local resources.</li> <li>New <code>custom.js</code> and <code>custom.css</code> for custom responsive behavior.</li> <li>New sample glow effect with css.</li> <li>New sample click to full-screen behavior with javascript.</li> <li>Removed all third-party theme dependencies.</li> <li>Update links to new github server <code>abhiTronix/vidgear-vitals</code></li> <li>Updated docs with new theme's screenshots.</li> </ul> </li> <li>Added <code>enable_infinite_frames</code> attribute for enabling infinite frames.</li> <li>Added New modular and flexible configuration for Custom Sources.</li> <li>Bumped WebGear Theme Version to v0.1.1.</li> <li>Updated Docs and CI tests.</li> </ul> </li> <li> ScreenGear API:<ul> <li>Implemented Improved Pure-Python Multiple-Threaded like CamGear.</li> <li>Added support for <code>THREAD_TIMEOUT</code> attribute to its <code>options</code> parameter.</li> </ul> </li> <li> StreamGear API:<ul> <li>Enabled pseudo live-streaming flag <code>re</code> for live content.</li> </ul> </li> <li> Docs:<ul> <li>Added new native docs versioning to mkdocs-material.</li> <li>Added new examples and few visual tweaks.</li> <li>Updated Stylesheet for versioning.</li> <li>Added new DASH video chunks at https://github.com/abhiTronix/vidgear-docs-additionals for StreamGear and Stabilizer streams.</li> <li>Added open-sourced \"Tears of Steel\" * project Mango Teaser video chunks.</li> <li>Added open-sourced \"Subspace Video Stabilization\" http://web.cecs.pdx.edu/~fliu/project/subspace_stabilization/ video chunks.</li> <li>Added support for DASH Video Thumbnail preview in Clappr within <code>custom.js</code>.</li> <li>Added responsive clappr DASH player with bootstrap's <code>embed-responsive</code>.</li> <li>Added new permalink icon and slugify to toc.</li> <li>Added \"back-to-top\" button for easy navigation.</li> </ul> </li> <li> Helper:<ul> <li>New GitHub Mirror with latest Auto-built FFmpeg Static Binaries:<ul> <li>Replaced new GitHub Mirror <code>abhiTronix/FFmpeg-Builds</code> in helper.py</li> <li>New CI maintained Auto-built FFmpeg Static Binaries.</li> <li>Removed all 3rd-party and old links for better compatibility and Open-Source reliability.</li> <li>Updated Related CI tests.</li> </ul> </li> <li>Added auto-font-scaling for <code>create_blank_frame</code> method.</li> <li>Added <code>c_name</code> parameter to <code>generate_webdata</code> and <code>download_webdata</code> to specify class.</li> <li>A more robust Implementation of Downloading Artifacts:<ul> <li>Added a custom HTTP <code>TimeoutHTTPAdapter</code> Adapter with a default timeout for all HTTP calls based on this GitHub comment.</li> <li>Implemented http client and the <code>send()</code> method to ensure that the default timeout is used if a timeout argument isn't provided.</li> <li>Implemented Requests session<code>with</code> block to exit properly even if there are unhandled exceptions.</li> <li>Add a retry strategy to custom <code>TimeoutHTTPAdapter</code> Adapter with max 3 retries and sleep(<code>backoff_factor=1</code>) between failed requests.</li> </ul> </li> <li>Added <code>create_blank_frame</code> method to create bland frames with suitable text.</li> </ul> </li> <li> [CI] Continuous Integration:<ul> <li>Added new fake frame generated for fake <code>picamera</code> class with numpy.</li> <li>Added new <code>create_bug</code> parameter to fake <code>picamera</code> class for emulating various artificial bugs.</li> <li>Added float/int instance check on <code>time_delay</code> for camgear and pigear.</li> <li>Added <code>EXIT_CODE</code> to new timeout implementation for pytests to upload codecov report when no timeout.</li> <li>Added auxiliary classes to  fake <code>picamera</code> for facilitating the emulation.</li> <li>Added new CI tests for PiGear Class for testing on all platforms.</li> <li>Added <code>shutdown()</code> function to gracefully terminate WebGear_RTC API.</li> <li>Added new <code>coreutils</code> brew dependency.</li> <li>Added handler for variable check on exit and codecov upload.</li> <li>Added <code>is_running</code> flag to WebGear_RTC to exit safely.    </li> </ul> </li> <li> Setup:<ul> <li>New automated latest version retriever for packages:<ul> <li>Implemented new <code>latest_version</code> method to automatically retrieve latest version for packages.</li> <li>Added Some Dependencies.</li> </ul> </li> <li>Added <code>simplejpeg</code> package for all platforms.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Added exception for RunTimeErrors in NetGear CI tests.</li> <li> WriteGear: Critical file write access checking method:<ul> <li>Added new <code>check_WriteAccess</code> Helper method.</li> <li>Implemented a new robust algorithm to check if given directory has write-access.</li> <li>Removed old behavior which gives irregular results.</li> </ul> </li> <li> Helper: Maintenance Updates<ul> <li>Added workaround for Python bug.</li> <li>Added <code>safe_mkdir</code> to <code>check_WriteAccess</code> to automatically create non-existential parent folder in path.</li> <li>Extended <code>check_WriteAccess</code> Patch to StreamGear.</li> <li>Simplified <code>check_WriteAccess</code> to handle Windows envs easily.</li> <li>Updated FFmpeg Static Download URL for WriteGear.</li> <li>Implemented fallback option for auto-calculating bitrate from extracted audio sample-rate in <code>validate_audio</code> method.</li> </ul> </li> <li> Docs: General UI Updates<ul> <li>Updated Meta tags for og site and twitter cards.</li> <li>Replaced Custom dark theme toggle with mkdocs-material's official Color palette toggle</li> <li>Added example for external audio input and creating segmented MP4 video in WriteGear FAQ.</li> <li>Added example for YouTube streaming with WriteGear.</li> <li>Removed custom <code>dark-material.js</code> and <code>header.html</code> files from theme.</li> <li>Added blogpost link for detailed information on Stabilizer Working.</li> <li>Updated <code>mkdocs.yml</code> and <code>custom.css</code> configuration.</li> <li>Remove old hack to resize clappr DASH player with css.</li> <li>Updated Admonitions.</li> <li>Improved docs contexts.</li> <li>Updated CSS for version-selector-button.</li> <li>Adjusted files to match new themes.</li> <li>Updated welcome-bot message for typos.</li> <li>Removed redundant FAQs from NetGear Docs.</li> <li>Updated Assets Images.</li> <li>Updated spacing.</li> </ul> </li> <li> CI:<ul> <li>Removed unused <code>github.ref</code> from yaml.</li> <li>Updated OpenCV Bash Script for Linux envs.</li> <li>Added <code>timeout-minutes</code> flag to github-actions workflow.</li> <li>Added <code>timeout</code> flag to pytest.</li> <li>Replaced Threaded Gears with OpenCV VideoCapture API.</li> <li>Moved files and Removed redundant code.</li> <li>Replaced grayscale frames with color frames for WebGear tests. </li> <li>Updated pytest timeout value to 15mins.</li> <li>Removed <code>aiortc</code> automated install on Windows platform within setup.py.</li> <li>Added new timeout logic to continue to run on external timeout for GitHub Actions Workflows.</li> <li>Removed unreliable old timeout solution from WebGear_RTC.</li> <li>Removed <code>timeout_decorator</code> and <code>asyncio_timeout</code> dependencies for CI.</li> <li>Removed WebGear_RTC API exception from codecov.</li> <li>Implemented new fake <code>picamera</code> class to CI utils for emulating RPi Camera-Module Real-time capabilities.</li> <li>Implemented new <code>get_RTCPeer_payload</code> method to receive WebGear_RTC peer payload.</li> <li>Removed PiGear from Codecov exceptions.</li> <li>Disable Frame Compression in few NetGear tests failing on frame matching.</li> <li>Updated NetGear CI  tests to support new attributes</li> <li>Removed warnings and updated yaml<ul> <li>Added <code>pytest.ini</code> to address multiple warnings.</li> <li>Updated azure workflow condition syntax.</li> </ul> </li> <li>Update <code>mike</code> settings for mkdocs versioning.</li> <li>Updated codecov configurations.</li> <li>Minor logging and docs updates.</li> <li>Implemented pytest timeout for azure pipelines for macOS envs.</li> <li>Added <code>aiortc</code> as external dependency in <code>appveyor.yml</code>.</li> <li>Re-implemented WebGear_RTC improper offer-answer handshake in CI tests.</li> <li>WebGear_RTC CI Updated with <code>VideoTransformTrack</code> to test stream play.</li> <li>Implemented fake <code>AttributeError</code> for fake picamera class.</li> <li>Updated PiGear CI tests to increment codecov.</li> <li>Update Tests docs and other minor tweaks to increase overall coverage.</li> <li>Enabled debugging and disabled exit 1 on error in azure pipeline.</li> <li>Removed redundant benchmark tests.</li> </ul> </li> <li> Helper: Added missing RTSP URL scheme to <code>is_valid_url</code> method.</li> <li> NetGear_Async: Added fix for uvloop only supporting python&gt;=3.7 legacies.</li> <li> Extended WebGear's Video-Handler scope to <code>https</code>.</li> <li> CI: Remove all redundant 32-bit Tests from Appveyor:<ul> <li>Appveyor 32-bit Windows envs are actually running on 64-bit machines.</li> <li>More information here: https://help.appveyor.com/discussions/questions/20637-is-it-possible-to-force-running-tests-on-both-32-bit-and-64-bit-windows</li> </ul> </li> <li> Setup: Removed <code>latest_version</code> behavior from some packages.</li> <li> NetGear_Async: Revised logic for handling uvloop for all platforms and legacies.</li> <li> Setup: Updated logic to install uvloop-\"v0.14.0\" for python-3.6 legacies.</li> <li> Removed any redundant code from webgear.</li> <li> StreamGear:<ul> <li>Replaced Ordinary dict with Ordered Dict to use <code>move_to_end</code> method.</li> <li>Moved external audio input to output parameters dict.</li> <li>Added additional imports.</li> <li>Updated docs to reflect changes.</li> </ul> </li> <li> Numerous Updates to Readme and <code>mkdocs.yml</code>.</li> <li> Updated font to <code>FONT_HERSHEY_SCRIPT_COMPLEX</code> and enabled logging in create_blank_frame.</li> <li> Separated channels for downloading and storing theme files for WebGear and WebGear_RTC APIs.</li> <li> Removed <code>logging</code> condition to always inform user in a event of FFmpeg binary download failure.</li> <li> WebGear_RTC: <ul> <li>Improved auto internal termination.</li> <li>More Performance updates through <code>setCodecPreferences</code>.</li> <li>Moved default Video RTC video launcher to <code>__offer</code>.</li> </ul> </li> <li> NetGear_Async: Added timeout to client in CI tests.</li> <li> Reimplemented and updated <code>changelog.md</code>.</li> <li> Updated code comments.</li> <li> Setup: Updated keywords and classifiers.</li> <li> Bumped codecov.</li> </ul> Breaking Updates/Changes <ul> <li> WriteGear will automatically switch video encoder to default if specified encoder not found.</li> <li> WriteGear will throw <code>RuntimeError</code> if no suitable default encoder found!</li> <li> Removed format specific OpenCV decoding and encoding support for NetGear.</li> <li> Dropped support for <code>compression_format</code>, <code>compression_param</code> attributes from NetGear.</li> <li> Non-existent parent folder in <code>output_filename</code> value will no longer be considered as invalid in StreamGear and WriteGear APIs.</li> <li> None-type <code>source</code> parameter value is allowed for WebGear and NetGear_Async for defining custom sources.</li> </ul> Bug-fixes <ul> <li> CamGear: Fixed F821 undefined name 'queue' bug.</li> <li> NetGear_Async: Fixed <code>source</code> parameter missing <code>None</code> as default value.</li> <li> Fixed uvloops only supporting python&gt;=3.7 in NetGear_Async.</li> <li> Helper:<ul> <li>Fixed Zombie processes in <code>check_output</code> method due a hidden bug in python. For reference: https://bugs.python.org/issue37380</li> <li>Fixed regex in <code>validate_video</code> method.</li> </ul> </li> <li> Docs: <ul> <li>Invalid <code>site_url</code> bug patched in mkdocs.yml</li> <li>Remove redundant mike theme support and its files.</li> <li>Fixed video not centered when DASH video in fullscreen mode with clappr.</li> <li>Fixed Incompatible new mkdocs-docs theme.</li> <li>Fixed missing hyperlinks.</li> </ul> </li> <li> CI: <ul> <li>Fixed NetGear Address bug</li> <li>Fixed bugs related to termination in WebGear_RTC.</li> <li>Fixed random CI test failures and code cleanup.</li> <li>Fixed string formating bug in Helper.py.</li> <li>Fixed F821 undefined name bugs in WebGear_RTC tests.</li> <li>NetGear_Async Tests fixes.</li> <li>Fixed F821 undefined name bugs.</li> <li>Fixed typo bugs in <code>main.py</code>.</li> <li>Fixed Relative import bug in PiGear.</li> <li>Fixed regex bug in warning filter.</li> <li>Fixed WebGear_RTC frozen threads on exit.</li> <li>Fixed bugs in codecov bash uploader setting for azure pipelines.</li> <li>Fixed False-positive <code>picamera</code> import due to improper sys.module settings.</li> <li>Fixed Frozen Threads on exit in WebGear_RTC API.</li> <li>Fixed deploy error in <code>VidGear Docs Deployer</code> workflow</li> <li>Fixed low timeout bug.</li> <li>Fixed bugs in PiGear tests.</li> <li>Patched F821 undefined name bug.</li> </ul> </li> <li> StreamGear:<ul> <li>Fixed StreamGear throwing <code>Picture size 0x0 is invalid</code> bug with external audio.</li> <li>Fixed default input framerate value getting discarded in Real-time Frame Mode.</li> <li>Fixed internal list-formatting bug.</li> </ul> </li> <li> Fixed E999 SyntaxError bug in <code>main.py</code>.</li> <li> Fixed Typo in bash script.</li> <li> Fixed WebGear freeze on reloading bug.</li> <li> Fixed anomalies in <code>install_opencv</code> bash script.</li> <li> Helper: Bug Fixed in <code>download_ffmpeg_binaries</code> method.</li> <li> Helper: Fixed OSError bug in <code>check_WriteAccess</code> method.</li> <li> Helper: Fixed Input Audio stream bitrate test failing to detect audio-bitrate in certain videos with <code>validate_audio</code> method.</li> <li> Fixed bugs in <code>requests</code> module's function arguments.</li> <li> Fixed None-type stream bug in WebGear.</li> <li> Fixed random crashes in WebGear.</li> <li> Fixed numerous CI test bugs.</li> <li> Fixed several typos.</li> </ul> Pull Requests <ul> <li>PR #192</li> <li>PR #196</li> <li>PR #203</li> <li>PR #206</li> </ul> New Contributors <ul> <li>@bml1g12</li> </ul>"},{"location":"changelog/#v020-2021-01-01","title":"v0.2.0 (2021-01-01)","text":"New Features <ul> <li> CamGear API:<ul> <li>Support for various Live-Video-Streaming services:<ul> <li>Added seamless support for live video streaming sites like Twitch, LiveStream, Dailymotion etc.</li> <li>Implemented flexible framework around <code>streamlink</code> python library with easy control over parameters and quality.</li> <li>Stream Mode can now automatically detects whether <code>source</code> belong to YouTube or elsewhere, and handles it with appropriate API.</li> </ul> </li> <li>Re-implemented YouTube URLs Handler:<ul> <li>Re-implemented CamGear's YouTube URLs Handler completely from scratch.</li> <li>New Robust Logic to flexibly handing video and video-audio streams.</li> <li>Intelligent stream selector for selecting best possible stream compatible with OpenCV.</li> <li>Added support for selecting stream qualities and parameters.</li> <li>Implemented new <code>get_supported_quality</code> helper method for handling specified qualities</li> <li>Fixed Live-Stream URLs not supported by OpenCV's Videocapture and its FFmpeg.</li> </ul> </li> <li>Added additional <code>STREAM_QUALITY</code> and <code>STREAM_PARAMS</code> attributes.</li> </ul> </li> <li> ScreenGear API:<ul> <li>Multiple Backends Support:<ul> <li>Added new multiple backend support with new <code>pyscreenshot</code> python library.</li> <li>Made <code>pyscreenshot</code> the default API for ScreenGear, replaces <code>mss</code>.</li> <li>Added new <code>backend</code> parameter for this feature while retaining previous behavior.</li> <li>Added native automated RGB to BGR conversion for default PIL backend.</li> <li>Kept support for old <code>mss</code> for old compatibility and multi-screen support.</li> <li>Added native dimensional support for multi-screen.</li> <li>Added support all input from all multiple screens.</li> <li>Updated ScreenGear Docs.</li> <li>Updated ScreenGear CI tests.</li> </ul> </li> </ul> </li> <li> StreamGear API:<ul> <li>Changed default behaviour to support complete video transcoding.</li> <li>Added <code>-livestream</code> attribute to support live-streaming.</li> <li>Added additional parameters for <code>-livestream</code> attribute functionality.</li> <li>Updated StreamGear Tests.</li> <li>Updated StreamGear docs.</li> </ul> </li> <li> Stabilizer Class: <ul> <li>New Robust Error Handling with Blank Frames:<ul> <li>Elegantly handles all crashes due to Empty/Blank/Dark frames.</li> <li>Stabilizer throws Warning with this new behavior instead of crashing.</li> <li>Updated CI test for this feature.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Automated Docs Versioning:<ul> <li>Implemented Docs versioning through <code>mike</code> API.</li> <li>Separate new workflow steps to handle different versions.</li> <li>Updated docs deploy worflow to support <code>release</code> and <code>dev</code> builds.</li> <li>Added automatic version extraction from github events.</li> <li>Added <code>version-select.js</code> and <code>version-select.css</code> files.</li> </ul> </li> <li>Toggleable Dark-White Docs Support:<ul> <li>Toggle-button to easily switch dark, white and preferred theme.</li> <li>New Updated Assets for dark backgrounds</li> <li>New css, js files/content to implement this behavior.</li> <li>New material icons for button.</li> <li>Updated scheme to <code>slate</code> in <code>mkdocs.yml</code>.</li> </ul> </li> <li>New Theme and assets:<ul> <li>New <code>purple</code> theme with <code>dark-purple</code> accent color.</li> <li>New images assets with updated transparent background.</li> <li>Support for both dark and white theme.</li> <li>Increased <code>rebufferingGoal</code> for dash videos.</li> <li>New updated custom 404 page for docs.</li> </ul> </li> <li>Issue and PR automated-bots changes<ul> <li>New <code>need_info.yml</code> YAML Workflow.</li> <li>New <code>needs-more-info.yml</code> Request-Info template.</li> <li>Replaced Request-Info templates.</li> <li>Improved PR and Issue welcome formatting.</li> </ul> </li> <li>Added custom HTML pages.</li> <li>Added <code>show_root_heading</code> flag to disable headings in References.</li> <li>Added new <code>inserAfter</code> function to version-select.js.</li> <li>Adjusted hue for dark-theme for better contrast.</li> <li>New usage examples and FAQs.</li> <li>Added <code>gitmoji</code> for commits.</li> </ul> </li> <li> Continuous Integration:<ul> <li>Maintenance Updates:<ul> <li>Added support for new <code>VIDGEAR_LOGFILE</code> environment variable in Travis CI.</li> <li>Added missing CI tests.</li> <li>Added logging for helper functions.</li> </ul> </li> <li>Azure-Pipeline workflow for MacOS envs<ul> <li>Added Azure-Pipeline Workflow for testing MacOS environment.</li> <li>Added codecov support.</li> </ul> </li> <li>GitHub Actions workflow for Linux envs<ul> <li>Added GitHub Action work-flow for testing Linux environment.</li> </ul> </li> <li>New YAML to implement GitHub Action workflow for python 3.6, 3.7, 3,8 &amp; 3.9 matrices.</li> <li>Added Upload coverage to Codecov GitHub Action workflow.</li> <li>New codecov-bash uploader for Azure Pipelines.</li> </ul> </li> <li> Logging:<ul> <li>Added file support<ul> <li>Added <code>VIDGEAR_LOGFILE</code> environment variable to manually add file/dir path.</li> <li>Reworked <code>logger_handler()</code> Helper methods (in asyncio too).</li> <li>Added new formatter and Filehandler for handling logger files.</li> </ul> </li> <li>Added <code>restore_levelnames</code> auxiliary method for restoring logging levelnames.</li> </ul> </li> <li> Added auto version extraction from package <code>version.py</code> in setup.py.</li> </ul> Updates/Improvements <ul> <li> Added missing Lazy-pirate auto-reconnection support for Multi-Servers and Multi-Clients Mode in NetGear API.</li> <li> Added new FFmpeg test path to Bash-Script and updated README broken links.</li> <li> Asset Cleanup:<ul> <li>Removed all third-party javascripts from projects.</li> <li>Linked all third-party javascript directly.</li> <li>Cleaned up necessary code from CSS and JS files.</li> <li>Removed any copyrighted material or links.</li> </ul> </li> <li> Rewritten Docs from scratch:<ul> <li>Improved complete docs formatting.</li> <li>Simplified language for easier understanding.</li> <li>Fixed <code>mkdocstrings</code> showing root headings.</li> <li>Included all APIs methods to <code>mkdocstrings</code> docs.</li> <li>Removed unnecessary information from docs.</li> <li>Corrected Spelling and typos.</li> <li>Fixed context and grammar.</li> <li>Removed <code>motivation.md</code>.</li> <li>Renamed many terms.</li> <li>Fixed hyper-links.</li> <li>Reformatted missing or improper information.</li> <li>Fixed context and spellings in Docs files.</li> <li>Simplified language for easy understanding.</li> <li>Updated image sizes for better visibility.</li> </ul> </li> <li> Bash Script: Updated to Latest OpenCV Binaries version and related changes</li> <li> Docs: Moved version-selector to header and changed default to alias.</li> <li> Docs: Updated <code>deploy_docs.yml</code> for releasing dev, stable, and release versions.</li> <li> Re-implemented overridden material theme.</li> <li> Updated docs with all new additions and examples.</li> <li> CamGear: CI Stream Mode test updated.</li> <li> Updated ReadMe.md badges.</li> <li> Updated CI tests. </li> <li> Updated <code>setup.py</code> with new features.</li> <li> Updated <code>contributing.md</code> and <code>ReadMe.md</code>.</li> <li> Updated OpenCV version to <code>4.5.1-dev</code> in bash scripts</li> <li> Updated <code>changelog.md</code>.</li> <li> Moved WebGear API to Streaming Gears.</li> <li> Bumped Codecov.</li> <li> UI changes to version-select.js</li> <li> Docs: Retitle the versions and <code>mkdocs.yml</code> formatting updated.</li> <li> Docs: Version Selector UI reworked and other minor changes.</li> </ul> Breaking Updates/Changes <ul> <li> <code>y_tube</code> parameter renamed as <code>stream_mode</code> in CamGear API!</li> <li> Removed Travis support and <code>travis.yml</code> deleted.</li> </ul> Bug-fixes <ul> <li> Fixed StreamGear API Limited Segments Bug</li> <li> Fixed Missing links in docs and bump up version.</li> <li> CI: Fixed Appveyor need newer VM image to support Python 3.9.x matrix.</li> <li> ScreenGear BugFix: Fixed Error Handling and updated CI Tests.</li> <li> Fixed improper <code>mkdocs.yml</code> variables.</li> <li> Fixed GStreamer plugin support in bash scripts.</li> <li> Fixed typos in YAMLs and docs.</li> <li> Docs: Fixed Docs Deployer YAML bug for CI envs.</li> <li> Fixed wrong import in YAML.</li> <li> Fixed visible hyperlink on hover in dark-toggle button.</li> <li> Docs: Deployer YAML bug fixed.</li> <li> Docs YAML: issue jimporter/mike#33 patched and fixed <code>fetch-depth=0</code>.</li> <li> Docs: <code>version-select.js</code> bug fixed.</li> <li> Docs: UI Bugs Fixed.</li> <li> CI: Codecov bugfixes.</li> <li> Azure-Pipelines Codecov BugFixes.</li> <li> Fixed <code>version.json</code> not detecting properly in <code>version-select.js</code>.</li> <li> Fixed images not centered inside <code>&lt;figure&gt;</code> tag.</li> <li> Fixed Asset Colors.</li> <li> Fixed failing CI tests.</li> <li> Fixed Several logging bugs.</li> </ul> Pull Requests <ul> <li>PR #164</li> <li>PR #170</li> <li>PR #173</li> <li>PR #181</li> <li>PR #183</li> <li>PR #184 </li> </ul>"},{"location":"changelog/#v019-2020-08-31","title":"v0.1.9 (2020-08-31)","text":"New Features <ul> <li> StreamGear API:<ul> <li>New API that automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats.</li> <li>Implemented multi-platform , standalone, highly extensible and flexible wrapper around FFmpeg for generating chunked-encoded media segments of the media, and easily accessing almost all of its parameters.</li> <li>API automatically transcodes videos/audio files &amp; real-time frames into a sequence of multiple smaller chunks/segments and also creates a Manifest file.</li> <li>Added initial support for MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1).</li> <li>Constructed default behavior in StreamGear, for auto-creating a Primary Stream of same resolution and framerate as source.</li> <li>Added TQDM progress bar in non-debugged output for visual representation of internal processes.</li> <li>Implemented several internal methods for preprocessing FFmpeg and internal parameters for producing streams.</li> <li>Several standalone internal checks to ensure robust performance.</li> <li>New <code>terminate()</code> function to terminate StremGear Safely.</li> <li>New StreamGear Dual Modes of Operation:<ul> <li>Implemented Single-Source and Real-time Frames like independent Transcoding Modes.</li> <li>Linked <code>-video_source</code> attribute for activating these modes</li> <li>Single-Source Mode, transcodes entire video/audio file (as opposed to frames by frame) into a sequence of multiple smaller segments for streaming</li> <li>Real-time Frames Mode, directly transcodes video-frames (as opposed to a entire file), into a sequence of multiple smaller segments for streaming</li> <li>Added separate functions, <code>stream()</code> for Real-time Frame Mode and <code>transcode_source()</code> for Single-Source Mode for easy transcoding.</li> <li>Included auto-colorspace detection and RGB Mode like features (extracted from WriteGear), into StreamGear.  </li> </ul> </li> <li>New StreamGear Parameters:<ul> <li>Developed several new parameters such as:<ul> <li><code>output</code>: handles assets directory</li> <li><code>formats</code>: handles adaptive HTTP streaming format.</li> <li><code>custom_ffmpeg</code>: handles custom FFmpeg location.</li> <li><code>stream_params</code>: handles internal and FFmpeg parameter seamlessly.</li> <li><code>logging</code>: turns logging on or off.</li> </ul> </li> <li>New <code>stream_params</code> parameter allows us to exploit almost all FFmpeg parameters and flexibly change its internal settings, and seamlessly generating high-quality streams with its attributes:<ul> <li><code>-streams</code> (list of dictionaries) for building additional streams with <code>-resolution</code>, <code>-video_bitrate</code> &amp; <code>-framerate</code> like sub-attributes.</li> <li><code>-audio</code> for specifying external audio.</li> <li><code>-video_source</code> for specifying Single-Source Mode source.</li> <li><code>-input_framerate</code> for handling input framerate in Real-time Frames Mode.</li> <li><code>-bpp</code> attribute for handling bits-per-pixels used to auto-calculate video-bitrate.</li> <li><code>-gop</code> to manually specify GOP length.</li> <li><code>-ffmpeg_download_path</code> to handle custom FFmpeg download path on windows.</li> <li><code>-clear_prev_assets</code> to remove any previous copies of SteamGear Assets.</li> </ul> </li> </ul> </li> <li>New StreamGear docs, MPEG-DASH demo, and recommended DASH players list:<ul> <li>Added new StreamGear docs, usage examples, parameters, references, new FAQs.</li> <li>Added Several StreamGear usage examples w.r.t Mode of Operation.</li> <li>Implemented Clappr based on Shaka-Player, as Demo Player.</li> <li>Added Adaptive-dimensional behavior for Demo-player, purely in css.</li> <li>Hosted StreamGear generated DASH chunks on GitHub and served with <code>raw.githack.com</code>.</li> <li>Introduced variable quality level-selector plugin for Clapper Player.</li> <li>Provide various required javascripts and implemented additional functionality for player in <code>extra.js</code>.</li> <li>Recommended tested Online, Command-line and GUI Adaptive Stream players.</li> <li>Implemented separate FFmpeg installation doc for StreamGear API.</li> <li>Reduced <code>rebufferingGoal</code> for faster response.</li> </ul> </li> <li>New StreamGear CI tests:<ul> <li>Added IO and API initialization CI tests for its Modes.</li> <li>Added various mode Streaming check CI tests.</li> </ul> </li> </ul> </li> <li> NetGear_Async API:<ul> <li>Added new <code>send_terminate_signal</code> internal method.</li> <li>Added <code>WindowsSelectorEventLoopPolicy()</code> for windows 3.8+ envs.</li> <li>Moved Client auto-termination to separate method.</li> <li>Implemented graceful termination with <code>signal</code> API on UNIX machines.</li> <li>Added new <code>timeout</code> attribute for controlling Timeout in Connections.</li> <li>Added missing termination optimizer (<code>linger=0</code>) flag.</li> <li>Several ZMQ Optimizer Flags added to boost performance.</li> </ul> </li> <li> WriteGear API:<ul> <li>Added support for adding duplicate FFmpeg parameters to <code>output_params</code>:<ul> <li>Added new <code>-clones</code> attribute in <code>output_params</code> parameter for handing this behavior..</li> <li>Support to pass FFmpeg parameters as list, while maintaining the exact order it was specified.</li> <li>Built support for <code>zmq.REQ/zmq.REP</code> and <code>zmq.PUB/zmq.SUB</code> patterns in this mode.</li> <li>Added new CI tests debugging this behavior.</li> <li>Updated docs accordingly.</li> </ul> </li> <li>Added support for Networks URLs in Compression Mode:<ul> <li><code>output_filename</code> parameter supports Networks URLs in compression modes only</li> <li>Added automated handling of non path/file Networks URLs as input.</li> <li>Implemented new <code>is_valid_url</code> helper method to easily validate assigned URLs value.</li> <li>Validates whether the given URL value has scheme/protocol supported by assigned/installed ffmpeg or not. </li> <li>WriteGear will throw <code>ValueError</code> if <code>-output_filename</code> is not supported.</li> <li>Added related CI tests and docs.</li> </ul> </li> <li>Added <code>disable_force_termination</code> attribute in WriteGear to disable force-termination.</li> </ul> </li> <li> NetGear API:<ul> <li>Added option to completely disable Native Frame-Compression:<ul> <li>Checks if any Incorrect/Invalid value is assigned on <code>compression_format</code> attribute.</li> <li>Completely disables Native Frame-Compression.</li> <li>Updated docs accordingly.</li> </ul> </li> </ul> </li> <li> CamGear API:<ul> <li>Added new and robust regex for identifying YouTube URLs.</li> <li>Moved <code>youtube_url_validator</code> to Helper.</li> </ul> </li> <li> New <code>helper.py</code> methods: <ul> <li>Added <code>validate_video</code> function to validate video_source.</li> <li>Added <code>extract_time</code> Extract time from give string value.</li> <li>Added <code>get_video_bitrate</code> to calculate video birate from resolution, framerate, bits-per-pixels values.</li> <li>Added <code>delete_safe</code> to safely delete files of given extension.</li> <li>Added <code>validate_audio</code> to validate audio source.</li> <li>Added new Helper CI tests.<ul> <li>Added new <code>check_valid_mpd</code> function to test MPD files validity.</li> <li>Added <code>mpegdash</code> library to CI requirements.</li> </ul> </li> </ul> </li> <li> Deployed New Docs Upgrades:<ul> <li>Added new assets like images, gifs, custom scripts, javascripts fonts etc. for achieving better visual graphics in docs.</li> <li>Added <code>clappr.min.js</code>, <code>dash-shaka-playback.js</code>, <code>clappr-level-selector.min.js</code> third-party javascripts locally.</li> <li>Extended Overview docs Hyperlinks to include all major sub-pages (such as Usage Examples, Reference, FAQs etc.).</li> <li>Replaced GIF with interactive MPEG-DASH Video Example in Stabilizer Docs. </li> <li>Added new <code>pymdownx.keys</code> to replace <code>[Ctrl+C]/[\u2318+C]</code> formats.</li> <li>Added new <code>custom.css</code> stylescripts variables for fluid animations in docs.</li> <li>Overridden announce bar and added donation button. </li> <li>Lossless WEBP compressed all PNG assets for faster loading.</li> <li>Enabled lazy-loading for GIFS and Images for performance.</li> <li>Reimplemented Admonitions contexts and added new ones.</li> <li>Added StreamGear and its different modes Docs Assets.</li> <li>Added patch for images &amp; unicodes for PiP flavored markdown in <code>setup.py</code>.</li> </ul> </li> <li> Added <code>Request Info</code> and <code>Welcome</code> GitHub Apps to automate PR and issue workflow<ul> <li>Added new <code>config.yml</code> for customizations.</li> <li>Added various suitable configurations.</li> </ul> </li> <li> Added new <code>-clones</code> attribute to handle FFmpeg parameter clones in StreamGear and WriteGear API.</li> <li> Added new Video-only and Audio-Only sources in bash script.</li> <li> Added new paths in bash script for storing StreamGear &amp; WriteGear assets temporarily.</li> </ul> Updates/Improvements <ul> <li> Added patch for <code>NotImplementedError</code> in NetGear_Async API on Windows 3.8+ envs.</li> <li> Check for valid <code>output</code> file extension according to <code>format</code> selected in StreamGear.</li> <li> Completed migration to <code>travis.com</code>.</li> <li> Created new <code>temp_write</code> temp directory for WriteGear Assets in bash script.</li> <li> Deleted old Redundant assets and added new ones.</li> <li> Employed <code>isort</code> library to sort and group imports in Vidgear APIs.</li> <li> Enabled exception for <code>list, tuple, int, float</code> in WriteGear API's <code>output_params</code> dict.</li> <li> Enabled missing support for frame-compression in its primary Receive Mode.</li> <li> Enforced pixel formats for streams.</li> <li> Improved check for valid system path detection in WriteGear API.</li> <li> Overrided <code>pytest-asyncio</code> fixture in NetGear_Async API.</li> <li> Quoted Gear Headline for understanding each gear easily. </li> <li> Re-Positioned Gear's banner images in overview for better readability.</li> <li> Reduced redundant try-except blocks in NetGear Async.</li> <li> Reformatted and Simplified Docs context.</li> <li> Reimplemented <code>return_testvideo_path</code> CI function with variable streams.</li> <li> Reimplemented <code>skip_loop</code> in NetGear_Async to fix <code>asyncio.CancelledError</code>.</li> <li> Reimplemented buggy audio handler in StreamGear.</li> <li> Reimplemented images with <code>&lt;figure&gt;</code> and <code>&lt;figurecaption&gt;</code> like tags.</li> <li> Removed Python &lt; 3.8 condition from all CI tests.</li> <li> Removed or Grouped redundant code for increasing codecov.</li> <li> Removed redundant code and simplified algorithmic complexities in Gears.</li> <li> Replaced <code>;nbsp</code> with <code>;thinsp</code> and <code>;emsp</code>.</li> <li> Replaced <code>IOError</code> with more reliable <code>RuntimeError</code> in StreamGear Pipelines.</li> <li> Replaced <code>del</code> with <code>pop</code> in dicts.</li> <li> Replaced all Netgear CI tests with more reliable <code>try-except-final</code> blocks.</li> <li> Replaced simple lists with <code>pymdownx.tasklist</code>.</li> <li> Replaced subprocess <code>call()</code> with <code>run()</code> for better error handling in <code>execute_ffmpeg_cmd</code> function.</li> <li> Resized over-sized docs images. </li> <li> Simplified <code>delete_safe</code> Helper function.</li> <li> Simplified default audio-bitrate logic in StreamGear</li> <li> Updated CI tests and cleared redundant code from NetGear_Async API.</li> <li> Updated CI with new tests and Bumped Codecov.</li> <li> Updated Issue and PR templates.</li> <li> Updated Licenses for new files and shrink images dimensions.</li> <li> Updated Missing Helpful tips and increased logging.</li> <li> Updated PR guidelines for more clarity.</li> <li> Updated WebGear examples addresses from <code>0.0.0.0</code> to <code>localhost</code>.</li> <li> Updated WriteGear and StreamGear CI tests for not supporting temp directory.</li> <li> Updated <code>README.md</code> and <code>changelog.md</code> with new changes.</li> <li> Updated <code>check_output</code> and added <code>force_retrieve_stderr</code> support to <code>**kwargs</code> to extract <code>stderr</code> output even on FFmpeg  error.</li> <li> Updated <code>dicts2args</code> to support internal repeated <code>coreX</code> FFmpeg parameters for StreamGear. </li> <li> Updated <code>mkdocs.yml</code>, <code>changelog.md</code> and <code>README.md</code> with latest changes.</li> <li> Updated <code>validate_audio</code> Helper function will now retrieve audio-bitrate for validation.</li> <li> Updated buggy <code>mpegdash</code> dependency with custom dev fork for Windows machines.</li> <li> Updated core parameters for audio handling.</li> <li> Updated logging for debugging selected eventloops in NetGear_Async API.</li> <li> Updated termination linger to zero at Server's end.</li> </ul> Breaking Updates/Changes <ul> <li> Changed Webgear API default address to <code>localhost</code> for cross-compatibility between different platforms.</li> <li> In Netgear_Async API, <code>source</code> value can now be NoneType for a custom frame-generator at Server-end only.</li> <li> Temp (such as <code>/tmp</code> in linux) is now not a valid directory for WriteGear &amp; StreamGear API outputs.</li> <li> Moved vidgear docs assets (i.e images, gifs, javascripts and stylescripts) to <code>override</code> directory.</li> </ul> Bug-fixes <ul> <li> Added workaround for system path not handle correctly.</li> <li> Fixed Bug: URL Audio format not being handled properly.</li> <li> Fixed Critical Bug in NetGear_Async throwing <code>ValueError</code> with None-type Source.</li> <li> Fixed Critical StreamGear Bug: FFmpeg pipeline terminating prematurely in Single-Source Mode.</li> <li> Fixed Critical external audio handler bug: moved audio-input to input_parameters.</li> <li> Fixed Frozen-threads bug in CI tests.</li> <li> Fixed Mkdocs only accepting Relative paths.</li> <li> Fixed OSError in WriteGear's compression mode.</li> <li> Fixed StreamGear CI bugs for Windows and CI envs.</li> <li> Fixed Typos and Indentation bugs in NetGear API.</li> <li> Fixed ZMQ throwing error on termination if all max-tries exhausted.</li> <li> Fixed <code>NameError</code> bug in NetGear API and CI tests.</li> <li> Fixed <code>TimeoutError</code> bug in NetGear_Async CI tests.</li> <li> Fixed <code>get_valid_ffmpeg_path</code> throwing <code>TypeError</code> with non-string values.</li> <li> Fixed broken links in docs. </li> <li> Fixed critical duplicate logging bug.</li> <li> Fixed default <code>gop</code> value not handle correctly.</li> <li> Fixed handling of incorrect paths detection.</li> <li> Fixed incorrect definitions in NetGear_Async.</li> <li> Fixed left-over attribute bug in WriteGear.</li> <li> Fixed logic and indentation bugs in CI tests.</li> <li> Fixed logic for handling output parameters in WriteGear API.</li> <li> Fixed missing definitions and logic bug in StreamGear.</li> <li> Fixed missing import and incorrect CI definitions. </li> <li> Fixed missing source dimensions from <code>extract_resolutions</code> output in StreamGear API.</li> <li> Fixed missing support for compression parameters in Multi-Clients Mode.</li> <li> Fixed round off error in FPS.</li> <li> Fixed several CI bugs and updated <code>extract_resolutions</code> method.</li> <li> Fixed several bugs from CI Bidirectional Mode tests.</li> <li> Fixed several typos in docs usage examples.</li> <li> Fixed various <code>AttributeError</code> with wrong attribute names and definition in CI Helper functions.</li> <li> Fixed wrong and missing definitions in docs.</li> <li> Fixed wrong logic for extracting OpenCV frames.</li> <li> Fixed wrong type bug in StreamGear API.</li> <li> Fixed wrong type error bug in WriteGear API.</li> <li> Fixed wrong variable assignments bug in WriteGear API.</li> <li> Fixes to CLI tests and missing docs imports.</li> <li> Many minor typos and wrong definitions.</li> </ul> Pull Requests <ul> <li>PR #129</li> <li>PR #130</li> <li>PR #155</li> </ul>"},{"location":"changelog/#v018-2020-06-12","title":"v0.1.8 (2020-06-12)","text":"New Features <ul> <li> NetGear API:<ul> <li>Multiple Clients support:<ul> <li>Implemented support for handling any number of Clients simultaneously with a single Server in this mode.</li> <li>Added new <code>multiclient_mode</code> attribute for enabling this mode easily.</li> <li>Built support for <code>zmq.REQ/zmq.REP</code> and <code>zmq.PUB/zmq.SUB</code> patterns in this mode.</li> <li>Implemented ability to receive data from all Client(s) along with frames with <code>zmq.REQ/zmq.REP</code> pattern only.</li> <li>Updated related CI tests</li> </ul> </li> <li>Support for robust Lazy Pirate pattern(auto-reconnection) in NetGear API for both server and client ends:<ul> <li>Implemented a algorithm where NetGear rather than doing a blocking receive, will now:<ul> <li>Poll the socket and receive from it only when it's sure a reply has arrived.</li> <li>Attempt to reconnect, if no reply has arrived within a timeout period.</li> <li>Abandon the connection if there is still no reply after several requests.</li> </ul> </li> <li>Implemented its default support for <code>REQ/REP</code> and <code>PAIR</code> messaging patterns internally.</li> <li>Added new <code>max_retries</code> and <code>request_timeout</code>(in seconds) for handling polling.</li> <li>Added <code>DONTWAIT</code> flag for interruption-free data receiving.</li> <li>Both Server and Client can now reconnect even after a premature termination.</li> </ul> </li> <li>Performance Updates:<ul> <li>Added default Frame Compression support for Bidirectional frame transmission in Bidirectional mode.</li> <li>Added support for <code>Reducer()</code> function in Helper.py to aid reducing frame-size on-the-go for more performance.</li> <li>Added small delay in <code>recv()</code> function at client's end to reduce system load. </li> <li>Reworked and Optimized NetGear termination, and also removed/changed redundant definitions and flags.</li> </ul> </li> </ul> </li> <li> Docs: Migration to Mkdocs<ul> <li>Implemented a beautiful, static documentation site based on MkDocs which will then be hosted on GitHub Pages.</li> <li>Crafted base mkdocs with third-party elegant &amp; simplistic <code>mkdocs-material</code> theme.</li> <li>Implemented new <code>mkdocs.yml</code> for Mkdocs with relevant data.</li> <li>Added new <code>docs</code> folder to handle markdown pages and its assets.</li> <li>Added new Markdown pages(<code>.md</code>) to docs folder, which are carefully crafted documents - [x] based on previous Wiki's docs, and some completely new additions.</li> <li>Added navigation under tabs for easily accessing each document.</li> <li>New Assets:<ul> <li>Added new assets like gifs, images, custom scripts, favicons, site.webmanifest etc. for bringing standard and quality to docs visual design.</li> <li>Designed brand new logo and banner for VidGear Documents.</li> <li>Deployed all assets under separate Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License.</li> </ul> </li> <li>Added Required Plugins and Extensions:<ul> <li>Added support for all pymarkdown-extensions.</li> <li>Added support for some important <code>admonition</code>, <code>attr_list</code>, <code>codehilite</code>, <code>def_list</code>, <code>footnotes</code>, <code>meta</code>, and <code>toc</code> like Mkdocs extensions.</li> <li>Enabled <code>search</code>, <code>minify</code> and <code>git-revision-date-localized</code> plugins support.</li> <li>Added various VidGear's social links to yaml.</li> <li>Added support for <code>en</code> (English) language.</li> </ul> </li> <li>Auto-Build API Reference with <code>mkdocstrings:</code><ul> <li>Added support for <code>mkdocstrings</code> plugin for auto-building each VidGear's API references.</li> <li>Added python handler for parsing python source-code to <code>mkdocstrings</code>.</li> </ul> </li> <li>Auto-Deploy Docs with GitHub Actions:<ul> <li>Implemented Automated Docs Deployment on gh-pages through GitHub Actions workflow.</li> <li>Added new workflow yaml with minimal configuration for automated docs deployment.</li> <li>Added all required  python dependencies and environment for this workflow.</li> <li>Added <code>master</code> branch on Ubuntu machine to build matrix.</li> </ul> </li> </ul> </li> </ul> Updates/Improvements <ul> <li> Added in-built support for bidirectional frames(<code>NDarray</code>) transfer in Bidirectional mode.</li> <li> Added support for User-Defined compression params in Bidirectional frames transfer.</li> <li> Added workaround for <code>address already in use</code> bug at client's end.</li> <li> Unified Bidirectional and Multi-Clients mode for client's return data transmission.</li> <li> Replaced <code>ValueError</code> with more suitable <code>RuntimeError</code>.</li> <li> Updated logging for better readability.</li> <li> Added CI test for Multi-Clients mode.</li> <li> Reformatted and grouped imports in VidGear.</li> <li> Added <code>Reducer</code> Helper function CI test.</li> <li> Added Reliability tests for both Server and Client end.</li> <li> Disabled reliable reconnection for Multi-Clients mode.</li> <li> Replaced <code>os.devnull</code> with suprocess's inbuilt function.</li> <li> Updated README.md, Issue and PR templates with new information and updates.</li> <li> Moved <code>changelog.md</code> to <code>/docs</code> and updated contribution guidelines.</li> <li> Improved source-code docs for compatibility with <code>mkdocstrings</code>.</li> <li> Added additional dependency <code>mkdocs-exclude</code>, for excluding files from Mkdocs builds.</li> <li> Updated license and compressed images/diagrams.</li> <li> Added new CI tests and Bumped Codecov.</li> <li> Changed YouTube video URL for CI tests to Creative Commons(CC) video.</li> <li> Removed redundant code.</li> </ul> Breaking Updates/Changes <ul> <li> VidGear Docs moved to GitHub Pages, Now Available at https://abhitronix.github.io/vidgear.</li> <li> Removed <code>filter</code> attribute from <code>options</code> parameter in NetGear API.</li> <li> Removed <code>force_terminate</code> parameter support from NetGear API.</li> <li> Disabled additional data of datatype <code>numpy.ndarray</code> for Server end in Bidirectional Mode.</li> </ul> Bug-fixes <ul> <li> Fixed <code>'NoneType' object is not subscriptable</code> bug.</li> <li> Fixed bugs related to delayed termination in NetGear API.</li> <li> Reduced default <code>request_timeout</code> value to 4 and also lowered cut-off limit for the same.</li> <li> Removed redundant ZMQ context termination and similar variables.</li> <li> Added missing VidGear installation in workflow.</li> <li> Excluded conflicting assets <code>README.md</code> from Mkdocs builds.</li> <li> Fixed <code>pattern</code> value check bypassed if wrong value is assigned.</li> <li> Fixed incorrect handling of additional data transferred in synchronous mode at both Server and Client end.</li> <li> Replaced Netgear CI test with more reliable <code>try-except-final</code> blocks.</li> <li> Updated termination linger to zero at Server's end.</li> <li> Fixed <code>NameError</code> bug in NetGear API.</li> <li> Fixed missing support for compression parameters in Multi-Clients Mode.</li> <li> Fixed ZMQ throwing error on termination if all max-tries exhausted.</li> <li> Enabled missing support for frame compression in its primary receive mode.</li> <li> Fixed several bugs from CI Bidirectional Mode tests.</li> <li> Removed or Grouped redundant code for increasing codecov.</li> <li> Fixed Mkdocs only accepting Relative paths.</li> <li> Fixed broken links in docs. </li> <li> Fixed round off error in FPS.</li> <li> Many small typos and bugs fixes.</li> </ul> Pull Requests <ul> <li>PR #129</li> <li>PR #130</li> </ul>"},{"location":"changelog/#v017-2020-04-29","title":"v0.1.7 (2020-04-29)","text":"New Features <ul> <li> WebGear API:<ul> <li>Added a robust Live Video Server API that can transfer live video frames to any web browser on the network in real-time.</li> <li>Implemented a flexible asyncio wrapper around <code>starlette</code> ASGI Application Server.</li> <li>Added seamless access to various starlette's Response classes, Routing tables, Static Files, Template engine(with Jinja2), etc.</li> <li>Added a special internal access to VideoGear API and all its parameters.</li> <li>Implemented a new Auto-Generation Work-flow to generate/download &amp; thereby validate WebGear API data files from its GitHub server automatically.</li> <li>Added on-the-go dictionary parameter in WebGear to tweak performance, Route Tables and other internal properties easily.</li> <li>Added new simple &amp; elegant default Bootstrap Cover Template for WebGear Server.</li> <li>Added <code>__main__.py</code> to directly run WebGear Server through the terminal.</li> <li>Added new gif and related docs for WebGear API.</li> <li>Added and Updated various CI tests for this API.</li> </ul> </li> <li> NetGear_Async API: <ul> <li>Designed NetGear_Async asynchronous network API built upon ZeroMQ's asyncio API.</li> <li>Implemented support for state-of-the-art asyncio event loop <code>uvloop</code> at its backend.</li> <li>Achieved Unmatchable high-speed and lag-free video streaming over the network with minimal resource constraint.</li> <li>Added exclusive internal wrapper around VideoGear API for this API.</li> <li>Implemented complete server-client handling and options to use variable protocols/patterns for this API.</li> <li>Implemented support for  all four ZeroMQ messaging patterns: i.e <code>zmq.PAIR</code>, <code>zmq.REQ/zmq.REP</code>, <code>zmq.PUB/zmq.SUB</code>, and <code>zmq.PUSH/zmq.PULL</code>.</li> <li>Implemented initial support for <code>tcp</code> and <code>ipc</code> protocols.</li> <li>Added new Coverage CI tests for NetGear_Async Network Gear.</li> <li>Added new Benchmark tests for benchmarking NetGear_Async against NetGear.</li> </ul> </li> <li> Asynchronous Enhancements: <ul> <li>Added <code>asyncio</code> package to for handling asynchronous APIs.</li> <li>Moved WebGear API(webgear.py) to <code>asyncio</code> and created separate asyncio <code>helper.py</code> for it.</li> <li>Various Performance tweaks for Asyncio APIs with concurrency within a single thread.</li> <li>Moved <code>__main__.py</code> to asyncio for easier access to WebGear API through the terminal.</li> <li>Updated <code>setup.py</code> with new dependencies and separated asyncio dependencies.</li> </ul> </li> <li> General Enhancements:<ul> <li>Added new highly-precise Threaded FPS class for accurate benchmarking with <code>time.perf_counter</code> python module.</li> <li>Added a new Gitter community channel.</li> <li>Added a new Reducer function to reduce the frame size on-the-go.</li> <li>Add Flake8 tests to Travis CI to find undefined names. (PR by @cclauss)</li> <li>Added a new unified <code>logging handler</code> helper function for vidgear.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Re-implemented and simplified logic for NetGear Async server-end.</li> <li> Added new dependencies for upcoming asyncio updates to <code>setup.py</code>.</li> <li> Added <code>retry</code> function and replaced <code>wget</code> with <code>curl</code> for Linux test envs. </li> <li> Bumped OpenCV to latest <code>4.2.0-dev</code> for Linux test envs.</li> <li> Updated YAML files to reflect new changes to different CI envs.</li> <li> Separated each API logger with a common helper method to avoid multiple copies. </li> <li> Limited Importing OpenCV API version check's scope to <code>helper.py</code> only.</li> <li> Implemented case for incorrect <code>color_space</code> value in ScreenGear API.</li> <li> Removed old conflicting logging formatter with a common method and expanded logging.</li> <li> Improved and added <code>shutdown</code> function for safely stopping frame producer threads in WebGear API.</li> <li> Re-implemented and simplified all CI tests with maximum code-coverage in mind.</li> <li> Replaced old <code>mkdir</code> function with new <code>mkdir_safe</code> helper function for creating directories safely.</li> <li> Updated ReadMe.md with updated diagrams, gifs and information.</li> <li> Improve, structured and Simplified the Contribution Guidelines.</li> <li> Bundled CI requirements in a single command.(Suggested by @cclauss)</li> <li> Replaced line endings CRLF with LF endings.</li> <li> Added dos2unix for Travis OSX envs.</li> <li> Bumped Codecov to maximum. </li> </ul> Breaking Updates/Changes <ul> <li> Dropped support for Python 3.5 and below legacies. (See issue #99)</li> <li> Dropped and replaced Python 3.5 matrices with new Python 3.8 matrices in all CI environments.</li> <li> Implemented PEP-8 Styled Black formatting throughout the source-code.</li> <li> Limited protocols support to <code>tcp</code> and <code>ipc</code> only, in NetGear API.</li> </ul> Bug-fixes <ul> <li> Fixed Major NetGear_Async bug where <code>__address</code> and <code>__port</code> are not set in async mode.(PR by @otter-in-a-suit) </li> <li> Fixed Major PiGear Color-space Conversion logic bug.</li> <li> Workaround for <code>CAP_IMAGES</code> error in YouTube Mode.</li> <li> Replaced incorrect <code>terminate()</code> with <code>join()</code> in PiGear.</li> <li> Removed <code>uvloop</code> for windows as still NOT yet supported.</li> <li> Refactored Asynchronous Package name <code>async</code> to <code>asyncio</code>, since it is used as Keyword in python&gt;=3.7 (raises SyntaxError).</li> <li> Fixed unfinished close of event loops bug in WebGear API.</li> <li> Fixed NameError in helper.py.</li> <li> Added fix for OpenCV installer failure on Linux test envs.</li> <li> Fixed undefined NameError in <code>helper.py</code> context. (@cclauss)</li> <li> Fixed incorrect logic while pulling frames from ScreenGear API.</li> <li> Fixed missing functions in <code>__main__.py</code>.</li> <li> Fixed Typos and definitions in docs.</li> <li> Added missing <code>camera_num</code> parameter to VideoGear.</li> <li> Added OpenSSL's [SSL: CERTIFICATE_VERIFY_FAILED] bug workaround for macOS envs.</li> <li> Removed <code>download_url</code> meta from setup.py.</li> <li> Removed PiGear from CI completely due to hardware emulation limitation.</li> <li> Removed VideoCapture benchmark tests for macOS envs.</li> <li> Removed trivial <code>__main__.py</code> from codecov.</li> <li> Removed several redundant <code>try-catch</code> loops.</li> <li> Renamed <code>youtube_url_validation</code> as <code>youtube_url_validator</code>.</li> <li> Several minor wrong/duplicate variable definitions and various bugs fixed.</li> <li> Fixed, Improved &amp; removed many Redundant CI tests for various APIs.</li> </ul> Pull Requests <ul> <li>PR #88</li> <li>PR #91</li> <li>PR #93</li> <li>PR #95</li> <li>PR #98</li> <li>PR #101</li> <li>PR #114</li> <li>PR #118</li> <li>PR #124</li> </ul> New Contributors <ul> <li>@cclauss</li> <li>@chollinger93</li> </ul>"},{"location":"changelog/#v016-2020-01-01","title":"v0.1.6 (2020-01-01)","text":"New Features <ul> <li> NetGear API:<ul> <li>Added powerful ZMQ Authentication &amp; Data Encryption features for NetGear API:<ul> <li>Added exclusive <code>secure_mode</code> param for enabling it.</li> <li>Added support for two most powerful <code>Stonehouse</code> &amp; <code>Ironhouse</code> ZMQ security mechanisms.</li> <li>Added smart auth-certificates/key generation and validation features.</li> </ul> </li> <li>Implemented Robust Multi-Servers support for NetGear API:<ul> <li>Enables Multiple Servers messaging support with a single client.</li> <li>Added exclusive <code>multiserver_mode</code> param for enabling it.</li> <li>Added support for <code>REQ/REP</code> &amp;  <code>PUB/SUB</code> patterns for this mode.</li> <li>Added ability to send additional data of any datatype along with the frame in realtime in this mode.</li> </ul> </li> <li>Introducing exclusive Bidirectional Mode for bidirectional data transmission:<ul> <li>Added new <code>return_data</code> parameter to <code>recv()</code> function.</li> <li>Added new <code>bidirectional_mode</code> attribute for enabling this mode.</li> <li>Added support for <code>PAIR</code> &amp; <code>REQ/REP</code> patterns for this mode</li> <li>Added support for sending data of any python datatype.</li> <li>Added support for <code>message</code> parameter for non-exclusive primary modes for this mode.</li> </ul> </li> <li>Implemented compression support with on-the-fly flexible frame encoding for the Server-end:<ul> <li>Added initial support for <code>JPEG</code>, <code>PNG</code> &amp; <code>BMP</code> encoding formats .</li> <li>Added exclusive options attribute <code>compression_format</code> &amp; <code>compression_param</code> to tweak this feature.</li> <li>Client-end will now decode frame automatically based on the encoding as well as support decoding flags.</li> </ul> </li> <li>Added <code>force_terminate</code> attribute flag for handling force socket termination at the Server-end if there's latency in the network. </li> <li>Implemented new Publish/Subscribe(<code>zmq.PUB/zmq.SUB</code>) pattern for seamless Live Streaming in NetGear API.</li> </ul> </li> <li> PiGear API:<ul> <li>Added new threaded internal timing function for PiGear to handle any hardware failures/frozen threads.</li> <li>PiGear will not exit safely with <code>SystemError</code> if Picamera ribbon cable is pulled out to save resources.</li> <li>Added support for new user-defined <code>HWFAILURE_TIMEOUT</code> options attribute to alter timeout.</li> </ul> </li> <li> VideoGear API: <ul> <li>Added <code>framerate</code> global variable and removed redundant function.</li> <li>Added <code>CROP_N_ZOOM</code> attribute in Videogear API for supporting Crop and Zoom stabilizer feature.</li> </ul> </li> <li> WriteGear API: <ul> <li>Added new <code>execute_ffmpeg_cmd</code> function to pass a custom command to its FFmpeg pipeline.</li> </ul> </li> <li> Stabilizer class: <ul> <li>Added new Crop and Zoom feature.<ul> <li>Added <code>crop_n_zoom</code> param for enabling this feature.</li> </ul> </li> <li>Updated docs.</li> </ul> </li> <li> CI &amp; Tests updates:<ul> <li>Replaced python 3.5 matrices with latest python 3.8 matrices in Linux environment.</li> <li>Added full support for Codecov in all CI environments.</li> <li>Updated OpenCV to v4.2.0-pre(master branch). </li> <li>Added various Netgear API tests.</li> <li>Added initial Screengear API test.</li> <li>More test RTSP feeds added with better error handling in CamGear network test.</li> <li>Added tests for ZMQ authentication certificate generation.</li> <li>Added badge and Minor doc updates.</li> </ul> </li> <li> Added VidGear's official native support for MacOS environments.</li> </ul> Updates/Improvements <ul> <li> Replace <code>print</code> logging commands with python's logging module completely.</li> <li> Implemented encapsulation for class functions and variables on all gears.</li> <li> Updated support for screen casting from multiple/all monitors in ScreenGear API.</li> <li> Updated ScreenGear API to use Threaded Queue Mode by default, thereby removed redundant <code>THREADED_QUEUE_MODE</code> param.</li> <li> Updated bash script path to download test dataset in <code>$TMPDIR</code> rather than <code>$HOME</code> directory for downloading testdata.</li> <li> Implemented better error handling of colorspace in various videocapture APIs.</li> <li> Updated bash scripts, Moved FFmpeg static binaries to <code>github.com</code>.</li> <li> Updated bash scripts, Added additional flag to support un-secure apt sources.</li> <li> CamGear API will now throw <code>RuntimeError</code> if source provided is invalid.</li> <li> Updated threaded Queue mode in CamGear API for more robust performance.</li> <li> Added new <code>camera_num</code> to support multiple Picameras.</li> <li> Moved thread exceptions to the main thread and then re-raised.</li> <li> Added alternate github mirror for FFmpeg static binaries auto-installation on windows oses.</li> <li> Added <code>colorlog</code> python module for presentable colored logging.</li> <li> Replaced <code>traceback</code> with <code>sys.exc_info</code>.</li> <li> Overall APIs Code and Docs optimizations.</li> <li> Updated Code Readability and Wiki Docs.</li> <li> Updated ReadMe &amp; Changelog with the latest changes.</li> <li> Updated Travis CI Tests with support for macOS environment.</li> <li> Reformatted &amp; implemented necessary MacOS related changes and dependencies in <code>travis.yml</code>.</li> </ul> Breaking Updates/Changes <ul> <li> Python 2.7 legacy support dropped completely.</li> <li> Source-code Relicensed to Apache 2.0 License.</li> <li> Python 3+ are only supported legacies for installing v0.1.6 and above.</li> <li> Python 2.7 and 3.4 legacies support dropped from CI tests.</li> </ul> Bug-fixes <ul> <li> Reimplemented <code>Pub/Sub</code> pattern for smoother performance on various networks.</li> <li> Fixed Assertion error in CamGear API during colorspace manipulation.</li> <li> Fixed random freezing in <code>Secure Mode</code> and several related performance updates</li> <li> Fixed <code>multiserver_mode</code> not working properly over some networks.</li> <li> Fixed assigned Port address ignored bug (commit 073bca1).</li> <li> Fixed several wrong definition bugs from NetGear API(commit 8f7153c).</li> <li> Fixed unreliable dataset video URL(rehosted file on <code>github.com</code>).</li> <li> Disabled <code>overwrite_cert</code> for client-end in NetGear API.</li> <li> Disabled Universal Python wheel builds in <code>setup.cfg</code>file.</li> <li> Removed duplicate code to import MSS(@BoboTiG) from ScreenGear API.</li> <li> Eliminated unused redundant code blocks from library.</li> <li> Fixed Code indentation in <code>setup.py</code> and updated new release information.</li> <li> Fixed code definitions &amp; Typos.</li> <li> Fixed several bugs related to <code>secure_mode</code> &amp; <code>multiserver_mode</code> Modes.</li> <li> Fixed various macOS environment bugs.</li> </ul> Pull Requests <ul> <li> PR #39</li> <li> PR #42</li> <li> PR #44</li> <li> PR #52</li> <li> PR #55</li> <li> PR #62</li> <li> PR #67</li> <li> PR #72</li> <li> PR #77</li> <li> PR #78</li> <li> PR #82</li> <li> PR #84</li> </ul> New Contributors <ul> <li>@BoboTiG</li> </ul>"},{"location":"changelog/#v015-2019-07-24","title":"v0.1.5 (2019-07-24)","text":"New Features <ul> <li> Added new ScreenGear API, supports Live ScreenCasting.</li> <li> Added new NetGear API, aids real-time frame transfer through messaging(ZmQ) over network.</li> <li> Added new new Stabilizer Class, for minimum latency Video Stabilization with OpenCV.</li> <li> Added Option to use API's standalone.</li> <li> Added Option to use VideoGear API as internal wrapper around Stabilizer Class.</li> <li> Added new parameter <code>stabilize</code> to API, to enable or disable Video Stabilization.</li> <li> Added support for <code>**option</code> dict attributes to update VidGear's video stabilizer parameters directly. </li> <li> Added brand new logo and functional block diagram (<code>.svg</code>) in readme.md</li> <li> Added new pictures and GIFs for improving readme.md readability </li> <li> Added new <code>contributing.md</code> and <code>changelog.md</code> for reference.</li> <li> Added <code>collections.deque</code> import in Threaded Queue Mode for performance consideration</li> <li> Added new <code>install_opencv.sh</code> bash scripts for Travis cli, to handle OpenCV installation.</li> <li> Added new Project Issue &amp; PR Templates</li> <li> Added new Sponsor Button(<code>FUNDING.yml</code>)</li> </ul> Updates/Improvements <ul> <li> Updated New dependencies: <code>mss</code>, <code>pyzmq</code> and rejected redundant ones.</li> <li> Revamped and refreshed look for <code>readme.md</code> and added new badges.</li> <li> Updated Releases Documentation completely.</li> <li> Updated CI tests for new changes</li> <li> Updated Code Documentation.</li> <li> Updated bash scripts and removed redundant information</li> <li> Updated <code>Youtube video</code> URL in tests</li> <li> Completely Reformatted and Updated Wiki Docs with new changes.</li> </ul> Breaking Updates/Changes <ul> <li> Implemented experimental Threaded Queue Mode(a.k.a Blocking Mode) for fast, synchronized, error-free multi-threading.</li> <li> Renamed bash script <code>pre-install.sh</code> to <code>prepare_dataset.sh</code> - [x] downloads opensourced test datasets and static FFmpeg binaries for debugging.</li> <li> Changed <code>script</code> folder location to <code>bash/script</code>.</li> <li> <code>Python 3.4</code> removed from Travis CI tests.</li> </ul> Bug-fixes <ul> <li> Temporarily fixed Travis CI bug: Replaced <code>opencv-contrib-python</code> with OpenCV built from scratch as dependency.</li> <li> Fixed CI Timeout Bug: Disable Threaded Queue Mode for CI Tests</li> <li> Fixes** <code>sys.stderr.close()</code> throws ValueError bug: Replaced <code>sys.close()</code> with <code>DEVNULL.close()</code></li> <li> Fixed Youtube Live Stream bug that return <code>NonType</code> frames in CamGear API.</li> <li> Fixed <code>NoneType</code> frames bug in  PiGear class on initialization.</li> <li> Fixed Wrong function definitions</li> <li> Removed <code>/xe2</code> unicode bug from Stabilizer class.</li> <li> Fixed <code>**output_params</code> KeyError bug in WriteGear API</li> <li> Fixed subprocess not closing properly on exit in WriteGear API.</li> <li> Fixed bugs in ScreenGear: Non-negative <code>monitor</code> values</li> <li> Fixed missing import, typos, wrong variable definitions</li> <li> Removed redundant hack from <code>setup.py</code></li> <li> Fixed Minor YouTube playback Test CI Bug </li> <li> Fixed new Twitter Intent</li> <li> Fixed bug in bash script that not working properly due to changes at server end.</li> </ul> Pull Requests <ul> <li> PR #17</li> <li> PR #21</li> <li> PR #22</li> <li> PR #27</li> <li> PR #31</li> <li> PR #32</li> <li> PR #33</li> <li> PR #34</li> </ul>"},{"location":"changelog/#v014-2019-05-11","title":"v0.1.4 (2019-05-11)","text":"New Features <ul> <li> Added new WriteGear API: for enabling lossless video encoding and compression(built around FFmpeg and OpenCV Video Writer)</li> <li> Added YouTube Mode for direct Video Pipelining from YouTube in CamGear API</li> <li> Added new <code>y_tube</code> to access YouTube Mode in CamGear API.</li> <li> Added flexible Output file Compression control capabilities in compression-mode(WriteGear).</li> <li> Added <code>-output_dimensions</code> special parameter to WriteGear API.</li> <li> Added new <code>helper.py</code> to handle special helper functions.</li> <li> Added feature to auto-download and configure FFmpeg Static binaries(if not found) on Windows platforms.</li> <li> Added <code>-input_framerate</code> special parameter to WriteGear class to change/control output constant framerate in compression mode(WriteGear).</li> <li> Added new Direct Video colorspace Conversion capabilities in CamGear and PiGear API.</li> <li> Added new <code>framerate</code> class variable for CamGear API, to retrieve input framerate.</li> <li> Added new parameter <code>backend</code> - [x] changes the backend of CamGear's API</li> <li> Added automatic required prerequisites installation ability, when installation from source.</li> <li> Added Travis CI Complete Integration for Linux-based Testing for VidGear.</li> <li> Added and configured <code>travis.yml</code></li> <li> Added Appveyor CI Complete Integration for Windows-based Testing in VidGear.</li> <li> Added and configured new <code>appveyor.yml</code></li> <li> Added new bash script <code>pre-install.sh</code> to download opensourced test datasets and static FFmpeg binaries for debugging.</li> <li> Added several new Tests(including Benchmarking Tests) for each API for testing with <code>pytest</code>.</li> <li> Added license to code docs.</li> <li> Added <code>Say Thank you!</code> badge to <code>Readme.md</code>.</li> </ul> Updates/Improvements <ul> <li> Removed redundant dependencies</li> <li> Updated <code>youtube-dl</code> as a dependency, as required by <code>pafy</code>'s backend.</li> <li> Updated common VideoGear API with new parameter.</li> <li> Update robust algorithm to auto-detect FFmpeg executables and test them, if failed, auto fallback to OpenCV's VideoWriter API. </li> <li> Improved system previously installed OpenCV detection in setup.py.</li> <li> Updated setup.py with hack to remove bullets from pypi description. </li> <li> Updated Code Documentation</li> <li> Reformatted &amp; Modernized readme.md with new badges.</li> <li> Reformatted and Updated Wiki Docs.</li> </ul> Breaking Updates/Changes <ul> <li> Removed <code>-height</code> and <code>-width</code> parameter from CamGear API.</li> <li> Replaced dependency <code>opencv-python</code> with <code>opencv-contrib-python</code> completely</li> </ul> Bug-fixes <ul> <li> Windows Cross-Platform fix: replaced dependency <code>os</code> with <code>platform</code> in setup.py.</li> <li> Fixed Bug: Arises due to spaces in input <code>**options</code>/<code>**output_param</code> dictionary keys.</li> <li> Fixed several wrong/missing variable &amp; function definitions.</li> <li> Fixed code uneven indentation.</li> <li> Fixed several typos in docs.</li> </ul> Pull Requests <ul> <li> PR #7</li> <li> PR #8</li> <li> PR #10</li> <li> PR #12</li> </ul>"},{"location":"changelog/#v013-2019-04-07","title":"v0.1.3 (2019-04-07)","text":"Bug-fixes <ul> <li> Patched Major PiGear Bug: Incorrect import of PiRGBArray function in PiGear Class</li> <li> Several Fixes for backend <code>picamera</code> API handling during frame capture(PiGear)</li> <li> Fixed missing frame variable initialization.</li> <li> Fixed minor typos</li> </ul> Pull Requests <ul> <li> PR #6</li> <li> PR #5</li> </ul>"},{"location":"changelog/#v012-2019-03-27","title":"v0.1.2 (2019-03-27)","text":"New Features <ul> <li> Added easy Source manipulation feature in CamGear API, to control features like <code>resolution, brightness, framerate etc.</code></li> <li> Added new <code>**option</code> parameter to CamGear API, provides the flexibility to manipulate input stream directly.</li> <li> Added new parameters for Camgear API for time delay and logging.</li> <li> Added new Logo to readme.md</li> <li> Added new Wiki Documentation.</li> </ul> Updates/Improvements <ul> <li> Reformatted readme.md.</li> <li> Updated Wiki Docs with new changes.</li> </ul> Bug-fixes <ul> <li> Improved Error Handling in CamGear &amp; PiGear API.</li> <li> Fixed minor typos in docs.</li> </ul> Pull Requests <ul> <li> PR #4</li> </ul>"},{"location":"changelog/#v011-2019-03-24","title":"v0.1.1 (2019-03-24)","text":"New Features <ul> <li> Release ViGear binaries on the Python Package Index (PyPI)</li> <li> Added new and configured <code>setup.py</code> &amp; <code>setup.cfg</code></li> </ul> Bug-fixes <ul> <li> Fixed PEP bugs: added and configured properly <code>__init__.py</code> in each folder </li> <li> Fixed PEP bugs: improved code Indentation</li> <li> Fixed wrong imports: replaced <code>distutils.core</code> with <code>setuptools</code></li> <li> Fixed readme.md</li> </ul>"},{"location":"changelog/#v010-2019-03-17","title":"v0.1.0 (2019-03-17)","text":"New Features <ul> <li> Initial Release</li> <li> Converted my <code>imutils</code> PR into Python Project.</li> <li> Renamed conventions and reformatted complete source-code from scratch.</li> <li> Added support for both python 2.7 and 3 legacies</li> <li> Added new multi-threaded CamGear, PiGear, and VideoGear APIs</li> <li> Added multi-platform compatibility</li> <li> Added robust &amp; flexible control over the source in PiGear API.</li> </ul>"},{"location":"contribution/","title":"Contribution Overview","text":""},{"location":"contribution/#contribution-overview","title":"Contribution Overview","text":"<p>Contributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features!</p> <p>Contribution Opportunities </p> <p>If you're looking for something to work on, check for the PR WELCOMED  labeled issues on our GitHub Repository.</p> <p> </p>"},{"location":"contribution/#submission-guidelines","title":"Submission Guidelines","text":"<ul> <li>Submitting an Issue Guidelines \u27b6</li> <li>Submitting Pull Request(PR) Guidelines \u27b6</li> </ul>"},{"location":"contribution/#submission-contexts","title":"Submission Contexts","text":""},{"location":"contribution/#got-a-question-or-problem","title":"Got a question or problem?","text":"<p>For quick questions, please refrain from opening an issue, instead read our FAQ &amp; Troubleshooting section or you can reach us on Gitter community channel.</p>"},{"location":"contribution/#found-a-typo","title":"Found a typo?","text":"<p>There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time. </p>"},{"location":"contribution/#found-a-bug","title":"Found a bug?","text":"<p>If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6.</p>"},{"location":"contribution/#request-for-a-featureimprovement","title":"Request for a feature/improvement?","text":"Subscribe to Github Repository <p>You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in VidGear. Learn more about it here \u27b6</p> <p>You can request our GitHub Repository for a new feature/improvement based on the type of request:</p> <p>Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community.</p> <ul> <li> <p>Major Feature Requests: If you require a major feature for VidGear, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! </p> </li> <li> <p>Minor Feature Requests:  Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.</p> </li> </ul> <p> </p>"},{"location":"gears/","title":"Introduction","text":"Gears: generalized workflow"},{"location":"gears/#gears-what-are-these","title":"Gears , What are these?","text":"<p>VidGear is built on Standalone APIs - also known as Gears, each with some unique functionality. Each Gears is designed exclusively to handle/control/process different data-specific &amp; device-specific video streams, network streams, and media encoders/decoders. </p> <p>Gears allows users to work with an inherently optimized, easy-to-use, extensible, and exposed API Framework on top of many state-of-the-art libraries, while silently delivering robust error handling and unmatched real-time performance.</p>"},{"location":"gears/#gears-classification","title":"Gears Classification","text":"<p>These Gears can be classified as follows:</p>"},{"location":"gears/#a-videocapture-gears","title":"A. VideoCapture Gears","text":"<p>Basic Function: Retrieves <code>numpy.ndarray</code> frames from various sources.</p> <ul> <li>CamGear: Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs.</li> <li>PiGear: Multi-Threaded API targeting various Raspberry-Pi Camera Modules.</li> <li>ScreenGear: Multi-Threaded API targeting ultra-fast Screencasting.    </li> <li>VideoGear: Common Video-Capture API with internal Video Stabilizer wrapper. </li> </ul>"},{"location":"gears/#b-videowriter-gears","title":"B. VideoWriter Gears","text":"<p>Basic Function: Writes <code>numpy.ndarray</code> frames to a video file or network stream.</p> <ul> <li>WriteGear: Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.</li> </ul>"},{"location":"gears/#c-streaming-gears","title":"C. Streaming Gears","text":"<p>Basic Function: Transcodes/Broadcasts files and <code>numpy.ndarray</code> frames for streaming.</p> <p>You can also use WriteGear for  streaming with traditional protocols such as RTMP, RTSP/RTP.</p> <ul> <li> <p>StreamGear: Handles Transcoding of High-Quality, Dynamic &amp; Adaptive Streaming Formats.</p> </li> <li> <p>Asynchronous I/O Streaming Gear:</p> <ul> <li> <p>WebGear: ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network.</p> </li> <li> <p>WebGear_RTC: Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.</p> </li> </ul> </li> </ul>"},{"location":"gears/#d-network-gears","title":"D. Network Gears","text":"<p>Basic Function: Sends/Receives data and <code>numpy.ndarray</code> frames over connected networks.</p> <ul> <li> <p>NetGear: Handles High-Performance Video-Frames &amp; Data Transfer between interconnecting systems over the network.</p> </li> <li> <p>Asynchronous I/O Network Gear:</p> <ul> <li>NetGear_Async: Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.</li> </ul> </li> </ul> <p> </p>"},{"location":"help/","title":"Helping VidGear","text":"<p>Liked VidGear? Would you like to help VidGear, other users, and the author?</p> <p>There are many simple ways to help us:</p> <p> </p>"},{"location":"help/#star-vidgear-on-github","title":"Star VidGear on GitHub","text":"<p>You can star  VidGear on GitHub: </p> <p>It helps us a lot by making it easier for others to find &amp; trust this library. Thanks!</p> <p> </p>"},{"location":"help/#help-others-with-issues-on-github","title":"Help others with issues on GitHub","text":"<p>You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: </p> <p> </p>"},{"location":"help/#watch-the-github-repository","title":"Watch the GitHub repository","text":"<p>You can watch \ud83d\udc40 VidGear Activities on GitHub: </p> <p>When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request.</p> <p>You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.</p> <p> </p>"},{"location":"help/#tweet-about-vidgear","title":"Tweet about VidGear","text":"<p>Tweet about VidGear and Spread the word \ud83d\udde3:</p> <p>Tweet #vidgear</p> <p>Let others know how you are using VidGear and why you like it!</p> <p> </p>"},{"location":"help/#helping-author","title":"Helping Author","text":"<p>Donations help keep VidGear's development alive and motivate me (as author). </p> <p>It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference </p> kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); <p>Thanks a million! </p> <p> </p>"},{"location":"help/#connect-with-author","title":"Connect with Author","text":"<p>You can connect with me, the author \ud83d\udc4b:</p> <p></p> <ul> <li>Follow author on GitHub: </li> <li>Follow author on Twitter: Follow @abhi_una12</li> <li>Get in touch with author on Linkedin: </li> </ul> <p> </p>"},{"location":"installation/","title":"Installation Overview","text":""},{"location":"installation/#installation-overview","title":"Installation Overview","text":""},{"location":"installation/#supported-systems","title":"Supported Systems","text":"<p>VidGear is well-tested and supported on the following systems(but not limited to), with python 3.7+ and pip installed:</p> <ul> <li>Any  Linux distro released in 2016 or later</li> <li> Windows 7 or later</li> <li> MacOS 10.12.6 (Sierra) or later</li> </ul> <p> </p>"},{"location":"installation/#supported-python-legacies","title":"Supported Python legacies","text":"<p>Depreciation Notice</p> <p>Python-3.6 legacies support has been dropped from Vidgear.</p> <p> Python 3.7+ are only supported legacies for installing Vidgear v0.2.5 and above.</p> <p> </p>"},{"location":"installation/#installation-methods","title":"Installation methods","text":"<ul> <li>Install using pip (recommended)</li> <li>Install from source</li> </ul>"},{"location":"license/","title":"License","text":"<p>This library is released under the Apache 2.0 License.</p>"},{"location":"license/#copyright-notice","title":"Copyright Notice","text":"<pre><code>Copyright (c) 2019 Abhishek Thakur(@abhiTronix) &lt;abhi.una12@gmail.com&gt;\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"switch_from_cv/","title":"Switching from OpenCV","text":""},{"location":"switch_from_cv/#switching-from-opencv-library","title":"Switching from OpenCV Library","text":"<p>Switching OpenCV with VidGear APIs is fairly painless process, and will just require changing a few lines in your python script. </p> <p>This document is intended to software developers who want to migrate their python code from OpenCV Library to VidGear APIs.</p> <p>Prior knowledge of Python or OpenCV won't be covered in this guide. Proficiency with OpenCV-Python (Python API for OpenCV) is a must in order understand this document.</p> <p>If you're just getting started with OpenCV-Python programming, then refer this FAQ \u27b6</p> <p> </p>"},{"location":"switch_from_cv/#why-vidgear-is-better-than-opencv","title":"Why VidGear is better than OpenCV?","text":"<p>Learn more about OpenCV here \u27b6</p> <p>VidGear employs OpenCV at its backend and enhances its existing capabilities even further by introducing many new state-of-the-art functionalities such as:</p> <ul> <li> Accelerated Multi-Threaded Performance.</li> <li> Out-of-the-box support for OpenCV APIs.</li> <li> Real-time Stabilization ready.</li> <li> Lossless hardware enabled video encoding and transcoding.</li> <li> Inherited multi-backend support for various video sources and devices.</li> <li> Screen-casting, Multi-bitrate network-streaming, and way much more \u27b6</li> </ul> <p>Vidgear offers all this at once while maintaining the same standard OpenCV-Python (Python API for OpenCV) coding syntax for all of its APIs, thereby making it even easier to implement complex real-time OpenCV applications in python code without changing things much.</p> <p> </p>"},{"location":"switch_from_cv/#switching-the-videocapture-apis","title":"Switching the VideoCapture APIs","text":"<p>Let's compare a bare-minimum python code for extracting frames out of any Webcam/USB-camera (connected at index 0), between OpenCV's VideoCapture Class and VidGear's CamGear VideoCapture API side-by-side:</p> <p>CamGear API share the same syntax as other VideoCapture APIs, thereby you can easily switch to any of those APIs in a similar manner.</p> OpenCV VideoCapture ClassVidGear's CamGear API <pre><code># import required libraries\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p>and both syntax almost looks the same, easy, isn't it?</p> <p> </p>"},{"location":"switch_from_cv/#differences","title":"Differences","text":"<p>Let's breakdown a few noteworthy difference in both syntaxes:</p> Task OpenCV VideoCapture Class VidGear's CamGear API Initiating <code>stream = cv2.VideoCapture(0)</code> <code>stream = CamGear(source=0).start()</code> Reading frames <code>(grabbed, frame) = stream.read()</code> <code>frame = stream.read()</code> Checking empty frame <code>if not grabbed:</code> <code>if frame is None:</code> Terminating <code>stream.release()</code> <code>stream.stop()</code> <p>Now checkout other VideoCapture Gears \u27b6</p> <p> </p> <p> </p>"},{"location":"switch_from_cv/#switching-the-videowriter-api","title":"Switching the VideoWriter API","text":"<p>Let's extend previous bare-minimum python code and save those extracted frames to disk as a valid file, with OpenCV's VideoWriter Class and VidGear's WriteGear (with FFmpeg backend), compared side-to-side:</p> <p>WriteGear API also provides backend for OpenCV's VideoWriter Class. More information here \u27b6</p> OpenCV VideoWriter ClassVidGear's WriteGear API <pre><code># import required libraries\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n# Define the codec and create VideoWriter object with suitable output \n# filename for e.g. `Output.avi`\nfourcc = cv2.VideoWriter_fourcc(*'XVID') \nwriter = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480)) \n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close writer\nwriter.release() \n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n# Define WriteGear Object with suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output = 'Output.mp4') \n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p>Noticed WriteGear's coding syntax looks similar but less complex?</p> <p> </p>"},{"location":"switch_from_cv/#differences_1","title":"Differences","text":"<p>Let's breakdown a few noteworthy difference in both syntaxes:</p> Task OpenCV VideoWriter Class VidGear's WriteGear API Initiating <code>writer = cv2.VideoWriter('output.avi', cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))</code> <code>writer = WriteGear(output='Output.mp4')</code> Writing frames <code>writer.write(frame)</code> <code>writer.write(frame)</code> Terminating <code>writer.release()</code> <code>writer.close()</code> <p>Now checkout more about WriteGear API here \u27b6</p> <p> </p>"},{"location":"bonus/TQM/","title":"Threaded Queue Mode","text":""},{"location":"bonus/TQM/#overview","title":"Overview","text":"Threaded-Queue-Mode: generalized timing diagram <p>Threaded Queue Mode is designed exclusively for VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and few Network Gears (such as NetGear(Client's end)) for achieving high-performance, asynchronous, error-free video-frames handling. </p> <p>Threaded-Queue-Mode is enabled by default, but can be disabled, only if extremely necessary.</p> <p>Threaded-Queue-Mode is NOT required and thereby automatically disabled for Live feed such as Camera Devices/Modules, since .</p> <p> </p>"},{"location":"bonus/TQM/#what-does-threaded-queue-mode-exactly-do","title":"What does Threaded-Queue-Mode exactly do?","text":"<p>Threaded-Queue-Mode helps VidGear do the Threaded Video-Processing tasks in highly optimized, well-organized, and most competent way possible: </p>"},{"location":"bonus/TQM/#a-enables-multi-threading","title":"A. Enables Multi-Threading","text":"<p>In case you don't already know, OpenCV's' <code>read()</code> is a Blocking I/O function for reading and decoding the next video-frame, and consumes much of the I/O bound memory depending upon our video source properties &amp; system hardware. This essentially means, the corresponding thread that reads data from it, is continuously blocked from retrieving the next frame. As a result, our python program appears slow and sluggish even without any type of computationally expensive image processing operations. This problem is far more severe on low memory SBCs like Raspberry Pis.</p> <p>In Threaded-Queue-Mode, VidGear creates several Python Threads within one process to offload the frame-decoding task to a different thread. Thereby,  VidGear is able to execute different Video I/O-bounded operations at the same time by overlapping there waiting times. Moreover,  threads are managed by operating system itself and is capable of distributing them between available CPU cores efficiently. In this way, Threaded-Queue-Mode keeps on processing frames faster in the background without affecting by sluggishness in our main python program thread.</p>"},{"location":"bonus/TQM/#b-utilizes-fixed-size-queues","title":"B. Utilizes Fixed-Size Queues","text":"<p>Although Multi-threading is fast, easy, and efficient, it can lead to some serious undesired effects like frame-skipping, Global Interpreter Lock, race conditions, etc. This is because there is no isolation whatsoever in python threads, and in case there is any crash it will cause the whole process to crash. That's not all, the memory of the process is shared by different threads and that may result in random process crashes due to unwanted race conditions.</p> <p>These problems are avoided in Threaded-Queue-Mode by utilizing Thread-Safe, Memory-Efficient, and Fixed-Size <code>Queues</code> (with approximately same O(1) performance in both directions), that isolates the frame-decoding thread from other parallel threads and provide synchronized access to incoming frames without any obstruction. </p>"},{"location":"bonus/TQM/#c-accelerates-frame-processing","title":"C. Accelerates Frame Processing","text":"<p>With queues, VidGear always maintains a fixed-length frames buffer in the memory and blocks the thread temporarily if the queue is full to avoid possible frame drops or otherwise pops out the frames synchronously without any obstructions. This significantly accelerates frame processing rate (and therefore our overall video processing pipeline) comes from dramatically reducing latency \u2014 since we don\u2019t have to wait for the <code>read()</code> method to finish reading and decoding a frame; instead, there is always a pre-decoded frame ready for us to process.</p> <p> </p>"},{"location":"bonus/TQM/#what-are-the-advantages-of-threaded-queue-mode","title":"What are the advantages of Threaded-Queue-Mode?","text":"<ul> <li> <p> Enables Blocking, Sequential and Threaded LIFO Frame Handling.</p> </li> <li> <p> Sequentially adds and releases frames from <code>queues</code> and handles the overflow.</p> </li> <li> <p> Utilizes thread-safe, memory efficient <code>queues</code> that appends and pops frames with same O(1) performance from either side.</p> </li> <li> <p> Faster frame access due to buffered frames in the <code>queue</code>.</p> </li> <li> <p> Provides isolation for source thread and prevents GIL.</p> </li> </ul> <p> </p>"},{"location":"bonus/TQM/#manually-disabling-threaded-queue-mode","title":"Manually disabling Threaded-Queue-Mode","text":"<p>To manually disable Threaded-Queue-Mode, VidGear provides <code>THREADED_QUEUE_MODE</code> boolean attribute for <code>options</code> dictionary parameter in respective VideoCapture APIs:  </p> <p>Important Warnings</p> <ul> <li> <p>Disabling Threaded-Queue-Mode does NOT disables Multi-Threading.</p> </li> <li> <p><code>THREADED_QUEUE_MODE</code> attribute does NOT work with Live feed, such as Camera Devices/Modules.</p> </li> <li> <p><code>THREADED_QUEUE_MODE</code> attribute is NOT supported by ScreenGear &amp; NetGear APIs, as Threaded Queue Mode is essential for their core operations.</p> </li> </ul> <p>Disabling Threaded-Queue-Mode may lead to Random Intermittent Bugs that can be quite difficult to discover. More insight can be found here \u27b6</p> <p><code>THREADED_QUEUE_MODE</code> (boolean): This attribute can be used to override Threaded-Queue-Mode mode to manually disable it:</p> <pre><code>options = {'THREADED_QUEUE_MODE': False} # to disable Threaded Queue Mode. \n</code></pre> <p>and you can pass it to <code>options</code> dictionary parameter of the respective API.</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/","title":"Colorspace Manipulation for VideoCapture Gears","text":""},{"location":"bonus/colorspace_manipulation/#source-colorspace-manipulation","title":"Source ColorSpace manipulation","text":"<p>All VidGear's Videocapture Gears (namely CamGear, ScreenGear, VideoGear) and some Streaming Gears (namely WebGear, WebGear_RTC) and Network Gears (Client's end) - provides exclusive internal support for Source Color Space manipulation. </p> <p>There are two ways to alter source colorspace:</p>"},{"location":"bonus/colorspace_manipulation/#using-colorspace-parameter","title":"Using <code>colorspace</code> parameter","text":"<p>Primarily, the safest way is by <code>colorspace</code> (string) parameter of the respective VideoCapture API, that can be used to easily alter the colorspace of the input source, during initialization. But on the downside, <code>colorspace</code> parameter value CANNOT be changed/altered at runtime. </p> <p>All possible values for this parameter are discussed below \u27b6</p>"},{"location":"bonus/colorspace_manipulation/#using-color_space-global-variable","title":"Using <code>color_space</code> global variable","text":"<p>Alternatively, a more direct approach is by using <code>color_space</code> (integer) global variable the respective VideoCapture API, can be used for directly changing the source colorspace at runtime. It can be used in conjunction with <code>colorspace</code> parameter easily. </p> <p> </p> <p>Supported Colorspace Conversions</p> <p>Any conversion from default Source colorspace (i.e. BGR in case of OpenCV), to any other colorspace and vice-versa (use <code>None</code> to revert), is supported.</p> <p>Important Information</p> <ul> <li> <p>Using <code>color_space</code> global variable is NOT Supported in VideoGear API, calling it will result in <code>AttribueError</code>.</p> </li> <li> <p>Any incorrect or None-type value, will immediately revert the colorspace to default (i.e. <code>BGR</code>).</p> </li> <li> <p>Using <code>color_space</code> global variable with Threaded Queue Mode may have minor lag, User discretion is advised.</p> </li> </ul> <p>Tip</p> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#supported-colorspace-parameter-values","title":"Supported <code>colorspace</code> parameter values","text":"<p>All supported string values for <code>colorspace</code> parameter are as follows:</p> <p>You can check all OpenCV Colorspace Conversion Codes here \u27b6.</p> Supported Conversion Values Description COLOR_BGR2BGRA BGR to BGRA COLOR_BGR2RGBA BGR to RGBA COLOR_BGR2RGB BGR to RGB backward conversions to RGB/BGR COLOR_BGR2GRAY BGR to GRAY COLOR_BGR2BGR565 BGR to BGR565 COLOR_BGR2BGR555 BGR to BGR555 COLOR_BGR2XYZ BGR to CIE XYZ COLOR_BGR2YCrCb BGR to luma-chroma (aka YCC) COLOR_BGR2HSV BGR to HSV (hue saturation value) COLOR_BGR2Lab BGR to CIE Lab COLOR_BGR2Luv BGR to CIE Luv COLOR_BGR2HLS BGR to HLS (hue lightness saturation) COLOR_BGR2HSV_FULL BGR to HSV_FULL COLOR_BGR2HLS_FULL BGR to HLS_FULL COLOR_BGR2YUV BGR to YUV COLOR_BGR2YUV_I420 BGR to YUV 4:2:0 family COLOR_BGR2YUV_IYUV BGR to IYUV COLOR_BGR2YUV_YV12 BGR to YUV_YV12 None Back to default colorspace (i.e. BGR) <p> </p>"},{"location":"bonus/colorspace_manipulation/#usage-examples","title":"Usage examples","text":""},{"location":"bonus/colorspace_manipulation/#using-camgear-with-direct-colorspace-manipulation","title":"Using CamGear with Direct Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#using-pigear-with-direct-colorspace-manipulation","title":"Using PiGear with Direct Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#using-videogear-with-colorspace-manipulation","title":"Using VideoGear with Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/colorspace_manipulation/#using-screengear-with-direct-colorspace-manipulation","title":"Using ScreenGear with Direct Colorspace Manipulation","text":"<p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"bonus/reference/camgear/","title":"CamGear API","text":"<p>CamGear API usage examples can be found here \u27b6</p> <p>CamGear API parameters are explained here \u27b6</p> <p>CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rtsp, rtmp, mms, etc. It also supports Gstreamer's RAW pipelines.</p> <p>CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters. It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.</p> <p>CamGear internally implements <code>yt_dlp</code> backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Dailymotion, Twitch, and many more \u27b6</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>class CamGear:\n\"\"\"\n    CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested),\n    any network stream URL such as http(s), rtp, rtsp, rtmp, mms, etc. It also supports Gstreamer's RAW pipelines.\n    CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters.\n    It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.\n    CamGear internally implements `yt_dlp` backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Dailymotion,\n    Twitch, and [many more \u27b6](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites)\n    \"\"\"\ndef __init__(\nself,\nsource=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the CamGear class.\n        Parameters:\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Source Tweak Parameters.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\n# initialize global\nself.ytv_metadata = {}\n# check if Stream-Mode is ON (True)\nif stream_mode:\n# check GStreamer backend support\ngst_support = check_gstreamer_support(logging=logging)\n# handle special Stream Mode parameters\nstream_resolution = get_supported_resolution(\noptions.pop(\"STREAM_RESOLUTION\", \"best\"), logging=logging\n)\n# handle Stream-Mode\nif not (yt_dlp is None):\n# extract user-defined params\nyt_stream_params = options.pop(\"STREAM_PARAMS\", {})\nif isinstance(yt_stream_params, dict):\nyt_stream_params = {\nstr(k).strip(): v for k, v in yt_stream_params.items()\n}\nelse:\nyt_stream_params = {}\ntry:\n# Validate source for Yt_dlp backend\nlogger.info(\n\"Verifying Streaming URL using yt-dlp backend. Please wait...\"\n)\n# initialize YT_backend\nytbackend = YT_backend(\nsource_url=source, logging=logging, **yt_stream_params\n)\nif ytbackend:\n# save video metadata\nself.ytv_metadata = ytbackend.meta_data\n# handle live-streams\nif ytbackend.is_livestream:\n# Throw warning for livestreams\nlogger.warning(\n\"Livestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\"\n)\n# check whether stream-resolution was specified and available\nif not (stream_resolution in ytbackend.streams.keys()):\nlogger.warning(\n\"Specified stream-resolution `{}` is not available. Reverting to `best`!\".format(\nstream_resolution\n)\n)\n# revert to best\nstream_resolution = \"best\"\nelse:\nif self.__logging:\nlogger.debug(\n\"Using `{}` resolution for streaming.\".format(\nstream_resolution\n)\n)\n# extract stream URL as source using stream-resolution\nsource = ytbackend.streams[stream_resolution]\n# log progress\nself.__logging and logger.debug(\n\"YouTube source ID: `{}`, Title: `{}`, Quality: `{}`\".format(\nself.ytv_metadata[\"id\"],\nself.ytv_metadata[\"title\"],\nstream_resolution,\n)\n)\nexcept Exception as e:\n# raise error if something went wrong\nraise ValueError(\n\"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\"\n)\nelse:\n# raise import errors\nimport_dependency_safe(\"yt_dlp\")\n# youtube mode variable initialization\nself.__youtube_mode = stream_mode\n# assigns special parameter to global variable and clear\n# Threaded Queue Mode\nself.__threaded_queue_mode = options.pop(\"THREADED_QUEUE_MODE\", True)\nif not isinstance(self.__threaded_queue_mode, bool):\n# reset improper values\nself.__threaded_queue_mode = True\n# Thread Timeout\nself.__thread_timeout = options.pop(\"THREAD_TIMEOUT\", None)\nif self.__thread_timeout and isinstance(self.__thread_timeout, (int, float)):\n# set values\nself.__thread_timeout = float(self.__thread_timeout)\nelse:\n# defaults to 5mins timeout\nself.__thread_timeout = None\nself.__queue = None\n# initialize queue for video files only\nif self.__threaded_queue_mode and isinstance(source, str):\n# define queue and assign it to global var\nself.__queue = queue.Queue(maxsize=96)  # max bufferlen 96 to check overflow\n# log it\nself.__logging and logger.debug(\n\"Enabling Threaded Queue Mode for the current video source!\"\n)\nelse:\n# otherwise disable it\nself.__threaded_queue_mode = False\n# log it\nself.__logging and logger.warning(\n\"Threaded Queue Mode is disabled for the current video source!\"\n)\nif self.__thread_timeout:\nlogger.debug(\n\"Setting Video-Thread Timeout to {}s.\".format(self.__thread_timeout)\n)\n# stream variable initialization\nself.stream = None\nif backend and isinstance(backend, int):\n# add backend if specified and initialize the camera stream\nif check_CV_version() == 3:\n# Different OpenCV 3.4.x statement\nself.stream = cv2.VideoCapture(source + backend)\nelse:\n# Two parameters are available since OpenCV 4+ (master branch)\nself.stream = cv2.VideoCapture(source, backend)\nlogger.debug(\"Setting backend `{}` for this source.\".format(backend))\nelse:\n# initialize the camera stream\nself.stream = cv2.VideoCapture(source)\n# initializing colorspace variable\nself.color_space = None\n# apply attributes to source if specified\noptions = {str(k).strip(): v for k, v in options.items()}\nfor key, value in options.items():\nproperty = capPropId(key)\nif not (property is None):\nself.stream.set(property, value)\n# handle colorspace value\nif not (colorspace is None):\nself.color_space = capPropId(colorspace.strip())\nif self.__logging and not (self.color_space is None):\nlogger.debug(\n\"Enabling `{}` colorspace for this video stream!\".format(\ncolorspace.strip()\n)\n)\n# initialize and assign frame-rate variable\nself.framerate = 0.0\n_fps = self.stream.get(cv2.CAP_PROP_FPS)\nif _fps &gt; 1.0:\nself.framerate = _fps\n# applying time delay to warm-up webcam only if specified\nif time_delay and isinstance(time_delay, (int, float)):\ntime.sleep(time_delay)\n# frame variable initialization\n(grabbed, self.frame) = self.stream.read()\n# check if valid stream\nif grabbed:\n# render colorspace if defined\nif not (self.color_space is None):\nself.frame = cv2.cvtColor(self.frame, self.color_space)\nif self.__threaded_queue_mode:\n# initialize and append to queue\nself.__queue.put(self.frame)\nelse:\nraise RuntimeError(\n\"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\"\n)\n# thread initialization\nself.__thread = None\n# initialize termination flag event\nself.__terminate = Event()\n# initialize stream read flag event\nself.__stream_read = Event()\ndef start(self):\n\"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon.\n        **Returns:** A reference to the CamGear class object.\n        \"\"\"\nself.__thread = Thread(target=self.__update, name=\"CamGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\nreturn self\ndef __update(self):\n\"\"\"\n        A **Threaded Frames Extractor**, that keep iterating frames from OpenCV's VideoCapture API to a internal monitored queue,\n        until the thread is terminated, or frames runs out.\n        \"\"\"\n# keep iterating infinitely\n# until the thread is terminated\n# or frames runs out\n# if the thread indicator variable is set, stop the thread\nwhile not self.__terminate.is_set():\n# stream not read yet\nself.__stream_read.clear()\n# otherwise, read the next frame from the stream\n(grabbed, frame) = self.stream.read()\n# stream read completed\nself.__stream_read.set()\n# check for valid frame if received\nif not grabbed:\n# no frames received, then safely exit\nif self.__threaded_queue_mode:\nif self.__queue.empty():\nbreak\nelse:\ncontinue\nelse:\nbreak\n# apply colorspace to frames if valid\nif not (self.color_space is None):\ncolor_frame = None\ntry:\nif isinstance(self.color_space, int):\ncolor_frame = cv2.cvtColor(frame, self.color_space)\nelse:\nraise ValueError(\n\"Global color_space parameter value `{}` is not a valid!\".format(\nself.color_space\n)\n)\nexcept Exception as e:\n# Catch if any error occurred\nself.color_space = None\nif self.__logging:\nlogger.exception(str(e))\nlogger.warning(\"Input colorspace is not a valid colorspace!\")\nif not (color_frame is None):\nself.frame = color_frame\nelse:\nself.frame = frame\nelse:\nself.frame = frame\n# append to queue\nif self.__threaded_queue_mode:\nself.__queue.put(self.frame)\n# signal queue we're done\nself.__threaded_queue_mode and self.__queue.put(None)\nself.__threaded_queue_mode = False\n# indicate immediate termination\nself.__terminate.set()\nself.__stream_read.set()\n# release resources\nself.stream.release()\ndef read(self):\n\"\"\"\n        Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory,\n        and blocks the thread if the queue is full.\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\nwhile self.__threaded_queue_mode and not self.__terminate.is_set():\nreturn self.__queue.get(timeout=self.__thread_timeout)\n# return current frame\n# only after stream is read\nreturn (\nself.frame\nif not self.__terminate.is_set()  # check if already terminated\nand self.__stream_read.wait(timeout=self.__thread_timeout)  # wait for it\nelse None\n)\ndef stop(self):\n\"\"\"\n        Safely terminates the thread, and release the VideoStream resources.\n        \"\"\"\nself.__logging and logger.debug(\"Terminating processes.\")\n# terminate Threaded queue mode separately\nself.__threaded_queue_mode = False\n# indicate that the thread\n# should be terminated immediately\nself.__stream_read.set()\nself.__terminate.set()\n# wait until stream resources are released (producer thread might be still grabbing frame)\nif self.__thread is not None:\nif not (self.__queue is None):\nwhile not self.__queue.empty():\ntry:\nself.__queue.get_nowait()\nexcept queue.Empty:\ncontinue\nself.__queue.task_done()\nself.__thread.join()\n</code></pre> <p> </p>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.__init__","title":"<code>__init__(self, source=0, stream_mode=False, backend=0, colorspace=None, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the CamGear class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>0</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive Stream Mode for handling streaming URLs.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Source Tweak Parameters.</p> <code>{}</code> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def __init__(\nself,\nsource=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the CamGear class.\n    Parameters:\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive **Stream Mode** for handling streaming URLs.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Source Tweak Parameters.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\n# initialize global\nself.ytv_metadata = {}\n# check if Stream-Mode is ON (True)\nif stream_mode:\n# check GStreamer backend support\ngst_support = check_gstreamer_support(logging=logging)\n# handle special Stream Mode parameters\nstream_resolution = get_supported_resolution(\noptions.pop(\"STREAM_RESOLUTION\", \"best\"), logging=logging\n)\n# handle Stream-Mode\nif not (yt_dlp is None):\n# extract user-defined params\nyt_stream_params = options.pop(\"STREAM_PARAMS\", {})\nif isinstance(yt_stream_params, dict):\nyt_stream_params = {\nstr(k).strip(): v for k, v in yt_stream_params.items()\n}\nelse:\nyt_stream_params = {}\ntry:\n# Validate source for Yt_dlp backend\nlogger.info(\n\"Verifying Streaming URL using yt-dlp backend. Please wait...\"\n)\n# initialize YT_backend\nytbackend = YT_backend(\nsource_url=source, logging=logging, **yt_stream_params\n)\nif ytbackend:\n# save video metadata\nself.ytv_metadata = ytbackend.meta_data\n# handle live-streams\nif ytbackend.is_livestream:\n# Throw warning for livestreams\nlogger.warning(\n\"Livestream URL detected. It is advised to use GStreamer backend(`cv2.CAP_GSTREAMER`) with it.\"\n)\n# check whether stream-resolution was specified and available\nif not (stream_resolution in ytbackend.streams.keys()):\nlogger.warning(\n\"Specified stream-resolution `{}` is not available. Reverting to `best`!\".format(\nstream_resolution\n)\n)\n# revert to best\nstream_resolution = \"best\"\nelse:\nif self.__logging:\nlogger.debug(\n\"Using `{}` resolution for streaming.\".format(\nstream_resolution\n)\n)\n# extract stream URL as source using stream-resolution\nsource = ytbackend.streams[stream_resolution]\n# log progress\nself.__logging and logger.debug(\n\"YouTube source ID: `{}`, Title: `{}`, Quality: `{}`\".format(\nself.ytv_metadata[\"id\"],\nself.ytv_metadata[\"title\"],\nstream_resolution,\n)\n)\nexcept Exception as e:\n# raise error if something went wrong\nraise ValueError(\n\"[CamGear:ERROR] :: Stream Mode is enabled but Input URL is invalid!\"\n)\nelse:\n# raise import errors\nimport_dependency_safe(\"yt_dlp\")\n# youtube mode variable initialization\nself.__youtube_mode = stream_mode\n# assigns special parameter to global variable and clear\n# Threaded Queue Mode\nself.__threaded_queue_mode = options.pop(\"THREADED_QUEUE_MODE\", True)\nif not isinstance(self.__threaded_queue_mode, bool):\n# reset improper values\nself.__threaded_queue_mode = True\n# Thread Timeout\nself.__thread_timeout = options.pop(\"THREAD_TIMEOUT\", None)\nif self.__thread_timeout and isinstance(self.__thread_timeout, (int, float)):\n# set values\nself.__thread_timeout = float(self.__thread_timeout)\nelse:\n# defaults to 5mins timeout\nself.__thread_timeout = None\nself.__queue = None\n# initialize queue for video files only\nif self.__threaded_queue_mode and isinstance(source, str):\n# define queue and assign it to global var\nself.__queue = queue.Queue(maxsize=96)  # max bufferlen 96 to check overflow\n# log it\nself.__logging and logger.debug(\n\"Enabling Threaded Queue Mode for the current video source!\"\n)\nelse:\n# otherwise disable it\nself.__threaded_queue_mode = False\n# log it\nself.__logging and logger.warning(\n\"Threaded Queue Mode is disabled for the current video source!\"\n)\nif self.__thread_timeout:\nlogger.debug(\n\"Setting Video-Thread Timeout to {}s.\".format(self.__thread_timeout)\n)\n# stream variable initialization\nself.stream = None\nif backend and isinstance(backend, int):\n# add backend if specified and initialize the camera stream\nif check_CV_version() == 3:\n# Different OpenCV 3.4.x statement\nself.stream = cv2.VideoCapture(source + backend)\nelse:\n# Two parameters are available since OpenCV 4+ (master branch)\nself.stream = cv2.VideoCapture(source, backend)\nlogger.debug(\"Setting backend `{}` for this source.\".format(backend))\nelse:\n# initialize the camera stream\nself.stream = cv2.VideoCapture(source)\n# initializing colorspace variable\nself.color_space = None\n# apply attributes to source if specified\noptions = {str(k).strip(): v for k, v in options.items()}\nfor key, value in options.items():\nproperty = capPropId(key)\nif not (property is None):\nself.stream.set(property, value)\n# handle colorspace value\nif not (colorspace is None):\nself.color_space = capPropId(colorspace.strip())\nif self.__logging and not (self.color_space is None):\nlogger.debug(\n\"Enabling `{}` colorspace for this video stream!\".format(\ncolorspace.strip()\n)\n)\n# initialize and assign frame-rate variable\nself.framerate = 0.0\n_fps = self.stream.get(cv2.CAP_PROP_FPS)\nif _fps &gt; 1.0:\nself.framerate = _fps\n# applying time delay to warm-up webcam only if specified\nif time_delay and isinstance(time_delay, (int, float)):\ntime.sleep(time_delay)\n# frame variable initialization\n(grabbed, self.frame) = self.stream.read()\n# check if valid stream\nif grabbed:\n# render colorspace if defined\nif not (self.color_space is None):\nself.frame = cv2.cvtColor(self.frame, self.color_space)\nif self.__threaded_queue_mode:\n# initialize and append to queue\nself.__queue.put(self.frame)\nelse:\nraise RuntimeError(\n\"[CamGear:ERROR] :: Source is invalid, CamGear failed to initialize stream on this source!\"\n)\n# thread initialization\nself.__thread = None\n# initialize termination flag event\nself.__terminate = Event()\n# initialize stream read flag event\nself.__stream_read = Event()\n</code></pre>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the queue is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def read(self):\n\"\"\"\n    Extracts frames synchronously from monitored queue, while maintaining a fixed-length frame buffer in the memory,\n    and blocks the thread if the queue is full.\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\nwhile self.__threaded_queue_mode and not self.__terminate.is_set():\nreturn self.__queue.get(timeout=self.__thread_timeout)\n# return current frame\n# only after stream is read\nreturn (\nself.frame\nif not self.__terminate.is_set()  # check if already terminated\nand self.__stream_read.wait(timeout=self.__thread_timeout)  # wait for it\nelse None\n)\n</code></pre>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon.</p> <p>Returns: A reference to the CamGear class object.</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def start(self):\n\"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon.\n    **Returns:** A reference to the CamGear class object.\n    \"\"\"\nself.__thread = Thread(target=self.__update, name=\"CamGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\nreturn self\n</code></pre>"},{"location":"bonus/reference/camgear/#vidgear.gears.camgear.CamGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the VideoStream resources.</p> Source code in <code>vidgear/gears/camgear.py</code> <pre><code>def stop(self):\n\"\"\"\n    Safely terminates the thread, and release the VideoStream resources.\n    \"\"\"\nself.__logging and logger.debug(\"Terminating processes.\")\n# terminate Threaded queue mode separately\nself.__threaded_queue_mode = False\n# indicate that the thread\n# should be terminated immediately\nself.__stream_read.set()\nself.__terminate.set()\n# wait until stream resources are released (producer thread might be still grabbing frame)\nif self.__thread is not None:\nif not (self.__queue is None):\nwhile not self.__queue.empty():\ntry:\nself.__queue.get_nowait()\nexcept queue.Empty:\ncontinue\nself.__queue.task_done()\nself.__thread.join()\n</code></pre>"},{"location":"bonus/reference/helper/","title":"Helper Methods","text":""},{"location":"bonus/reference/helper/#vidgear.gears.helper.logger_handler--logger_handler","title":"logger_handler","text":"<p>Returns the logger handler</p> <p>Returns: A logger handler</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def logger_handler():\n\"\"\"\n    ## logger_handler\n    Returns the logger handler\n    **Returns:** A logger handler\n    \"\"\"\n# logging formatter\nformatter = ColoredFormatter(\n\"{green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message}\",\ndatefmt=\"%H:%M:%S\",\nreset=True,\nlog_colors={\n\"INFO\": \"bold_cyan\",\n\"DEBUG\": \"bold_yellow\",\n\"WARNING\": \"bold_red,fg_thin_yellow\",\n\"ERROR\": \"bold_red\",\n\"CRITICAL\": \"bold_red,bg_white\",\n},\nstyle=\"{\",\n)\n# check if VIDGEAR_LOGFILE defined\nfile_mode = os.environ.get(\"VIDGEAR_LOGFILE\", False)\n# define handler\nhandler = log.StreamHandler()\nif file_mode and isinstance(file_mode, str):\nfile_path = os.path.abspath(file_mode)\nif (os.name == \"nt\" or os.access in os.supports_effective_ids) and os.access(\nos.path.dirname(file_path), os.W_OK\n):\nfile_path = (\nos.path.join(file_path, \"vidgear.log\")\nif os.path.isdir(file_path)\nelse file_path\n)\nhandler = log.FileHandler(file_path, mode=\"a\")\nformatter = log.Formatter(\n\"{asctime} :: {name} :: {levelname} :: {message}\",\ndatefmt=\"%H:%M:%S\",\nstyle=\"{\",\n)\nhandler.setFormatter(formatter)\nreturn handler\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_CV_version--check_cv_version","title":"check_CV_version","text":"<p>Returns: OpenCV's version first bit</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_CV_version():\n\"\"\"\n    ## check_CV_version\n    **Returns:** OpenCV's version first bit\n    \"\"\"\nif parse_version(cv2.__version__) &gt;= parse_version(\"4\"):\nreturn 4\nelse:\nreturn 3\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_gstreamer_support--check_gstreamer_support","title":"check_gstreamer_support","text":"<p>Checks whether OpenCV is compiled with Gstreamer(<code>&gt;=1.0.0</code>) support.</p> <p>Parameters:</p> Name Type Description Default <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A Boolean value</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_gstreamer_support(logging=False):\n\"\"\"\n    ## check_gstreamer_support\n    Checks whether OpenCV is compiled with Gstreamer(`&gt;=1.0.0`) support.\n    Parameters:\n        logging (bool): enables logging for its operations\n    **Returns:** A Boolean value\n    \"\"\"\nraw = cv2.getBuildInformation()\ngst = [\nx.strip()\nfor x in raw.split(\"\\n\")\nif x and re.search(r\"GStreamer[,-:]+\\s*(?:YES|NO)\", x)\n]\nif gst and \"YES\" in gst[0]:\nversion = re.search(r\"(\\d+\\.)?(\\d+\\.)?(\\*|\\d+)\", gst[0])\nlogging and logger.debug(\"Found GStreamer version:{}\".format(version[0]))\nreturn version[0] &gt;= \"1.0.0\"\nelse:\nlogger.warning(\"GStreamer not found!\")\nreturn False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_resolution--get_supported_resolution","title":"get_supported_resolution","text":"<p>Parameters:</p> Name Type Description Default <code>value</code> <code>string</code> <p>value to be validated</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: Valid stream resolution</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_supported_resolution(value, logging=False):\n\"\"\"\n    ## get_supported_resolution\n    Parameters:\n        value (string): value to be validated\n        logging (bool): enables logging for its operations\n    **Returns:** Valid stream resolution\n    \"\"\"\n# default to best\nstream_resolution = \"best\"\nsupported_stream_qualities = [\n\"144p\",\n\"240p\",\n\"360p\",\n\"480p\",\n\"720p\",\n\"1080p\",\n\"1440p\",\n\"2160p\",\n\"4320p\",\n\"worst\",\n\"best\",\n]\nif isinstance(value, str):\nif value.strip().lower() in supported_stream_qualities:\nstream_resolution = value.strip().lower()\nlogging and logger.debug(\n\"Selecting `{}` resolution for streams.\".format(stream_resolution)\n)\nelse:\nlogger.warning(\n\"Specified stream-resolution `{}` is not supported. Reverting to `best`!\".format(\nvalue\n)\n)\nelse:\nlogger.warning(\n\"Specified stream-resolution `{}` is Invalid. Reverting to `best`!\".format(\nvalue\n)\n)\nreturn stream_resolution\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dimensions_to_resolutions--dimensions_to_resolutions","title":"dimensions_to_resolutions","text":"<p>Parameters:</p> Name Type Description Default <code>value</code> <code>list</code> <p>list of dimensions (e.g. <code>640x360</code>)</p> required <p>Returns: list of resolutions (e.g. <code>360p</code>)</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def dimensions_to_resolutions(value):\n\"\"\"\n    ## dimensions_to_resolutions\n    Parameters:\n        value (list): list of dimensions (e.g. `640x360`)\n    **Returns:** list of resolutions (e.g. `360p`)\n    \"\"\"\nsupported_resolutions = {\n\"256x144\": \"144p\",\n\"426x240\": \"240p\",\n\"640x360\": \"360p\",\n\"854x480\": \"480p\",\n\"1280x720\": \"720p\",\n\"1920x1080\": \"1080p\",\n\"2560x1440\": \"1440p\",\n\"3840x2160\": \"2160p\",\n\"7680x4320\": \"4320p\",\n}\nreturn (\nlist(map(supported_resolutions.get, value, value))\nif isinstance(value, list)\nelse []\n)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.mkdir_safe--mkdir_safe","title":"mkdir_safe","text":"<p>Safely creates directory at given path.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>string</code> <p>path to the directory</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def mkdir_safe(dir_path, logging=False):\n\"\"\"\n    ## mkdir_safe\n    Safely creates directory at given path.\n    Parameters:\n        dir_path (string): path to the directory\n        logging (bool): enables logging for its operations\n    \"\"\"\ntry:\nos.makedirs(dir_path)\nlogging and logger.debug(\"Created directory at `{}`\".format(dir_path))\nexcept (OSError, IOError) as e:\nif e.errno != errno.EACCES and e.errno != errno.EEXIST:\nraise\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_ext_safe--delete_ext_safe","title":"delete_ext_safe","text":"<p>Safely deletes files with given extensions at given path.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>string</code> <p>path to the directory</p> required <code>extensions</code> <code>list</code> <p>list of extensions to be deleted</p> <code>[]</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def delete_ext_safe(dir_path, extensions=[], logging=False):\n\"\"\"\n    ## delete_ext_safe\n    Safely deletes files with given extensions at given path.\n    Parameters:\n        dir_path (string): path to the directory\n        extensions (list): list of extensions to be deleted\n        logging (bool): enables logging for its operations\n    \"\"\"\nif not extensions or not os.path.exists(dir_path):\nlogger.warning(\"Invalid input provided for deleting!\")\nreturn\nlogger.critical(\"Clearing Assets at `{}`!\".format(dir_path))\nfor ext in extensions:\nif len(ext) == 2:\nfiles_ext = [\nos.path.join(dir_path, f)\nfor f in os.listdir(dir_path)\nif f.startswith(ext[0]) and f.endswith(ext[1])\n]\nelse:\nfiles_ext = [\nos.path.join(dir_path, f)\nfor f in os.listdir(dir_path)\nif f.endswith(ext)\n]\nfor file in files_ext:\ndelete_file_safe(file)\nlogging and logger.debug(\"Deleted file: `{}`\".format(file))\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.capPropId--cappropid","title":"capPropId","text":"<p>Retrieves the OpenCV property's Integer(Actual) value from string.</p> <p>Parameters:</p> Name Type Description Default <code>property</code> <code>string</code> <p>inputs OpenCV property as string.</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>True</code> <p>Returns: Resultant integer value.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def capPropId(property, logging=True):\n\"\"\"\n    ## capPropId\n    Retrieves the OpenCV property's Integer(Actual) value from string.\n    Parameters:\n        property (string): inputs OpenCV property as string.\n        logging (bool): enables logging for its operations\n    **Returns:** Resultant integer value.\n    \"\"\"\ninteger_value = 0\ntry:\ninteger_value = getattr(cv2, property)\nexcept Exception as e:\nif logging:\nlogger.exception(str(e))\nlogger.critical(\"`{}` is not a valid OpenCV property!\".format(property))\nreturn None\nreturn integer_value\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.reducer--reducer","title":"reducer","text":"<p>Reduces frame size by given percentage</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>percentage</code> <code>int/float</code> <p>inputs size-reduction percentage.</p> <code>0</code> <code>interpolation</code> <code>int</code> <p>Change resize interpolation.</p> <code>4</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def reducer(frame=None, percentage=0, interpolation=cv2.INTER_LANCZOS4):\n\"\"\"\n    ## reducer\n    Reduces frame size by given percentage\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        percentage (int/float): inputs size-reduction percentage.\n        interpolation (int): Change resize interpolation.\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n# check if frame is valid\nif frame is None:\nraise ValueError(\"[Helper:ERROR] :: Input frame cannot be NoneType!\")\n# check if valid reduction percentage is given\nif not (percentage &gt; 0 and percentage &lt; 90):\nraise ValueError(\n\"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\"\n)\nif not (isinstance(interpolation, int)):\nraise ValueError(\n\"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\"\n)\n# grab the frame size\n(height, width) = frame.shape[:2]\n# calculate the ratio of the width from percentage\nreduction = ((100 - percentage) / 100) * width\nratio = reduction / float(width)\n# construct the dimensions\ndimensions = (int(reduction), int(height * ratio))\n# return the resized frame\nreturn cv2.resize(frame, dimensions, interpolation=interpolation)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.create_blank_frame--create_blank_frame","title":"create_blank_frame","text":"<p>Create blank frames of given frame size with text</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>text</code> <code>str</code> <p>Text to be written on frame.</p> <code>''</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def create_blank_frame(frame=None, text=\"\", logging=False):\n\"\"\"\n    ## create_blank_frame\n    Create blank frames of given frame size with text\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        text (str): Text to be written on frame.\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n# check if frame is valid\nif frame is None or not (isinstance(frame, np.ndarray)):\nraise ValueError(\"[Helper:ERROR] :: Input frame is invalid!\")\n# grab the frame size\n(height, width) = frame.shape[:2]\n# create blank frame\nblank_frame = np.zeros(frame.shape, frame.dtype)\n# setup text\nif text and isinstance(text, str):\nlogging and logger.debug(\"Adding text: {}\".format(text))\n# setup font\nfont = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n# get boundary of this text\nfontScale = min(height, width) / (25 / 0.25)\ntextsize = cv2.getTextSize(text, font, fontScale, 5)[0]\n# get coords based on boundary\ntextX = (width - textsize[0]) // 2\ntextY = (height + textsize[1]) // 2\n# put text\ncv2.putText(\nblank_frame, text, (textX, textY), font, fontScale, (125, 125, 125), 6\n)\n# return frame\nreturn blank_frame\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.dict2Args--dict2args","title":"dict2Args","text":"<p>Converts dictionary attributes to list(args)</p> <p>Parameters:</p> Name Type Description Default <code>param_dict</code> <code>dict</code> <p>Parameters dictionary</p> required <p>Returns: Arguments list</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def dict2Args(param_dict):\n\"\"\"\n    ## dict2Args\n    Converts dictionary attributes to list(args)\n    Parameters:\n        param_dict (dict): Parameters dictionary\n    **Returns:** Arguments list\n    \"\"\"\nargs = []\nfor key in param_dict.keys():\nif key in [\"-clones\"] or key.startswith(\"-core\"):\nif isinstance(param_dict[key], list):\nargs.extend(param_dict[key])\nelse:\nlogger.warning(\n\"{} with invalid datatype:`{}`, Skipped!\".format(\n\"Core parameter\" if key.startswith(\"-core\") else \"Clone\",\nparam_dict[key],\n)\n)\nelse:\nargs.append(key)\nargs.append(str(param_dict[key]))\nreturn args\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","title":"get_valid_ffmpeg_path","text":"<p>Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.</p> <p>Parameters:</p> Name Type Description Default <code>custom_ffmpeg</code> <code>string</code> <p>path to custom FFmpeg executables</p> <code>''</code> <code>is_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>ffmpeg_download_path</code> <code>string</code> <p>FFmpeg static binaries download location (Windows only)</p> <code>''</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_valid_ffmpeg_path(\ncustom_ffmpeg=\"\", is_windows=False, ffmpeg_download_path=\"\", logging=False\n):\n\"\"\"\n    ## get_valid_ffmpeg_path\n    Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.\n    Parameters:\n        custom_ffmpeg (string): path to custom FFmpeg executables\n        is_windows (boolean): is running on Windows OS?\n        ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_\n        logging (bool): enables logging for its operations\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\nfinal_path = \"\"\nif is_windows:\n# checks if current os is windows\nif custom_ffmpeg:\n# if custom FFmpeg path is given assign to local variable\nfinal_path += custom_ffmpeg\nelse:\n# otherwise auto-download them\ntry:\nif not (ffmpeg_download_path):\n# otherwise save to Temp Directory\nimport tempfile\nffmpeg_download_path = tempfile.gettempdir()\nlogging and logger.debug(\n\"FFmpeg Windows Download Path: {}\".format(ffmpeg_download_path)\n)\n# download Binaries\nos_bit = (\n(\"win64\" if platform.machine().endswith(\"64\") else \"win32\")\nif is_windows\nelse \"\"\n)\n_path = download_ffmpeg_binaries(\npath=ffmpeg_download_path, os_windows=is_windows, os_bit=os_bit\n)\n# assign to local variable\nfinal_path += _path\nexcept Exception as e:\n# log if any error occurred\nlogger.exception(str(e))\nlogger.error(\n\"Error in downloading FFmpeg binaries, Check your network and Try again!\"\n)\nreturn False\nif os.path.isfile(final_path):\n# check if valid FFmpeg file exist\npass\nelif os.path.isfile(os.path.join(final_path, \"ffmpeg.exe\")):\n# check if FFmpeg directory exists, if does, then check for valid file\nfinal_path = os.path.join(final_path, \"ffmpeg.exe\")\nelse:\n# else return False\nlogging and logger.debug(\n\"No valid FFmpeg executables found at Custom FFmpeg path!\"\n)\nreturn False\nelse:\n# otherwise perform test for Unix\nif custom_ffmpeg:\n# if custom FFmpeg path is given assign to local variable\nif os.path.isfile(custom_ffmpeg):\n# check if valid FFmpeg file exist\nfinal_path += custom_ffmpeg\nelif os.path.isfile(os.path.join(custom_ffmpeg, \"ffmpeg\")):\n# check if FFmpeg directory exists, if does, then check for valid file\nfinal_path = os.path.join(custom_ffmpeg, \"ffmpeg\")\nelse:\n# else return False\nlogging and logger.debug(\n\"No valid FFmpeg executables found at Custom FFmpeg path!\"\n)\nreturn False\nelse:\n# otherwise assign ffmpeg binaries from system\nfinal_path += \"ffmpeg\"\nlogging and logger.debug(\"Final FFmpeg Path: {}\".format(final_path))\n# Final Auto-Validation for FFmeg Binaries. returns final path if test is passed\nreturn final_path if validate_ffmpeg(final_path, logging=logging) else False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.download_ffmpeg_binaries--download_ffmpeg_binaries","title":"download_ffmpeg_binaries","text":"<p>Generates FFmpeg Static Binaries for windows(if not available)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for downloading custom FFmpeg executables</p> required <code>os_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>os_bit</code> <code>string</code> <p>32-bit or 64-bit OS?</p> <code>''</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def download_ffmpeg_binaries(path, os_windows=False, os_bit=\"\"):\n\"\"\"\n    ## download_ffmpeg_binaries\n    Generates FFmpeg Static Binaries for windows(if not available)\n    Parameters:\n        path (string): path for downloading custom FFmpeg executables\n        os_windows (boolean): is running on Windows OS?\n        os_bit (string): 32-bit or 64-bit OS?\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\nfinal_path = \"\"\nif os_windows and os_bit:\n# initialize with available FFmpeg Static Binaries GitHub Server\nfile_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static-{}-gpl.zip\".format(\nos_bit\n)\nfile_name = os.path.join(\nos.path.abspath(path), \"ffmpeg-static-{}-gpl.zip\".format(os_bit)\n)\nfile_path = os.path.join(\nos.path.abspath(path),\n\"ffmpeg-static-{}-gpl/bin/ffmpeg.exe\".format(os_bit),\n)\nbase_path, _ = os.path.split(file_name)  # extract file base path\n# check if file already exists\nif os.path.isfile(file_path):\nfinal_path += file_path  # skip download if does\nelse:\n# import libs\nimport zipfile\n# check if given path has write access\nassert os.access(path, os.W_OK), (\n\"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \"\n+ path\n)\n# remove leftovers if exists\nos.path.isfile(file_name) and delete_file_safe(file_name)\n# download and write file to the given path\nwith open(file_name, \"wb\") as f:\nlogger.debug(\n\"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\"\n)\n# create session\nwith requests.Session() as http:\n# setup retry strategy\nretries = Retry(\ntotal=3,\nbackoff_factor=1,\nstatus_forcelist=[429, 500, 502, 503, 504],\n)\n# Mount it for https usage\nadapter = TimeoutHTTPAdapter(timeout=2.0, max_retries=retries)\nhttp.mount(\"https://\", adapter)\nresponse = http.get(file_url, stream=True)\nresponse.raise_for_status()\ntotal_length = (\nresponse.headers.get(\"content-length\")\nif \"content-length\" in response.headers\nelse len(response.content)\n)\nassert not (\ntotal_length is None\n), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\"\nbar = tqdm(total=int(total_length), unit=\"B\", unit_scale=True)\nfor data in response.iter_content(chunk_size=4096):\nf.write(data)\nlen(data) &gt; 0 and bar.update(len(data))\nbar.close()\nlogger.debug(\"Extracting executables.\")\nwith zipfile.ZipFile(file_name, \"r\") as zip_ref:\nzip_fname, _ = os.path.split(zip_ref.infolist()[0].filename)\nzip_ref.extractall(base_path)\n# perform cleaning\ndelete_file_safe(file_name)\nlogger.debug(\"FFmpeg binaries for Windows configured successfully!\")\nfinal_path += file_path\n# return final path\nreturn final_path\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_ffmpeg--validate_ffmpeg","title":"validate_ffmpeg","text":"<p>Validate FFmeg Binaries. returns <code>True</code> if tests are passed.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_ffmpeg(path, logging=False):\n\"\"\"\n    ## validate_ffmpeg\n    Validate FFmeg Binaries. returns `True` if tests are passed.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        logging (bool): enables logging for its operations\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\ntry:\n# get the FFmpeg version\nversion = check_output([path, \"-version\"])\nfirstline = version.split(b\"\\n\")[0]\nversion = firstline.split(b\" \")[2].strip()\nif logging:  # log if test are passed\nlogger.debug(\"FFmpeg validity Test Passed!\")\nlogger.debug(\n\"Found valid FFmpeg Version: `{}` installed on this system\".format(\nversion\n)\n)\nexcept Exception as e:\n# log if test are failed\nif logging:\nlogger.exception(str(e))\nlogger.warning(\"FFmpeg validity Test Failed!\")\nreturn False\nreturn True\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_output--check_output","title":"check_output","text":"<p>Returns stdin output from subprocess module</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_output(*args, **kwargs):\n\"\"\"\n    ## check_output\n    Returns stdin output from subprocess module\n    \"\"\"\n# import libs\nimport subprocess as sp\n# workaround for python bug: https://bugs.python.org/issue37380\nif platform.system() == \"Windows\":\n# see comment https://bugs.python.org/msg370334\nsp._cleanup = lambda: None\n# handle additional params\nretrieve_stderr = kwargs.pop(\"force_retrieve_stderr\", False)\n# execute command in subprocess\nprocess = sp.Popen(\nstdout=sp.PIPE,\nstderr=sp.DEVNULL if not (retrieve_stderr) else sp.PIPE,\n*args,\n**kwargs,\n)\noutput, stderr = process.communicate()\nretcode = process.poll()\n# handle return code\nif retcode and not (retrieve_stderr):\ncmd = kwargs.get(\"args\")\nif cmd is None:\ncmd = args[0]\nerror = sp.CalledProcessError(retcode, cmd)\nerror.output = output\nraise error\nreturn output if not (retrieve_stderr) else stderr\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.generate_auth_certificates--generate_auth_certificates","title":"generate_auth_certificates","text":"<p>Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for generating CURVE key-pairs</p> required <code>overwrite</code> <code>boolean</code> <p>overwrite existing key-pairs or not?</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid CURVE key-pairs path as string.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def generate_auth_certificates(path, overwrite=False, logging=False):\n\"\"\"\n    ## generate_auth_certificates\n    Auto-Generates, and Auto-validates CURVE ZMQ key-pairs for NetGear API's Secure Mode.\n    Parameters:\n        path (string): path for generating CURVE key-pairs\n        overwrite (boolean): overwrite existing key-pairs or not?\n        logging (bool): enables logging for its operations\n    **Returns:** A valid CURVE key-pairs path as string.\n    \"\"\"\n# import necessary lib\nimport zmq.auth\n# check if path corresponds to vidgear only\nif os.path.basename(path) != \".vidgear\":\npath = os.path.join(path, \".vidgear\")\n# generate keys dir\nkeys_dir = os.path.join(path, \"keys\")\nmkdir_safe(keys_dir, logging=logging)\n# generate separate public and private key dirs\npublic_keys_dir = os.path.join(keys_dir, \"public_keys\")\nsecret_keys_dir = os.path.join(keys_dir, \"private_keys\")\n# check if overwriting is allowed\nif overwrite:\n# delete previous certificates\nfor dirs in [public_keys_dir, secret_keys_dir]:\nif os.path.exists(dirs):\nshutil.rmtree(dirs)\nmkdir_safe(dirs, logging=logging)\n# generate new keys\nserver_public_file, server_secret_file = zmq.auth.create_certificates(\nkeys_dir, \"server\"\n)\nclient_public_file, client_secret_file = zmq.auth.create_certificates(\nkeys_dir, \"client\"\n)\n# move keys to their appropriate directory respectively\nfor key_file in os.listdir(keys_dir):\nif key_file.endswith(\".key\"):\nshutil.move(os.path.join(keys_dir, key_file), public_keys_dir)\nelif key_file.endswith(\".key_secret\"):\nshutil.move(os.path.join(keys_dir, key_file), secret_keys_dir)\nelse:\n# clean redundant keys if present\nredundant_key = os.path.join(keys_dir, key_file)\nif os.path.isfile(redundant_key):\ndelete_file_safe(redundant_key)\nelse:\n# otherwise validate available keys\nstatus_public_keys = validate_auth_keys(public_keys_dir, \".key\")\nstatus_private_keys = validate_auth_keys(secret_keys_dir, \".key_secret\")\n# check if all valid keys are found\nif status_private_keys and status_public_keys:\nreturn (keys_dir, secret_keys_dir, public_keys_dir)\n# check if valid public keys are found\nif not (status_public_keys):\nmkdir_safe(public_keys_dir, logging=logging)\n# check if valid private keys are found\nif not (status_private_keys):\nmkdir_safe(secret_keys_dir, logging=logging)\n# generate new keys\nserver_public_file, server_secret_file = zmq.auth.create_certificates(\nkeys_dir, \"server\"\n)\nclient_public_file, client_secret_file = zmq.auth.create_certificates(\nkeys_dir, \"client\"\n)\n# move keys to their appropriate directory respectively\nfor key_file in os.listdir(keys_dir):\nif key_file.endswith(\".key\") and not (status_public_keys):\nshutil.move(\nos.path.join(keys_dir, key_file), os.path.join(public_keys_dir, \".\")\n)\nelif key_file.endswith(\".key_secret\") and not (status_private_keys):\nshutil.move(\nos.path.join(keys_dir, key_file), os.path.join(secret_keys_dir, \".\")\n)\nelse:\n# clean redundant keys if present\nredundant_key = os.path.join(keys_dir, key_file)\nif os.path.isfile(redundant_key):\ndelete_file_safe(redundant_key)\n# validate newly generated keys\nstatus_public_keys = validate_auth_keys(public_keys_dir, \".key\")\nstatus_private_keys = validate_auth_keys(secret_keys_dir, \".key_secret\")\n# raise error is validation test fails\nif not (status_private_keys) or not (status_public_keys):\nraise RuntimeError(\n\"[Helper:ERROR] :: Unable to generate valid ZMQ authentication certificates at `{}`!\".format(\nkeys_dir\n)\n)\n# finally return valid key paths\nreturn (keys_dir, secret_keys_dir, public_keys_dir)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_audio--validate_audio","title":"validate_audio","text":"<p>Validates audio by retrieving audio-bitrate from file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>source</code> <code>string/list</code> <p>source to be validated.</p> <code>None</code> <p>Returns: A string value, confirming whether audio is present, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_audio(path, source=None):\n\"\"\"\n    ## validate_audio\n    Validates audio by retrieving audio-bitrate from file.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        source (string/list): source to be validated.\n    **Returns:** A string value, confirming whether audio is present, or not?.\n    \"\"\"\nif source is None or not (source):\nlogger.warning(\"Audio input source is empty!\")\nreturn \"\"\n# create ffmpeg command\ncmd = [path, \"-hide_banner\"] + (\nsource if isinstance(source, list) else [\"-i\", source]\n)\n# extract metadata\nmetadata = check_output(cmd, force_retrieve_stderr=True)\n# extract bitrate\naudio_bitrate_meta = [\nline.strip()\nfor line in metadata.decode(\"utf-8\").split(\"\\n\")\nif \"Audio:\" in line\n]\naudio_bitrate = (\nre.findall(r\"([0-9]+)\\s(kb|mb|gb)\\/s\", audio_bitrate_meta[0])[-1]\nif audio_bitrate_meta\nelse \"\"\n)\n# extract samplerate\naudio_samplerate_metadata = [\nline.strip()\nfor line in metadata.decode(\"utf-8\").split(\"\\n\")\nif all(x in line for x in [\"Audio:\", \"Hz\"])\n]\naudio_samplerate = (\nre.findall(r\"[0-9]+\\sHz\", audio_samplerate_metadata[0])[0]\nif audio_samplerate_metadata\nelse \"\"\n)\n# format into actual readable bitrate value\nif audio_bitrate:\n# return bitrate directly\nreturn \"{}{}\".format(int(audio_bitrate[0].strip()), audio_bitrate[1].strip()[0])\nelif audio_samplerate:\n# convert samplerate to bitrate first\nsample_rate_value = int(audio_samplerate.split(\" \")[0])\nchannels_value = 1 if \"mono\" in audio_samplerate_metadata[0] else 2\nbit_depth_value = re.findall(\nr\"(u|s|f)([0-9]+)(le|be)\", audio_samplerate_metadata[0]\n)[0][1]\nreturn (\n(\nstr(\nget_audio_bitrate(\nsample_rate_value, channels_value, int(bit_depth_value)\n)\n)\n+ \"k\"\n)\nif bit_depth_value\nelse \"\"\n)\nelse:\nreturn \"\"\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.extract_time--extract_time","title":"extract_time","text":"<p>Extract time from give string value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>string</code> <p>string value.</p> required <p>Returns: Time (in seconds) as integer.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def extract_time(value):\n\"\"\"\n    ## extract_time\n    Extract time from give string value.\n    Parameters:\n        value (string): string value.\n    **Returns:** Time _(in seconds)_ as integer.\n    \"\"\"\nif not (value):\nlogger.warning(\"Value is empty!\")\nreturn 0\nelse:\nstripped_data = value.strip()\nt_duration = re.findall(\nr\"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d)\", stripped_data\n)\nreturn (\nsum(\nint(x) * 60**i\nfor i, x in enumerate(reversed(t_duration[0].split(\":\")))\n)\nif t_duration\nelse 0\n)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_video--validate_video","title":"validate_video","text":"<p>Validates video by retrieving resolution/size and framerate from file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>video_path</code> <code>string</code> <p>absolute path to Video.</p> <code>None</code> <p>Returns: A dictionary of retieved Video resolution (as tuple(width, height)) and framerate (as float).</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_video(path, video_path=None, logging=False):\n\"\"\"\n    ## validate_video\n    Validates video by retrieving resolution/size and framerate from file.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        video_path (string): absolute path to Video.\n    **Returns:** A dictionary of retieved Video resolution _(as tuple(width, height))_ and framerate _(as float)_.\n    \"\"\"\nif video_path is None or not (video_path):\nlogger.warning(\"Video path is empty!\")\nreturn None\n# extract metadata\nmetadata = check_output(\n[path, \"-hide_banner\", \"-i\", video_path], force_retrieve_stderr=True\n)\n# clean and search\nstripped_data = [x.decode(\"utf-8\").strip() for x in metadata.split(b\"\\n\")]\nlogging and logger.debug(stripped_data)\nresult = {}\nfor data in stripped_data:\noutput_a = re.findall(r\"([1-9]\\d+)x([1-9]\\d+)\", data)\noutput_b = re.findall(r\"\\d+(?:\\.\\d+)?\\sfps\", data)\nif len(result) == 2:\nbreak\nif output_b and not \"framerate\" in result:\nresult[\"framerate\"] = re.findall(r\"[\\d\\.\\d]+\", output_b[0])[0]\nif output_a and not \"resolution\" in result:\nresult[\"resolution\"] = output_a[-1]\n# return values\nreturn result if (len(result) == 2) else None\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.is_valid_url--is_valid_url","title":"is_valid_url","text":"<p>Checks URL validity by testing its scheme against FFmpeg's supported protocols</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>url</code> <code>string</code> <p>URL to be validated</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def is_valid_url(path, url=None, logging=False):\n\"\"\"\n    ## is_valid_url\n    Checks URL validity by testing its scheme against\n    FFmpeg's supported protocols\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        url (string): URL to be validated\n        logging (bool): enables logging for its operations\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\nif url is None or not (url):\nlogger.warning(\"URL is empty!\")\nreturn False\n# extract URL scheme\nextracted_scheme_url = url.split(\"://\", 1)[0]\n# extract all FFmpeg supported protocols\nprotocols = check_output([path, \"-hide_banner\", \"-protocols\"])\nsplitted = [x.decode(\"utf-8\").strip() for x in protocols.split(b\"\\n\")]\nsupported_protocols = splitted[splitted.index(\"Output:\") + 1 : len(splitted) - 1]\n# rtsp is a demuxer somehow\nsupported_protocols += [\"rtsp\"] if \"rtsp\" in get_supported_demuxers(path) else []\n# Test and return result whether scheme is supported\nif extracted_scheme_url and extracted_scheme_url in supported_protocols:\nlogging and logger.debug(\n\"URL scheme `{}` is supported by FFmpeg.\".format(extracted_scheme_url)\n)\nreturn True\nelse:\nlogger.warning(\n\"URL scheme `{}` isn't supported by FFmpeg!\".format(extracted_scheme_url)\n)\nreturn False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.import_dependency_safe--import_dependency_safe","title":"import_dependency_safe","text":"<p>Imports specified dependency safely. By default(<code>error = raise</code>), if a dependency is missing, an ImportError with a meaningful message will be raised. Otherwise if <code>error = log</code> a warning will be logged and on <code>error = silent</code> everything will be quit. But If a dependency is present, but older than specified, an error is raised if specified.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>string</code> <p>name of dependency to be imported.</p> required <code>error</code> <code>string</code> <p>raise or Log or silence ImportError. Possible values are <code>\"raise\"</code>, <code>\"log\"</code> and <code>silent</code>. Default is <code>\"raise\"</code>.</p> <code>'raise'</code> <code>pkg_name</code> <code>string</code> <p>(Optional) package name of dependency(if different <code>pip</code> name). Otherwise <code>name</code> will be used.</p> <code>None</code> <code>min_version</code> <code>string</code> <p>(Optional) required minimum version of the dependency to be imported.</p> <code>None</code> <code>custom_message</code> <code>string</code> <p>(Optional) custom Import error message to be raised or logged.</p> <code>None</code> <p>Returns: The imported module, when found and the version is correct(if specified). Otherwise <code>None</code>.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def import_dependency_safe(\nname,\nerror=\"raise\",\npkg_name=None,\nmin_version=None,\ncustom_message=None,\n):\n\"\"\"\n    ## import_dependency_safe\n    Imports specified dependency safely. By default(`error = raise`), if a dependency is missing,\n    an ImportError with a meaningful message will be raised. Otherwise if `error = log` a warning\n    will be logged and on `error = silent` everything will be quit. But If a dependency is present,\n    but older than specified, an error is raised if specified.\n    Parameters:\n        name (string): name of dependency to be imported.\n        error (string): raise or Log or silence ImportError. Possible values are `\"raise\"`, `\"log\"` and `silent`. Default is `\"raise\"`.\n        pkg_name (string): (Optional) package name of dependency(if different `pip` name). Otherwise `name` will be used.\n        min_version (string): (Optional) required minimum version of the dependency to be imported.\n        custom_message (string): (Optional) custom Import error message to be raised or logged.\n    **Returns:** The imported module, when found and the version is correct(if specified). Otherwise `None`.\n    \"\"\"\n# check specified parameters\nsub_class = \"\"\nif not name or not isinstance(name, str):\nreturn None\nelse:\n# extract name in case of relative import\nname = name.strip()\nif name.startswith(\"from\"):\nname = name.split(\" \")\nname, sub_class = (name[1].strip(), name[-1].strip())\nassert error in [\n\"raise\",\n\"log\",\n\"silent\",\n], \"[Vidgear:ERROR] :: Invalid value at `error` parameter.\"\n# specify package name of dependency(if defined). Otherwise use name\ninstall_name = pkg_name if not (pkg_name is None) else name\n# create message\nmsg = (\ncustom_message\nif not (custom_message is None)\nelse \"Failed to find required dependency '{}'. Install it with  `pip install {}` command.\".format(\nname, install_name\n)\n)\n# try importing dependency\ntry:\nmodule = importlib.import_module(name)\nif sub_class:\nmodule = getattr(module, sub_class)\nexcept Exception:\n# handle errors.\nif error == \"raise\":\nraise ImportError(msg) from None\nelif error == \"log\":\nlogger.error(msg)\nreturn None\nelse:\nreturn None\n# check if minimum required version\nif not (min_version) is None:\n# Handle submodules\nparent_module = name.split(\".\")[0]\nif parent_module != name:\n# grab parent module\nmodule_to_get = sys.modules[parent_module]\nelse:\nmodule_to_get = module\n# extract version\nversion = get_module_version(module_to_get)\n# verify\nif parse_version(version) &lt; parse_version(min_version):\n# create message\nmsg = \"\"\"Unsupported version '{}' found. Vidgear requires '{}' dependency installed with version '{}' or greater. \n            Update it with  `pip install -U {}` command.\"\"\".format(\nparent_module, min_version, version, install_name\n)\n# handle errors.\nif error == \"silent\":\nreturn None\nelse:\n# raise\nraise ImportError(msg)\nreturn module\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_video_bitrate--get_video_bitrate","title":"get_video_bitrate","text":"<p>Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values</p> <p>Parameters:</p> Name Type Description Default <code>width</code> <code>int</code> <p>video-width</p> required <code>height</code> <code>int</code> <p>video-height</p> required <code>fps</code> <code>float</code> <p>video-framerate</p> required <code>bpp</code> <code>float</code> <p>bit-per-pixels value</p> required <p>Returns: Video bitrate (in Kbps) as integer.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_video_bitrate(width, height, fps, bpp):\n\"\"\"\n    ## get_video_bitrate\n    Calculate optimum Bitrate from resolution, framerate, bits-per-pixels values\n    Parameters:\n        width (int): video-width\n        height (int): video-height\n        fps (float): video-framerate\n        bpp (float): bit-per-pixels value\n    **Returns:** Video bitrate _(in Kbps)_ as integer.\n    \"\"\"\nreturn round((width * height * bpp * fps) / 1000)\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_WriteAccess--check_writeaccess","title":"check_WriteAccess","text":"<p>Checks whether given path directory has Write-Access.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of directory</p> required <code>is_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether Write-Access available, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_WriteAccess(path, is_windows=False, logging=False):\n\"\"\"\n    ## check_WriteAccess\n    Checks whether given path directory has Write-Access.\n    Parameters:\n        path (string): absolute path of directory\n        is_windows (boolean): is running on Windows OS?\n        logging (bool): enables logging for its operations\n    **Returns:** A boolean value, confirming whether Write-Access available, or not?.\n    \"\"\"\n# check if path exists\ndirpath = Path(path)\ntry:\nif not (dirpath.exists() and dirpath.is_dir()):\nlogger.warning(\n\"Specified directory `{}` doesn't exists or valid.\".format(path)\n)\nreturn False\nelse:\npath = dirpath.resolve()\nexcept:\nreturn False\n# check filepath on *nix systems\nif not is_windows:\nuid = os.geteuid()\ngid = os.getegid()\ns = os.stat(path)\nmode = s[stat.ST_MODE]\nreturn (\n((s[stat.ST_UID] == uid) and (mode &amp; stat.S_IWUSR))\nor ((s[stat.ST_GID] == gid) and (mode &amp; stat.S_IWGRP))\nor (mode &amp; stat.S_IWOTH)\n)\n# otherwise, check filepath on windows\nelse:\nwrite_accessible = False\ntemp_fname = os.path.join(path, \"temp.tmp\")\ntry:\nfd = os.open(temp_fname, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)\nos.close(fd)\nwrite_accessible = True\nexcept Exception as e:\nif isinstance(e, PermissionError):\nlogger.error(\n\"You don't have adequate access rights to use `{}` directory!\".format(\npath\n)\n)\nlogging and logger.exception(str(e))\nfinally:\ndelete_file_safe(temp_fname)\nreturn write_accessible\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.check_open_port--check_open_port","title":"check_open_port","text":"<p>Checks whether specified port open at given IP address.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>string</code> <p>given IP address.</p> required <code>port</code> <code>int</code> <p>check if port is open at given address.</p> <code>22</code> <p>Returns: A boolean value, confirming whether given port is open at given IP address.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def check_open_port(address, port=22):\n\"\"\"\n    ## check_open_port\n    Checks whether specified port open at given IP address.\n    Parameters:\n        address (string): given IP address.\n        port (int): check if port is open at given address.\n    **Returns:** A boolean value, confirming whether given port is open at given IP address.\n    \"\"\"\nif not address:\nreturn False\nwith closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as sock:\nif sock.connect_ex((address, port)) == 0:\nreturn True\nelse:\nreturn False\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.delete_file_safe--delete_ext_safe","title":"delete_ext_safe","text":"<p>Safely deletes files at given path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>string</code> <p>path to the file</p> required Source code in <code>vidgear/gears/helper.py</code> <pre><code>def delete_file_safe(file_path):\n\"\"\"\n    ## delete_ext_safe\n    Safely deletes files at given path.\n    Parameters:\n        file_path (string): path to the file\n    \"\"\"\ntry:\ndfile = Path(file_path)\nif sys.version_info &gt;= (3, 8, 0):\ndfile.unlink(missing_ok=True)\nelse:\ndfile.exists() and dfile.unlink()\nexcept Exception as e:\nlogger.exception(str(e))\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_demuxers--get_supported_demuxers","title":"get_supported_demuxers","text":"<p>Find and returns FFmpeg's supported demuxers</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported demuxers.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_supported_demuxers(path):\n\"\"\"\n    ## get_supported_demuxers\n    Find and returns FFmpeg's supported demuxers\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n    **Returns:** List of supported demuxers.\n    \"\"\"\ndemuxers = check_output([path, \"-hide_banner\", \"-demuxers\"])\nsplitted = [x.decode(\"utf-8\").strip() for x in demuxers.split(b\"\\n\")]\nsupported_demuxers = splitted[splitted.index(\"--\") + 1 : len(splitted) - 1]\n# compile regex\nfinder = re.compile(r\"\\s\\s[a-z0-9_,-]+\\s+\")\n# find all outputs\noutputs = finder.findall(\"\\n\".join(supported_demuxers))\n# return output findings\nreturn [o.strip() for o in outputs]\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.get_supported_vencoders--get_supported_vencoders","title":"get_supported_vencoders","text":"<p>Find and returns FFmpeg's supported video encoders</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported encoders.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def get_supported_vencoders(path):\n\"\"\"\n    ## get_supported_vencoders\n    Find and returns FFmpeg's supported video encoders\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n    **Returns:** List of supported encoders.\n    \"\"\"\nencoders = check_output([path, \"-hide_banner\", \"-encoders\"])\nsplitted = encoders.split(b\"\\n\")\n# extract video encoders\nsupported_vencoders = [\nx.decode(\"utf-8\").strip()\nfor x in splitted[2 : len(splitted) - 1]\nif x.decode(\"utf-8\").strip().startswith(\"V\")\n]\n# compile regex\nfinder = re.compile(r\"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\")\n# find all outputs\noutputs = finder.findall(\"\\n\".join(supported_vencoders))\n# return output findings\nreturn [[s for s in o.split(\" \")][-1] for o in outputs]\n</code></pre>"},{"location":"bonus/reference/helper/#vidgear.gears.helper.validate_auth_keys--validate_auth_keys","title":"validate_auth_keys","text":"<p>Validates, and also maintains generated ZMQ CURVE Key-pairs.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path of generated CURVE key-pairs</p> required <code>extension</code> <code>string</code> <p>type of key-pair to be validated</p> required <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/helper.py</code> <pre><code>def validate_auth_keys(path, extension):\n\"\"\"\n    ## validate_auth_keys\n    Validates, and also maintains generated ZMQ CURVE Key-pairs.\n    Parameters:\n        path (string): path of generated CURVE key-pairs\n        extension (string): type of key-pair to be validated\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n# check for valid path\nif not (os.path.exists(path)):\nreturn False\n# check if directory empty\nif not (os.listdir(path)):\nreturn False\nkeys_buffer = []  # stores auth-keys\n# loop over auth-keys\nfor key_file in os.listdir(path):\nkey = os.path.splitext(key_file)\n# check if valid key is generated\nif key and (key[0] in [\"server\", \"client\"]) and (key[1] == extension):\nkeys_buffer.append(key_file)  # store it\n# remove invalid keys if found\nlen(keys_buffer) == 1 and delete_file_safe(os.path.join(path, keys_buffer[0]))\n# return results\nreturn True if (len(keys_buffer) == 2) else False\n</code></pre>"},{"location":"bonus/reference/helper_async/","title":"Helper Methods","text":""},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.reducer--reducer","title":"reducer","text":"<p>Asynchronous method that reduces frame size by given percentage.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>percentage</code> <code>int/float</code> <p>inputs size-reduction percentage.</p> <code>0</code> <code>interpolation</code> <code>int</code> <p>Change resize interpolation.</p> <code>4</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>async def reducer(frame=None, percentage=0, interpolation=cv2.INTER_LANCZOS4):\n\"\"\"\n    ## reducer\n    Asynchronous method that reduces frame size by given percentage.\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        percentage (int/float): inputs size-reduction percentage.\n        interpolation (int): Change resize interpolation.\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n# check if frame is valid\nif frame is None:\nraise ValueError(\"[Helper:ERROR] :: Input frame cannot be NoneType!\")\n# check if valid reduction percentage is given\nif not (percentage &gt; 0 and percentage &lt; 90):\nraise ValueError(\n\"[Helper:ERROR] :: Given frame-size reduction percentage is invalid, Kindly refer docs.\"\n)\nif not (isinstance(interpolation, int)):\nraise ValueError(\n\"[Helper:ERROR] :: Given interpolation is invalid, Kindly refer docs.\"\n)\n# grab the frame size\n(height, width) = frame.shape[:2]\n# calculate the ratio of the width from percentage\nreduction = ((100 - percentage) / 100) * width\nratio = reduction / float(width)\n# construct the dimensions\ndimensions = (int(reduction), int(height * ratio))\n# return the resized frame\nreturn cv2.resize(frame, dimensions, interpolation=interpolation)\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.create_blank_frame--create_blank_frame","title":"create_blank_frame","text":"<p>Create blank frames of given frame size with text</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> <code>None</code> <code>text</code> <code>str</code> <p>Text to be written on frame.</p> <code>''</code> <p>Returns:  A reduced numpy ndarray array.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def create_blank_frame(frame=None, text=\"\", logging=False):\n\"\"\"\n    ## create_blank_frame\n    Create blank frames of given frame size with text\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        text (str): Text to be written on frame.\n    **Returns:**  A reduced numpy ndarray array.\n    \"\"\"\n# check if frame is valid\nif frame is None or not (isinstance(frame, np.ndarray)):\nraise ValueError(\"[Helper:ERROR] :: Input frame is invalid!\")\n# grab the frame size\n(height, width) = frame.shape[:2]\n# create blank frame\nblank_frame = np.zeros(frame.shape, frame.dtype)\n# setup text\nif text and isinstance(text, str):\nif logging:\nlogger.debug(\"Adding text: {}\".format(text))\n# setup font\nfont = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n# get boundary of this text\nfontScale = min(height, width) / (25 / 0.25)\ntextsize = cv2.getTextSize(text, font, fontScale, 5)[0]\n# get coords based on boundary\ntextX = (width - textsize[0]) // 2\ntextY = (height + textsize[1]) // 2\n# put text\ncv2.putText(\nblank_frame, text, (textX, textY), font, fontScale, (125, 125, 125), 6\n)\n# return frame\nreturn blank_frame\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.generate_webdata--generate_webdata","title":"generate_webdata","text":"<p>Auto-Generates, and Auto-validates default data for WebGear API.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for generating data</p> required <code>c_name</code> <code>string</code> <p>class name that is generating files</p> <code>'webgear'</code> <code>overwrite_default</code> <code>boolean</code> <p>overwrite existing data or not?</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid data path as string.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def generate_webdata(path, c_name=\"webgear\", overwrite_default=False, logging=False):\n\"\"\"\n    ## generate_webdata\n    Auto-Generates, and Auto-validates default data for WebGear API.\n    Parameters:\n        path (string): path for generating data\n        c_name (string): class name that is generating files\n        overwrite_default (boolean): overwrite existing data or not?\n        logging (bool): enables logging for its operations\n    **Returns:** A valid data path as string.\n    \"\"\"\n# check if path corresponds to vidgear only\nif os.path.basename(path) != \".vidgear\":\npath = os.path.join(path, \".vidgear\")\n# generate parent directory\npath = os.path.join(path, c_name)\nmkdir_safe(path, logging=logging)\n# self-generate dirs\ntemplate_dir = os.path.join(path, \"templates\")  # generates HTML templates dir\nstatic_dir = os.path.join(path, \"static\")  # generates static dir\n# generate js &amp; css static and favicon img subdirs\njs_static_dir = os.path.join(static_dir, \"js\")\ncss_static_dir = os.path.join(static_dir, \"css\")\nfavicon_dir = os.path.join(static_dir, \"img\")\nmkdir_safe(static_dir, logging=logging)\nmkdir_safe(template_dir, logging=logging)\nmkdir_safe(js_static_dir, logging=logging)\nmkdir_safe(css_static_dir, logging=logging)\nmkdir_safe(favicon_dir, logging=logging)\n# check if overwriting is enabled\nif overwrite_default or not validate_webdata(\ntemplate_dir, [\"index.html\", \"404.html\", \"500.html\"]\n):\nlogger.critical(\n\"Overwriting existing WebGear data-files with default data-files from the server!\"\nif overwrite_default\nelse \"Failed to detect critical WebGear data-files: index.html, 404.html &amp; 500.html!\"\n)\n# download default files\nlogging and logger.info(\n\"Downloading default data-files from the Gitlab Server: {}.\".format(\n\"https://gitlab.com/abhiTronix/vidgear-vitals\"\n)\n)\ndownload_webdata(\ntemplate_dir,\nc_name=c_name,\nfiles=[\"index.html\", \"404.html\", \"500.html\", \"base.html\"],\nlogging=logging,\n)\ndownload_webdata(\ncss_static_dir, c_name=c_name, files=[\"custom.css\"], logging=logging\n)\ndownload_webdata(\njs_static_dir,\nc_name=c_name,\nfiles=[\"custom.js\"],\nlogging=logging,\n)\ndownload_webdata(\nfavicon_dir, c_name=c_name, files=[\"favicon-32x32.png\"], logging=logging\n)\nelse:\n# validate important data-files\nif logging:\nlogger.debug(\"Found valid WebGear data-files successfully.\")\nreturn path\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.download_webdata--download_webdata","title":"download_webdata","text":"<p>Downloads given list of files for WebGear API(if not available) from GitHub Server, and also Validates them.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for downloading data</p> required <code>c_name</code> <code>string</code> <p>class name that is generating files</p> <code>'webgear'</code> <code>files</code> <code>list</code> <p>list of files to be downloaded</p> <code>[]</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A valid path as string.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def download_webdata(path, c_name=\"webgear\", files=[], logging=False):\n\"\"\"\n    ## download_webdata\n    Downloads given list of files for WebGear API(if not available) from GitHub Server,\n    and also Validates them.\n    Parameters:\n        path (string): path for downloading data\n        c_name (string): class name that is generating files\n        files (list): list of files to be downloaded\n        logging (bool): enables logging for its operations\n    **Returns:** A valid path as string.\n    \"\"\"\nbasename = os.path.basename(path)\nif logging:\nlogger.debug(\"Downloading {} data-files at `{}`\".format(basename, path))\n# create session\nwith requests.Session() as http:\nfor file in files:\n# get filename\nfile_name = os.path.join(path, file)\n# get URL\nfile_url = \"https://gitlab.com/abhiTronix/vidgear-vitals/-/raw/main/{}{}/{}/{}\".format(\nc_name, \"/static\" if basename != \"templates\" else \"\", basename, file\n)\n# download and write file to the given path\nlogging and logger.debug(\n\"Downloading {} data-file: {}.\".format(basename, file)\n)\nwith open(file_name, \"wb\") as f:\n# setup retry strategy\nretries = Retry(\ntotal=3,\nbackoff_factor=1,\nstatus_forcelist=[429, 500, 502, 503, 504],\n)\n# Mount it for https usage\nadapter = TimeoutHTTPAdapter(timeout=2.0, max_retries=retries)\nhttp.mount(\"https://\", adapter)\nresponse = http.get(file_url, stream=True)\nresponse.raise_for_status()\ntotal_length = (\nresponse.headers.get(\"content-length\")\nif \"content-length\" in response.headers\nelse len(response.content)\n)\nassert not (\ntotal_length is None\n), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\"\nbar = tqdm(total=int(total_length), unit=\"B\", unit_scale=True)\nfor data in response.iter_content(chunk_size=256):\nf.write(data)\nif len(data) &gt; 0:\nbar.update(len(data))\nbar.close()\nif logging:\nlogger.debug(\"Verifying downloaded data:\")\nif validate_webdata(path, files=files, logging=logging):\nif logging:\nlogger.info(\"Successful!\")\nreturn path\nelse:\nraise RuntimeError(\n\"[Helper:ERROR] :: Failed to download required {} data-files at: {}, Check your Internet connectivity!\".format(\nbasename, path\n)\n)\n</code></pre>"},{"location":"bonus/reference/helper_async/#vidgear.gears.asyncio.helper.validate_webdata--validate_auth_keys","title":"validate_auth_keys","text":"<p>Validates, and also maintains downloaded list of files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path of downloaded files</p> required <code>files</code> <code>list</code> <p>list of files to be validated</p> <code>[]</code> <code>logging</code> <code>bool</code> <p>enables logging for its operations</p> <code>False</code> <p>Returns: A  boolean value, confirming whether tests passed, or not?.</p> Source code in <code>vidgear/gears/asyncio/helper.py</code> <pre><code>def validate_webdata(path, files=[], logging=False):\n\"\"\"\n    ## validate_auth_keys\n    Validates, and also maintains downloaded list of files.\n    Parameters:\n        path (string): path of downloaded files\n        files (list): list of files to be validated\n        logging (bool): enables logging for its operations\n    **Returns:** A  boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n# check if valid path or directory empty\nif not (os.path.exists(path)) or not (os.listdir(path)):\nreturn False\nfiles_buffer = []\n# loop over files\nfor file in os.listdir(path):\nif file in files:\nfiles_buffer.append(file)  # store them\n# return results\nif len(files_buffer) &lt; len(files):\nif logging:\nlogger.warning(\n\"`{}` file(s) missing from data-files!\".format(\n\" ,\".join(list(set(files_buffer) ^ set(files)))\n)\n)\nreturn False\nelse:\nreturn True\n</code></pre>"},{"location":"bonus/reference/netgear/","title":"NetGear API","text":"<p>NetGear API usage examples can be found here \u27b6</p> <p>NetGear API parameters are explained here \u27b6</p> <p>NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time.</p> <p>NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker.</p> <p>NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending it and decoding it on the client's end automatically in real-time.</p> <p>Info</p> <p>NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns (i.e. <code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) at both Server and Client ends, where its API instead of doing a blocking receive, will:</p> <ul> <li>Poll the socket and receive from it only when it's sure a reply has arrived.</li> <li>Attempt to reconnect, if no reply has arrived within a timeout period.</li> <li>Abandon the connection if there is still no reply after several requests.</li> </ul> <p>NetGear as of now seamlessly supports three ZeroMQ messaging patterns:</p> <ul> <li><code>zmq.PAIR</code> (ZMQ Pair Pattern)</li> <li><code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern)</li> <li><code>zmq.PUB/zmq.SUB</code> (ZMQ Publish/Subscribe Pattern)</li> </ul> <p>whereas the supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> Modes of Operation <ul> <li> <p>Primary Modes</p> <p>NetGear API primarily has two modes of operations:</p> <ul> <li> <p>Send Mode: which employs <code>send()</code> function to send video frames over the network in real-time.</p> </li> <li> <p>Receive Mode: which employs <code>recv()</code> function to receive frames, sent over the network with Send Mode in real-time. The mode sends back confirmation when the frame is received successfully in few patterns.</p> </li> </ul> </li> <li> <p>Exclusive Modes</p> <p>In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes:</p> <ul> <li> <p>Multi-Servers Mode: In this exclusive mode, NetGear API robustly handles multiple servers at once, thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time.</p> </li> <li> <p>Multi-Clients Mode: In this exclusive mode, NetGear API robustly handles multiple clients at once, thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time.</p> </li> <li> <p>Bidirectional Mode: This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames.</p> </li> <li> <p>Secure Mode: In this exclusive mode, NetGear API provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network.</p> </li> </ul> </li> </ul> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>class NetGear:\n\"\"\"\n    NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time.\n    NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library\n    that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker.\n    NetGear also supports real-time Frame Compression capabilities for optimizing performance while sending the frames directly over the network, by encoding the frame before sending\n    it and decoding it on the client's end automatically in real-time.\n    !!! info\n        NetGear API now internally implements robust *Lazy Pirate pattern* (auto-reconnection) for its synchronous messaging patterns _(i.e. `zmq.PAIR` &amp; `zmq.REQ/zmq.REP`)_\n        at both Server and Client ends, where its API instead of doing a blocking receive, will:\n        * Poll the socket and receive from it only when it's sure a reply has arrived.\n        * Attempt to reconnect, if no reply has arrived within a timeout period.\n        * Abandon the connection if there is still no reply after several requests.\n    NetGear as of now seamlessly supports three ZeroMQ messaging patterns:\n    - `zmq.PAIR` _(ZMQ Pair Pattern)_\n    - `zmq.REQ/zmq.REP` _(ZMQ Request/Reply Pattern)_\n    - `zmq.PUB/zmq.SUB` _(ZMQ Publish/Subscribe Pattern)_\n    _whereas the supported protocol are: `tcp` and `ipc`_.\n    ??? tip \"Modes of Operation\"\n        * **Primary Modes**\n            NetGear API primarily has two modes of operations:\n            * **Send Mode:** _which employs `send()` function to send video frames over the network in real-time._\n            * **Receive Mode:** _which employs `recv()` function to receive frames, sent over the network with *Send Mode* in real-time. The mode sends back confirmation when the\n            frame is received successfully in few patterns._\n        * **Exclusive Modes**\n            In addition to these primary modes, NetGear API offers applications-specific Exclusive Modes:\n            * **Multi-Servers Mode:** _In this exclusive mode, NetGear API robustly **handles multiple servers at once**, thereby providing seamless access to frames and unidirectional\n            data transfer from multiple Servers/Publishers across the network in real-time._\n            * **Multi-Clients Mode:** _In this exclusive mode, NetGear API robustly **handles multiple clients at once**, thereby providing seamless access to frames and unidirectional\n            data transfer to multiple Client/Consumers across the network in real-time._\n            * **Bidirectional Mode:** _This exclusive mode **provides seamless support for bidirectional data transmission between between Server and Client along with video frames**._\n            * **Secure Mode:** _In this exclusive mode, NetGear API **provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers** that enables strong encryption on\n            data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication\n            for distributed systems over the network._\n    \"\"\"\ndef __init__(\nself,\naddress=None,\nport=None,\nprotocol=None,\npattern=0,\nreceive_mode=False,\nlogging=False,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the NetGear class.\n        Parameters:\n            address (str): sets the valid network address of the Server/Client.\n            port (str): sets the valid Network Port of the Server/Client.\n            protocol (str): sets the valid messaging protocol between Server/Client.\n            pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n            receive_mode (bool): select the Netgear's Mode of operation.\n            logging (bool): enables/disables logging.\n            options (dict): provides the flexibility to alter various NetGear internal properties.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n)\nimport_dependency_safe(\n\"simplejpeg\" if simplejpeg is None else \"\", error=\"log\", min_version=\"1.6.1\"\n)\n# enable logging if specified\nself.__logging = True if logging else False\n# define valid messaging patterns =&gt; `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB)\nvalid_messaging_patterns = {\n0: (zmq.PAIR, zmq.PAIR),\n1: (zmq.REQ, zmq.REP),\n2: (zmq.PUB, zmq.SUB),\n}\n# Handle messaging pattern\nmsg_pattern = None\n# check whether user-defined messaging pattern is valid\nif isinstance(pattern, int) and pattern in valid_messaging_patterns.keys():\n# assign value\nmsg_pattern = valid_messaging_patterns[pattern]\nelse:\n# otherwise default to 0:`zmq.PAIR`\npattern = 0\nmsg_pattern = valid_messaging_patterns[pattern]\nself.__logging and logger.warning(\n\"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\"\n)\n# assign pattern to global parameter for further use\nself.__pattern = pattern\n# Handle messaging protocol\nif protocol is None or not (protocol in [\"tcp\", \"ipc\"]):\n# else default to `tcp` protocol\nprotocol = \"tcp\"\n# log it\nself.__logging and logger.warning(\n\"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\"\n)\n# Handle connection params\nself.__msg_flag = 0  # handles connection flags\nself.__msg_copy = False  # handles whether to copy data\nself.__msg_track = False  # handles whether to track packets\n# Handle NetGear's internal exclusive modes and params\n# define SSH Tunneling Mode\nself.__ssh_tunnel_mode = None  # handles ssh_tunneling mode state\nself.__ssh_tunnel_pwd = None\nself.__ssh_tunnel_keyfile = None\nself.__paramiko_present = False if paramiko is None else True\n# define Multi-Server mode\nself.__multiserver_mode = False  # handles multi-server mode state\n# define Multi-Client mode\nself.__multiclient_mode = False  # handles multi-client mode state\n# define Bidirectional mode\nself.__bi_mode = False  # handles Bidirectional mode state\n# define Secure mode\nvalid_security_mech = {0: \"Grasslands\", 1: \"StoneHouse\", 2: \"IronHouse\"}\nself.__secure_mode = 0  # handles ZMQ security layer status\nauth_cert_dir = \"\"  # handles valid ZMQ certificates dir\nself.__auth_publickeys_dir = \"\"  # handles valid ZMQ public certificates dir\nself.__auth_secretkeys_dir = \"\"  # handles valid ZMQ private certificates dir\noverwrite_cert = False  # checks if certificates overwriting allowed\ncustom_cert_location = \"\"  # handles custom ZMQ certificates path\n# define frame-compression handler\nself.__jpeg_compression = (\nTrue if not (simplejpeg is None) else False\n)  # enabled by default for all connections if simplejpeg is installed\nself.__jpeg_compression_quality = 90  # 90% quality\nself.__jpeg_compression_fastdct = True  # fastest DCT on by default\nself.__jpeg_compression_fastupsample = False  # fastupsample off by default\nself.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\n# defines frame compression on return data\nself.__ex_compression_params = None\n# define receiver return data handler\nself.__return_data = None\n# generate 8-digit random system id\nself.__id = \"\".join(\nsecrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n)\n# define termination flag\nself.__terminate = False\n# additional settings for reliability\nif pattern &lt; 2:\n# define zmq poller for reliable transmission\nself.__poll = zmq.Poller()\n# define max retries\nself.__max_retries = 3\n# request timeout\nself.__request_timeout = 4000  # 4 secs\n# Handle user-defined options dictionary values\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# loop over dictionary key &amp; values and assign to global variables if valid\nfor key, value in options.items():\n# handle multi-server mode\nif key == \"multiserver_mode\" and isinstance(value, bool):\n# check if valid pattern assigned\nif pattern &gt; 0:\n# activate Multi-server mode\nself.__multiserver_mode = value\nelse:\n# otherwise disable it and raise error\nself.__multiserver_mode = False\nlogger.critical(\"Multi-Server Mode is disabled!\")\nraise ValueError(\n\"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\".format(\npattern\n)\n)\n# handle multi-client mode\nelif key == \"multiclient_mode\" and isinstance(value, bool):\n# check if valid pattern assigned\nif pattern &gt; 0:\n# activate Multi-client mode\nself.__multiclient_mode = value\nelse:\n# otherwise disable it and raise error\nself.__multiclient_mode = False\nlogger.critical(\"Multi-Client Mode is disabled!\")\nraise ValueError(\n\"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\".format(\npattern\n)\n)\n# handle bidirectional mode\nelif key == \"bidirectional_mode\" and isinstance(value, bool):\n# check if pattern is valid\nif pattern &lt; 2:\n# activate Bidirectional mode if specified\nself.__bi_mode = value\nelse:\n# otherwise disable it and raise error\nself.__bi_mode = False\nlogger.warning(\"Bidirectional data transmission is disabled!\")\nraise ValueError(\n\"[NetGear:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\npattern\n)\n)\n# handle secure mode\nelif (\nkey == \"secure_mode\"\nand isinstance(value, int)\nand (value in valid_security_mech)\n):\nself.__secure_mode = value\nelif key == \"custom_cert_location\" and isinstance(value, str):\n# verify custom auth certificates path for secure mode\ncustom_cert_location = os.path.abspath(value)\nassert os.path.isdir(\ncustom_cert_location\n), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\"\nassert check_WriteAccess(\ncustom_cert_location,\nis_windows=True if os.name == \"nt\" else False,\nlogging=self.__logging,\n), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to '{}' directory!\".format(\nvalue\n)\nelif key == \"overwrite_cert\" and isinstance(value, bool):\n# enable/disable auth certificate overwriting in secure mode\noverwrite_cert = value\n# handle ssh-tunneling mode\nelif key == \"ssh_tunnel_mode\" and isinstance(value, str):\n# enable SSH Tunneling Mode\nself.__ssh_tunnel_mode = value.strip()\nelif key == \"ssh_tunnel_pwd\" and isinstance(value, str):\n# add valid SSH Tunneling password\nself.__ssh_tunnel_pwd = value\nelif key == \"ssh_tunnel_keyfile\" and isinstance(value, str):\n# add valid SSH Tunneling key-file\nself.__ssh_tunnel_keyfile = value if os.path.isfile(value) else None\nif self.__ssh_tunnel_keyfile is None:\nlogger.warning(\n\"Discarded invalid or non-existential SSH Tunnel Key-file at {}!\".format(\nvalue\n)\n)\n# handle jpeg compression\nelif (\nkey == \"jpeg_compression\"\nand not (simplejpeg is None)\nand isinstance(value, (bool, str))\n):\nif isinstance(value, str) and value.strip().upper() in [\n\"RGB\",\n\"BGR\",\n\"RGBX\",\n\"BGRX\",\n\"XBGR\",\n\"XRGB\",\n\"GRAY\",\n\"RGBA\",\n\"BGRA\",\n\"ABGR\",\n\"ARGB\",\n\"CMYK\",\n]:\n# set encoding colorspace\nself.__jpeg_compression_colorspace = value.strip().upper()\n# enable frame-compression encoding value\nself.__jpeg_compression = True\nelse:\n# enable frame-compression encoding value\nself.__jpeg_compression = value\nelif key == \"jpeg_compression_quality\" and isinstance(value, (int, float)):\n# set valid jpeg quality\nif value &gt;= 10 and value &lt;= 100:\nself.__jpeg_compression_quality = int(value)\nelse:\nlogger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\nelif key == \"jpeg_compression_fastdct\" and isinstance(value, bool):\n# enable jpeg fastdct\nself.__jpeg_compression_fastdct = value\nelif key == \"jpeg_compression_fastupsample\" and isinstance(value, bool):\n# enable jpeg  fastupsample\nself.__jpeg_compression_fastupsample = value\n# assign maximum retries in synchronous patterns\nelif key == \"max_retries\" and isinstance(value, int) and pattern &lt; 2:\nif value &gt;= 0:\nself.__max_retries = value\nelse:\nlogger.warning(\"Invalid `max_retries` value skipped!\")\n# assign request timeout in synchronous patterns\nelif key == \"request_timeout\" and isinstance(value, int) and pattern &lt; 2:\nif value &gt;= 4:\nself.__request_timeout = value * 1000  # covert to milliseconds\nelse:\nlogger.warning(\"Invalid `request_timeout` value skipped!\")\n# handle ZMQ flags\nelif key == \"flag\" and isinstance(value, int):\nself.__msg_flag = value\nelif key == \"copy\" and isinstance(value, bool):\nself.__msg_copy = value\nelif key == \"track\" and isinstance(value, bool):\nself.__msg_track = value\nelse:\npass\n# Handle Secure mode\nif self.__secure_mode:\n# activate and log if overwriting is enabled\nif overwrite_cert:\nif not receive_mode:\nself.__logging and logger.warning(\n\"Overwriting ZMQ Authentication certificates over previous ones!\"\n)\nelse:\noverwrite_cert = False\nself.__logging and logger.critical(\n\"Overwriting ZMQ Authentication certificates is disabled for Client's end!\"\n)\n# Validate certificate generation paths\ntry:\n# check if custom certificates path is specified\nif custom_cert_location:\n(\nauth_cert_dir,\nself.__auth_secretkeys_dir,\nself.__auth_publickeys_dir,\n) = generate_auth_certificates(\ncustom_cert_location, overwrite=overwrite_cert, logging=logging\n)\nelse:\n# otherwise auto-generate suitable path\n(\nauth_cert_dir,\nself.__auth_secretkeys_dir,\nself.__auth_publickeys_dir,\n) = generate_auth_certificates(\nos.path.join(expanduser(\"~\"), \".vidgear\"),\noverwrite=overwrite_cert,\nlogging=logging,\n)\n# log it\nself.__logging and logger.debug(\n\"`{}` is the default location for storing ZMQ authentication certificates/keys.\".format(\nauth_cert_dir\n)\n)\nexcept Exception as e:\n# catch if any error occurred and disable Secure mode\nlogger.exception(str(e))\nself.__secure_mode = 0\nlogger.critical(\n\"ZMQ Security Mechanism is disabled for this connection due to errors!\"\n)\n# Handle ssh tunneling if enabled\nif not (self.__ssh_tunnel_mode is None):\n# SSH Tunnel Mode only available for server mode\nif receive_mode:\nlogger.error(\"SSH Tunneling cannot be enabled for Client-end!\")\nelse:\n# check if SSH tunneling possible\nssh_address = self.__ssh_tunnel_mode\nssh_address, ssh_port = (\nssh_address.split(\":\")\nif \":\" in ssh_address\nelse [ssh_address, \"22\"]\n)  # default to port 22\nif \"47\" in ssh_port:\nself.__ssh_tunnel_mode = self.__ssh_tunnel_mode.replace(\n\":47\", \"\"\n)  # port-47 is reserved for testing\nelse:\n# extract ip for validation\nssh_user, ssh_ip = (\nssh_address.split(\"@\")\nif \"@\" in ssh_address\nelse [\"\", ssh_address]\n)\n# validate ip specified port\nassert check_open_port(\nssh_ip, port=int(ssh_port)\n), \"[NetGear:ERROR] :: Host `{}` is not available for SSH Tunneling at port-{}!\".format(\nssh_address, ssh_port\n)\n# Handle multiple exclusive modes if enabled\nif self.__multiclient_mode and self.__multiserver_mode:\nraise ValueError(\n\"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\"\n)\nelif self.__multiserver_mode or self.__multiclient_mode:\n# check if Bidirectional Mode also enabled\nif self.__bi_mode:\n# log it\nself.__logging and logger.debug(\n\"Bidirectional Data Transmission is also enabled for this connection!\"\n)\n# check if SSH Tunneling Mode also enabled\nif self.__ssh_tunnel_mode:\n# raise error\nraise ValueError(\n\"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\".format(\n\"Multi-Server\" if self.__multiserver_mode else \"Multi-Client\"\n)\n)\nelif self.__bi_mode:\n# log Bidirectional mode activation\nself.__logging and logger.debug(\n\"Bidirectional Data Transmission is enabled for this connection!\"\n)\nelif self.__ssh_tunnel_mode:\n# log Bidirectional mode activation\nself.__logging and logger.debug(\n\"SSH Tunneling is enabled for host:`{}` with `{}` back-end.\".format(\nself.__ssh_tunnel_mode,\n\"paramiko\" if self.__paramiko_present else \"pexpect\",\n)\n)\n# define messaging context instance\nself.__msg_context = zmq.Context.instance()\n# initialize and assign receive mode to global variable\nself.__receive_mode = receive_mode\n# check whether `receive_mode` is enabled\nif self.__receive_mode:\n# define connection address\nif address is None:\naddress = \"*\"  # define address\n# check if multiserver_mode is enabled\nif self.__multiserver_mode:\n# check if unique server port address list/tuple is assigned or not in multiserver_mode\nif port is None or not isinstance(port, (tuple, list)):\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Server Mode at PORTS: {}!\".format(port)\n)\n# create port address buffer for keeping track of connected client's port(s)\nself.__port_buffer = []\n# check if multiclient_mode is enabled\nelif self.__multiclient_mode:\n# check if unique server port address is assigned or not in multiclient_mode\nif port is None:\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Client-end. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Client Mode at PORT: {} on this device!\".format(\nport\n)\n)\n# assign value to global variable\nself.__port = port\nelse:\n# otherwise assign local port address if None\nif port is None:\nport = \"5555\"\ntry:\n# activate secure_mode threaded authenticator\nif self.__secure_mode &gt; 0:\n# start an authenticator for this context\nz_auth = ThreadAuthenticator(self.__msg_context)\nz_auth.start()\nz_auth.allow(str(address))  # allow current address\n# check if `IronHouse` is activated\nif self.__secure_mode == 2:\n# tell authenticator to use the certificate from given valid dir\nz_auth.configure_curve(\ndomain=\"*\", location=self.__auth_publickeys_dir\n)\nelse:\n# otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated\nz_auth.configure_curve(\ndomain=\"*\", location=auth.CURVE_ALLOW_ANY\n)\n# define thread-safe messaging socket\nself.__msg_socket = self.__msg_context.socket(msg_pattern[1])\n# define pub-sub flag\nif self.__pattern == 2:\nself.__msg_socket.set_hwm(1)\n# enable specified secure mode for the socket\nif self.__secure_mode &gt; 0:\n# load server key\nserver_secret_file = os.path.join(\nself.__auth_secretkeys_dir, \"server.key_secret\"\n)\nserver_public, server_secret = auth.load_certificate(\nserver_secret_file\n)\n# load  all CURVE keys\nself.__msg_socket.curve_secretkey = server_secret\nself.__msg_socket.curve_publickey = server_public\n# enable CURVE connection for this socket\nself.__msg_socket.curve_server = True\n# define exclusive socket options for patterns\nif self.__pattern == 2:\nself.__msg_socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n# if multiserver_mode is enabled, then assign port addresses to zmq socket\nif self.__multiserver_mode:\n# bind socket to given server protocol, address and ports\nfor pt in port:\nself.__msg_socket.bind(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\n# bind socket to given protocol, address and port normally\nself.__msg_socket.bind(\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\n# additional settings\nif pattern &lt; 2:\nif self.__multiserver_mode:\nself.__connection_address = []\nfor pt in port:\nself.__connection_address.append(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\nself.__connection_address = (\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\nself.__msg_pattern = msg_pattern[1]\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\nself.__logging and logger.debug(\n\"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\nself.__max_retries, self.__request_timeout / 1000\n)\n)\nexcept Exception as e:\n# otherwise log and raise error\nlogger.exception(str(e))\nif self.__secure_mode:\nlogger.critical(\n\"Failed to activate Secure Mode: `{}` for this connection!\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nif self.__multiserver_mode or self.__multiclient_mode:\nraise RuntimeError(\n\"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n\"Multi-Server\"\nif self.__multiserver_mode\nelse \"Multi-Client\",\n(protocol + \"://\" + str(address) + \":\" + str(port)),\npattern,\n)\n)\nelse:\nif self.__bi_mode:\nlogger.critical(\n\"Failed to activate Bidirectional Mode for this connection!\"\n)\nraise RuntimeError(\n\"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\n# Handle threaded queue mode\nself.__logging and logger.debug(\n\"Threaded Queue Mode is enabled by default for this connection.\"\n)\n# define deque and assign it to global var\nself.__queue = deque(maxlen=96)  # max len 96 to check overflow\n# initialize and start threaded recv_handler\nself.__thread = Thread(target=self.__recv_handler, name=\"NetGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\nif self.__logging:\n# finally log progress\nlogger.debug(\n\"Successfully Binded to address: {} with pattern: {}.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\nif self.__jpeg_compression:\nlogger.debug(\n\"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\nself.__jpeg_compression_colorspace,\nself.__jpeg_compression_quality,\n\"enabled\"\nif self.__jpeg_compression_fastdct\nelse \"disabled\",\n\"enabled\"\nif self.__jpeg_compression_fastupsample\nelse \"disabled\",\n)\n)\nif self.__secure_mode:\nlogger.debug(\n\"Successfully enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nlogger.debug(\"Multi-threaded Receive Mode is successfully enabled.\")\nlogger.debug(\"Unique System ID is {}.\".format(self.__id))\nlogger.debug(\"Receive Mode is now activated.\")\nelse:\n# otherwise default to `Send Mode`\n# define connection address\nif address is None:\naddress = \"localhost\"\n# check if multiserver_mode is enabled\nif self.__multiserver_mode:\n# check if unique server port address is assigned or not in multiserver_mode\nif port is None:\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Server-end. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Server Mode at PORT: {} on this device!\".format(\nport\n)\n)\n# assign value to global variable\nself.__port = port\n# check if multiclient_mode is enabled\nelif self.__multiclient_mode:\n# check if unique client port address list/tuple is assigned or not in multiclient_mode\nif port is None or not isinstance(port, (tuple, list)):\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Client Mode at PORTS: {}!\".format(port)\n)\n# create port address buffer for keeping track of connected client ports\nself.__port_buffer = []\nelse:\n# otherwise assign local port address if None\nif port is None:\nport = \"5555\"\ntry:\n# activate secure_mode threaded authenticator\nif self.__secure_mode &gt; 0:\n# start an authenticator for this context\nz_auth = ThreadAuthenticator(self.__msg_context)\nz_auth.start()\nz_auth.allow(str(address))  # allow current address\n# check if `IronHouse` is activated\nif self.__secure_mode == 2:\n# tell authenticator to use the certificate from given valid dir\nz_auth.configure_curve(\ndomain=\"*\", location=self.__auth_publickeys_dir\n)\nelse:\n# otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated\nz_auth.configure_curve(\ndomain=\"*\", location=auth.CURVE_ALLOW_ANY\n)\n# define thread-safe messaging socket\nself.__msg_socket = self.__msg_context.socket(msg_pattern[0])\n# if req/rep pattern, define additional flags\nif self.__pattern == 1:\nself.__msg_socket.REQ_RELAXED = True\nself.__msg_socket.REQ_CORRELATE = True\n# if pub/sub pattern, define additional optimizer\nif self.__pattern == 2:\nself.__msg_socket.set_hwm(1)\n# enable specified secure mode for the socket\nif self.__secure_mode &gt; 0:\n# load client key\nclient_secret_file = os.path.join(\nself.__auth_secretkeys_dir, \"client.key_secret\"\n)\nclient_public, client_secret = auth.load_certificate(\nclient_secret_file\n)\n# load  all CURVE keys\nself.__msg_socket.curve_secretkey = client_secret\nself.__msg_socket.curve_publickey = client_public\n# load server key\nserver_public_file = os.path.join(\nself.__auth_publickeys_dir, \"server.key\"\n)\nserver_public, _ = auth.load_certificate(server_public_file)\n# inject public key to make a CURVE connection.\nself.__msg_socket.curve_serverkey = server_public\n# check if multi-client_mode is enabled\nif self.__multiclient_mode:\n# bind socket to given server protocol, address and ports\nfor pt in port:\nself.__msg_socket.connect(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\n# handle SSH tunneling if enabled\nif self.__ssh_tunnel_mode:\n# establish tunnel connection\nssh.tunnel_connection(\nself.__msg_socket,\nprotocol + \"://\" + str(address) + \":\" + str(port),\nself.__ssh_tunnel_mode,\nkeyfile=self.__ssh_tunnel_keyfile,\npassword=self.__ssh_tunnel_pwd,\nparamiko=self.__paramiko_present,\n)\nelse:\n# connect socket to given protocol, address and port\nself.__msg_socket.connect(\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\n# additional settings\nif pattern &lt; 2:\nif self.__multiclient_mode:\nself.__connection_address = []\nfor pt in port:\nself.__connection_address.append(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\nself.__connection_address = (\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\nself.__msg_pattern = msg_pattern[0]\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\nself.__logging and logger.debug(\n\"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\nself.__max_retries, self.__request_timeout / 1000\n)\n)\nexcept Exception as e:\n# otherwise log and raise error\nlogger.exception(str(e))\nif self.__secure_mode:\nlogger.critical(\n\"Failed to activate Secure Mode: `{}` for this connection!\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nif self.__multiserver_mode or self.__multiclient_mode:\nraise RuntimeError(\n\"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n\"Multi-Server\"\nif self.__multiserver_mode\nelse \"Multi-Client\",\n(protocol + \"://\" + str(address) + \":\" + str(port)),\npattern,\n)\n)\nelse:\nif self.__bi_mode:\nlogger.critical(\n\"Failed to activate Bidirectional Mode for this connection!\"\n)\nif self.__ssh_tunnel_mode:\nlogger.critical(\n\"Failed to initiate SSH Tunneling Mode for this server with `{}` back-end!\".format(\n\"paramiko\" if self.__paramiko_present else \"pexpect\"\n)\n)\nraise RuntimeError(\n\"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\nif self.__logging:\n# finally log progress\nlogger.debug(\n\"Successfully connected to address: {} with pattern: {}.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\nif self.__jpeg_compression:\nlogger.debug(\n\"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\nself.__jpeg_compression_colorspace,\nself.__jpeg_compression_quality,\n\"enabled\"\nif self.__jpeg_compression_fastdct\nelse \"disabled\",\n\"enabled\"\nif self.__jpeg_compression_fastupsample\nelse \"disabled\",\n)\n)\nif self.__secure_mode:\nlogger.debug(\n\"Enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nlogger.debug(\"Unique System ID is {}.\".format(self.__id))\nlogger.debug(\n\"Send Mode is successfully activated and ready to send data.\"\n)\ndef __recv_handler(self):\n\"\"\"\n        A threaded receiver handler, that keep iterating data from ZMQ socket to a internally monitored deque,\n        until the thread is terminated, or socket disconnects.\n        \"\"\"\n# initialize frame variable\nframe = None\n# keep looping infinitely until the thread is terminated\nwhile not self.__terminate:\n# check queue buffer for overflow\nif len(self.__queue) &gt;= 96:\n# stop iterating if overflowing occurs\ntime.sleep(0.000001)\ncontinue\nif self.__pattern &lt; 2:\nsocks = dict(self.__poll.poll(self.__request_timeout * 3))\nif socks.get(self.__msg_socket) == zmq.POLLIN:\nmsg_json = self.__msg_socket.recv_json(\nflags=self.__msg_flag | zmq.DONTWAIT\n)\nelse:\nlogger.critical(\"No response from Server(s), Reconnecting again...\")\nself.__msg_socket.close(linger=0)\nself.__poll.unregister(self.__msg_socket)\nself.__max_retries -= 1\nif not (self.__max_retries):\nif self.__multiserver_mode:\nlogger.error(\"All Servers seems to be offline, Abandoning!\")\nelse:\nlogger.error(\"Server seems to be offline, Abandoning!\")\nself.__terminate = True\ncontinue\n# Create new connection\ntry:\nself.__msg_socket = self.__msg_context.socket(\nself.__msg_pattern\n)\nif isinstance(self.__connection_address, list):\nfor _connection in self.__connection_address:\nself.__msg_socket.bind(_connection)\nelse:\nself.__msg_socket.bind(self.__connection_address)\nexcept Exception as e:\nlogger.exception(str(e))\nself.__terminate = True\nraise RuntimeError(\"API failed to restart the Client-end!\")\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\ncontinue\nelse:\nmsg_json = self.__msg_socket.recv_json(flags=self.__msg_flag)\n# check if terminate_flag` received\nif msg_json[\"terminate_flag\"]:\n# if multiserver_mode is enabled\nif self.__multiserver_mode:\n# check and remove from which ports signal is received\nif msg_json[\"port\"] in self.__port_buffer:\n# if pattern is 1, then send back server the info about termination\nif self.__pattern == 1:\nself.__msg_socket.send_string(\n\"Termination signal successfully received at client!\"\n)\nself.__port_buffer.remove(msg_json[\"port\"])\nself.__logging and logger.warning(\n\"Termination signal received from Server at port: {}!\".format(\nmsg_json[\"port\"]\n)\n)\n# if termination signal received from all servers then exit client.\nif not self.__port_buffer:\nlogger.critical(\n\"Termination signal received from all Servers!!!\"\n)\nself.__terminate = True  # termination\nelse:\n# if pattern is 1, then send back server the info about termination\nif self.__pattern == 1:\nself.__msg_socket.send_string(\n\"Termination signal successfully received at Client's end!\"\n)\n# termination\nself.__terminate = True\n# notify client\nself.__logging and logger.critical(\n\"Termination signal received from server!\"\n)\ncontinue\nmsg_data = self.__msg_socket.recv(\nflags=self.__msg_flag | zmq.DONTWAIT,\ncopy=self.__msg_copy,\ntrack=self.__msg_track,\n)\n# handle data transfer in synchronous modes.\nif self.__pattern &lt; 2:\nif self.__bi_mode or self.__multiclient_mode:\n# check if we are returning `ndarray` frames\nif not (self.__return_data is None) and isinstance(\nself.__return_data, np.ndarray\n):\n# handle return data for compression\nreturn_data = np.copy(self.__return_data)\n# check whether exit_flag is False\nif not (return_data.flags[\"C_CONTIGUOUS\"]):\n# check whether the incoming frame is contiguous\nreturn_data = np.ascontiguousarray(\nreturn_data, dtype=return_data.dtype\n)\n# handle jpeg-compression encoding\nif self.__jpeg_compression:\nif self.__jpeg_compression_colorspace == \"GRAY\":\nif return_data.ndim == 2:\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nreturn_data = return_data[:, :, np.newaxis]\nreturn_data = simplejpeg.encode_jpeg(\nreturn_data,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\nfastdct=self.__jpeg_compression_fastdct,\n)\nelse:\nreturn_data = simplejpeg.encode_jpeg(\nreturn_data,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\ncolorsubsampling=\"422\",\nfastdct=self.__jpeg_compression_fastdct,\n)\nreturn_dict = (\ndict(port=self.__port)\nif self.__multiclient_mode\nelse dict()\n)\nreturn_dict.update(\ndict(\nreturn_type=(type(self.__return_data).__name__),\ncompression={\n\"dct\": self.__jpeg_compression_fastdct,\n\"ups\": self.__jpeg_compression_fastupsample,\n\"colorspace\": self.__jpeg_compression_colorspace,\n}\nif self.__jpeg_compression\nelse False,\narray_dtype=str(self.__return_data.dtype)\nif not (self.__jpeg_compression)\nelse \"\",\narray_shape=self.__return_data.shape\nif not (self.__jpeg_compression)\nelse \"\",\ndata=None,\n)\n)\n# send the json dict\nself.__msg_socket.send_json(\nreturn_dict, self.__msg_flag | zmq.SNDMORE\n)\n# send the array with correct flags\nself.__msg_socket.send(\nreturn_data,\nflags=self.__msg_flag,\ncopy=self.__msg_copy,\ntrack=self.__msg_track,\n)\nelse:\nreturn_dict = (\ndict(port=self.__port)\nif self.__multiclient_mode\nelse dict()\n)\nreturn_dict.update(\ndict(\nreturn_type=(type(self.__return_data).__name__),\ndata=self.__return_data,\n)\n)\nself.__msg_socket.send_json(return_dict, self.__msg_flag)\nelse:\n# send confirmation message to server\nself.__msg_socket.send_string(\n\"Data received on device: {} !\".format(self.__id)\n)\nelse:\n# else raise warning\nif self.__return_data:\nlogger.warning(\"`return_data` is disabled for this pattern!\")\n# check if encoding was enabled\nif msg_json[\"compression\"]:\n# decode JPEG frame\nframe = simplejpeg.decode_jpeg(\nmsg_data,\ncolorspace=msg_json[\"compression\"][\"colorspace\"],\nfastdct=self.__jpeg_compression_fastdct\nor msg_json[\"compression\"][\"dct\"],\nfastupsample=self.__jpeg_compression_fastupsample\nor msg_json[\"compression\"][\"ups\"],\n)\n# check if valid frame returned\nif frame is None:\nself.__terminate = True\n# otherwise raise error and exit\nraise RuntimeError(\n\"[NetGear:ERROR] :: Received compressed JPEG frame decoding failed\"\n)\nif msg_json[\"compression\"][\"colorspace\"] == \"GRAY\" and frame.ndim == 3:\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nframe = np.squeeze(frame, axis=2)\nelse:\n# recover and reshape frame from buffer\nframe_buffer = np.frombuffer(msg_data, dtype=msg_json[\"dtype\"])\nframe = frame_buffer.reshape(msg_json[\"shape\"])\n# check if multiserver_mode\nif self.__multiserver_mode:\n# save the unique port addresses\nif not msg_json[\"port\"] in self.__port_buffer:\nself.__port_buffer.append(msg_json[\"port\"])\n# extract if any message from server and display it\nif msg_json[\"message\"]:\nself.__queue.append((msg_json[\"port\"], msg_json[\"message\"], frame))\nelse:\n# append recovered unique port and frame to queue\nself.__queue.append((msg_json[\"port\"], frame))\n# extract if any message from server if Bidirectional Mode is enabled\nelif self.__bi_mode:\nif msg_json[\"message\"]:\n# append grouped frame and data to queue\nself.__queue.append((msg_json[\"message\"], frame))\nelse:\nself.__queue.append((None, frame))\nelse:\n# otherwise append recovered frame to queue\nself.__queue.append(frame)\ndef recv(self, return_data=None):\n\"\"\"\n        A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a\n        fixed-length frame buffer in the memory, and blocks the thread if the deque is full.\n        Parameters:\n            return_data (any): inputs return data _(of any datatype)_, for sending back to Server.\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n# check whether `receive mode` is activated\nif not (self.__receive_mode):\n# raise value error and exit\nself.__terminate = True\nraise ValueError(\n\"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\"\n)\n# handle Bidirectional return data\nif (self.__bi_mode or self.__multiclient_mode) and not (return_data is None):\nself.__return_data = return_data\n# check whether or not termination flag is enabled\nwhile not self.__terminate:\ntry:\n# check if queue is empty\nif len(self.__queue) &gt; 0:\nreturn self.__queue.popleft()\nelse:\ntime.sleep(0.00001)\ncontinue\nexcept KeyboardInterrupt:\nself.__terminate = True\nbreak\n# otherwise return NoneType\nreturn None\ndef send(self, frame, message=None):\n\"\"\"\n        A Server end method, that sends the data and frames over the network to Client(s).\n        Parameters:\n            frame (numpy.ndarray): inputs numpy array(frame).\n            message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s).\n        **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type.\n        \"\"\"\n# check whether `receive_mode` is disabled\nif self.__receive_mode:\n# raise value error and exit\nself.__terminate = True\nraise ValueError(\n\"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\"\n)\nif not (message is None) and isinstance(message, np.ndarray):\nlogger.warning(\n\"Skipped unsupported `message` of datatype: {}!\".format(\ntype(message).__name__\n)\n)\nmessage = None\n# define exit_flag and assign value\nexit_flag = True if (frame is None or self.__terminate) else False\n# check whether exit_flag is False\nif not (exit_flag) and not (frame.flags[\"C_CONTIGUOUS\"]):\n# check whether the incoming frame is contiguous\nframe = np.ascontiguousarray(frame, dtype=frame.dtype)\n# handle JPEG compression encoding\nif self.__jpeg_compression:\nif self.__jpeg_compression_colorspace == \"GRAY\":\nif frame.ndim == 2:\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nframe = np.expand_dims(frame, axis=2)\nframe = simplejpeg.encode_jpeg(\nframe,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\nfastdct=self.__jpeg_compression_fastdct,\n)\nelse:\nframe = simplejpeg.encode_jpeg(\nframe,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\ncolorsubsampling=\"422\",\nfastdct=self.__jpeg_compression_fastdct,\n)\n# check if multiserver_mode is activated and assign values with unique port\nmsg_dict = dict(port=self.__port) if self.__multiserver_mode else dict()\n# prepare the exclusive json dict\nmsg_dict.update(\ndict(\nterminate_flag=exit_flag,\ncompression={\n\"dct\": self.__jpeg_compression_fastdct,\n\"ups\": self.__jpeg_compression_fastupsample,\n\"colorspace\": self.__jpeg_compression_colorspace,\n}\nif self.__jpeg_compression\nelse False,\nmessage=message,\npattern=str(self.__pattern),\ndtype=str(frame.dtype) if not (self.__jpeg_compression) else \"\",\nshape=frame.shape if not (self.__jpeg_compression) else \"\",\n)\n)\n# send the json dict\nself.__msg_socket.send_json(msg_dict, self.__msg_flag | zmq.SNDMORE)\n# send the frame array with correct flags\nself.__msg_socket.send(\nframe, flags=self.__msg_flag, copy=self.__msg_copy, track=self.__msg_track\n)\n# check if synchronous patterns, then wait for confirmation\nif self.__pattern &lt; 2:\n# check if Bidirectional data transmission is enabled\nif self.__bi_mode or self.__multiclient_mode:\n# handles return data\nrecvd_data = None\nsocks = dict(self.__poll.poll(self.__request_timeout))\nif socks.get(self.__msg_socket) == zmq.POLLIN:\n# handle return data\nrecv_json = self.__msg_socket.recv_json(flags=self.__msg_flag)\nelse:\nlogger.critical(\"No response from Client, Reconnecting again...\")\n# Socket is confused. Close and remove it.\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nself.__poll.unregister(self.__msg_socket)\nself.__max_retries -= 1\nif not (self.__max_retries):\nif self.__multiclient_mode:\nlogger.error(\n\"All Clients failed to respond on multiple attempts.\"\n)\nelse:\nlogger.error(\n\"Client failed to respond on multiple attempts.\"\n)\nself.__terminate = True\nraise RuntimeError(\n\"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\"\n)\n# Create new connection\nself.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\nif isinstance(self.__connection_address, list):\nfor _connection in self.__connection_address:\nself.__msg_socket.connect(_connection)\nelse:\n# handle SSH tunneling if enabled\nif self.__ssh_tunnel_mode:\n# establish tunnel connection\nssh.tunnel_connection(\nself.__msg_socket,\nself.__connection_address,\nself.__ssh_tunnel_mode,\nkeyfile=self.__ssh_tunnel_keyfile,\npassword=self.__ssh_tunnel_pwd,\nparamiko=self.__paramiko_present,\n)\nelse:\n# connect normally\nself.__msg_socket.connect(self.__connection_address)\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\n# return None for mean-time\nreturn None\n# save the unique port addresses\nif (\nself.__multiclient_mode\nand not recv_json[\"port\"] in self.__port_buffer\n):\nself.__port_buffer.append(recv_json[\"port\"])\nif recv_json[\"return_type\"] == \"ndarray\":\nrecv_array = self.__msg_socket.recv(\nflags=self.__msg_flag,\ncopy=self.__msg_copy,\ntrack=self.__msg_track,\n)\n# check if encoding was enabled\nif recv_json[\"compression\"]:\n# decode JPEG frame\nrecvd_data = simplejpeg.decode_jpeg(\nrecv_array,\ncolorspace=recv_json[\"compression\"][\"colorspace\"],\nfastdct=self.__jpeg_compression_fastdct\nor recv_json[\"compression\"][\"dct\"],\nfastupsample=self.__jpeg_compression_fastupsample\nor recv_json[\"compression\"][\"ups\"],\n)\n# check if valid frame returned\nif recvd_data is None:\nself.__terminate = True\n# otherwise raise error and exit\nraise RuntimeError(\n\"[NetGear:ERROR] :: Received compressed frame `{}` decoding failed with flag: {}.\".format(\nrecv_json[\"compression\"],\nself.__ex_compression_params,\n)\n)\nif (\nrecv_json[\"compression\"][\"colorspace\"] == \"GRAY\"\nand recvd_data.ndim == 3\n):\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nrecvd_data = np.squeeze(recvd_data, axis=2)\nelse:\nrecvd_data = np.frombuffer(\nrecv_array, dtype=recv_json[\"array_dtype\"]\n).reshape(recv_json[\"array_shape\"])\nelse:\nrecvd_data = recv_json[\"data\"]\nreturn (\n(recv_json[\"port\"], recvd_data)\nif self.__multiclient_mode\nelse recvd_data\n)\nelse:\n# otherwise log normally\nsocks = dict(self.__poll.poll(self.__request_timeout))\nif socks.get(self.__msg_socket) == zmq.POLLIN:\nrecv_confirmation = self.__msg_socket.recv()\nelse:\nlogger.critical(\"No response from Client, Reconnecting again...\")\n# Socket is confused. Close and remove it.\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nself.__poll.unregister(self.__msg_socket)\nself.__max_retries -= 1\nif not (self.__max_retries):\nlogger.error(\"Client failed to respond on repeated attempts.\")\nself.__terminate = True\nraise RuntimeError(\n\"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\"\n)\n# Create new connection\nself.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\n# handle SSH tunneling if enabled\nif self.__ssh_tunnel_mode:\n# establish tunnel connection\nssh.tunnel_connection(\nself.__msg_socket,\nself.__connection_address,\nself.__ssh_tunnel_mode,\nkeyfile=self.__ssh_tunnel_keyfile,\npassword=self.__ssh_tunnel_pwd,\nparamiko=self.__paramiko_present,\n)\nelse:\n# connect normally\nself.__msg_socket.connect(self.__connection_address)\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\nreturn None\n# log confirmation\nself.__logging and logger.debug(recv_confirmation)\ndef close(self):\n\"\"\"\n        Safely terminates the threads, and NetGear resources.\n        \"\"\"\n# log it\nself.__logging and logger.debug(\n\"Terminating various {} Processes.\".format(\n\"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n)\n)\n#  whether `receive_mode` is enabled or not\nif self.__receive_mode:\n# check whether queue mode is empty\nif not (self.__queue is None) and self.__queue:\nself.__queue.clear()\n# call immediate termination\nself.__terminate = True\n# wait until stream resources are released (producer thread might be still grabbing frame)\nif self.__thread is not None:\n# properly handle thread exit\nself.__thread.join()\nself.__thread = None\nself.__logging and logger.debug(\"Terminating. Please wait...\")\n# properly close the socket\nself.__msg_socket.close(linger=0)\nself.__logging and logger.debug(\"Terminated Successfully!\")\nelse:\n# indicate that process should be terminated\nself.__terminate = True\n# check if all attempts of reconnecting failed, then skip to closure\nif (self.__pattern &lt; 2 and not self.__max_retries) or (\nself.__multiclient_mode and not self.__port_buffer\n):\ntry:\n# properly close the socket\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nexcept ZMQError:\npass\nfinally:\n# exit\nreturn\nif self.__multiserver_mode:\n# check if multiserver_mode\n# send termination flag to client with its unique port\nterm_dict = dict(terminate_flag=True, port=self.__port)\nelse:\n# otherwise send termination flag to client\nterm_dict = dict(terminate_flag=True)\ntry:\nif self.__multiclient_mode:\nfor _ in self.__port_buffer:\nself.__msg_socket.send_json(term_dict)\nelse:\nself.__msg_socket.send_json(term_dict)\n# check for confirmation if available within 1/5 timeout\nif self.__pattern &lt; 2:\nself.__logging and logger.debug(\"Terminating. Please wait...\")\nif self.__msg_socket.poll(self.__request_timeout // 5, zmq.POLLIN):\nself.__msg_socket.recv()\nexcept Exception as e:\nif not isinstance(e, ZMQError):\nlogger.exception(str(e))\nfinally:\n# properly close the socket\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nself.__logging and logger.debug(\"Terminated Successfully!\")\n</code></pre> <p> </p>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.__init__","title":"<code>__init__(self, address=None, port=None, protocol=None, pattern=0, receive_mode=False, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the NetGear class.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>sets the valid network address of the Server/Client.</p> <code>None</code> <code>port</code> <code>str</code> <p>sets the valid Network Port of the Server/Client.</p> <code>None</code> <code>protocol</code> <code>str</code> <p>sets the valid messaging protocol between Server/Client.</p> <code>None</code> <code>pattern</code> <code>int</code> <p>sets the supported messaging pattern(flow of communication) between Server/Client</p> <code>0</code> <code>receive_mode</code> <code>bool</code> <p>select the Netgear's Mode of operation.</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>options</code> <code>dict</code> <p>provides the flexibility to alter various NetGear internal properties.</p> <code>{}</code> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def __init__(\nself,\naddress=None,\nport=None,\nprotocol=None,\npattern=0,\nreceive_mode=False,\nlogging=False,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the NetGear class.\n    Parameters:\n        address (str): sets the valid network address of the Server/Client.\n        port (str): sets the valid Network Port of the Server/Client.\n        protocol (str): sets the valid messaging protocol between Server/Client.\n        pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n        receive_mode (bool): select the Netgear's Mode of operation.\n        logging (bool): enables/disables logging.\n        options (dict): provides the flexibility to alter various NetGear internal properties.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n)\nimport_dependency_safe(\n\"simplejpeg\" if simplejpeg is None else \"\", error=\"log\", min_version=\"1.6.1\"\n)\n# enable logging if specified\nself.__logging = True if logging else False\n# define valid messaging patterns =&gt; `0`: zmq.PAIR, `1`:(zmq.REQ,zmq.REP), and `1`:(zmq.SUB,zmq.PUB)\nvalid_messaging_patterns = {\n0: (zmq.PAIR, zmq.PAIR),\n1: (zmq.REQ, zmq.REP),\n2: (zmq.PUB, zmq.SUB),\n}\n# Handle messaging pattern\nmsg_pattern = None\n# check whether user-defined messaging pattern is valid\nif isinstance(pattern, int) and pattern in valid_messaging_patterns.keys():\n# assign value\nmsg_pattern = valid_messaging_patterns[pattern]\nelse:\n# otherwise default to 0:`zmq.PAIR`\npattern = 0\nmsg_pattern = valid_messaging_patterns[pattern]\nself.__logging and logger.warning(\n\"Wrong pattern value, Defaulting to `zmq.PAIR`! Kindly refer Docs for more Information.\"\n)\n# assign pattern to global parameter for further use\nself.__pattern = pattern\n# Handle messaging protocol\nif protocol is None or not (protocol in [\"tcp\", \"ipc\"]):\n# else default to `tcp` protocol\nprotocol = \"tcp\"\n# log it\nself.__logging and logger.warning(\n\"Protocol is not supported or not provided. Defaulting to `tcp` protocol!\"\n)\n# Handle connection params\nself.__msg_flag = 0  # handles connection flags\nself.__msg_copy = False  # handles whether to copy data\nself.__msg_track = False  # handles whether to track packets\n# Handle NetGear's internal exclusive modes and params\n# define SSH Tunneling Mode\nself.__ssh_tunnel_mode = None  # handles ssh_tunneling mode state\nself.__ssh_tunnel_pwd = None\nself.__ssh_tunnel_keyfile = None\nself.__paramiko_present = False if paramiko is None else True\n# define Multi-Server mode\nself.__multiserver_mode = False  # handles multi-server mode state\n# define Multi-Client mode\nself.__multiclient_mode = False  # handles multi-client mode state\n# define Bidirectional mode\nself.__bi_mode = False  # handles Bidirectional mode state\n# define Secure mode\nvalid_security_mech = {0: \"Grasslands\", 1: \"StoneHouse\", 2: \"IronHouse\"}\nself.__secure_mode = 0  # handles ZMQ security layer status\nauth_cert_dir = \"\"  # handles valid ZMQ certificates dir\nself.__auth_publickeys_dir = \"\"  # handles valid ZMQ public certificates dir\nself.__auth_secretkeys_dir = \"\"  # handles valid ZMQ private certificates dir\noverwrite_cert = False  # checks if certificates overwriting allowed\ncustom_cert_location = \"\"  # handles custom ZMQ certificates path\n# define frame-compression handler\nself.__jpeg_compression = (\nTrue if not (simplejpeg is None) else False\n)  # enabled by default for all connections if simplejpeg is installed\nself.__jpeg_compression_quality = 90  # 90% quality\nself.__jpeg_compression_fastdct = True  # fastest DCT on by default\nself.__jpeg_compression_fastupsample = False  # fastupsample off by default\nself.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\n# defines frame compression on return data\nself.__ex_compression_params = None\n# define receiver return data handler\nself.__return_data = None\n# generate 8-digit random system id\nself.__id = \"\".join(\nsecrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n)\n# define termination flag\nself.__terminate = False\n# additional settings for reliability\nif pattern &lt; 2:\n# define zmq poller for reliable transmission\nself.__poll = zmq.Poller()\n# define max retries\nself.__max_retries = 3\n# request timeout\nself.__request_timeout = 4000  # 4 secs\n# Handle user-defined options dictionary values\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# loop over dictionary key &amp; values and assign to global variables if valid\nfor key, value in options.items():\n# handle multi-server mode\nif key == \"multiserver_mode\" and isinstance(value, bool):\n# check if valid pattern assigned\nif pattern &gt; 0:\n# activate Multi-server mode\nself.__multiserver_mode = value\nelse:\n# otherwise disable it and raise error\nself.__multiserver_mode = False\nlogger.critical(\"Multi-Server Mode is disabled!\")\nraise ValueError(\n\"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Server Mode is enabled. Kindly refer Docs for more Information.\".format(\npattern\n)\n)\n# handle multi-client mode\nelif key == \"multiclient_mode\" and isinstance(value, bool):\n# check if valid pattern assigned\nif pattern &gt; 0:\n# activate Multi-client mode\nself.__multiclient_mode = value\nelse:\n# otherwise disable it and raise error\nself.__multiclient_mode = False\nlogger.critical(\"Multi-Client Mode is disabled!\")\nraise ValueError(\n\"[NetGear:ERROR] :: `{}` pattern is not valid when Multi-Client Mode is enabled. Kindly refer Docs for more Information.\".format(\npattern\n)\n)\n# handle bidirectional mode\nelif key == \"bidirectional_mode\" and isinstance(value, bool):\n# check if pattern is valid\nif pattern &lt; 2:\n# activate Bidirectional mode if specified\nself.__bi_mode = value\nelse:\n# otherwise disable it and raise error\nself.__bi_mode = False\nlogger.warning(\"Bidirectional data transmission is disabled!\")\nraise ValueError(\n\"[NetGear:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\npattern\n)\n)\n# handle secure mode\nelif (\nkey == \"secure_mode\"\nand isinstance(value, int)\nand (value in valid_security_mech)\n):\nself.__secure_mode = value\nelif key == \"custom_cert_location\" and isinstance(value, str):\n# verify custom auth certificates path for secure mode\ncustom_cert_location = os.path.abspath(value)\nassert os.path.isdir(\ncustom_cert_location\n), \"[NetGear:ERROR] :: `custom_cert_location` value must be the path to a valid directory!\"\nassert check_WriteAccess(\ncustom_cert_location,\nis_windows=True if os.name == \"nt\" else False,\nlogging=self.__logging,\n), \"[NetGear:ERROR] :: Permission Denied!, cannot write ZMQ authentication certificates to '{}' directory!\".format(\nvalue\n)\nelif key == \"overwrite_cert\" and isinstance(value, bool):\n# enable/disable auth certificate overwriting in secure mode\noverwrite_cert = value\n# handle ssh-tunneling mode\nelif key == \"ssh_tunnel_mode\" and isinstance(value, str):\n# enable SSH Tunneling Mode\nself.__ssh_tunnel_mode = value.strip()\nelif key == \"ssh_tunnel_pwd\" and isinstance(value, str):\n# add valid SSH Tunneling password\nself.__ssh_tunnel_pwd = value\nelif key == \"ssh_tunnel_keyfile\" and isinstance(value, str):\n# add valid SSH Tunneling key-file\nself.__ssh_tunnel_keyfile = value if os.path.isfile(value) else None\nif self.__ssh_tunnel_keyfile is None:\nlogger.warning(\n\"Discarded invalid or non-existential SSH Tunnel Key-file at {}!\".format(\nvalue\n)\n)\n# handle jpeg compression\nelif (\nkey == \"jpeg_compression\"\nand not (simplejpeg is None)\nand isinstance(value, (bool, str))\n):\nif isinstance(value, str) and value.strip().upper() in [\n\"RGB\",\n\"BGR\",\n\"RGBX\",\n\"BGRX\",\n\"XBGR\",\n\"XRGB\",\n\"GRAY\",\n\"RGBA\",\n\"BGRA\",\n\"ABGR\",\n\"ARGB\",\n\"CMYK\",\n]:\n# set encoding colorspace\nself.__jpeg_compression_colorspace = value.strip().upper()\n# enable frame-compression encoding value\nself.__jpeg_compression = True\nelse:\n# enable frame-compression encoding value\nself.__jpeg_compression = value\nelif key == \"jpeg_compression_quality\" and isinstance(value, (int, float)):\n# set valid jpeg quality\nif value &gt;= 10 and value &lt;= 100:\nself.__jpeg_compression_quality = int(value)\nelse:\nlogger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\nelif key == \"jpeg_compression_fastdct\" and isinstance(value, bool):\n# enable jpeg fastdct\nself.__jpeg_compression_fastdct = value\nelif key == \"jpeg_compression_fastupsample\" and isinstance(value, bool):\n# enable jpeg  fastupsample\nself.__jpeg_compression_fastupsample = value\n# assign maximum retries in synchronous patterns\nelif key == \"max_retries\" and isinstance(value, int) and pattern &lt; 2:\nif value &gt;= 0:\nself.__max_retries = value\nelse:\nlogger.warning(\"Invalid `max_retries` value skipped!\")\n# assign request timeout in synchronous patterns\nelif key == \"request_timeout\" and isinstance(value, int) and pattern &lt; 2:\nif value &gt;= 4:\nself.__request_timeout = value * 1000  # covert to milliseconds\nelse:\nlogger.warning(\"Invalid `request_timeout` value skipped!\")\n# handle ZMQ flags\nelif key == \"flag\" and isinstance(value, int):\nself.__msg_flag = value\nelif key == \"copy\" and isinstance(value, bool):\nself.__msg_copy = value\nelif key == \"track\" and isinstance(value, bool):\nself.__msg_track = value\nelse:\npass\n# Handle Secure mode\nif self.__secure_mode:\n# activate and log if overwriting is enabled\nif overwrite_cert:\nif not receive_mode:\nself.__logging and logger.warning(\n\"Overwriting ZMQ Authentication certificates over previous ones!\"\n)\nelse:\noverwrite_cert = False\nself.__logging and logger.critical(\n\"Overwriting ZMQ Authentication certificates is disabled for Client's end!\"\n)\n# Validate certificate generation paths\ntry:\n# check if custom certificates path is specified\nif custom_cert_location:\n(\nauth_cert_dir,\nself.__auth_secretkeys_dir,\nself.__auth_publickeys_dir,\n) = generate_auth_certificates(\ncustom_cert_location, overwrite=overwrite_cert, logging=logging\n)\nelse:\n# otherwise auto-generate suitable path\n(\nauth_cert_dir,\nself.__auth_secretkeys_dir,\nself.__auth_publickeys_dir,\n) = generate_auth_certificates(\nos.path.join(expanduser(\"~\"), \".vidgear\"),\noverwrite=overwrite_cert,\nlogging=logging,\n)\n# log it\nself.__logging and logger.debug(\n\"`{}` is the default location for storing ZMQ authentication certificates/keys.\".format(\nauth_cert_dir\n)\n)\nexcept Exception as e:\n# catch if any error occurred and disable Secure mode\nlogger.exception(str(e))\nself.__secure_mode = 0\nlogger.critical(\n\"ZMQ Security Mechanism is disabled for this connection due to errors!\"\n)\n# Handle ssh tunneling if enabled\nif not (self.__ssh_tunnel_mode is None):\n# SSH Tunnel Mode only available for server mode\nif receive_mode:\nlogger.error(\"SSH Tunneling cannot be enabled for Client-end!\")\nelse:\n# check if SSH tunneling possible\nssh_address = self.__ssh_tunnel_mode\nssh_address, ssh_port = (\nssh_address.split(\":\")\nif \":\" in ssh_address\nelse [ssh_address, \"22\"]\n)  # default to port 22\nif \"47\" in ssh_port:\nself.__ssh_tunnel_mode = self.__ssh_tunnel_mode.replace(\n\":47\", \"\"\n)  # port-47 is reserved for testing\nelse:\n# extract ip for validation\nssh_user, ssh_ip = (\nssh_address.split(\"@\")\nif \"@\" in ssh_address\nelse [\"\", ssh_address]\n)\n# validate ip specified port\nassert check_open_port(\nssh_ip, port=int(ssh_port)\n), \"[NetGear:ERROR] :: Host `{}` is not available for SSH Tunneling at port-{}!\".format(\nssh_address, ssh_port\n)\n# Handle multiple exclusive modes if enabled\nif self.__multiclient_mode and self.__multiserver_mode:\nraise ValueError(\n\"[NetGear:ERROR] :: Multi-Client and Multi-Server Mode cannot be enabled simultaneously!\"\n)\nelif self.__multiserver_mode or self.__multiclient_mode:\n# check if Bidirectional Mode also enabled\nif self.__bi_mode:\n# log it\nself.__logging and logger.debug(\n\"Bidirectional Data Transmission is also enabled for this connection!\"\n)\n# check if SSH Tunneling Mode also enabled\nif self.__ssh_tunnel_mode:\n# raise error\nraise ValueError(\n\"[NetGear:ERROR] :: SSH Tunneling and {} Mode cannot be enabled simultaneously. Kindly refer docs!\".format(\n\"Multi-Server\" if self.__multiserver_mode else \"Multi-Client\"\n)\n)\nelif self.__bi_mode:\n# log Bidirectional mode activation\nself.__logging and logger.debug(\n\"Bidirectional Data Transmission is enabled for this connection!\"\n)\nelif self.__ssh_tunnel_mode:\n# log Bidirectional mode activation\nself.__logging and logger.debug(\n\"SSH Tunneling is enabled for host:`{}` with `{}` back-end.\".format(\nself.__ssh_tunnel_mode,\n\"paramiko\" if self.__paramiko_present else \"pexpect\",\n)\n)\n# define messaging context instance\nself.__msg_context = zmq.Context.instance()\n# initialize and assign receive mode to global variable\nself.__receive_mode = receive_mode\n# check whether `receive_mode` is enabled\nif self.__receive_mode:\n# define connection address\nif address is None:\naddress = \"*\"  # define address\n# check if multiserver_mode is enabled\nif self.__multiserver_mode:\n# check if unique server port address list/tuple is assigned or not in multiserver_mode\nif port is None or not isinstance(port, (tuple, list)):\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Server ports while Multi-Server mode is enabled. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Server Mode at PORTS: {}!\".format(port)\n)\n# create port address buffer for keeping track of connected client's port(s)\nself.__port_buffer = []\n# check if multiclient_mode is enabled\nelif self.__multiclient_mode:\n# check if unique server port address is assigned or not in multiclient_mode\nif port is None:\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Client-end. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Client Mode at PORT: {} on this device!\".format(\nport\n)\n)\n# assign value to global variable\nself.__port = port\nelse:\n# otherwise assign local port address if None\nif port is None:\nport = \"5555\"\ntry:\n# activate secure_mode threaded authenticator\nif self.__secure_mode &gt; 0:\n# start an authenticator for this context\nz_auth = ThreadAuthenticator(self.__msg_context)\nz_auth.start()\nz_auth.allow(str(address))  # allow current address\n# check if `IronHouse` is activated\nif self.__secure_mode == 2:\n# tell authenticator to use the certificate from given valid dir\nz_auth.configure_curve(\ndomain=\"*\", location=self.__auth_publickeys_dir\n)\nelse:\n# otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated\nz_auth.configure_curve(\ndomain=\"*\", location=auth.CURVE_ALLOW_ANY\n)\n# define thread-safe messaging socket\nself.__msg_socket = self.__msg_context.socket(msg_pattern[1])\n# define pub-sub flag\nif self.__pattern == 2:\nself.__msg_socket.set_hwm(1)\n# enable specified secure mode for the socket\nif self.__secure_mode &gt; 0:\n# load server key\nserver_secret_file = os.path.join(\nself.__auth_secretkeys_dir, \"server.key_secret\"\n)\nserver_public, server_secret = auth.load_certificate(\nserver_secret_file\n)\n# load  all CURVE keys\nself.__msg_socket.curve_secretkey = server_secret\nself.__msg_socket.curve_publickey = server_public\n# enable CURVE connection for this socket\nself.__msg_socket.curve_server = True\n# define exclusive socket options for patterns\nif self.__pattern == 2:\nself.__msg_socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n# if multiserver_mode is enabled, then assign port addresses to zmq socket\nif self.__multiserver_mode:\n# bind socket to given server protocol, address and ports\nfor pt in port:\nself.__msg_socket.bind(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\n# bind socket to given protocol, address and port normally\nself.__msg_socket.bind(\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\n# additional settings\nif pattern &lt; 2:\nif self.__multiserver_mode:\nself.__connection_address = []\nfor pt in port:\nself.__connection_address.append(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\nself.__connection_address = (\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\nself.__msg_pattern = msg_pattern[1]\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\nself.__logging and logger.debug(\n\"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\nself.__max_retries, self.__request_timeout / 1000\n)\n)\nexcept Exception as e:\n# otherwise log and raise error\nlogger.exception(str(e))\nif self.__secure_mode:\nlogger.critical(\n\"Failed to activate Secure Mode: `{}` for this connection!\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nif self.__multiserver_mode or self.__multiclient_mode:\nraise RuntimeError(\n\"[NetGear:ERROR] :: Receive Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n\"Multi-Server\"\nif self.__multiserver_mode\nelse \"Multi-Client\",\n(protocol + \"://\" + str(address) + \":\" + str(port)),\npattern,\n)\n)\nelse:\nif self.__bi_mode:\nlogger.critical(\n\"Failed to activate Bidirectional Mode for this connection!\"\n)\nraise RuntimeError(\n\"[NetGear:ERROR] :: Receive Mode failed to bind address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\n# Handle threaded queue mode\nself.__logging and logger.debug(\n\"Threaded Queue Mode is enabled by default for this connection.\"\n)\n# define deque and assign it to global var\nself.__queue = deque(maxlen=96)  # max len 96 to check overflow\n# initialize and start threaded recv_handler\nself.__thread = Thread(target=self.__recv_handler, name=\"NetGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\nif self.__logging:\n# finally log progress\nlogger.debug(\n\"Successfully Binded to address: {} with pattern: {}.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\nif self.__jpeg_compression:\nlogger.debug(\n\"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\nself.__jpeg_compression_colorspace,\nself.__jpeg_compression_quality,\n\"enabled\"\nif self.__jpeg_compression_fastdct\nelse \"disabled\",\n\"enabled\"\nif self.__jpeg_compression_fastupsample\nelse \"disabled\",\n)\n)\nif self.__secure_mode:\nlogger.debug(\n\"Successfully enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nlogger.debug(\"Multi-threaded Receive Mode is successfully enabled.\")\nlogger.debug(\"Unique System ID is {}.\".format(self.__id))\nlogger.debug(\"Receive Mode is now activated.\")\nelse:\n# otherwise default to `Send Mode`\n# define connection address\nif address is None:\naddress = \"localhost\"\n# check if multiserver_mode is enabled\nif self.__multiserver_mode:\n# check if unique server port address is assigned or not in multiserver_mode\nif port is None:\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Kindly provide a unique &amp; valid port value at Server-end. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Server Mode at PORT: {} on this device!\".format(\nport\n)\n)\n# assign value to global variable\nself.__port = port\n# check if multiclient_mode is enabled\nelif self.__multiclient_mode:\n# check if unique client port address list/tuple is assigned or not in multiclient_mode\nif port is None or not isinstance(port, (tuple, list)):\n# raise error if not\nraise ValueError(\n\"[NetGear:ERROR] :: Incorrect port value! Kindly provide a list/tuple of Client ports while Multi-Client mode is enabled. For more information refer VidGear docs.\"\n)\nelse:\n# otherwise log it\nlogger.debug(\n\"Enabling Multi-Client Mode at PORTS: {}!\".format(port)\n)\n# create port address buffer for keeping track of connected client ports\nself.__port_buffer = []\nelse:\n# otherwise assign local port address if None\nif port is None:\nport = \"5555\"\ntry:\n# activate secure_mode threaded authenticator\nif self.__secure_mode &gt; 0:\n# start an authenticator for this context\nz_auth = ThreadAuthenticator(self.__msg_context)\nz_auth.start()\nz_auth.allow(str(address))  # allow current address\n# check if `IronHouse` is activated\nif self.__secure_mode == 2:\n# tell authenticator to use the certificate from given valid dir\nz_auth.configure_curve(\ndomain=\"*\", location=self.__auth_publickeys_dir\n)\nelse:\n# otherwise tell the authenticator how to handle the CURVE requests, if `StoneHouse` is activated\nz_auth.configure_curve(\ndomain=\"*\", location=auth.CURVE_ALLOW_ANY\n)\n# define thread-safe messaging socket\nself.__msg_socket = self.__msg_context.socket(msg_pattern[0])\n# if req/rep pattern, define additional flags\nif self.__pattern == 1:\nself.__msg_socket.REQ_RELAXED = True\nself.__msg_socket.REQ_CORRELATE = True\n# if pub/sub pattern, define additional optimizer\nif self.__pattern == 2:\nself.__msg_socket.set_hwm(1)\n# enable specified secure mode for the socket\nif self.__secure_mode &gt; 0:\n# load client key\nclient_secret_file = os.path.join(\nself.__auth_secretkeys_dir, \"client.key_secret\"\n)\nclient_public, client_secret = auth.load_certificate(\nclient_secret_file\n)\n# load  all CURVE keys\nself.__msg_socket.curve_secretkey = client_secret\nself.__msg_socket.curve_publickey = client_public\n# load server key\nserver_public_file = os.path.join(\nself.__auth_publickeys_dir, \"server.key\"\n)\nserver_public, _ = auth.load_certificate(server_public_file)\n# inject public key to make a CURVE connection.\nself.__msg_socket.curve_serverkey = server_public\n# check if multi-client_mode is enabled\nif self.__multiclient_mode:\n# bind socket to given server protocol, address and ports\nfor pt in port:\nself.__msg_socket.connect(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\n# handle SSH tunneling if enabled\nif self.__ssh_tunnel_mode:\n# establish tunnel connection\nssh.tunnel_connection(\nself.__msg_socket,\nprotocol + \"://\" + str(address) + \":\" + str(port),\nself.__ssh_tunnel_mode,\nkeyfile=self.__ssh_tunnel_keyfile,\npassword=self.__ssh_tunnel_pwd,\nparamiko=self.__paramiko_present,\n)\nelse:\n# connect socket to given protocol, address and port\nself.__msg_socket.connect(\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\n# additional settings\nif pattern &lt; 2:\nif self.__multiclient_mode:\nself.__connection_address = []\nfor pt in port:\nself.__connection_address.append(\nprotocol + \"://\" + str(address) + \":\" + str(pt)\n)\nelse:\nself.__connection_address = (\nprotocol + \"://\" + str(address) + \":\" + str(port)\n)\nself.__msg_pattern = msg_pattern[0]\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\nself.__logging and logger.debug(\n\"Reliable transmission is enabled for this pattern with max-retries: {} and timeout: {} secs.\".format(\nself.__max_retries, self.__request_timeout / 1000\n)\n)\nexcept Exception as e:\n# otherwise log and raise error\nlogger.exception(str(e))\nif self.__secure_mode:\nlogger.critical(\n\"Failed to activate Secure Mode: `{}` for this connection!\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nif self.__multiserver_mode or self.__multiclient_mode:\nraise RuntimeError(\n\"[NetGear:ERROR] :: Send Mode failed to activate {} Mode at address: {} with pattern: {}! Kindly recheck all parameters.\".format(\n\"Multi-Server\"\nif self.__multiserver_mode\nelse \"Multi-Client\",\n(protocol + \"://\" + str(address) + \":\" + str(port)),\npattern,\n)\n)\nelse:\nif self.__bi_mode:\nlogger.critical(\n\"Failed to activate Bidirectional Mode for this connection!\"\n)\nif self.__ssh_tunnel_mode:\nlogger.critical(\n\"Failed to initiate SSH Tunneling Mode for this server with `{}` back-end!\".format(\n\"paramiko\" if self.__paramiko_present else \"pexpect\"\n)\n)\nraise RuntimeError(\n\"[NetGear:ERROR] :: Send Mode failed to connect address: {} and pattern: {}! Kindly recheck all parameters.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\nif self.__logging:\n# finally log progress\nlogger.debug(\n\"Successfully connected to address: {} with pattern: {}.\".format(\n(protocol + \"://\" + str(address) + \":\" + str(port)), pattern\n)\n)\nif self.__jpeg_compression:\nlogger.debug(\n\"JPEG Frame-Compression is activated for this connection with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\nself.__jpeg_compression_colorspace,\nself.__jpeg_compression_quality,\n\"enabled\"\nif self.__jpeg_compression_fastdct\nelse \"disabled\",\n\"enabled\"\nif self.__jpeg_compression_fastupsample\nelse \"disabled\",\n)\n)\nif self.__secure_mode:\nlogger.debug(\n\"Enabled ZMQ Security Mechanism: `{}` for this connection.\".format(\nvalid_security_mech[self.__secure_mode]\n)\n)\nlogger.debug(\"Unique System ID is {}.\".format(self.__id))\nlogger.debug(\n\"Send Mode is successfully activated and ready to send data.\"\n)\n</code></pre>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.close","title":"<code>close(self)</code>","text":"<p>Safely terminates the threads, and NetGear resources.</p> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def close(self):\n\"\"\"\n    Safely terminates the threads, and NetGear resources.\n    \"\"\"\n# log it\nself.__logging and logger.debug(\n\"Terminating various {} Processes.\".format(\n\"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n)\n)\n#  whether `receive_mode` is enabled or not\nif self.__receive_mode:\n# check whether queue mode is empty\nif not (self.__queue is None) and self.__queue:\nself.__queue.clear()\n# call immediate termination\nself.__terminate = True\n# wait until stream resources are released (producer thread might be still grabbing frame)\nif self.__thread is not None:\n# properly handle thread exit\nself.__thread.join()\nself.__thread = None\nself.__logging and logger.debug(\"Terminating. Please wait...\")\n# properly close the socket\nself.__msg_socket.close(linger=0)\nself.__logging and logger.debug(\"Terminated Successfully!\")\nelse:\n# indicate that process should be terminated\nself.__terminate = True\n# check if all attempts of reconnecting failed, then skip to closure\nif (self.__pattern &lt; 2 and not self.__max_retries) or (\nself.__multiclient_mode and not self.__port_buffer\n):\ntry:\n# properly close the socket\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nexcept ZMQError:\npass\nfinally:\n# exit\nreturn\nif self.__multiserver_mode:\n# check if multiserver_mode\n# send termination flag to client with its unique port\nterm_dict = dict(terminate_flag=True, port=self.__port)\nelse:\n# otherwise send termination flag to client\nterm_dict = dict(terminate_flag=True)\ntry:\nif self.__multiclient_mode:\nfor _ in self.__port_buffer:\nself.__msg_socket.send_json(term_dict)\nelse:\nself.__msg_socket.send_json(term_dict)\n# check for confirmation if available within 1/5 timeout\nif self.__pattern &lt; 2:\nself.__logging and logger.debug(\"Terminating. Please wait...\")\nif self.__msg_socket.poll(self.__request_timeout // 5, zmq.POLLIN):\nself.__msg_socket.recv()\nexcept Exception as e:\nif not isinstance(e, ZMQError):\nlogger.exception(str(e))\nfinally:\n# properly close the socket\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nself.__logging and logger.debug(\"Terminated Successfully!\")\n</code></pre>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.recv","title":"<code>recv(self, return_data=None)</code>","text":"<p>A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Parameters:</p> Name Type Description Default <code>return_data</code> <code>any</code> <p>inputs return data (of any datatype), for sending back to Server.</p> <code>None</code> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def recv(self, return_data=None):\n\"\"\"\n    A Receiver end method, that extracts received frames synchronously from monitored deque, while maintaining a\n    fixed-length frame buffer in the memory, and blocks the thread if the deque is full.\n    Parameters:\n        return_data (any): inputs return data _(of any datatype)_, for sending back to Server.\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n# check whether `receive mode` is activated\nif not (self.__receive_mode):\n# raise value error and exit\nself.__terminate = True\nraise ValueError(\n\"[NetGear:ERROR] :: `recv()` function cannot be used while receive_mode is disabled. Kindly refer vidgear docs!\"\n)\n# handle Bidirectional return data\nif (self.__bi_mode or self.__multiclient_mode) and not (return_data is None):\nself.__return_data = return_data\n# check whether or not termination flag is enabled\nwhile not self.__terminate:\ntry:\n# check if queue is empty\nif len(self.__queue) &gt; 0:\nreturn self.__queue.popleft()\nelse:\ntime.sleep(0.00001)\ncontinue\nexcept KeyboardInterrupt:\nself.__terminate = True\nbreak\n# otherwise return NoneType\nreturn None\n</code></pre>"},{"location":"bonus/reference/netgear/#vidgear.gears.netgear.NetGear.send","title":"<code>send(self, frame, message=None)</code>","text":"<p>A Server end method, that sends the data and frames over the network to Client(s).</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs numpy array(frame).</p> required <code>message</code> <code>any</code> <p>input for sending additional data (of any datatype except <code>numpy.ndarray</code>) to Client(s).</p> <code>None</code> <p>Returns: Data (of any datatype) in selected exclusive modes, otherwise None-type.</p> Source code in <code>vidgear/gears/netgear.py</code> <pre><code>def send(self, frame, message=None):\n\"\"\"\n    A Server end method, that sends the data and frames over the network to Client(s).\n    Parameters:\n        frame (numpy.ndarray): inputs numpy array(frame).\n        message (any): input for sending additional data _(of any datatype except `numpy.ndarray`)_ to Client(s).\n    **Returns:** Data _(of any datatype)_ in selected exclusive modes, otherwise None-type.\n    \"\"\"\n# check whether `receive_mode` is disabled\nif self.__receive_mode:\n# raise value error and exit\nself.__terminate = True\nraise ValueError(\n\"[NetGear:ERROR] :: `send()` function cannot be used while receive_mode is enabled. Kindly refer vidgear docs!\"\n)\nif not (message is None) and isinstance(message, np.ndarray):\nlogger.warning(\n\"Skipped unsupported `message` of datatype: {}!\".format(\ntype(message).__name__\n)\n)\nmessage = None\n# define exit_flag and assign value\nexit_flag = True if (frame is None or self.__terminate) else False\n# check whether exit_flag is False\nif not (exit_flag) and not (frame.flags[\"C_CONTIGUOUS\"]):\n# check whether the incoming frame is contiguous\nframe = np.ascontiguousarray(frame, dtype=frame.dtype)\n# handle JPEG compression encoding\nif self.__jpeg_compression:\nif self.__jpeg_compression_colorspace == \"GRAY\":\nif frame.ndim == 2:\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nframe = np.expand_dims(frame, axis=2)\nframe = simplejpeg.encode_jpeg(\nframe,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\nfastdct=self.__jpeg_compression_fastdct,\n)\nelse:\nframe = simplejpeg.encode_jpeg(\nframe,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\ncolorsubsampling=\"422\",\nfastdct=self.__jpeg_compression_fastdct,\n)\n# check if multiserver_mode is activated and assign values with unique port\nmsg_dict = dict(port=self.__port) if self.__multiserver_mode else dict()\n# prepare the exclusive json dict\nmsg_dict.update(\ndict(\nterminate_flag=exit_flag,\ncompression={\n\"dct\": self.__jpeg_compression_fastdct,\n\"ups\": self.__jpeg_compression_fastupsample,\n\"colorspace\": self.__jpeg_compression_colorspace,\n}\nif self.__jpeg_compression\nelse False,\nmessage=message,\npattern=str(self.__pattern),\ndtype=str(frame.dtype) if not (self.__jpeg_compression) else \"\",\nshape=frame.shape if not (self.__jpeg_compression) else \"\",\n)\n)\n# send the json dict\nself.__msg_socket.send_json(msg_dict, self.__msg_flag | zmq.SNDMORE)\n# send the frame array with correct flags\nself.__msg_socket.send(\nframe, flags=self.__msg_flag, copy=self.__msg_copy, track=self.__msg_track\n)\n# check if synchronous patterns, then wait for confirmation\nif self.__pattern &lt; 2:\n# check if Bidirectional data transmission is enabled\nif self.__bi_mode or self.__multiclient_mode:\n# handles return data\nrecvd_data = None\nsocks = dict(self.__poll.poll(self.__request_timeout))\nif socks.get(self.__msg_socket) == zmq.POLLIN:\n# handle return data\nrecv_json = self.__msg_socket.recv_json(flags=self.__msg_flag)\nelse:\nlogger.critical(\"No response from Client, Reconnecting again...\")\n# Socket is confused. Close and remove it.\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nself.__poll.unregister(self.__msg_socket)\nself.__max_retries -= 1\nif not (self.__max_retries):\nif self.__multiclient_mode:\nlogger.error(\n\"All Clients failed to respond on multiple attempts.\"\n)\nelse:\nlogger.error(\n\"Client failed to respond on multiple attempts.\"\n)\nself.__terminate = True\nraise RuntimeError(\n\"[NetGear:ERROR] :: Client(s) seems to be offline, Abandoning.\"\n)\n# Create new connection\nself.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\nif isinstance(self.__connection_address, list):\nfor _connection in self.__connection_address:\nself.__msg_socket.connect(_connection)\nelse:\n# handle SSH tunneling if enabled\nif self.__ssh_tunnel_mode:\n# establish tunnel connection\nssh.tunnel_connection(\nself.__msg_socket,\nself.__connection_address,\nself.__ssh_tunnel_mode,\nkeyfile=self.__ssh_tunnel_keyfile,\npassword=self.__ssh_tunnel_pwd,\nparamiko=self.__paramiko_present,\n)\nelse:\n# connect normally\nself.__msg_socket.connect(self.__connection_address)\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\n# return None for mean-time\nreturn None\n# save the unique port addresses\nif (\nself.__multiclient_mode\nand not recv_json[\"port\"] in self.__port_buffer\n):\nself.__port_buffer.append(recv_json[\"port\"])\nif recv_json[\"return_type\"] == \"ndarray\":\nrecv_array = self.__msg_socket.recv(\nflags=self.__msg_flag,\ncopy=self.__msg_copy,\ntrack=self.__msg_track,\n)\n# check if encoding was enabled\nif recv_json[\"compression\"]:\n# decode JPEG frame\nrecvd_data = simplejpeg.decode_jpeg(\nrecv_array,\ncolorspace=recv_json[\"compression\"][\"colorspace\"],\nfastdct=self.__jpeg_compression_fastdct\nor recv_json[\"compression\"][\"dct\"],\nfastupsample=self.__jpeg_compression_fastupsample\nor recv_json[\"compression\"][\"ups\"],\n)\n# check if valid frame returned\nif recvd_data is None:\nself.__terminate = True\n# otherwise raise error and exit\nraise RuntimeError(\n\"[NetGear:ERROR] :: Received compressed frame `{}` decoding failed with flag: {}.\".format(\nrecv_json[\"compression\"],\nself.__ex_compression_params,\n)\n)\nif (\nrecv_json[\"compression\"][\"colorspace\"] == \"GRAY\"\nand recvd_data.ndim == 3\n):\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nrecvd_data = np.squeeze(recvd_data, axis=2)\nelse:\nrecvd_data = np.frombuffer(\nrecv_array, dtype=recv_json[\"array_dtype\"]\n).reshape(recv_json[\"array_shape\"])\nelse:\nrecvd_data = recv_json[\"data\"]\nreturn (\n(recv_json[\"port\"], recvd_data)\nif self.__multiclient_mode\nelse recvd_data\n)\nelse:\n# otherwise log normally\nsocks = dict(self.__poll.poll(self.__request_timeout))\nif socks.get(self.__msg_socket) == zmq.POLLIN:\nrecv_confirmation = self.__msg_socket.recv()\nelse:\nlogger.critical(\"No response from Client, Reconnecting again...\")\n# Socket is confused. Close and remove it.\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\nself.__poll.unregister(self.__msg_socket)\nself.__max_retries -= 1\nif not (self.__max_retries):\nlogger.error(\"Client failed to respond on repeated attempts.\")\nself.__terminate = True\nraise RuntimeError(\n\"[NetGear:ERROR] :: Client seems to be offline, Abandoning!\"\n)\n# Create new connection\nself.__msg_socket = self.__msg_context.socket(self.__msg_pattern)\n# handle SSH tunneling if enabled\nif self.__ssh_tunnel_mode:\n# establish tunnel connection\nssh.tunnel_connection(\nself.__msg_socket,\nself.__connection_address,\nself.__ssh_tunnel_mode,\nkeyfile=self.__ssh_tunnel_keyfile,\npassword=self.__ssh_tunnel_pwd,\nparamiko=self.__paramiko_present,\n)\nelse:\n# connect normally\nself.__msg_socket.connect(self.__connection_address)\nself.__poll.register(self.__msg_socket, zmq.POLLIN)\nreturn None\n# log confirmation\nself.__logging and logger.debug(recv_confirmation)\n</code></pre>"},{"location":"bonus/reference/netgear_async/","title":"NetGear_Async API","text":"<p>NetGear_Async API usage examples can be found here \u27b6</p> <p>NetGear_Async API parameters are explained here \u27b6</p> <p>NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes.</p> <p>NetGear_Async is built on <code>zmq.asyncio</code>, and powered by a high-performance asyncio event loop called uvloop to achieve unwatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system.</p> <p>NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define  our custom Server as source to transform frames easily before sending them across the network.</p> <p>NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code.</p> <p>In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> <p>NetGear_Async as of now supports four ZeroMQ messaging patterns:</p> <ul> <li><code>zmq.PAIR</code> (ZMQ Pair Pattern)</li> <li><code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern)</li> <li><code>zmq.PUB/zmq.SUB</code> (ZMQ Publish/Subscribe Pattern)</li> <li><code>zmq.PUSH/zmq.PULL</code> (ZMQ Push/Pull Pattern)</li> </ul> <p>Whereas supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>class NetGear_Async:\n\"\"\"\n    NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various\n    options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes.\n    NetGear_Async is built on `zmq.asyncio`, and powered by a high-performance asyncio event loop called uvloop to achieve unwatchable high-speed and lag-free video streaming\n    over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your\n    system.\n    NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define\n     our custom Server as source to transform frames easily before sending them across the network.\n    NetGear_Async now supports additional **bidirectional data transmission** between receiver(client) and sender(server) while transferring frames.\n    Users can easily build complex applications such as like _Real-Time Video Chat_ in just few lines of code.\n    In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby\n    granting it exclusive power for transferring frames incoming from any source to the network.\n    NetGear_Async as of now supports four ZeroMQ messaging patterns:\n    - `zmq.PAIR` _(ZMQ Pair Pattern)_\n    - `zmq.REQ/zmq.REP` _(ZMQ Request/Reply Pattern)_\n    - `zmq.PUB/zmq.SUB` _(ZMQ Publish/Subscribe Pattern)_\n    - `zmq.PUSH/zmq.PULL` _(ZMQ Push/Pull Pattern)_\n    Whereas supported protocol are: `tcp` and `ipc`.\n    \"\"\"\ndef __init__(\nself,\n# NetGear_Async parameters\naddress=None,\nport=None,\nprotocol=\"tcp\",\npattern=0,\nreceive_mode=False,\ntimeout=0.0,\n# Videogear parameters\nenablePiCamera=False,\nstabilize=False,\nsource=None,\ncamera_num=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nresolution=(640, 480),\nframerate=25,\ntime_delay=0,\n# common parameters\nlogging=False,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the NetGear_Async class.\n        Parameters:\n            address (str): sets the valid network address of the Server/Client.\n            port (str): sets the valid Network Port of the Server/Client.\n            protocol (str): sets the valid messaging protocol between Server/Client.\n            pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n            receive_mode (bool): select the NetGear_Async's Mode of operation.\n            timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`.\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n)\nimport_dependency_safe(\"msgpack\" if msgpack is None else \"\")\nimport_dependency_safe(\"msgpack_numpy\" if m is None else \"\")\n# enable logging if specified\nself.__logging = logging\n# define valid messaging patterns =&gt; `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL)\nvalid_messaging_patterns = {\n0: (zmq.PAIR, zmq.PAIR),\n1: (zmq.REQ, zmq.REP),\n2: (zmq.PUB, zmq.SUB),\n3: (zmq.PUSH, zmq.PULL),\n}\n# check whether user-defined messaging pattern is valid\nif isinstance(pattern, int) and pattern in valid_messaging_patterns:\n# assign value\nself.__msg_pattern = pattern\nself.__pattern = valid_messaging_patterns[pattern]\nelse:\n# otherwise default to 0:`zmq.PAIR`\nself.__msg_pattern = 0\nself.__pattern = valid_messaging_patterns[self.__msg_pattern]\nif self.__logging:\nlogger.warning(\n\"Invalid pattern {pattern}. Defaulting to `zmq.PAIR`!\".format(\npattern=pattern\n)\n)\n# check  whether user-defined messaging protocol is valid\nif isinstance(protocol, str) and protocol in [\"tcp\", \"ipc\"]:\n# assign value\nself.__protocol = protocol\nelse:\n# else default to `tcp` protocol\nself.__protocol = \"tcp\"\nif self.__logging:\nlogger.warning(\"Invalid protocol. Defaulting to `tcp`!\")\n# initialize Termination flag\nself.__terminate = False\n# initialize and assign `Receive Mode`\nself.__receive_mode = receive_mode\n# initialize stream handler\nself.__stream = None\n# initialize Messaging Socket\nself.__msg_socket = None\n# initialize NetGear_Async's configuration dictionary\nself.config = {}\n# asyncio queue handler\nself.__queue = None\n# define Bidirectional mode\nself.__bi_mode = False  # handles Bidirectional mode state\n# assign timeout for Receiver end\nif timeout and isinstance(timeout, (int, float)):\nself.__timeout = float(timeout)\nelse:\nself.__timeout = 15.0\n# generate 8-digit random system id\nself.__id = \"\".join(\nsecrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n)\n# Handle user-defined options dictionary values\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# handle bidirectional mode\nif \"bidirectional_mode\" in options:\nvalue = options[\"bidirectional_mode\"]\n# also check if pattern and source is valid\nif isinstance(value, bool) and pattern &lt; 2 and source is None:\n# activate Bidirectional mode if specified\nself.__bi_mode = value\nelse:\n# otherwise disable it\nself.__bi_mode = False\nlogger.warning(\"Bidirectional data transmission is disabled!\")\n# handle errors and logging\nif pattern &gt;= 2:\n# raise error\nraise ValueError(\n\"[NetGear_Async:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\npattern\n)\n)\nelif not (source is None):\nraise ValueError(\n\"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\npattern\n)\n)\nelif isinstance(value, bool) and self.__logging:\n# log Bidirectional mode activation\nlogger.debug(\n\"Bidirectional Data Transmission is {} for this connection!\".format(\n\"enabled\" if value else \"disabled\"\n)\n)\nelse:\nlogger.error(\"`bidirectional_mode` value is invalid!\")\n# clean\ndel options[\"bidirectional_mode\"]\n# define messaging asynchronous Context\nself.__msg_context = zmq.asyncio.Context()\n# check whether `Receive Mode` is enabled\nif receive_mode:\n# assign local IP address if None\nif address is None:\nself.__address = \"*\"  # define address\nelse:\nself.__address = address\n# assign default port address if None\nif port is None:\nself.__port = \"5555\"\nelse:\nself.__port = port\nelse:\n# Handle video source\nif source is None:\nself.config = {\"generator\": None}\nif self.__logging:\nlogger.warning(\"Given source is of NoneType!\")\nelse:\n# define stream with necessary params\nself.__stream = VideoGear(\nenablePiCamera=enablePiCamera,\nstabilize=stabilize,\nsource=source,\ncamera_num=camera_num,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nresolution=resolution,\nframerate=framerate,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# define default frame generator in configuration\nself.config = {\"generator\": self.__frame_generator()}\n# assign local ip address if None\nif address is None:\nself.__address = \"localhost\"\nelse:\nself.__address = address\n# assign default port address if None\nif port is None:\nself.__port = \"5555\"\nelse:\nself.__port = port\n# add server task handler\nself.task = None\n# Setup and assign event loop policy\nif platform.system() == \"Windows\":\n# On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is\n# the default in Python 3.7 and older, but new Python 3.8, defaults to an\n# event loop that is not compatible with it. Thereby, we had to set it manually.\nif sys.version_info[:2] &gt;= (3, 8):\nasyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\nelse:\nif not (uvloop is None):\n# Latest uvloop eventloop is only available for UNIX machines.\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nelse:\n# log if not present\nimport_dependency_safe(\"uvloop\", error=\"log\")\n# Retrieve event loop and assign it\nself.loop = asyncio.get_event_loop()\n# create asyncio queue if bidirectional mode activated\nself.__queue = asyncio.Queue() if self.__bi_mode else None\n# log eventloop for debugging\nif self.__logging:\n# debugging\nlogger.info(\n\"Using `{}` event loop for this process.\".format(\nself.loop.__class__.__name__\n)\n)\ndef launch(self):\n\"\"\"\n        Launches an asynchronous generators and loop executors for respective task.\n        \"\"\"\n# check if receive mode enabled\nif self.__receive_mode:\nif self.__logging:\nlogger.debug(\"Launching NetGear_Async asynchronous generator!\")\n# run loop executor for Receiver asynchronous generator\nself.loop.run_in_executor(None, self.recv_generator)\nelse:\n# Otherwise launch Server handler\nif self.__logging:\nlogger.debug(\"Creating NetGear_Async asynchronous server handler!\")\n# create task for Server Handler\nself.task = asyncio.ensure_future(self.__server_handler())\n# return instance\nreturn self\nasync def __server_handler(self):\n\"\"\"\n        Handles various Server-end processes/tasks.\n        \"\"\"\n# validate assigned frame generator in NetGear_Async configuration\nif isinstance(self.config, dict) and \"generator\" in self.config:\n# check if its  assigned value is a asynchronous generator\nif self.config[\"generator\"] is None or not inspect.isasyncgen(\nself.config[\"generator\"]\n):\n# otherwise raise error\nraise ValueError(\n\"[NetGear_Async:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\"\n)\nelse:\n# raise error if validation fails\nraise RuntimeError(\n\"[NetGear_Async:ERROR] :: Assigned NetGear_Async configuration is invalid!\"\n)\n# define our messaging socket\nself.__msg_socket = self.__msg_context.socket(self.__pattern[0])\n# if req/rep pattern, define additional flags\nif self.__msg_pattern == 1:\nself.__msg_socket.REQ_RELAXED = True\nself.__msg_socket.REQ_CORRELATE = True\n# if pub/sub pattern, define additional optimizer\nif self.__msg_pattern == 2:\nself.__msg_socket.set_hwm(1)\n# try connecting socket to assigned protocol, address and port\ntry:\nself.__msg_socket.connect(\nself.__protocol + \"://\" + str(self.__address) + \":\" + str(self.__port)\n)\n# finally log if successful\nif self.__logging:\nlogger.debug(\n\"Successfully connected to address: {} with pattern: {}.\".format(\n(\nself.__protocol\n+ \"://\"\n+ str(self.__address)\n+ \":\"\n+ str(self.__port)\n),\nself.__msg_pattern,\n)\n)\nlogger.critical(\n\"Send Mode is successfully activated and ready to send data!\"\n)\nexcept Exception as e:\n# log ad raise error if failed\nlogger.exception(str(e))\nif self.__bi_mode:\nlogger.error(\n\"Failed to activate Bidirectional Mode for this connection!\"\n)\nraise ValueError(\n\"[NetGear_Async:ERROR] :: Failed to connect address: {} and pattern: {}!\".format(\n(\nself.__protocol\n+ \"://\"\n+ str(self.__address)\n+ \":\"\n+ str(self.__port)\n),\nself.__msg_pattern,\n)\n)\n# loop over our Asynchronous frame generator\nasync for dataframe in self.config[\"generator\"]:\n# extract data if bidirectional mode\nif self.__bi_mode and len(dataframe) == 2:\n(data, frame) = dataframe\nif not (data is None) and isinstance(data, np.ndarray):\nlogger.warning(\n\"Skipped unsupported `data` of datatype: {}!\".format(\ntype(data).__name__\n)\n)\ndata = None\nassert isinstance(\nframe, np.ndarray\n), \"[NetGear_Async:ERROR] :: Invalid data received from server end!\"\nelif self.__bi_mode:\n# raise error for invalid data\nraise ValueError(\n\"[NetGear_Async:ERROR] :: Send Mode only accepts tuple(data, frame) as input in Bidirectional Mode. \\\n                    Kindly refer vidgear docs!\"\n)\nelse:\n# otherwise just make a copy of frame\nframe = np.copy(dataframe)\ndata = None\n# check if retrieved frame is `CONTIGUOUS`\nif not (frame.flags[\"C_CONTIGUOUS\"]):\n# otherwise make it\nframe = np.ascontiguousarray(frame, dtype=frame.dtype)\n# create data dict\ndata_dict = dict(\nterminate=False,\nbi_mode=self.__bi_mode,\ndata=data if not (data is None) else \"\",\n)\n# encode it\ndata_enc = msgpack.packb(data_dict)\n# send the encoded data with correct flags\nawait self.__msg_socket.send(data_enc, flags=zmq.SNDMORE)\n# encode frame\nframe_enc = msgpack.packb(frame, default=m.encode)\n# send the encoded frame\nawait self.__msg_socket.send_multipart([frame_enc])\n# check if bidirectional patterns used\nif self.__msg_pattern &lt; 2:\n# handle bidirectional data transfer if enabled\nif self.__bi_mode:\n# get receiver encoded message withing timeout limit\nrecvdmsg_encoded = await asyncio.wait_for(\nself.__msg_socket.recv(), timeout=self.__timeout\n)\n# retrieve receiver data from encoded message\nrecvd_data = msgpack.unpackb(recvdmsg_encoded, use_list=False)\n# check message type\nif recvd_data[\"return_type\"] == \"ndarray\":  # numpy.ndarray\n# get encoded frame from receiver\nrecvdframe_encoded = await asyncio.wait_for(\nself.__msg_socket.recv_multipart(), timeout=self.__timeout\n)\n# retrieve frame and put in queue\nawait self.__queue.put(\nmsgpack.unpackb(\nrecvdframe_encoded[0],\nuse_list=False,\nobject_hook=m.decode,\n)\n)\nelse:\n# otherwise put data directly in queue\nawait self.__queue.put(\nrecvd_data[\"return_data\"]\nif recvd_data[\"return_data\"]\nelse None\n)\nelse:\n# otherwise log received confirmation\nrecv_confirmation = await asyncio.wait_for(\nself.__msg_socket.recv(), timeout=self.__timeout\n)\nif self.__logging:\nlogger.debug(recv_confirmation)\nasync def recv_generator(self):\n\"\"\"\n        A default Asynchronous Frame Generator for NetGear_Async's Receiver-end.\n        \"\"\"\n# check whether `receive mode` is activated\nif not (self.__receive_mode):\n# raise Value error and exit\nself.__terminate = True\nraise ValueError(\n\"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\"\n)\n# initialize and define messaging socket\nself.__msg_socket = self.__msg_context.socket(self.__pattern[1])\n# define exclusive socket options for patterns\nif self.__msg_pattern == 2:\nself.__msg_socket.set_hwm(1)\nself.__msg_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\ntry:\n# bind socket to the assigned protocol, address and port\nself.__msg_socket.bind(\nself.__protocol + \"://\" + str(self.__address) + \":\" + str(self.__port)\n)\n# finally log progress\nif self.__logging:\nlogger.debug(\n\"Successfully binded to address: {} with pattern: {}.\".format(\n(\nself.__protocol\n+ \"://\"\n+ str(self.__address)\n+ \":\"\n+ str(self.__port)\n),\nself.__msg_pattern,\n)\n)\nlogger.critical(\"Receive Mode is activated successfully!\")\nexcept Exception as e:\nlogger.exception(str(e))\nraise RuntimeError(\n\"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{}!\".format(\n(\nself.__protocol\n+ \"://\"\n+ str(self.__address)\n+ \":\"\n+ str(self.__port)\n),\nself.__msg_pattern,\n\" and Bidirectional Mode enabled\" if self.__bi_mode else \"\",\n)\n)\n# loop until terminated\nwhile not self.__terminate:\n# get encoded data message from server withing timeout limit\ndatamsg_encoded = await asyncio.wait_for(\nself.__msg_socket.recv(), timeout=self.__timeout\n)\n# retrieve data from message\ndata = msgpack.unpackb(datamsg_encoded, use_list=False)\n# terminate if exit` flag received from server\nif data[\"terminate\"]:\n# send confirmation message to server if bidirectional patterns\nif self.__msg_pattern &lt; 2:\n# create termination confirmation message\nreturn_dict = dict(\nterminated=\"Client-`{}` successfully terminated!\".format(\nself.__id\n),\n)\n# encode message\nretdata_enc = msgpack.packb(return_dict)\n# send message back to server\nawait self.__msg_socket.send(retdata_enc)\nif self.__logging:\nlogger.info(\"Termination signal received from server!\")\n# break loop and terminate\nself.__terminate = True\nbreak\n# get encoded frame message from server withing timeout limit\nframemsg_encoded = await asyncio.wait_for(\nself.__msg_socket.recv_multipart(), timeout=self.__timeout\n)\n# retrieve frame from message\nframe = msgpack.unpackb(\nframemsg_encoded[0], use_list=False, object_hook=m.decode\n)\n# check if bidirectional patterns\nif self.__msg_pattern &lt; 2:\n# handle bidirectional data transfer if enabled\nif self.__bi_mode and data[\"bi_mode\"]:\n# handle empty queue\nif not self.__queue.empty():\nreturn_data = await self.__queue.get()\nself.__queue.task_done()\nelse:\nreturn_data = None\n# check if we are returning `ndarray` frames\nif not (return_data is None) and isinstance(\nreturn_data, np.ndarray\n):\n# check whether the incoming frame is contiguous\nif not (return_data.flags[\"C_CONTIGUOUS\"]):\nreturn_data = np.ascontiguousarray(\nreturn_data, dtype=return_data.dtype\n)\n# create return type dict without data\nrettype_dict = dict(\nreturn_type=(type(return_data).__name__),\nreturn_data=None,\n)\n# encode it\nrettype_enc = msgpack.packb(rettype_dict)\n# send it to server with correct flags\nawait self.__msg_socket.send(rettype_enc, flags=zmq.SNDMORE)\n# encode return ndarray data\nretframe_enc = msgpack.packb(return_data, default=m.encode)\n# send it over network to server\nawait self.__msg_socket.send_multipart([retframe_enc])\nelse:\n# otherwise create type and data dict\nreturn_dict = dict(\nreturn_type=(type(return_data).__name__),\nreturn_data=return_data\nif not (return_data is None)\nelse \"\",\n)\n# encode it\nretdata_enc = msgpack.packb(return_dict)\n# send it over network to server\nawait self.__msg_socket.send(retdata_enc)\nelif self.__bi_mode or data[\"bi_mode\"]:\n# raise error if bidirectional mode is disabled at server or client but not both\nraise RuntimeError(\n\"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\".format(\n\"client\" if self.__bi_mode else \"server\"\n)\n)\nelse:\n# otherwise just send confirmation message to server\nawait self.__msg_socket.send(\nbytes(\n\"Data received on client: {} !\".format(self.__id), \"utf-8\"\n)\n)\n# yield received tuple(data-frame) if bidirectional mode or else just frame\nif self.__bi_mode:\nyield (data[\"data\"], frame) if data[\"data\"] else (None, frame)\nelse:\nyield frame\n# sleep for sometime\nawait asyncio.sleep(0)\nasync def __frame_generator(self):\n\"\"\"\n        Returns a default frame-generator for NetGear_Async's Server Handler.\n        \"\"\"\n# start stream\nself.__stream.start()\n# loop over stream until its terminated\nwhile not self.__terminate:\n# read frames\nframe = self.__stream.read()\n# break if NoneType\nif frame is None:\nbreak\n# yield frame\nyield frame\n# sleep for sometime\nawait asyncio.sleep(0)\nasync def transceive_data(self, data=None):\n\"\"\"\n        Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_.\n        Parameters:\n            data (any): inputs data _(of any datatype)_ for sending back to Server.\n        \"\"\"\nrecvd_data = None\nif not self.__terminate:\nif self.__bi_mode:\nif self.__receive_mode:\nawait self.__queue.put(data)\nelse:\nif not self.__queue.empty():\nrecvd_data = await self.__queue.get()\nself.__queue.task_done()\nelse:\nlogger.error(\n\"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\"\n)\nreturn recvd_data\nasync def __terminate_connection(self, disable_confirmation=False):\n\"\"\"\n        Internal asyncio method to safely terminate ZMQ connection and queues\n        Parameters:\n            disable_confirmation (boolean): Force disable termination confirmation from client in bidirectional patterns.\n        \"\"\"\n# log termination\nif self.__logging:\nlogger.debug(\n\"Terminating various {} Processes. Please wait.\".format(\n\"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n)\n)\n# check whether `receive_mode` is enabled or not\nif self.__receive_mode:\n# indicate that process should be terminated\nself.__terminate = True\nelse:\n# indicate that process should be terminated\nself.__terminate = True\n# terminate stream\nif not (self.__stream is None):\nself.__stream.stop()\n# signal `exit` flag for termination!\ndata_dict = dict(terminate=True)\ndata_enc = msgpack.packb(data_dict)\nawait self.__msg_socket.send(data_enc)\n# check if bidirectional patterns\nif self.__msg_pattern &lt; 2 and not disable_confirmation:\n# then receive and log confirmation\nrecv_confirmation = await self.__msg_socket.recv()\nrecvd_conf = msgpack.unpackb(recv_confirmation, use_list=False)\nif self.__logging and \"terminated\" in recvd_conf:\nlogger.debug(recvd_conf[\"terminated\"])\n# close socket\nself.__msg_socket.setsockopt(zmq.LINGER, 0)\nself.__msg_socket.close()\n# handle asyncio queues in bidirectional mode\nif self.__bi_mode:\n# empty queue if not\nwhile not self.__queue.empty():\ntry:\nself.__queue.get_nowait()\nexcept asyncio.QueueEmpty:\ncontinue\nself.__queue.task_done()\n# join queues\nawait self.__queue.join()\nlogger.critical(\n\"{} successfully terminated!\".format(\n\"Receive Mode\" if self.__receive_mode else \"Send Mode\"\n)\n)\ndef close(self, skip_loop=False):\n\"\"\"\n        Terminates all NetGear_Async Asynchronous processes gracefully.\n        Parameters:\n            skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest).\n        \"\"\"\n# close event loop if specified\nif not (skip_loop):\n# close connection gracefully\nself.loop.run_until_complete(self.__terminate_connection())\nself.loop.close()\nelse:\n# otherwise create a task\nasyncio.ensure_future(\nself.__terminate_connection(disable_confirmation=True)\n)\n</code></pre> <p> </p>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.__init__","title":"<code>__init__(self, address=None, port=None, protocol='tcp', pattern=0, receive_mode=False, timeout=0.0, enablePiCamera=False, stabilize=False, source=None, camera_num=0, stream_mode=False, backend=0, colorspace=None, resolution=(640, 480), framerate=25, time_delay=0, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the NetGear_Async class.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>sets the valid network address of the Server/Client.</p> <code>None</code> <code>port</code> <code>str</code> <p>sets the valid Network Port of the Server/Client.</p> <code>None</code> <code>protocol</code> <code>str</code> <p>sets the valid messaging protocol between Server/Client.</p> <code>'tcp'</code> <code>pattern</code> <code>int</code> <p>sets the supported messaging pattern(flow of communication) between Server/Client</p> <code>0</code> <code>receive_mode</code> <code>bool</code> <p>select the NetGear_Async's Mode of operation.</p> <code>False</code> <code>timeout</code> <code>int/float</code> <p>controls the maximum waiting time(in sec) after which Client throws <code>TimeoutError</code>.</p> <code>0.0</code> <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>25</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>None</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>def __init__(\nself,\n# NetGear_Async parameters\naddress=None,\nport=None,\nprotocol=\"tcp\",\npattern=0,\nreceive_mode=False,\ntimeout=0.0,\n# Videogear parameters\nenablePiCamera=False,\nstabilize=False,\nsource=None,\ncamera_num=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nresolution=(640, 480),\nframerate=25,\ntime_delay=0,\n# common parameters\nlogging=False,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the NetGear_Async class.\n    Parameters:\n        address (str): sets the valid network address of the Server/Client.\n        port (str): sets the valid Network Port of the Server/Client.\n        protocol (str): sets the valid messaging protocol between Server/Client.\n        pattern (int): sets the supported messaging pattern(flow of communication) between Server/Client\n        receive_mode (bool): select the NetGear_Async's Mode of operation.\n        timeout (int/float): controls the maximum waiting time(in sec) after which Client throws `TimeoutError`.\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of NetGear_Async, CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"zmq\" if zmq is None else \"\", min_version=\"4.0\", pkg_name=\"pyzmq\"\n)\nimport_dependency_safe(\"msgpack\" if msgpack is None else \"\")\nimport_dependency_safe(\"msgpack_numpy\" if m is None else \"\")\n# enable logging if specified\nself.__logging = logging\n# define valid messaging patterns =&gt; `0`: PAIR, `1`:(REQ, REP), `2`:(SUB, PUB), `3`:(PUSH, PULL)\nvalid_messaging_patterns = {\n0: (zmq.PAIR, zmq.PAIR),\n1: (zmq.REQ, zmq.REP),\n2: (zmq.PUB, zmq.SUB),\n3: (zmq.PUSH, zmq.PULL),\n}\n# check whether user-defined messaging pattern is valid\nif isinstance(pattern, int) and pattern in valid_messaging_patterns:\n# assign value\nself.__msg_pattern = pattern\nself.__pattern = valid_messaging_patterns[pattern]\nelse:\n# otherwise default to 0:`zmq.PAIR`\nself.__msg_pattern = 0\nself.__pattern = valid_messaging_patterns[self.__msg_pattern]\nif self.__logging:\nlogger.warning(\n\"Invalid pattern {pattern}. Defaulting to `zmq.PAIR`!\".format(\npattern=pattern\n)\n)\n# check  whether user-defined messaging protocol is valid\nif isinstance(protocol, str) and protocol in [\"tcp\", \"ipc\"]:\n# assign value\nself.__protocol = protocol\nelse:\n# else default to `tcp` protocol\nself.__protocol = \"tcp\"\nif self.__logging:\nlogger.warning(\"Invalid protocol. Defaulting to `tcp`!\")\n# initialize Termination flag\nself.__terminate = False\n# initialize and assign `Receive Mode`\nself.__receive_mode = receive_mode\n# initialize stream handler\nself.__stream = None\n# initialize Messaging Socket\nself.__msg_socket = None\n# initialize NetGear_Async's configuration dictionary\nself.config = {}\n# asyncio queue handler\nself.__queue = None\n# define Bidirectional mode\nself.__bi_mode = False  # handles Bidirectional mode state\n# assign timeout for Receiver end\nif timeout and isinstance(timeout, (int, float)):\nself.__timeout = float(timeout)\nelse:\nself.__timeout = 15.0\n# generate 8-digit random system id\nself.__id = \"\".join(\nsecrets.choice(string.ascii_uppercase + string.digits) for i in range(8)\n)\n# Handle user-defined options dictionary values\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# handle bidirectional mode\nif \"bidirectional_mode\" in options:\nvalue = options[\"bidirectional_mode\"]\n# also check if pattern and source is valid\nif isinstance(value, bool) and pattern &lt; 2 and source is None:\n# activate Bidirectional mode if specified\nself.__bi_mode = value\nelse:\n# otherwise disable it\nself.__bi_mode = False\nlogger.warning(\"Bidirectional data transmission is disabled!\")\n# handle errors and logging\nif pattern &gt;= 2:\n# raise error\nraise ValueError(\n\"[NetGear_Async:ERROR] :: `{}` pattern is not valid when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\npattern\n)\n)\nelif not (source is None):\nraise ValueError(\n\"[NetGear_Async:ERROR] :: Custom source must be used when Bidirectional Mode is enabled. Kindly refer Docs for more Information!\".format(\npattern\n)\n)\nelif isinstance(value, bool) and self.__logging:\n# log Bidirectional mode activation\nlogger.debug(\n\"Bidirectional Data Transmission is {} for this connection!\".format(\n\"enabled\" if value else \"disabled\"\n)\n)\nelse:\nlogger.error(\"`bidirectional_mode` value is invalid!\")\n# clean\ndel options[\"bidirectional_mode\"]\n# define messaging asynchronous Context\nself.__msg_context = zmq.asyncio.Context()\n# check whether `Receive Mode` is enabled\nif receive_mode:\n# assign local IP address if None\nif address is None:\nself.__address = \"*\"  # define address\nelse:\nself.__address = address\n# assign default port address if None\nif port is None:\nself.__port = \"5555\"\nelse:\nself.__port = port\nelse:\n# Handle video source\nif source is None:\nself.config = {\"generator\": None}\nif self.__logging:\nlogger.warning(\"Given source is of NoneType!\")\nelse:\n# define stream with necessary params\nself.__stream = VideoGear(\nenablePiCamera=enablePiCamera,\nstabilize=stabilize,\nsource=source,\ncamera_num=camera_num,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nresolution=resolution,\nframerate=framerate,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# define default frame generator in configuration\nself.config = {\"generator\": self.__frame_generator()}\n# assign local ip address if None\nif address is None:\nself.__address = \"localhost\"\nelse:\nself.__address = address\n# assign default port address if None\nif port is None:\nself.__port = \"5555\"\nelse:\nself.__port = port\n# add server task handler\nself.task = None\n# Setup and assign event loop policy\nif platform.system() == \"Windows\":\n# On Windows, VidGear requires the ``WindowsSelectorEventLoop``, and this is\n# the default in Python 3.7 and older, but new Python 3.8, defaults to an\n# event loop that is not compatible with it. Thereby, we had to set it manually.\nif sys.version_info[:2] &gt;= (3, 8):\nasyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\nelse:\nif not (uvloop is None):\n# Latest uvloop eventloop is only available for UNIX machines.\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nelse:\n# log if not present\nimport_dependency_safe(\"uvloop\", error=\"log\")\n# Retrieve event loop and assign it\nself.loop = asyncio.get_event_loop()\n# create asyncio queue if bidirectional mode activated\nself.__queue = asyncio.Queue() if self.__bi_mode else None\n# log eventloop for debugging\nif self.__logging:\n# debugging\nlogger.info(\n\"Using `{}` event loop for this process.\".format(\nself.loop.__class__.__name__\n)\n)\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.close","title":"<code>close(self, skip_loop=False)</code>","text":"<p>Terminates all NetGear_Async Asynchronous processes gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>skip_loop</code> <code>Boolean</code> <p>(optional)used only if don't want to close eventloop(required in pytest).</p> <code>False</code> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>def close(self, skip_loop=False):\n\"\"\"\n    Terminates all NetGear_Async Asynchronous processes gracefully.\n    Parameters:\n        skip_loop (Boolean): (optional)used only if don't want to close eventloop(required in pytest).\n    \"\"\"\n# close event loop if specified\nif not (skip_loop):\n# close connection gracefully\nself.loop.run_until_complete(self.__terminate_connection())\nself.loop.close()\nelse:\n# otherwise create a task\nasyncio.ensure_future(\nself.__terminate_connection(disable_confirmation=True)\n)\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.launch","title":"<code>launch(self)</code>","text":"<p>Launches an asynchronous generators and loop executors for respective task.</p> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>def launch(self):\n\"\"\"\n    Launches an asynchronous generators and loop executors for respective task.\n    \"\"\"\n# check if receive mode enabled\nif self.__receive_mode:\nif self.__logging:\nlogger.debug(\"Launching NetGear_Async asynchronous generator!\")\n# run loop executor for Receiver asynchronous generator\nself.loop.run_in_executor(None, self.recv_generator)\nelse:\n# Otherwise launch Server handler\nif self.__logging:\nlogger.debug(\"Creating NetGear_Async asynchronous server handler!\")\n# create task for Server Handler\nself.task = asyncio.ensure_future(self.__server_handler())\n# return instance\nreturn self\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.recv_generator","title":"<code>recv_generator(self)</code>","text":"<p>A default Asynchronous Frame Generator for NetGear_Async's Receiver-end.</p> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>async def recv_generator(self):\n\"\"\"\n    A default Asynchronous Frame Generator for NetGear_Async's Receiver-end.\n    \"\"\"\n# check whether `receive mode` is activated\nif not (self.__receive_mode):\n# raise Value error and exit\nself.__terminate = True\nraise ValueError(\n\"[NetGear_Async:ERROR] :: `recv_generator()` function cannot be accessed while `receive_mode` is disabled. Kindly refer vidgear docs!\"\n)\n# initialize and define messaging socket\nself.__msg_socket = self.__msg_context.socket(self.__pattern[1])\n# define exclusive socket options for patterns\nif self.__msg_pattern == 2:\nself.__msg_socket.set_hwm(1)\nself.__msg_socket.setsockopt(zmq.SUBSCRIBE, b\"\")\ntry:\n# bind socket to the assigned protocol, address and port\nself.__msg_socket.bind(\nself.__protocol + \"://\" + str(self.__address) + \":\" + str(self.__port)\n)\n# finally log progress\nif self.__logging:\nlogger.debug(\n\"Successfully binded to address: {} with pattern: {}.\".format(\n(\nself.__protocol\n+ \"://\"\n+ str(self.__address)\n+ \":\"\n+ str(self.__port)\n),\nself.__msg_pattern,\n)\n)\nlogger.critical(\"Receive Mode is activated successfully!\")\nexcept Exception as e:\nlogger.exception(str(e))\nraise RuntimeError(\n\"[NetGear_Async:ERROR] :: Failed to bind address: {} and pattern: {}{}!\".format(\n(\nself.__protocol\n+ \"://\"\n+ str(self.__address)\n+ \":\"\n+ str(self.__port)\n),\nself.__msg_pattern,\n\" and Bidirectional Mode enabled\" if self.__bi_mode else \"\",\n)\n)\n# loop until terminated\nwhile not self.__terminate:\n# get encoded data message from server withing timeout limit\ndatamsg_encoded = await asyncio.wait_for(\nself.__msg_socket.recv(), timeout=self.__timeout\n)\n# retrieve data from message\ndata = msgpack.unpackb(datamsg_encoded, use_list=False)\n# terminate if exit` flag received from server\nif data[\"terminate\"]:\n# send confirmation message to server if bidirectional patterns\nif self.__msg_pattern &lt; 2:\n# create termination confirmation message\nreturn_dict = dict(\nterminated=\"Client-`{}` successfully terminated!\".format(\nself.__id\n),\n)\n# encode message\nretdata_enc = msgpack.packb(return_dict)\n# send message back to server\nawait self.__msg_socket.send(retdata_enc)\nif self.__logging:\nlogger.info(\"Termination signal received from server!\")\n# break loop and terminate\nself.__terminate = True\nbreak\n# get encoded frame message from server withing timeout limit\nframemsg_encoded = await asyncio.wait_for(\nself.__msg_socket.recv_multipart(), timeout=self.__timeout\n)\n# retrieve frame from message\nframe = msgpack.unpackb(\nframemsg_encoded[0], use_list=False, object_hook=m.decode\n)\n# check if bidirectional patterns\nif self.__msg_pattern &lt; 2:\n# handle bidirectional data transfer if enabled\nif self.__bi_mode and data[\"bi_mode\"]:\n# handle empty queue\nif not self.__queue.empty():\nreturn_data = await self.__queue.get()\nself.__queue.task_done()\nelse:\nreturn_data = None\n# check if we are returning `ndarray` frames\nif not (return_data is None) and isinstance(\nreturn_data, np.ndarray\n):\n# check whether the incoming frame is contiguous\nif not (return_data.flags[\"C_CONTIGUOUS\"]):\nreturn_data = np.ascontiguousarray(\nreturn_data, dtype=return_data.dtype\n)\n# create return type dict without data\nrettype_dict = dict(\nreturn_type=(type(return_data).__name__),\nreturn_data=None,\n)\n# encode it\nrettype_enc = msgpack.packb(rettype_dict)\n# send it to server with correct flags\nawait self.__msg_socket.send(rettype_enc, flags=zmq.SNDMORE)\n# encode return ndarray data\nretframe_enc = msgpack.packb(return_data, default=m.encode)\n# send it over network to server\nawait self.__msg_socket.send_multipart([retframe_enc])\nelse:\n# otherwise create type and data dict\nreturn_dict = dict(\nreturn_type=(type(return_data).__name__),\nreturn_data=return_data\nif not (return_data is None)\nelse \"\",\n)\n# encode it\nretdata_enc = msgpack.packb(return_dict)\n# send it over network to server\nawait self.__msg_socket.send(retdata_enc)\nelif self.__bi_mode or data[\"bi_mode\"]:\n# raise error if bidirectional mode is disabled at server or client but not both\nraise RuntimeError(\n\"[NetGear_Async:ERROR] :: Invalid configuration! Bidirectional Mode is not activate on {} end.\".format(\n\"client\" if self.__bi_mode else \"server\"\n)\n)\nelse:\n# otherwise just send confirmation message to server\nawait self.__msg_socket.send(\nbytes(\n\"Data received on client: {} !\".format(self.__id), \"utf-8\"\n)\n)\n# yield received tuple(data-frame) if bidirectional mode or else just frame\nif self.__bi_mode:\nyield (data[\"data\"], frame) if data[\"data\"] else (None, frame)\nelse:\nyield frame\n# sleep for sometime\nawait asyncio.sleep(0)\n</code></pre>"},{"location":"bonus/reference/netgear_async/#vidgear.gears.asyncio.netgear_async.NetGear_Async.transceive_data","title":"<code>transceive_data(self, data=None)</code>  <code>async</code>","text":"<p>Bidirectional Mode exclusive method to Transmit data (in Receive mode) and Receive data (in Send mode).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>any</code> <p>inputs data (of any datatype) for sending back to Server.</p> <code>None</code> Source code in <code>vidgear/gears/asyncio/netgear_async.py</code> <pre><code>async def transceive_data(self, data=None):\n\"\"\"\n    Bidirectional Mode exclusive method to Transmit data _(in Receive mode)_ and Receive data _(in Send mode)_.\n    Parameters:\n        data (any): inputs data _(of any datatype)_ for sending back to Server.\n    \"\"\"\nrecvd_data = None\nif not self.__terminate:\nif self.__bi_mode:\nif self.__receive_mode:\nawait self.__queue.put(data)\nelse:\nif not self.__queue.empty():\nrecvd_data = await self.__queue.get()\nself.__queue.task_done()\nelse:\nlogger.error(\n\"`transceive_data()` function cannot be used when Bidirectional Mode is disabled.\"\n)\nreturn recvd_data\n</code></pre>"},{"location":"bonus/reference/pigear/","title":"PiGear API","text":"<p>PiGear API usage examples can be found here \u27b6</p> <p>PiGear API parameters are explained here \u27b6</p> <p>PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module). PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness, saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards.</p> <p>Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources.</p> <p>Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>class PiGear:\n\"\"\"\n    PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module).\n    PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like brightness,\n    saturation, sensor_mode, iso, exposure, etc. effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards.\n    Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that\n    if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources.\n    !!! warning \"Make sure to enable [Raspberry Pi hardware-specific settings](https://picamera.readthedocs.io/en/release-1.13/quickstart.html) prior using this API, otherwise nothing will work.\"\n    \"\"\"\ndef __init__(\nself,\ncamera_num=0,\nresolution=(640, 480),\nframerate=30,\ncolorspace=None,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the PiGear class.\n        Parameters:\n            camera_num (int): selects the camera module index which will be used as source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source..\n            framerate (int/float): sets the framerate of the source.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Source Tweak Parameters.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"picamera\" if picamera is None else \"\",\n)\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\nassert (\nisinstance(framerate, (int, float)) and framerate &gt; 5.0\n), \"[PiGear:ERROR] :: Input framerate value `{}` is a Invalid! Kindly read docs.\".format(\nframerate\n)\nassert (\nisinstance(resolution, (tuple, list)) and len(resolution) == 2\n), \"[PiGear:ERROR] :: Input resolution value `{}` is a Invalid! Kindly read docs.\".format(\nresolution\n)\nif not (isinstance(camera_num, int) and camera_num &gt;= 0):\ncamera_num = 0\nlogger.warning(\n\"Input camera_num value `{}` is invalid, Defaulting to index 0!\"\n)\n# initialize the picamera stream at given index\nself.__camera = PiCamera(camera_num=camera_num)\nself.__camera.resolution = tuple(resolution)\nself.__camera.framerate = framerate\nself.__logging and logger.debug(\n\"Activating Pi camera at index: {} with resolution: {} &amp; framerate: {}\".format(\ncamera_num, resolution, framerate\n)\n)\n# initialize framerate variable\nself.framerate = framerate\n# initializing colorspace variable\nself.color_space = None\n# reformat dict\noptions = {str(k).strip(): v for k, v in options.items()}\n# define timeout variable default value(handles hardware failures)\nself.__failure_timeout = options.pop(\"HWFAILURE_TIMEOUT\", 2.0)\nif isinstance(self.__failure_timeout, (int, float)):\nif not (10.0 &gt; self.__failure_timeout &gt; 1.0):\nraise ValueError(\n\"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\"\n)\nself.__logging and logger.debug(\n\"Setting HW Failure Timeout: {} seconds\".format(self.__failure_timeout)\n)\nelse:\n# reset improper values\nself.__failure_timeout = 2.0\ntry:\n# apply attributes to source if specified\nfor key, value in options.items():\nself.__logging and logger.debug(\n\"Setting Parameter: {} = '{}'\".format(key, value)\n)\nsetattr(self.__camera, key, value)\nexcept Exception as e:\n# Catch if any error occurred\nlogger.exception(str(e))\n# separately handle colorspace value to int conversion\nif not (colorspace is None):\nself.color_space = capPropId(colorspace.strip())\nif self.__logging and not (self.color_space is None):\nlogger.debug(\n\"Enabling `{}` colorspace for this video stream!\".format(\ncolorspace.strip()\n)\n)\n# enable rgb capture array thread and capture stream\nself.__rawCapture = PiRGBArray(self.__camera, size=resolution)\nself.stream = self.__camera.capture_continuous(\nself.__rawCapture, format=\"bgr\", use_video_port=True\n)\n# frame variable initialization\nself.frame = None\ntry:\nstream = next(self.stream)\nself.frame = stream.array\nself.__rawCapture.seek(0)\nself.__rawCapture.truncate()\n# render colorspace if defined\nif not (self.frame is None) and not (self.color_space is None):\nself.frame = cv2.cvtColor(self.frame, self.color_space)\nexcept Exception as e:\nlogger.exception(str(e))\nraise RuntimeError(\"[PiGear:ERROR] :: Camera Module failed to initialize!\")\n# applying time delay to warm-up picamera only if specified\nif time_delay and isinstance(time_delay, (int, float)):\ntime.sleep(time_delay)\n# thread initialization\nself.__thread = None\n# timer thread initialization(Keeps check on frozen thread)\nself.__timer = None\nself.__t_elasped = 0.0  # records time taken by thread\n# catching thread exceptions\nself.__exceptions = None\n# initialize termination flag\nself.__terminate = False\ndef start(self):\n\"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon\n        **Returns:** A reference to the CamGear class object.\n        \"\"\"\n# Start frame producer thread\nself.__thread = Thread(target=self.__update, name=\"PiGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\n# Start internal timer thread\nself.__timer = Thread(target=self.__timeit, name=\"PiTimer\", args=())\nself.__timer.daemon = True\nself.__timer.start()\nreturn self\ndef __timeit(self):\n\"\"\"\n        Threaded Internal Timer that keep checks on thread execution timing\n        \"\"\"\n# assign current time\nself.__t_elasped = time.time()\n# loop until termainated\nwhile not (self.__terminate):\n# check for frozen thread\nif time.time() - self.__t_elasped &gt; self.__failure_timeout:\n# log failure\nself.__logging and logger.critical(\"Camera Module Disconnected!\")\n# prepare for clean exit\nself.__exceptions = True\nself.__terminate = True  # self-terminate\ndef __update(self):\n\"\"\"\n        A **Threaded Frames Extractor**, that keep iterating frames from PiCamera API to a internal monitored deque,\n        until the thread is terminated, or frames runs out.\n        \"\"\"\n# keep looping infinitely until the thread is terminated\nwhile not (self.__terminate):\ntry:\n# Try to iterate next frame from generator\nstream = next(self.stream)\nexcept Exception:\n# catch and save any exceptions\nself.__exceptions = sys.exc_info()\nbreak  # exit\n# __update timer\nself.__t_elasped = time.time()\n# grab the frame from the stream and clear the stream in\n# preparation for the next frame\nframe = stream.array\nself.__rawCapture.seek(0)\nself.__rawCapture.truncate()\n# apply colorspace if specified\nif not (self.color_space is None):\n# apply colorspace to frames\ncolor_frame = None\ntry:\nif isinstance(self.color_space, int):\ncolor_frame = cv2.cvtColor(frame, self.color_space)\nelse:\nself.__logging and logger.warning(\n\"Global color_space parameter value `{}` is not a valid!\".format(\nself.color_space\n)\n)\nself.color_space = None\nexcept Exception as e:\n# Catch if any error occurred\nself.color_space = None\nif self.__logging:\nlogger.exception(str(e))\nlogger.warning(\"Input colorspace is not a valid colorspace!\")\nif not (color_frame is None):\nself.frame = color_frame\nelse:\nself.frame = frame\nelse:\nself.frame = frame\n# terminate processes\nif not (self.__terminate):\nself.__terminate = True\n# release picamera resources\nself.__rawCapture.close()\nself.__camera.close()\ndef read(self):\n\"\"\"\n        Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n        and blocks the thread if the deque is full.\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n# check if there are any thread exceptions\nif not (self.__exceptions is None):\nif isinstance(self.__exceptions, bool):\n# clear frame\nself.frame = None\n# notify user about hardware failure\nraise SystemError(\n\"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\"\n)\nelse:\n# clear frame\nself.frame = None\n# re-raise error for debugging\nerror_msg = (\n\"[PiGear:ERROR] :: Camera Module API failure occured: {}\".format(\nself.__exceptions[1]\n)\n)\nraise RuntimeError(error_msg).with_traceback(self.__exceptions[2])\n# return the frame\nreturn self.frame\ndef stop(self):\n\"\"\"\n        Safely terminates the thread, and release the VideoStream resources.\n        \"\"\"\nself.__logging and logger.debug(\"Terminating PiGear Processes.\")\n# make sure that the threads should be terminated\nself.__terminate = True\n# stop timer thread\nif not (self.__timer is None):\nself.__timer.join()\nself.__timer = None\n# handle camera thread\nif not (self.__thread is None):\n# check if hardware failure occured\nif not (self.__exceptions is None) and isinstance(self.__exceptions, bool):\n# force release picamera resources\nself.__rawCapture.close()\nself.__camera.close()\n# properly handle thread exit\nself.__thread.join()  # wait if still process is still processing some information\n# remove any threads\nself.__thread = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.__init__","title":"<code>__init__(self, camera_num=0, resolution=(640, 480), framerate=30, colorspace=None, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the PiGear class.</p> <p>Parameters:</p> Name Type Description Default <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the source..</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the source.</p> <code>30</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Source Tweak Parameters.</p> <code>{}</code> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def __init__(\nself,\ncamera_num=0,\nresolution=(640, 480),\nframerate=30,\ncolorspace=None,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the PiGear class.\n    Parameters:\n        camera_num (int): selects the camera module index which will be used as source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the source..\n        framerate (int/float): sets the framerate of the source.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Source Tweak Parameters.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"picamera\" if picamera is None else \"\",\n)\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\nassert (\nisinstance(framerate, (int, float)) and framerate &gt; 5.0\n), \"[PiGear:ERROR] :: Input framerate value `{}` is a Invalid! Kindly read docs.\".format(\nframerate\n)\nassert (\nisinstance(resolution, (tuple, list)) and len(resolution) == 2\n), \"[PiGear:ERROR] :: Input resolution value `{}` is a Invalid! Kindly read docs.\".format(\nresolution\n)\nif not (isinstance(camera_num, int) and camera_num &gt;= 0):\ncamera_num = 0\nlogger.warning(\n\"Input camera_num value `{}` is invalid, Defaulting to index 0!\"\n)\n# initialize the picamera stream at given index\nself.__camera = PiCamera(camera_num=camera_num)\nself.__camera.resolution = tuple(resolution)\nself.__camera.framerate = framerate\nself.__logging and logger.debug(\n\"Activating Pi camera at index: {} with resolution: {} &amp; framerate: {}\".format(\ncamera_num, resolution, framerate\n)\n)\n# initialize framerate variable\nself.framerate = framerate\n# initializing colorspace variable\nself.color_space = None\n# reformat dict\noptions = {str(k).strip(): v for k, v in options.items()}\n# define timeout variable default value(handles hardware failures)\nself.__failure_timeout = options.pop(\"HWFAILURE_TIMEOUT\", 2.0)\nif isinstance(self.__failure_timeout, (int, float)):\nif not (10.0 &gt; self.__failure_timeout &gt; 1.0):\nraise ValueError(\n\"[PiGear:ERROR] :: `HWFAILURE_TIMEOUT` value can only be between 1.0 ~ 10.0\"\n)\nself.__logging and logger.debug(\n\"Setting HW Failure Timeout: {} seconds\".format(self.__failure_timeout)\n)\nelse:\n# reset improper values\nself.__failure_timeout = 2.0\ntry:\n# apply attributes to source if specified\nfor key, value in options.items():\nself.__logging and logger.debug(\n\"Setting Parameter: {} = '{}'\".format(key, value)\n)\nsetattr(self.__camera, key, value)\nexcept Exception as e:\n# Catch if any error occurred\nlogger.exception(str(e))\n# separately handle colorspace value to int conversion\nif not (colorspace is None):\nself.color_space = capPropId(colorspace.strip())\nif self.__logging and not (self.color_space is None):\nlogger.debug(\n\"Enabling `{}` colorspace for this video stream!\".format(\ncolorspace.strip()\n)\n)\n# enable rgb capture array thread and capture stream\nself.__rawCapture = PiRGBArray(self.__camera, size=resolution)\nself.stream = self.__camera.capture_continuous(\nself.__rawCapture, format=\"bgr\", use_video_port=True\n)\n# frame variable initialization\nself.frame = None\ntry:\nstream = next(self.stream)\nself.frame = stream.array\nself.__rawCapture.seek(0)\nself.__rawCapture.truncate()\n# render colorspace if defined\nif not (self.frame is None) and not (self.color_space is None):\nself.frame = cv2.cvtColor(self.frame, self.color_space)\nexcept Exception as e:\nlogger.exception(str(e))\nraise RuntimeError(\"[PiGear:ERROR] :: Camera Module failed to initialize!\")\n# applying time delay to warm-up picamera only if specified\nif time_delay and isinstance(time_delay, (int, float)):\ntime.sleep(time_delay)\n# thread initialization\nself.__thread = None\n# timer thread initialization(Keeps check on frozen thread)\nself.__timer = None\nself.__t_elasped = 0.0  # records time taken by thread\n# catching thread exceptions\nself.__exceptions = None\n# initialize termination flag\nself.__terminate = False\n</code></pre>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def read(self):\n\"\"\"\n    Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n    and blocks the thread if the deque is full.\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n# check if there are any thread exceptions\nif not (self.__exceptions is None):\nif isinstance(self.__exceptions, bool):\n# clear frame\nself.frame = None\n# notify user about hardware failure\nraise SystemError(\n\"[PiGear:ERROR] :: Hardware failure occurred, Kindly reconnect Camera Module and restart your Pi!\"\n)\nelse:\n# clear frame\nself.frame = None\n# re-raise error for debugging\nerror_msg = (\n\"[PiGear:ERROR] :: Camera Module API failure occured: {}\".format(\nself.__exceptions[1]\n)\n)\nraise RuntimeError(error_msg).with_traceback(self.__exceptions[2])\n# return the frame\nreturn self.frame\n</code></pre>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon</p> <p>Returns: A reference to the CamGear class object.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def start(self):\n\"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon\n    **Returns:** A reference to the CamGear class object.\n    \"\"\"\n# Start frame producer thread\nself.__thread = Thread(target=self.__update, name=\"PiGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\n# Start internal timer thread\nself.__timer = Thread(target=self.__timeit, name=\"PiTimer\", args=())\nself.__timer.daemon = True\nself.__timer.start()\nreturn self\n</code></pre>"},{"location":"bonus/reference/pigear/#vidgear.gears.pigear.PiGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the VideoStream resources.</p> Source code in <code>vidgear/gears/pigear.py</code> <pre><code>def stop(self):\n\"\"\"\n    Safely terminates the thread, and release the VideoStream resources.\n    \"\"\"\nself.__logging and logger.debug(\"Terminating PiGear Processes.\")\n# make sure that the threads should be terminated\nself.__terminate = True\n# stop timer thread\nif not (self.__timer is None):\nself.__timer.join()\nself.__timer = None\n# handle camera thread\nif not (self.__thread is None):\n# check if hardware failure occured\nif not (self.__exceptions is None) and isinstance(self.__exceptions, bool):\n# force release picamera resources\nself.__rawCapture.close()\nself.__camera.close()\n# properly handle thread exit\nself.__thread.join()  # wait if still process is still processing some information\n# remove any threads\nself.__thread = None\n</code></pre>"},{"location":"bonus/reference/screengear/","title":"ScreenGear API","text":"<p>ScreenGear API usage examples can be found here \u27b6</p> <p>ScreenGear API parameters are explained here \u27b6</p> <p>ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends.</p> <p>ScreenGear API implements a multi-threaded wrapper around pyscreenshot &amp; python-mss python library, and also flexibly supports its internal parameter.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>class ScreenGear:\n\"\"\"\n    ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen,\n    at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends.\n    ScreenGear API implements a multi-threaded wrapper around pyscreenshot &amp; python-mss python library, and also flexibly supports its internal parameter.\n    \"\"\"\ndef __init__(\nself, monitor=None, backend=\"\", colorspace=None, logging=False, **options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the ScreenGear class.\n        Parameters:\n            monitor (int): enables `mss` backend and sets the index of the monitor screen.\n            backend (str): enables `pyscreenshot` and select suitable backend for extracting frames.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            options (dict): provides the flexibility to manually set the dimensions of capture screen area.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"from mss import mss\" if mss is None else \"\", pkg_name=\"mss\"\n)\nimport_dependency_safe(\"pyscreenshot\" if pysct is None else \"\")\n# enable logging if specified:\nself.__logging = logging if isinstance(logging, bool) else False\n# create monitor instance for the user-defined monitor\nself.__monitor_instance = None\nself.__backend = \"\"\nif monitor is None:\nself.__capture_object = pysct\nself.__backend = backend.lower().strip()\nelse:\nself.__capture_object = mss()\nif backend.strip():\nlogger.warning(\n\"Backends are disabled for Monitor Indexing(monitor&gt;=0)!\"\n)\ntry:\nself.__monitor_instance = self.__capture_object.monitors[monitor]\nexcept Exception as e:\nlogger.exception(str(e))\nself.__monitor_instance = None\n# assigns special parameter to global variable and clear\n# Thread Timeout\nself.__thread_timeout = options.pop(\"THREAD_TIMEOUT\", None)\nif self.__thread_timeout and isinstance(self.__thread_timeout, (int, float)):\n# set values\nself.__thread_timeout = float(self.__thread_timeout)\nelse:\n# defaults to 5mins timeout\nself.__thread_timeout = None\n# define deque and assign it to global var\nself.__queue = queue.Queue(maxsize=96)  # max bufferlen 96 to check overflow\n# log it\nif logging:\nlogger.debug(\"Enabling Threaded Queue Mode by default for ScreenGear!\")\nif self.__thread_timeout:\nlogger.debug(\n\"Setting Video-Thread Timeout to {}s.\".format(self.__thread_timeout)\n)\n# intiate screen dimension handler\nscreen_dims = {}\n# reformat proper mss dict and assign to screen dimension handler\nscreen_dims = {\nk.strip(): v\nfor k, v in options.items()\nif k.strip() in [\"top\", \"left\", \"width\", \"height\"]\n}\n# check whether user-defined dimensions are provided\nif screen_dims and len(screen_dims) == 4:\nkey_order = (\"top\", \"left\", \"width\", \"height\")\nscreen_dims = OrderedDict((k, screen_dims[k]) for k in key_order)\nif logging:\nlogger.debug(\"Setting Capture-Area dimensions: {}!\".format(screen_dims))\nelse:\nscreen_dims.clear()\n# separately handle colorspace value to int conversion\nif colorspace:\nself.color_space = capPropId(colorspace.strip())\nif logging and not (self.color_space is None):\nlogger.debug(\n\"Enabling `{}` colorspace for this video stream!\".format(\ncolorspace.strip()\n)\n)\nelse:\nself.color_space = None\n# intialize mss capture instance\nself.__mss_capture_instance = \"\"\ntry:\nif self.__monitor_instance is None:\nif screen_dims:\nself.__mss_capture_instance = tuple(screen_dims.values())\n# extract global frame from instance\nself.frame = np.asanyarray(\nself.__capture_object.grab(\nbbox=self.__mss_capture_instance,\nchildprocess=False,\nbackend=self.__backend,\n)\n)\nelse:\nif screen_dims:\nself.__mss_capture_instance = {\n\"top\": self.__monitor_instance[\"top\"] + screen_dims[\"top\"],\n\"left\": self.__monitor_instance[\"left\"] + screen_dims[\"left\"],\n\"width\": screen_dims[\"width\"],\n\"height\": screen_dims[\"height\"],\n\"mon\": monitor,\n}\nelse:\nself.__mss_capture_instance = (\nself.__monitor_instance  # otherwise create instance from monitor\n)\n# extract global frame from instance\nself.frame = np.asanyarray(\nself.__capture_object.grab(self.__mss_capture_instance)\n)\n# initialize and append to queue\nself.__queue.put(self.frame)\nexcept Exception as e:\nif isinstance(e, ScreenShotError):\n# otherwise catch and log errors\nif logging:\nlogger.exception(self.__capture_object.get_error_details())\nraise ValueError(\n\"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\"\n)\nelif isinstance(e, KeyError):\nraise ValueError(\n\"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: `{}`, Kindly Refer Docs!\".format(\nbackend\n)\n)\nelse:\nraise SystemError(\n\"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\"\n)\n# thread initialization\nself.__thread = None\n# initialize termination flag\nself.__terminate = Event()\ndef start(self):\n\"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon\n        **Returns:** A reference to the ScreenGear class object.\n        \"\"\"\nself.__thread = Thread(target=self.__update, name=\"ScreenGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\nreturn self\ndef __update(self):\n\"\"\"\n        A **Threaded Frames Extractor**, that keep iterating frames from `mss` API to a internal monitored deque,\n        until the thread is terminated, or frames runs out.\n        \"\"\"\n# initialize frame variable\nframe = None\n# keep looping infinitely until the thread is terminated\nwhile not self.__terminate.is_set():\ntry:\nif self.__monitor_instance:\nframe = np.asanyarray(\nself.__capture_object.grab(self.__mss_capture_instance)\n)\nelse:\nframe = np.asanyarray(\nself.__capture_object.grab(\nbbox=self.__mss_capture_instance,\nchildprocess=False,\nbackend=self.__backend,\n)\n)\nif not self.__backend or self.__backend == \"pil\":\nframe = frame[:, :, ::-1]\nassert not (\nframe is None or np.shape(frame) == ()\n), \"[ScreenGear:ERROR] :: Failed to retreive any valid frames!\"\nexcept Exception as e:\nif isinstance(e, ScreenShotError):\nraise RuntimeError(self.__capture_object.get_error_details())\nelse:\nlogger.exception(str(e))\nself.__terminate.set()\ncontinue\nif not (self.color_space is None):\n# apply colorspace to frames\ncolor_frame = None\ntry:\nif isinstance(self.color_space, int):\ncolor_frame = cv2.cvtColor(frame, self.color_space)\nelse:\nself.__logging and logger.warning(\n\"Global color_space parameter value `{}` is not a valid!\".format(\nself.color_space\n)\n)\nself.color_space = None\nexcept Exception as e:\n# Catch if any error occurred\nself.color_space = None\nif self.__logging:\nlogger.exception(str(e))\nlogger.warning(\"Input colorspace is not a valid colorspace!\")\nif not (color_frame is None):\nself.frame = color_frame\nelse:\nself.frame = frame\nelse:\nself.frame = frame\n# append to queue\nself.__queue.put(self.frame)\n# signal queue we're done\nself.__queue.put(None)\n# indicate immediate termination\nself.__terminate.set()\n# finally release mss resources\nif self.__monitor_instance:\nself.__capture_object.close()\ndef read(self):\n\"\"\"\n        Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n        and blocks the thread if the deque is full.\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\n# check whether or not termination flag is enabled\nwhile not self.__terminate.is_set():\nif self.__queue.empty():\nbreak\nreturn self.__queue.get(timeout=self.__thread_timeout)\n# otherwise return NoneType\nreturn None\ndef stop(self):\n\"\"\"\n        Safely terminates the thread, and release the resources.\n        \"\"\"\nself.__logging and logger.debug(\"Terminating ScreenGear Processes.\")\n# indicate that the thread should be terminate\nself.__terminate.set()\n# wait until stream resources are released (producer thread might be still grabbing frame)\nif self.__thread is not None:\nif not (self.__queue is None):\nwhile not self.__queue.empty():\ntry:\nself.__queue.get_nowait()\nexcept queue.Empty:\ncontinue\nself.__queue.task_done()\nself.__thread.join()\n</code></pre> <p> </p>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.__init__","title":"<code>__init__(self, monitor=None, backend='', colorspace=None, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the ScreenGear class.</p> <p>Parameters:</p> Name Type Description Default <code>monitor</code> <code>int</code> <p>enables <code>mss</code> backend and sets the index of the monitor screen.</p> <code>None</code> <code>backend</code> <code>str</code> <p>enables <code>pyscreenshot</code> and select suitable backend for extracting frames.</p> <code>''</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>options</code> <code>dict</code> <p>provides the flexibility to manually set the dimensions of capture screen area.</p> <code>{}</code> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def __init__(\nself, monitor=None, backend=\"\", colorspace=None, logging=False, **options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the ScreenGear class.\n    Parameters:\n        monitor (int): enables `mss` backend and sets the index of the monitor screen.\n        backend (str): enables `pyscreenshot` and select suitable backend for extracting frames.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        options (dict): provides the flexibility to manually set the dimensions of capture screen area.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\n\"from mss import mss\" if mss is None else \"\", pkg_name=\"mss\"\n)\nimport_dependency_safe(\"pyscreenshot\" if pysct is None else \"\")\n# enable logging if specified:\nself.__logging = logging if isinstance(logging, bool) else False\n# create monitor instance for the user-defined monitor\nself.__monitor_instance = None\nself.__backend = \"\"\nif monitor is None:\nself.__capture_object = pysct\nself.__backend = backend.lower().strip()\nelse:\nself.__capture_object = mss()\nif backend.strip():\nlogger.warning(\n\"Backends are disabled for Monitor Indexing(monitor&gt;=0)!\"\n)\ntry:\nself.__monitor_instance = self.__capture_object.monitors[monitor]\nexcept Exception as e:\nlogger.exception(str(e))\nself.__monitor_instance = None\n# assigns special parameter to global variable and clear\n# Thread Timeout\nself.__thread_timeout = options.pop(\"THREAD_TIMEOUT\", None)\nif self.__thread_timeout and isinstance(self.__thread_timeout, (int, float)):\n# set values\nself.__thread_timeout = float(self.__thread_timeout)\nelse:\n# defaults to 5mins timeout\nself.__thread_timeout = None\n# define deque and assign it to global var\nself.__queue = queue.Queue(maxsize=96)  # max bufferlen 96 to check overflow\n# log it\nif logging:\nlogger.debug(\"Enabling Threaded Queue Mode by default for ScreenGear!\")\nif self.__thread_timeout:\nlogger.debug(\n\"Setting Video-Thread Timeout to {}s.\".format(self.__thread_timeout)\n)\n# intiate screen dimension handler\nscreen_dims = {}\n# reformat proper mss dict and assign to screen dimension handler\nscreen_dims = {\nk.strip(): v\nfor k, v in options.items()\nif k.strip() in [\"top\", \"left\", \"width\", \"height\"]\n}\n# check whether user-defined dimensions are provided\nif screen_dims and len(screen_dims) == 4:\nkey_order = (\"top\", \"left\", \"width\", \"height\")\nscreen_dims = OrderedDict((k, screen_dims[k]) for k in key_order)\nif logging:\nlogger.debug(\"Setting Capture-Area dimensions: {}!\".format(screen_dims))\nelse:\nscreen_dims.clear()\n# separately handle colorspace value to int conversion\nif colorspace:\nself.color_space = capPropId(colorspace.strip())\nif logging and not (self.color_space is None):\nlogger.debug(\n\"Enabling `{}` colorspace for this video stream!\".format(\ncolorspace.strip()\n)\n)\nelse:\nself.color_space = None\n# intialize mss capture instance\nself.__mss_capture_instance = \"\"\ntry:\nif self.__monitor_instance is None:\nif screen_dims:\nself.__mss_capture_instance = tuple(screen_dims.values())\n# extract global frame from instance\nself.frame = np.asanyarray(\nself.__capture_object.grab(\nbbox=self.__mss_capture_instance,\nchildprocess=False,\nbackend=self.__backend,\n)\n)\nelse:\nif screen_dims:\nself.__mss_capture_instance = {\n\"top\": self.__monitor_instance[\"top\"] + screen_dims[\"top\"],\n\"left\": self.__monitor_instance[\"left\"] + screen_dims[\"left\"],\n\"width\": screen_dims[\"width\"],\n\"height\": screen_dims[\"height\"],\n\"mon\": monitor,\n}\nelse:\nself.__mss_capture_instance = (\nself.__monitor_instance  # otherwise create instance from monitor\n)\n# extract global frame from instance\nself.frame = np.asanyarray(\nself.__capture_object.grab(self.__mss_capture_instance)\n)\n# initialize and append to queue\nself.__queue.put(self.frame)\nexcept Exception as e:\nif isinstance(e, ScreenShotError):\n# otherwise catch and log errors\nif logging:\nlogger.exception(self.__capture_object.get_error_details())\nraise ValueError(\n\"[ScreenGear:ERROR] :: ScreenShotError caught, Wrong dimensions passed to python-mss, Kindly Refer Docs!\"\n)\nelif isinstance(e, KeyError):\nraise ValueError(\n\"[ScreenGear:ERROR] :: ScreenShotError caught, Invalid backend: `{}`, Kindly Refer Docs!\".format(\nbackend\n)\n)\nelse:\nraise SystemError(\n\"[ScreenGear:ERROR] :: Unable to grab any instance on this system, Are you running headless?\"\n)\n# thread initialization\nself.__thread = None\n# initialize termination flag\nself.__terminate = Event()\n</code></pre>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def read(self):\n\"\"\"\n    Extracts frames synchronously from monitored deque, while maintaining a fixed-length frame buffer in the memory,\n    and blocks the thread if the deque is full.\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\n# check whether or not termination flag is enabled\nwhile not self.__terminate.is_set():\nif self.__queue.empty():\nbreak\nreturn self.__queue.get(timeout=self.__thread_timeout)\n# otherwise return NoneType\nreturn None\n</code></pre>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon</p> <p>Returns: A reference to the ScreenGear class object.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def start(self):\n\"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon\n    **Returns:** A reference to the ScreenGear class object.\n    \"\"\"\nself.__thread = Thread(target=self.__update, name=\"ScreenGear\", args=())\nself.__thread.daemon = True\nself.__thread.start()\nreturn self\n</code></pre>"},{"location":"bonus/reference/screengear/#vidgear.gears.screengear.ScreenGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the resources.</p> Source code in <code>vidgear/gears/screengear.py</code> <pre><code>def stop(self):\n\"\"\"\n    Safely terminates the thread, and release the resources.\n    \"\"\"\nself.__logging and logger.debug(\"Terminating ScreenGear Processes.\")\n# indicate that the thread should be terminate\nself.__terminate.set()\n# wait until stream resources are released (producer thread might be still grabbing frame)\nif self.__thread is not None:\nif not (self.__queue is None):\nwhile not self.__queue.empty():\ntry:\nself.__queue.get_nowait()\nexcept queue.Empty:\ncontinue\nself.__queue.task_done()\nself.__thread.join()\n</code></pre>"},{"location":"bonus/reference/stabilizer/","title":"Stabilizer Class","text":"<p>Stabilizer API usage examples can be found here \u27b6</p> <p>Stabilizer API parameters are explained here \u27b6</p> <p>This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements.</p> <p>The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies heavily on Threaded Queue mode for error-free &amp; ultra-fast frame handling.</p> Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>class Stabilizer:\n\"\"\"\n    This is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense\n    of little to no additional computational requirements.\n    The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses\n    these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies\n    heavily on **Threaded Queue mode** for error-free &amp; ultra-fast frame handling.\n    \"\"\"\ndef __init__(\nself,\nsmoothing_radius=25,\nborder_type=\"black\",\nborder_size=0,\ncrop_n_zoom=False,\nlogging=False,\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the Stabilizer class.\n        Parameters:\n            smoothing_radius (int): alter averaging window size.\n            border_type (str): changes the extended border type.\n            border_size (int): enables and set the value for extended border size to reduce the black borders.\n            crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders.\n            logging (bool): enables/disables logging.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# initialize deques for handling input frames and its indexes\nself.__frame_queue = deque(maxlen=smoothing_radius)\nself.__frame_queue_indexes = deque(maxlen=smoothing_radius)\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\n# define and create Adaptive histogram equalization (AHE) object for optimizations\nself.__clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n# initialize global vars\nself.__smoothing_radius = smoothing_radius  # averaging window, handles the quality of stabilization at expense of latency and sudden panning\nself.__smoothed_path = None  # handles the smoothed path with box filter\nself.__path = None  # handles path i.e cumulative sum of pevious_2_current transformations along a axis\nself.__transforms = []  # handles pevious_2_current transformations [dx,dy,da]\nself.__frame_transforms_smoothed = None  # handles smoothed array of pevious_2_current transformations w.r.t to frames\nself.__previous_gray = None  # handles previous gray frame\nself.__previous_keypoints = (\nNone  # handles previous detect_GFTTed keypoints w.r.t previous gray frame\n)\nself.__frame_height, self.frame_width = (\n0,\n0,\n)  # handles width and height of input frames\nself.__crop_n_zoom = 0  # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable.\n# if check if crop_n_zoom defined\nif crop_n_zoom and border_size:\nself.__crop_n_zoom = border_size  # crops and zoom frame to original size\nself.__border_size = 0  # zero out border size\nself.__frame_size = None  # handles frame size for zooming\nif logging:\nlogger.debug(\"Setting Cropping margin {} pixels\".format(border_size))\nelse:\n# Add output borders to frame\nself.__border_size = border_size\nif self.__logging and border_size:\nlogger.debug(\"Setting Border size {} pixels\".format(border_size))\n# define valid border modes\nborder_modes = {\n\"black\": cv2.BORDER_CONSTANT,\n\"reflect\": cv2.BORDER_REFLECT,\n\"reflect_101\": cv2.BORDER_REFLECT_101,\n\"replicate\": cv2.BORDER_REPLICATE,\n\"wrap\": cv2.BORDER_WRAP,\n}\n# choose valid border_mode from border_type\nif border_type in [\"black\", \"reflect\", \"reflect_101\", \"replicate\", \"wrap\"]:\nif not crop_n_zoom:\n# initialize global border mode variable\nself.__border_mode = border_modes[border_type]\nif self.__logging and border_type != \"black\":\nlogger.debug(\"Setting Border type: {}\".format(border_type))\nelse:\n# log and reset to default\nif self.__logging and border_type != \"black\":\nlogger.debug(\n\"Setting border type is disabled if cropping is enabled!\"\n)\nself.__border_mode = border_modes[\"black\"]\nelse:\n# otherwise log if not\nif logging:\nlogger.debug(\"Invalid input border type!\")\nself.__border_mode = border_modes[\"black\"]  # reset to default mode\n# define OpenCV version\nself.__cv2_version = check_CV_version()\n# retrieve best interpolation\nself.__interpolation = retrieve_best_interpolation(\n[\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n)\n# define normalized box filter\nself.__box_filter = np.ones(smoothing_radius) / smoothing_radius\ndef stabilize(self, frame):\n\"\"\"\n        This method takes an unstabilized video frame, and returns a stabilized one.\n        Parameters:\n            frame (numpy.ndarray): inputs unstabilized video frames.\n        \"\"\"\n# check if frame is None\nif frame is None:\n# return if it does\nreturn\n# save frame size for zooming\nif self.__crop_n_zoom and self.__frame_size == None:\nself.__frame_size = frame.shape[:2]\n# initiate transformations capturing\nif not self.__frame_queue:\n# for first frame\nprevious_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to gray\nprevious_gray = self.__clahe.apply(previous_gray)  # optimize gray frame\nself.__previous_keypoints = cv2.goodFeaturesToTrack(\nprevious_gray,\nmaxCorners=200,\nqualityLevel=0.05,\nminDistance=30.0,\nblockSize=3,\nmask=None,\nuseHarrisDetector=False,\nk=0.04,\n)  # track features using GFTT\nself.__frame_height, self.frame_width = frame.shape[\n:2\n]  # save input frame height and width\nself.__frame_queue.append(frame)  # save frame to deque\nself.__frame_queue_indexes.append(0)  # save frame index to deque\nself.__previous_gray = previous_gray[\n:\n]  # save gray frame clone for further processing\nelif self.__frame_queue_indexes[-1] &lt;= self.__smoothing_radius - 1:\n# for rest of frames\nself.__frame_queue.append(frame)  # save frame to deque\nself.__frame_queue_indexes.append(\nself.__frame_queue_indexes[-1] + 1\n)  # save frame index\nself.__generate_transformations()  # generate transformations\nif self.__frame_queue_indexes[-1] == self.__smoothing_radius - 1:\n# calculate smooth path once transformation capturing is completed\nfor i in range(3):\n# apply normalized box filter to the path\nself.__smoothed_path[:, i] = self.__box_filter_convolve(\n(self.__path[:, i]), window_size=self.__smoothing_radius\n)\n# calculate deviation of path from smoothed path\ndeviation = self.__smoothed_path - self.__path\n# save smoothed transformation\nself.__frame_transforms_smoothed = self.frame_transform + deviation\nelse:\n# start applying transformations\nself.__frame_queue.append(frame)  # save frame to deque\nself.__frame_queue_indexes.append(\nself.__frame_queue_indexes[-1] + 1\n)  # save frame index\nself.__generate_transformations()  # generate transformations\n# calculate smooth path once transformation capturing is completed\nfor i in range(3):\n# apply normalized box filter to the path\nself.__smoothed_path[:, i] = self.__box_filter_convolve(\n(self.__path[:, i]), window_size=self.__smoothing_radius\n)\n# calculate deviation of path from smoothed path\ndeviation = self.__smoothed_path - self.__path\n# save smoothed transformation\nself.__frame_transforms_smoothed = self.frame_transform + deviation\n# return transformation applied stabilized frame\nreturn self.__apply_transformations()\ndef __generate_transformations(self):\n\"\"\"\n        An internal method that generate previous-to-current transformations [dx,dy,da].\n        \"\"\"\nframe_gray = cv2.cvtColor(\nself.__frame_queue[-1], cv2.COLOR_BGR2GRAY\n)  # retrieve current frame and convert to gray\nframe_gray = self.__clahe.apply(frame_gray)  # optimize it\ntransformation = None\ntry:\n# calculate optical flow using Lucas-Kanade differential method\ncurr_kps, status, error = cv2.calcOpticalFlowPyrLK(\nself.__previous_gray, frame_gray, self.__previous_keypoints, None\n)\n# select only valid key-points\nvalid_curr_kps = curr_kps[status == 1]  # current\nvalid_previous_keypoints = self.__previous_keypoints[\nstatus == 1\n]  # previous\n# calculate optimal affine transformation between pevious_2_current key-points\nif self.__cv2_version == 3:\n# backward compatibility with OpenCV3\ntransformation = cv2.estimateRigidTransform(\nvalid_previous_keypoints, valid_curr_kps, False\n)\nelse:\ntransformation = cv2.estimateAffinePartial2D(\nvalid_previous_keypoints, valid_curr_kps\n)[0]\nexcept cv2.error as e:\n# catch any OpenCV assertion errors and warn user\nlogger.warning(\"Video-Frame is too dark to generate any transformations!\")\ntransformation = None\n# check if transformation is not None\nif not (transformation is None):\n# pevious_2_current translation in x direction\ndx = transformation[0, 2]\n# pevious_2_current translation in y direction\ndy = transformation[1, 2]\n# pevious_2_current rotation in angle\nda = np.arctan2(transformation[1, 0], transformation[0, 0])\nelse:\n# otherwise zero it\ndx = dy = da = 0\n# save this transformation\nself.__transforms.append([dx, dy, da])\n# calculate path from cumulative transformations sum\nself.frame_transform = np.array(self.__transforms, dtype=\"float32\")\nself.__path = np.cumsum(self.frame_transform, axis=0)\n# create smoothed path from a copy of path\nself.__smoothed_path = np.copy(self.__path)\n# re-calculate and save GFTT key-points for current gray frame\nself.__previous_keypoints = cv2.goodFeaturesToTrack(\nframe_gray,\nmaxCorners=200,\nqualityLevel=0.05,\nminDistance=30.0,\nblockSize=3,\nmask=None,\nuseHarrisDetector=False,\nk=0.04,\n)\n# save this gray frame for further processing\nself.__previous_gray = frame_gray[:]\ndef __box_filter_convolve(self, path, window_size):\n\"\"\"\n        An internal method that applies *normalized linear box filter* to path w.r.t averaging window\n        Parameters:\n        * path (numpy.ndarray): a cumulative sum of transformations\n        * window_size (int): averaging window size\n        \"\"\"\n# pad path to size of averaging window\npath_padded = np.pad(path, (window_size, window_size), \"median\")\n# apply linear box filter to path\npath_smoothed = np.convolve(path_padded, self.__box_filter, mode=\"same\")\n# crop the smoothed path to original path\npath_smoothed = path_smoothed[window_size:-window_size]\n# assert if cropping is completed\nassert path.shape == path_smoothed.shape\n# return smoothed path\nreturn path_smoothed\ndef __apply_transformations(self):\n\"\"\"\n        An internal method that applies affine transformation to the given frame\n        from previously calculated transformations\n        \"\"\"\n# extract frame and its index from deque\nqueue_frame = self.__frame_queue.popleft()\nqueue_frame_index = self.__frame_queue_indexes.popleft()\n# create border around extracted frame w.r.t border_size\nbordered_frame = cv2.copyMakeBorder(\nqueue_frame,\ntop=self.__border_size,\nbottom=self.__border_size,\nleft=self.__border_size,\nright=self.__border_size,\nborderType=self.__border_mode,\nvalue=[0, 0, 0],\n)\nalpha_bordered_frame = cv2.cvtColor(\nbordered_frame, cv2.COLOR_BGR2BGRA\n)  # create alpha channel\n# extract alpha channel\nalpha_bordered_frame[:, :, 3] = 0\nalpha_bordered_frame[\nself.__border_size : self.__border_size + self.__frame_height,\nself.__border_size : self.__border_size + self.frame_width,\n3,\n] = 255\n# extracting Transformations w.r.t frame index\ndx = self.__frame_transforms_smoothed[queue_frame_index, 0]  # x-axis\ndy = self.__frame_transforms_smoothed[queue_frame_index, 1]  # y-axis\nda = self.__frame_transforms_smoothed[queue_frame_index, 2]  # angle\n# building 2x3 transformation matrix from extracted transformations\nqueue_frame_transform = np.zeros((2, 3), np.float32)\nqueue_frame_transform[0, 0] = np.cos(da)\nqueue_frame_transform[0, 1] = -np.sin(da)\nqueue_frame_transform[1, 0] = np.sin(da)\nqueue_frame_transform[1, 1] = np.cos(da)\nqueue_frame_transform[0, 2] = dx\nqueue_frame_transform[1, 2] = dy\n# Applying an affine transformation to the frame\nframe_wrapped = cv2.warpAffine(\nalpha_bordered_frame,\nqueue_frame_transform,\nalpha_bordered_frame.shape[:2][::-1],\nborderMode=self.__border_mode,\n)\n# drop alpha channel\nframe_stabilized = frame_wrapped[:, :, :3]\n# crop and zoom\nif self.__crop_n_zoom:\n# crop stabilized frame\nframe_cropped = frame_stabilized[\nself.__crop_n_zoom : -self.__crop_n_zoom,\nself.__crop_n_zoom : -self.__crop_n_zoom,\n]\n# zoom stabilized frame\nframe_stabilized = cv2.resize(\nframe_cropped,\nself.__frame_size[::-1],\ninterpolation=self.__interpolation,\n)\n# finally return stabilized frame\nreturn frame_stabilized\ndef clean(self):\n\"\"\"\n        Cleans Stabilizer resources\n        \"\"\"\n# check if deque present\nif self.__frame_queue:\n# clear frame deque\nself.__frame_queue.clear()\n# clear frame indexes deque\nself.__frame_queue_indexes.clear()\n</code></pre> <p> </p>"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.__init__","title":"<code>__init__(self, smoothing_radius=25, border_type='black', border_size=0, crop_n_zoom=False, logging=False)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the Stabilizer class.</p> <p>Parameters:</p> Name Type Description Default <code>smoothing_radius</code> <code>int</code> <p>alter averaging window size.</p> <code>25</code> <code>border_type</code> <code>str</code> <p>changes the extended border type.</p> <code>'black'</code> <code>border_size</code> <code>int</code> <p>enables and set the value for extended border size to reduce the black borders.</p> <code>0</code> <code>crop_n_zoom</code> <code>bool</code> <p>enables croping and zooming of frames(to original size) to reduce the black borders.</p> <code>False</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>def __init__(\nself,\nsmoothing_radius=25,\nborder_type=\"black\",\nborder_size=0,\ncrop_n_zoom=False,\nlogging=False,\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the Stabilizer class.\n    Parameters:\n        smoothing_radius (int): alter averaging window size.\n        border_type (str): changes the extended border type.\n        border_size (int): enables and set the value for extended border size to reduce the black borders.\n        crop_n_zoom (bool): enables croping and zooming of frames(to original size) to reduce the black borders.\n        logging (bool): enables/disables logging.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# initialize deques for handling input frames and its indexes\nself.__frame_queue = deque(maxlen=smoothing_radius)\nself.__frame_queue_indexes = deque(maxlen=smoothing_radius)\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\n# define and create Adaptive histogram equalization (AHE) object for optimizations\nself.__clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n# initialize global vars\nself.__smoothing_radius = smoothing_radius  # averaging window, handles the quality of stabilization at expense of latency and sudden panning\nself.__smoothed_path = None  # handles the smoothed path with box filter\nself.__path = None  # handles path i.e cumulative sum of pevious_2_current transformations along a axis\nself.__transforms = []  # handles pevious_2_current transformations [dx,dy,da]\nself.__frame_transforms_smoothed = None  # handles smoothed array of pevious_2_current transformations w.r.t to frames\nself.__previous_gray = None  # handles previous gray frame\nself.__previous_keypoints = (\nNone  # handles previous detect_GFTTed keypoints w.r.t previous gray frame\n)\nself.__frame_height, self.frame_width = (\n0,\n0,\n)  # handles width and height of input frames\nself.__crop_n_zoom = 0  # handles cropping and zooms frames to reduce the black borders from stabilization being too noticeable.\n# if check if crop_n_zoom defined\nif crop_n_zoom and border_size:\nself.__crop_n_zoom = border_size  # crops and zoom frame to original size\nself.__border_size = 0  # zero out border size\nself.__frame_size = None  # handles frame size for zooming\nif logging:\nlogger.debug(\"Setting Cropping margin {} pixels\".format(border_size))\nelse:\n# Add output borders to frame\nself.__border_size = border_size\nif self.__logging and border_size:\nlogger.debug(\"Setting Border size {} pixels\".format(border_size))\n# define valid border modes\nborder_modes = {\n\"black\": cv2.BORDER_CONSTANT,\n\"reflect\": cv2.BORDER_REFLECT,\n\"reflect_101\": cv2.BORDER_REFLECT_101,\n\"replicate\": cv2.BORDER_REPLICATE,\n\"wrap\": cv2.BORDER_WRAP,\n}\n# choose valid border_mode from border_type\nif border_type in [\"black\", \"reflect\", \"reflect_101\", \"replicate\", \"wrap\"]:\nif not crop_n_zoom:\n# initialize global border mode variable\nself.__border_mode = border_modes[border_type]\nif self.__logging and border_type != \"black\":\nlogger.debug(\"Setting Border type: {}\".format(border_type))\nelse:\n# log and reset to default\nif self.__logging and border_type != \"black\":\nlogger.debug(\n\"Setting border type is disabled if cropping is enabled!\"\n)\nself.__border_mode = border_modes[\"black\"]\nelse:\n# otherwise log if not\nif logging:\nlogger.debug(\"Invalid input border type!\")\nself.__border_mode = border_modes[\"black\"]  # reset to default mode\n# define OpenCV version\nself.__cv2_version = check_CV_version()\n# retrieve best interpolation\nself.__interpolation = retrieve_best_interpolation(\n[\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n)\n# define normalized box filter\nself.__box_filter = np.ones(smoothing_radius) / smoothing_radius\n</code></pre>"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.clean","title":"<code>clean(self)</code>","text":"<p>Cleans Stabilizer resources</p> Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>def clean(self):\n\"\"\"\n    Cleans Stabilizer resources\n    \"\"\"\n# check if deque present\nif self.__frame_queue:\n# clear frame deque\nself.__frame_queue.clear()\n# clear frame indexes deque\nself.__frame_queue_indexes.clear()\n</code></pre>"},{"location":"bonus/reference/stabilizer/#vidgear.gears.stabilizer.Stabilizer.stabilize","title":"<code>stabilize(self, frame)</code>","text":"<p>This method takes an unstabilized video frame, and returns a stabilized one.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>numpy.ndarray</code> <p>inputs unstabilized video frames.</p> required Source code in <code>vidgear/gears/stabilizer.py</code> <pre><code>def stabilize(self, frame):\n\"\"\"\n    This method takes an unstabilized video frame, and returns a stabilized one.\n    Parameters:\n        frame (numpy.ndarray): inputs unstabilized video frames.\n    \"\"\"\n# check if frame is None\nif frame is None:\n# return if it does\nreturn\n# save frame size for zooming\nif self.__crop_n_zoom and self.__frame_size == None:\nself.__frame_size = frame.shape[:2]\n# initiate transformations capturing\nif not self.__frame_queue:\n# for first frame\nprevious_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to gray\nprevious_gray = self.__clahe.apply(previous_gray)  # optimize gray frame\nself.__previous_keypoints = cv2.goodFeaturesToTrack(\nprevious_gray,\nmaxCorners=200,\nqualityLevel=0.05,\nminDistance=30.0,\nblockSize=3,\nmask=None,\nuseHarrisDetector=False,\nk=0.04,\n)  # track features using GFTT\nself.__frame_height, self.frame_width = frame.shape[\n:2\n]  # save input frame height and width\nself.__frame_queue.append(frame)  # save frame to deque\nself.__frame_queue_indexes.append(0)  # save frame index to deque\nself.__previous_gray = previous_gray[\n:\n]  # save gray frame clone for further processing\nelif self.__frame_queue_indexes[-1] &lt;= self.__smoothing_radius - 1:\n# for rest of frames\nself.__frame_queue.append(frame)  # save frame to deque\nself.__frame_queue_indexes.append(\nself.__frame_queue_indexes[-1] + 1\n)  # save frame index\nself.__generate_transformations()  # generate transformations\nif self.__frame_queue_indexes[-1] == self.__smoothing_radius - 1:\n# calculate smooth path once transformation capturing is completed\nfor i in range(3):\n# apply normalized box filter to the path\nself.__smoothed_path[:, i] = self.__box_filter_convolve(\n(self.__path[:, i]), window_size=self.__smoothing_radius\n)\n# calculate deviation of path from smoothed path\ndeviation = self.__smoothed_path - self.__path\n# save smoothed transformation\nself.__frame_transforms_smoothed = self.frame_transform + deviation\nelse:\n# start applying transformations\nself.__frame_queue.append(frame)  # save frame to deque\nself.__frame_queue_indexes.append(\nself.__frame_queue_indexes[-1] + 1\n)  # save frame index\nself.__generate_transformations()  # generate transformations\n# calculate smooth path once transformation capturing is completed\nfor i in range(3):\n# apply normalized box filter to the path\nself.__smoothed_path[:, i] = self.__box_filter_convolve(\n(self.__path[:, i]), window_size=self.__smoothing_radius\n)\n# calculate deviation of path from smoothed path\ndeviation = self.__smoothed_path - self.__path\n# save smoothed transformation\nself.__frame_transforms_smoothed = self.frame_transform + deviation\n# return transformation applied stabilized frame\nreturn self.__apply_transformations()\n</code></pre>"},{"location":"bonus/reference/streamgear/","title":"StreamGear API","text":"<p>StreamGear API usage examples for: Single-Source Mode \u27b6 and Real-time Frames Mode \u27b6</p> <p>StreamGear API parameters are explained here \u27b6</p> <p>StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH and HLS) in just few lines of python code. StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content.</p> <p>SteamGear easily transcodes source videos/audio files &amp; real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of suitable length. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests.</p> <p>SteamGear also creates a Manifest/Playlist file (such as MPD in-case of DASH and M3U8 in-case of HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates)  and is provided to the client before the streaming session.</p> <p>SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP live streaming).</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>class StreamGear:\n\"\"\"\n    StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH and HLS) in just few lines of python code.\n    StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content.\n    SteamGear easily transcodes source videos/audio files &amp; real-time video-frames and breaks them into a sequence of multiple smaller chunks/segments of suitable length. These segments make it\n    possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth\n    permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests.\n    SteamGear also creates a Manifest/Playlist file (such as MPD in-case of DASH and M3U8 in-case of HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates)\n     and is provided to the client before the streaming session.\n    SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) and Apple HLS (HTTP live streaming).\n    \"\"\"\ndef __init__(\nself, output=\"\", format=\"dash\", custom_ffmpeg=\"\", logging=False, **stream_params\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the StreamGear class.\n        Parameters:\n            output (str): sets the valid filename/path for storing the StreamGear assets.\n            format (str): select the adaptive HTTP streaming format(DASH and HLS).\n            custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n            logging (bool): enables/disables logging.\n            stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# checks if machine in-use is running windows os or not\nself.__os_windows = True if os.name == \"nt\" else False\n# enable logging if specified\nself.__logging = logging if (logging and isinstance(logging, bool)) else False\n# initialize various class variables\n# handles user-defined parameters\nself.__params = {}\n# handle input video/frame resolution and channels\nself.__inputheight = None\nself.__inputwidth = None\nself.__inputchannels = None\nself.__sourceframerate = None\n# handle process to be frames written\nself.__process = None\n# handle valid FFmpeg assets location\nself.__ffmpeg = \"\"\n# handle one time process for valid process initialization\nself.__initiate_stream = True\n# cleans and reformat user-defined parameters\nself.__params = {\nstr(k).strip(): str(v).strip()\nif not isinstance(v, (dict, list, int, float))\nelse v\nfor k, v in stream_params.items()\n}\n# handle where to save the downloaded FFmpeg Static assets on Windows(if specified)\n__ffmpeg_download_path = self.__params.pop(\"-ffmpeg_download_path\", \"\")\nif not isinstance(__ffmpeg_download_path, (str)):\n# reset improper values\n__ffmpeg_download_path = \"\"\n# validate the FFmpeg assets and return location (also downloads static assets on windows)\nself.__ffmpeg = get_valid_ffmpeg_path(\nstr(custom_ffmpeg),\nself.__os_windows,\nffmpeg_download_path=__ffmpeg_download_path,\nlogging=self.__logging,\n)\n# check if valid FFmpeg path returned\nif self.__ffmpeg:\nself.__logging and logger.debug(\n\"Found valid FFmpeg executables: `{}`.\".format(self.__ffmpeg)\n)\nelse:\n# else raise error\nraise RuntimeError(\n\"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\"\n)\n# handle Audio-Input\naudio = self.__params.pop(\"-audio\", \"\")\nif audio and isinstance(audio, str):\nif os.path.isfile(audio):\nself.__audio = os.path.abspath(audio)\nelif is_valid_url(self.__ffmpeg, url=audio, logging=self.__logging):\nself.__audio = audio\nelse:\nself.__audio = \"\"\nelif audio and isinstance(audio, list):\nself.__audio = audio\nelse:\nself.__audio = \"\"\nif self.__audio and self.__logging:\nlogger.debug(\"External audio source detected!\")\n# handle Video-Source input\nsource = self.__params.pop(\"-video_source\", \"\")\n# Check if input is valid string\nif source and isinstance(source, str) and len(source) &gt; 1:\n# Differentiate input\nif os.path.isfile(source):\nself.__video_source = os.path.abspath(source)\nelif is_valid_url(self.__ffmpeg, url=source, logging=self.__logging):\nself.__video_source = source\nelse:\n# discard the value otherwise\nself.__video_source = \"\"\n# Validate input\nif self.__video_source:\nvalidation_results = validate_video(\nself.__ffmpeg, video_path=self.__video_source\n)\nassert not (\nvalidation_results is None\n), \"[StreamGear:ERROR] :: Given `{}` video_source is Invalid, Check Again!\".format(\nself.__video_source\n)\nself.__aspect_source = validation_results[\"resolution\"]\nself.__fps_source = validation_results[\"framerate\"]\n# log it\nself.__logging and logger.debug(\n\"Given video_source is valid and has {}x{} resolution, and a framerate of {} fps.\".format(\nself.__aspect_source[0],\nself.__aspect_source[1],\nself.__fps_source,\n)\n)\nelse:\nlogger.warning(\"No valid video_source provided.\")\nelse:\n# discard the value otherwise\nself.__video_source = \"\"\n# handle user-defined framerate\nself.__inputframerate = self.__params.pop(\"-input_framerate\", 0.0)\nif isinstance(self.__inputframerate, (float, int)):\n# must be float\nself.__inputframerate = float(self.__inputframerate)\nelse:\n# reset improper values\nself.__inputframerate = 0.0\n# handle old assests\nself.__clear_assets = self.__params.pop(\"-clear_prev_assets\", False)\nif not isinstance(self.__clear_assets, bool):\n# reset improper values\nself.__clear_assets = False\n# handle whether to livestream?\nself.__livestreaming = self.__params.pop(\"-livestream\", False)\nif not isinstance(self.__livestreaming, bool):\n# reset improper values\nself.__livestreaming = False\n# handle Streaming formats\nsupported_formats = [\"dash\", \"hls\"]  # will be extended in future\n# Validate\nif not (format is None) and format and isinstance(format, str):\n_format = format.strip().lower()\nif _format in supported_formats:\nself.__format = _format\nlogger.info(\n\"StreamGear will generate files for {} HTTP streaming format.\".format(\nself.__format.upper()\n)\n)\nelif difflib.get_close_matches(_format, supported_formats):\nraise ValueError(\n\"[StreamGear:ERROR] :: Incorrect format! Did you mean `{}`?\".format(\ndifflib.get_close_matches(_format, supported_formats)[0]\n)\n)\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: format value `{}` not valid/supported!\".format(\nformat\n)\n)\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: format value is Missing/Incorrect. Check vidgear docs!\"\n)\n# handles output name\nif not output:\nraise ValueError(\n\"[StreamGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more information.\"\n)\nelse:\n# validate this class has the access rights to specified directory or not\nabs_path = os.path.abspath(output)\nif check_WriteAccess(\nos.path.dirname(abs_path),\nis_windows=self.__os_windows,\nlogging=self.__logging,\n):\n# check if given path is directory\nvalid_extension = \"mpd\" if self.__format == \"dash\" else \"m3u8\"\n# get all assets extensions\nassets_exts = [\n(\"chunk-stream\", \".m4s\"),  # filename prefix, extension\n(\"chunk-stream\", \".ts\"),  # filename prefix, extension\n\".{}\".format(valid_extension),\n]\n# add source file extension too\nif self.__video_source:\nassets_exts.append(\n(\n\"chunk-stream\",\nos.path.splitext(self.__video_source)[1],\n)  # filename prefix, extension\n)\nif os.path.isdir(abs_path):\nif self.__clear_assets:\ndelete_ext_safe(abs_path, assets_exts, logging=self.__logging)\nabs_path = os.path.join(\nabs_path,\n\"{}-{}.{}\".format(\nself.__format,\ntime.strftime(\"%Y%m%d-%H%M%S\"),\nvalid_extension,\n),\n)  # auto-assign valid name and adds it to path\nelif self.__clear_assets and os.path.isfile(abs_path):\ndelete_ext_safe(\nos.path.dirname(abs_path),\nassets_exts,\nlogging=self.__logging,\n)\n# check if path has valid file extension\nassert abs_path.endswith(\nvalid_extension\n), \"Given `{}` path has invalid file-extension w.r.t selected format: `{}`!\".format(\noutput, self.__format.upper()\n)\nself.__logging and logger.debug(\n\"Path:`{}` is sucessfully configured for streaming.\".format(\nabs_path\n)\n)\n# assign it\nself.__out_file = abs_path.replace(\n\"\\\\\", \"/\"\n)  # workaround for Windows platform only, others will not be affected\nelif platform.system() == \"Linux\" and pathlib.Path(output).is_char_device():\n# check if linux video device path (such as `/dev/video0`)\nself.__logging and logger.debug(\n\"Path:`{}` is a valid Linux Video Device path.\".format(output)\n)\nself.__out_file = output\n# check if given output is a valid URL\nelif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\nself.__logging and logger.debug(\n\"URL:`{}` is valid and sucessfully configured for streaming.\".format(\noutput\n)\n)\nself.__out_file = output\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: Output value:`{}` is not valid/supported!\".format(\noutput\n)\n)\n# log Mode of operation\nlogger.info(\n\"StreamGear has been successfully configured for {} Mode.\".format(\n\"Single-Source\" if self.__video_source else \"Real-time Frames\"\n)\n)\ndef stream(self, frame, rgb_mode=False):\n\"\"\"\n        Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets.\n        Parameters:\n            frame (ndarray): a valid numpy frame\n            rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_.\n        \"\"\"\n# check if function is called in correct context\nif self.__video_source:\nraise RuntimeError(\n\"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\"\n)\n# None-Type frames will be skipped\nif frame is None:\nreturn\n# extract height, width and number of channels of frame\nheight, width = frame.shape[:2]\nchannels = frame.shape[-1] if frame.ndim == 3 else 1\n# assign values to class variables on first run\nif self.__initiate_stream:\nself.__inputheight = height\nself.__inputwidth = width\nself.__inputchannels = channels\nself.__sourceframerate = (\n25.0 if not (self.__inputframerate) else self.__inputframerate\n)\nself.__logging and logger.debug(\n\"InputFrame =&gt; Height:{} Width:{} Channels:{}\".format(\nself.__inputheight, self.__inputwidth, self.__inputchannels\n)\n)\n# validate size of frame\nif height != self.__inputheight or width != self.__inputwidth:\nraise ValueError(\"[StreamGear:ERROR] :: All frames must have same size!\")\n# validate number of channels\nif channels != self.__inputchannels:\nraise ValueError(\n\"[StreamGear:ERROR] :: All frames must have same number of channels!\"\n)\n# initiate FFmpeg process on first run\nif self.__initiate_stream:\n# launch pre-processing\nself.__PreProcess(channels=channels, rgb=rgb_mode)\n# Check status of the process\nassert self.__process is not None\n# write the frame to pipeline\ntry:\nself.__process.stdin.write(frame.tobytes())\nexcept (OSError, IOError):\n# log something is wrong!\nlogger.error(\n\"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\"\n)\nraise ValueError  # for testing purpose only\ndef transcode_source(self):\n\"\"\"\n        Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets\n        \"\"\"\n# check if function is called in correct context\nif not (self.__video_source):\nraise RuntimeError(\n\"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\"\n)\n# assign height, width and framerate\nself.__inputheight = int(self.__aspect_source[1])\nself.__inputwidth = int(self.__aspect_source[0])\nself.__sourceframerate = float(self.__fps_source)\n# launch pre-processing\nself.__PreProcess()\ndef __PreProcess(self, channels=0, rgb=False):\n\"\"\"\n        Internal method that pre-processes default FFmpeg parameters before beginning pipelining.\n        Parameters:\n            channels (int): Number of channels\n            rgb_mode (boolean): activates RGB mode _(if enabled)_.\n        \"\"\"\n# turn off initiate flag\nself.__initiate_stream = False\n# initialize parameters\ninput_parameters = OrderedDict()\noutput_parameters = OrderedDict()\n# pre-assign default codec parameters (if not assigned by user).\ndefault_codec = \"libx264rgb\" if rgb else \"libx264\"\noutput_parameters[\"-vcodec\"] = self.__params.pop(\"-vcodec\", default_codec)\n# enable optimizations and enforce compatibility\noutput_parameters[\"-vf\"] = self.__params.pop(\"-vf\", \"format=yuv420p\")\naspect_ratio = Fraction(\nself.__inputwidth / self.__inputheight\n).limit_denominator(10)\noutput_parameters[\"-aspect\"] = \":\".join(str(aspect_ratio).split(\"/\"))\n# w.r.t selected codec\nif output_parameters[\"-vcodec\"] in [\n\"libx264\",\n\"libx264rgb\",\n\"libx265\",\n\"libvpx-vp9\",\n]:\noutput_parameters[\"-crf\"] = self.__params.pop(\"-crf\", \"20\")\nif output_parameters[\"-vcodec\"] in [\"libx264\", \"libx264rgb\"]:\nif not (self.__video_source):\noutput_parameters[\"-profile:v\"] = self.__params.pop(\n\"-profile:v\", \"high\"\n)\noutput_parameters[\"-tune\"] = self.__params.pop(\"-tune\", \"zerolatency\")\noutput_parameters[\"-preset\"] = self.__params.pop(\"-preset\", \"veryfast\")\nif output_parameters[\"-vcodec\"] == \"libx265\":\noutput_parameters[\"-x265-params\"] = self.__params.pop(\n\"-x265-params\", \"lossless=1\"\n)\n# enable audio (if present)\nif self.__audio:\n# validate audio source\nbitrate = validate_audio(self.__ffmpeg, source=self.__audio)\nif bitrate:\nlogger.info(\n\"Detected External Audio Source is valid, and will be used for streams.\"\n)\n# assign audio source\noutput_parameters[\n\"{}\".format(\n\"-core_asource\" if isinstance(self.__audio, list) else \"-i\"\n)\n] = self.__audio\n# assign audio codec\noutput_parameters[\"-acodec\"] = self.__params.pop(\n\"-acodec\", \"aac\" if isinstance(self.__audio, list) else \"copy\"\n)\noutput_parameters[\"a_bitrate\"] = bitrate  # temporary handler\noutput_parameters[\"-core_audio\"] = (\n[\"-map\", \"1:a:0\"] if self.__format == \"dash\" else []\n)\nelse:\nlogger.warning(\n\"Audio source `{}` is not valid, Skipped!\".format(self.__audio)\n)\nelif self.__video_source:\n# validate audio source\nbitrate = validate_audio(self.__ffmpeg, source=self.__video_source)\nif bitrate:\nlogger.info(\"Source Audio will be used for streams.\")\n# assign audio codec\noutput_parameters[\"-acodec\"] = (\n\"aac\" if self.__format == \"hls\" else \"copy\"\n)\noutput_parameters[\"a_bitrate\"] = bitrate  # temporary handler\nelse:\nlogger.warning(\n\"No valid audio_source available. Disabling audio for streams!\"\n)\nelse:\nlogger.warning(\n\"No valid audio_source provided. Disabling audio for streams!\"\n)\n# enable audio optimizations based on audio codec\nif \"-acodec\" in output_parameters and output_parameters[\"-acodec\"] == \"aac\":\noutput_parameters[\"-movflags\"] = \"+faststart\"\n# set input framerate\nif self.__sourceframerate &gt; 0 and not (self.__video_source):\n# set input framerate\nself.__logging and logger.debug(\n\"Setting Input framerate: {}\".format(self.__sourceframerate)\n)\ninput_parameters[\"-framerate\"] = str(self.__sourceframerate)\n# handle input resolution and pixel format\nif not (self.__video_source):\ndimensions = \"{}x{}\".format(self.__inputwidth, self.__inputheight)\ninput_parameters[\"-video_size\"] = str(dimensions)\n# handles pix_fmt based on channels(HACK)\nif channels == 1:\ninput_parameters[\"-pix_fmt\"] = \"gray\"\nelif channels == 2:\ninput_parameters[\"-pix_fmt\"] = \"ya8\"\nelif channels == 3:\ninput_parameters[\"-pix_fmt\"] = \"rgb24\" if rgb else \"bgr24\"\nelif channels == 4:\ninput_parameters[\"-pix_fmt\"] = \"rgba\" if rgb else \"bgra\"\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\"\n)\n# process assigned format parameters\nprocess_params = self.__handle_streams(\ninput_params=input_parameters, output_params=output_parameters\n)\n# check if processing completed successfully\nassert not (\nprocess_params is None\n), \"[StreamGear:ERROR] :: {} stream cannot be initiated!\".format(\nself.__format.upper()\n)\n# Finally start FFmpef pipline and process everything\nself.__Build_n_Execute(process_params[0], process_params[1])\ndef __handle_streams(self, input_params, output_params):\n\"\"\"\n        An internal function that parses various streams and its parameters.\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# handle bit-per-pixels\nbpp = self.__params.pop(\"-bpp\", 0.1000)\nif isinstance(bpp, (float, int)) and bpp &gt; 0.0:\nbpp = float(bpp) if (bpp &gt; 0.001) else 0.1000\nelse:\n# reset to defaut if invalid\nbpp = 0.1000\n# log it\nself.__logging and logger.debug(\n\"Setting bit-per-pixels: {} for this stream.\".format(bpp)\n)\n# handle gop\ngop = self.__params.pop(\"-gop\", 0)\nif isinstance(gop, (int, float)) and gop &gt; 0:\ngop = int(gop)\nelse:\n# reset to some recommended value\ngop = 2 * int(self.__sourceframerate)\n# log it\nself.__logging and logger.debug(\"Setting GOP: {} for this stream.\".format(gop))\n# define and map default stream\nif self.__format != \"hls\":\noutput_params[\"-map\"] = 0\nelse:\noutput_params[\"-corev0\"] = [\"-map\", \"0:v\"]\nif \"-acodec\" in output_params:\noutput_params[\"-corea0\"] = [\n\"-map\",\n\"{}:a\".format(1 if \"-core_audio\" in output_params else 0),\n]\n# assign resolution\nif \"-s:v:0\" in self.__params:\n# prevent duplicates\ndel self.__params[\"-s:v:0\"]\noutput_params[\"-s:v:0\"] = \"{}x{}\".format(self.__inputwidth, self.__inputheight)\n# assign video-bitrate\nif \"-b:v:0\" in self.__params:\n# prevent duplicates\ndel self.__params[\"-b:v:0\"]\noutput_params[\"-b:v:0\"] = (\nstr(\nget_video_bitrate(\nint(self.__inputwidth),\nint(self.__inputheight),\nself.__sourceframerate,\nbpp,\n)\n)\n+ \"k\"\n)\n# assign audio-bitrate\nif \"-b:a:0\" in self.__params:\n# prevent duplicates\ndel self.__params[\"-b:a:0\"]\n# extract audio-bitrate from temporary handler\na_bitrate = output_params.pop(\"a_bitrate\", \"\")\nif \"-acodec\" in output_params and a_bitrate:\noutput_params[\"-b:a:0\"] = a_bitrate\n# handle user-defined streams\nstreams = self.__params.pop(\"-streams\", {})\noutput_params = self.__evaluate_streams(streams, output_params, bpp)\n# define additional stream optimization parameters\nif output_params[\"-vcodec\"] in [\"libx264\", \"libx264rgb\"]:\nif not \"-bf\" in self.__params:\noutput_params[\"-bf\"] = 1\nif not \"-sc_threshold\" in self.__params:\noutput_params[\"-sc_threshold\"] = 0\nif not \"-keyint_min\" in self.__params:\noutput_params[\"-keyint_min\"] = gop\nif output_params[\"-vcodec\"] in [\"libx264\", \"libx264rgb\", \"libvpx-vp9\"]:\nif not \"-g\" in self.__params:\noutput_params[\"-g\"] = gop\nif output_params[\"-vcodec\"] == \"libx265\":\noutput_params[\"-core_x265\"] = [\n\"-x265-params\",\n\"keyint={}:min-keyint={}\".format(gop, gop),\n]\n# process given dash/hls stream\nprocessed_params = None\nif self.__format == \"dash\":\nprocessed_params = self.__generate_dash_stream(\ninput_params=input_params,\noutput_params=output_params,\n)\nelse:\nprocessed_params = self.__generate_hls_stream(\ninput_params=input_params,\noutput_params=output_params,\n)\nreturn processed_params\ndef __evaluate_streams(self, streams, output_params, bpp):\n\"\"\"\n        Internal function that Extracts, Evaluates &amp; Validates user-defined streams\n        Parameters:\n            streams (dict): Indivisual streams formatted as list of dict.\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# temporary streams count variable\noutput_params[\"stream_count\"] = 1  # default is 1\n# check if streams are empty\nif not streams:\nlogger.warning(\"No `-streams` are provided!\")\nreturn output_params\n# check if streams are valid\nif isinstance(streams, list) and all(isinstance(x, dict) for x in streams):\nstream_count = 1  # keep track of streams\n# calculate source aspect-ratio\nsource_aspect_ratio = self.__inputwidth / self.__inputheight\n# log the process\nself.__logging and logger.debug(\n\"Processing {} streams.\".format(len(streams))\n)\n# iterate over given streams\nfor stream in streams:\nstream_copy = stream.copy()  # make copy\nintermediate_dict = {}  # handles intermediate stream data as dictionary\n# define and map stream to intermediate dict\nif self.__format != \"hls\":\nintermediate_dict[\"-core{}\".format(stream_count)] = [\"-map\", \"0\"]\nelse:\nintermediate_dict[\"-corev{}\".format(stream_count)] = [\"-map\", \"0:v\"]\nif \"-acodec\" in output_params:\nintermediate_dict[\"-corea{}\".format(stream_count)] = [\n\"-map\",\n\"{}:a\".format(1 if \"-core_audio\" in output_params else 0),\n]\n# extract resolution &amp; indivisual dimension of stream\nresolution = stream.pop(\"-resolution\", \"\")\ndimensions = (\nresolution.lower().split(\"x\")\nif (resolution and isinstance(resolution, str))\nelse []\n)\n# validate resolution\nif (\nlen(dimensions) == 2\nand dimensions[0].isnumeric()\nand dimensions[1].isnumeric()\n):\n# verify resolution is w.r.t source aspect-ratio\nexpected_width = math.floor(\nint(dimensions[1]) * source_aspect_ratio\n)\nif int(dimensions[0]) != expected_width:\nlogger.warning(\n\"Given stream resolution `{}` is not in accordance with the Source Aspect-Ratio. Stream Output may appear Distorted!\".format(\nresolution\n)\n)\n# assign stream resolution to intermediate dict\nintermediate_dict[\"-s:v:{}\".format(stream_count)] = resolution\nelse:\n# otherwise log error and skip stream\nlogger.error(\n\"Missing `-resolution` value, Stream `{}` Skipped!\".format(\nstream_copy\n)\n)\ncontinue\n# verify given stream video-bitrate\nvideo_bitrate = stream.pop(\"-video_bitrate\", \"\")\nif (\nvideo_bitrate\nand isinstance(video_bitrate, str)\nand video_bitrate.endswith((\"k\", \"M\"))\n):\n# assign it\nintermediate_dict[\"-b:v:{}\".format(stream_count)] = video_bitrate\nelse:\n# otherwise calculate video-bitrate\nfps = stream.pop(\"-framerate\", 0.0)\nif dimensions and isinstance(fps, (float, int)) and fps &gt; 0:\nintermediate_dict[\n\"-b:v:{}\".format(stream_count)\n] = \"{}k\".format(\nget_video_bitrate(\nint(dimensions[0]), int(dimensions[1]), fps, bpp\n)\n)\nelse:\n# If everything fails, log and skip the stream!\nlogger.error(\n\"Unable to determine Video-Bitrate for the stream `{}`, Skipped!\".format(\nstream_copy\n)\n)\ncontinue\n# verify given stream audio-bitrate\naudio_bitrate = stream.pop(\"-audio_bitrate\", \"\")\nif \"-acodec\" in output_params:\nif audio_bitrate and audio_bitrate.endswith((\"k\", \"M\")):\nintermediate_dict[\n\"-b:a:{}\".format(stream_count)\n] = audio_bitrate\nelse:\n# otherwise calculate audio-bitrate\nif dimensions:\naspect_width = int(dimensions[0])\nintermediate_dict[\n\"-b:a:{}\".format(stream_count)\n] = \"{}k\".format(128 if (aspect_width &gt; 800) else 96)\n# update output parameters\noutput_params.update(intermediate_dict)\n# clear intermediate dict\nintermediate_dict.clear()\n# clear stream copy\nstream_copy.clear()\n# increment to next stream\nstream_count += 1\noutput_params[\"stream_count\"] = stream_count\nself.__logging and logger.debug(\"All streams processed successfully!\")\nelse:\nlogger.warning(\"Invalid type `-streams` skipped!\")\nreturn output_params\ndef __generate_hls_stream(self, input_params, output_params):\n\"\"\"\n        An internal function that parses user-defined parameters and generates\n        suitable FFmpeg Terminal Command for transcoding input into HLS Stream.\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# Check if live-streaming or not?\n# validate `hls_segment_type`\ndefault_hls_segment_type = self.__params.pop(\"-hls_segment_type\", \"mpegts\")\nif isinstance(\ndefault_hls_segment_type, str\n) and default_hls_segment_type.strip() in [\"fmp4\", \"mpegts\"]:\noutput_params[\"-hls_segment_type\"] = default_hls_segment_type.strip()\nelse:\noutput_params[\"-hls_segment_type\"] = \"mpegts\"\n# gather required parameters\nif self.__livestreaming:\n# `hls_list_size` must be greater than 0\ndefault_hls_list_size = self.__params.pop(\"-hls_list_size\", 6)\nif isinstance(default_hls_list_size, int) and default_hls_list_size &gt; 0:\noutput_params[\"-hls_list_size\"] = default_hls_list_size\nelse:\n# otherwise reset to  default\noutput_params[\"-hls_list_size\"] = 6\n# default behaviour\noutput_params[\"-hls_init_time\"] = self.__params.pop(\"-hls_init_time\", 4)\noutput_params[\"-hls_time\"] = self.__params.pop(\"-hls_time\", 6)\noutput_params[\"-hls_flags\"] = self.__params.pop(\n\"-hls_flags\", \"delete_segments+discont_start+split_by_time\"\n)\n# clean everything at exit?\noutput_params[\"-remove_at_exit\"] = self.__params.pop(\"-remove_at_exit\", 0)\nelse:\n# enforce \"contain all the segments\"\noutput_params[\"-hls_list_size\"] = 0\noutput_params[\"-hls_playlist_type\"] = \"vod\"\n# handle base URL for absolute paths\noutput_params[\"-hls_base_url\"] = self.__params.pop(\"-hls_base_url\", \"\")\n# Finally, some hardcoded HLS parameters (Refer FFmpeg docs for more info.)\noutput_params[\"-allowed_extensions\"] = \"ALL\"\n# Handling &lt;hls_segment_filename&gt;\n# Here filenname will be based on `stream_count` dict parameter that\n# would be used to check whether stream is multivariant(&gt;1) or single(0-1)\nsegment_template = (\n\"{}-stream%v-%03d.{}\"\nif output_params[\"stream_count\"] &gt; 1\nelse \"{}-stream-%03d.{}\"\n)\noutput_params[\"-hls_segment_filename\"] = segment_template.format(\nos.path.join(os.path.dirname(self.__out_file), \"chunk\"),\n\"m4s\" if output_params[\"-hls_segment_type\"] == \"fmp4\" else \"ts\",\n)\noutput_params[\"-hls_allow_cache\"] = 0\n# enable hls formatting\noutput_params[\"-f\"] = \"hls\"\nreturn (input_params, output_params)\ndef __generate_dash_stream(self, input_params, output_params):\n\"\"\"\n        An internal function that parses user-defined parameters and generates\n        suitable FFmpeg Terminal Command for transcoding input into MPEG-dash Stream.\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# Check if live-streaming or not?\nif self.__livestreaming:\noutput_params[\"-window_size\"] = self.__params.pop(\"-window_size\", 5)\noutput_params[\"-extra_window_size\"] = self.__params.pop(\n\"-extra_window_size\", 5\n)\n# clean everything at exit?\noutput_params[\"-remove_at_exit\"] = self.__params.pop(\"-remove_at_exit\", 0)\n# default behaviour\noutput_params[\"-seg_duration\"] = self.__params.pop(\"-seg_duration\", 20)\n# Disable (0) the use of a SegmentTimline inside a SegmentTemplate.\noutput_params[\"-use_timeline\"] = 0\nelse:\n# default behaviour\noutput_params[\"-seg_duration\"] = self.__params.pop(\"-seg_duration\", 5)\n# Enable (1) the use of a SegmentTimline inside a SegmentTemplate.\noutput_params[\"-use_timeline\"] = 1\n# Finally, some hardcoded DASH parameters (Refer FFmpeg docs for more info.)\noutput_params[\"-use_template\"] = 1\noutput_params[\"-adaptation_sets\"] = \"id=0,streams=v {}\".format(\n\"id=1,streams=a\" if (\"-acodec\" in output_params) else \"\"\n)\n# enable dash formatting\noutput_params[\"-f\"] = \"dash\"\nreturn (input_params, output_params)\ndef __Build_n_Execute(self, input_params, output_params):\n\"\"\"\n        An Internal function that launches FFmpeg subprocess and pipelines commands.\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# handle audio source if present\nif \"-core_asource\" in output_params:\noutput_params.move_to_end(\"-core_asource\", last=False)\n# finally handle `-i`\nif \"-i\" in output_params:\noutput_params.move_to_end(\"-i\", last=False)\n# copy streams count\nstream_count = output_params.pop(\"stream_count\", 1)\n# convert input parameters to list\ninput_commands = dict2Args(input_params)\n# convert output parameters to list\noutput_commands = dict2Args(output_params)\n# convert any additional parameters to list\nstream_commands = dict2Args(self.__params)\n# create exclusive HLS params\nhls_commands = []\n# handle HLS multi-variant streams\nif self.__format == \"hls\" and stream_count &gt; 1:\nstream_map = \"\"\nfor count in range(0, stream_count):\nstream_map += \"v:{}{} \".format(\ncount, \",a:{}\".format(count) if \"-acodec\" in output_params else \",\"\n)\nhls_commands += [\n\"-master_pl_name\",\nos.path.basename(self.__out_file),\n\"-var_stream_map\",\nstream_map.strip(),\nos.path.join(os.path.dirname(self.__out_file), \"stream_%v.m3u8\"),\n]\n# log it if enabled\nif self.__logging:\nlogger.debug(\n\"User-Defined Output parameters: `{}`\".format(\n\" \".join(output_commands) if output_commands else None\n)\n)\nlogger.debug(\n\"Additional parameters: `{}`\".format(\n\" \".join(stream_commands) if stream_commands else None\n)\n)\n# build FFmpeg command from parameters\nffmpeg_cmd = None\nhide_banner = (\n[] if self.__logging else [\"-hide_banner\"]\n)  # ensuring less cluterring if specified\n# format commands\nif self.__video_source:\nffmpeg_cmd = (\n[self.__ffmpeg, \"-y\"]\n+ ([\"-re\"] if self.__livestreaming else [])  # pseudo live-streaming\n+ hide_banner\n+ [\"-i\", self.__video_source]\n+ input_commands\n+ output_commands\n+ stream_commands\n)\nelse:\nffmpeg_cmd = (\n[self.__ffmpeg, \"-y\"]\n+ hide_banner\n+ [\"-f\", \"rawvideo\", \"-vcodec\", \"rawvideo\"]\n+ input_commands\n+ [\"-i\", \"-\"]\n+ output_commands\n+ stream_commands\n)\n# format outputs\nffmpeg_cmd.extend([self.__out_file] if not (hls_commands) else hls_commands)\n# Launch the FFmpeg pipeline with built command\nlogger.critical(\"Transcoding streaming chunks. Please wait...\")  # log it\nself.__process = sp.Popen(\nffmpeg_cmd,\nstdin=sp.PIPE,\nstdout=sp.DEVNULL\nif (not self.__video_source and not self.__logging)\nelse sp.PIPE,\nstderr=None if self.__logging else sp.STDOUT,\n)\n# post handle progress bar and runtime errors in case of video_source\nif self.__video_source:\nreturn_code = 0\npbar = None\nsec_prev = 0\nif not self.__logging:\n# iterate until stdout runs out\nwhile True:\n# read and process data\ndata = self.__process.stdout.readline()\nif data:\ndata = data.decode(\"utf-8\")\n# extract duration and time-left\nif pbar is None:\nif \"Duration:\" in data:\nsec_duration = extract_time(data)\n# initate progress bar\npbar = tqdm(\ntotal=sec_duration,\ndesc=\"Processing Frames\",\nunit=\"frame\",\n)\nelse:\nif \"time=\" in data:\nsec_current = extract_time(data)\n# update progress bar\nif sec_current:\npbar.update(sec_current - sec_prev)\nsec_prev = sec_current\nelse:\n# poll if no data\nif self.__process.poll() is not None:\nbreak\nreturn_code = self.__process.poll()\nelse:\nself.__process.communicate()\nreturn_code = self.__process.returncode\n# close progress bar\nif pbar:\npbar.close()\n# handle return_code\nif return_code:\n# log and raise error if return_code is `1`\nlogger.error(\n\"StreamGear failed to initiate stream for this video source!\"\n)\nerror = sp.CalledProcessError(return_code, ffmpeg_cmd)\nraise error\nelse:\n# log if successful\nlogger.critical(\n\"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\".format(\nself.__format.upper()\n)\n)\ndef __enter__(self):\n\"\"\"\n        Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        **Returns:** Returns a reference to the StreamGear Class\n        \"\"\"\nreturn self\ndef __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"\n        Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        \"\"\"\nself.terminate()\ndef terminate(self):\n\"\"\"\n        Safely terminates StreamGear.\n        \"\"\"\n# return if no process was initiated at first place\nif self.__process is None or not (self.__process.poll() is None):\nreturn\n# close `stdin` output\nif self.__process.stdin:\nself.__process.stdin.close()\n# force terminate if external audio source\nif isinstance(self.__audio, list):\nself.__process.terminate()\n# wait if still process is still processing some information\nself.__process.wait()\nself.__process = None\n# log it\nlogger.critical(\n\"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\".format(\nself.__format.upper()\n)\n)\n</code></pre> <p> </p>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__enter__","title":"<code>__enter__(self)</code>  <code>special</code>","text":"<p>Handles entry with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> <p>Returns: Returns a reference to the StreamGear Class</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def __enter__(self):\n\"\"\"\n    Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    **Returns:** Returns a reference to the StreamGear Class\n    \"\"\"\nreturn self\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__exit__","title":"<code>__exit__(self, exc_type, exc_val, exc_tb)</code>  <code>special</code>","text":"<p>Handles exit with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"\n    Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    \"\"\"\nself.terminate()\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.__init__","title":"<code>__init__(self, output='', format='dash', custom_ffmpeg='', logging=False, **stream_params)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the StreamGear class.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str</code> <p>sets the valid filename/path for storing the StreamGear assets.</p> <code>''</code> <code>format</code> <code>str</code> <p>select the adaptive HTTP streaming format(DASH and HLS).</p> <code>'dash'</code> <code>custom_ffmpeg</code> <code>str</code> <p>assigns the location of custom path/directory for custom FFmpeg executables.</p> <code>''</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>stream_params</code> <code>dict</code> <p>provides the flexibility to control supported internal parameters and FFmpeg properities.</p> <code>{}</code> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def __init__(\nself, output=\"\", format=\"dash\", custom_ffmpeg=\"\", logging=False, **stream_params\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the StreamGear class.\n    Parameters:\n        output (str): sets the valid filename/path for storing the StreamGear assets.\n        format (str): select the adaptive HTTP streaming format(DASH and HLS).\n        custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n        logging (bool): enables/disables logging.\n        stream_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# checks if machine in-use is running windows os or not\nself.__os_windows = True if os.name == \"nt\" else False\n# enable logging if specified\nself.__logging = logging if (logging and isinstance(logging, bool)) else False\n# initialize various class variables\n# handles user-defined parameters\nself.__params = {}\n# handle input video/frame resolution and channels\nself.__inputheight = None\nself.__inputwidth = None\nself.__inputchannels = None\nself.__sourceframerate = None\n# handle process to be frames written\nself.__process = None\n# handle valid FFmpeg assets location\nself.__ffmpeg = \"\"\n# handle one time process for valid process initialization\nself.__initiate_stream = True\n# cleans and reformat user-defined parameters\nself.__params = {\nstr(k).strip(): str(v).strip()\nif not isinstance(v, (dict, list, int, float))\nelse v\nfor k, v in stream_params.items()\n}\n# handle where to save the downloaded FFmpeg Static assets on Windows(if specified)\n__ffmpeg_download_path = self.__params.pop(\"-ffmpeg_download_path\", \"\")\nif not isinstance(__ffmpeg_download_path, (str)):\n# reset improper values\n__ffmpeg_download_path = \"\"\n# validate the FFmpeg assets and return location (also downloads static assets on windows)\nself.__ffmpeg = get_valid_ffmpeg_path(\nstr(custom_ffmpeg),\nself.__os_windows,\nffmpeg_download_path=__ffmpeg_download_path,\nlogging=self.__logging,\n)\n# check if valid FFmpeg path returned\nif self.__ffmpeg:\nself.__logging and logger.debug(\n\"Found valid FFmpeg executables: `{}`.\".format(self.__ffmpeg)\n)\nelse:\n# else raise error\nraise RuntimeError(\n\"[StreamGear:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\"\n)\n# handle Audio-Input\naudio = self.__params.pop(\"-audio\", \"\")\nif audio and isinstance(audio, str):\nif os.path.isfile(audio):\nself.__audio = os.path.abspath(audio)\nelif is_valid_url(self.__ffmpeg, url=audio, logging=self.__logging):\nself.__audio = audio\nelse:\nself.__audio = \"\"\nelif audio and isinstance(audio, list):\nself.__audio = audio\nelse:\nself.__audio = \"\"\nif self.__audio and self.__logging:\nlogger.debug(\"External audio source detected!\")\n# handle Video-Source input\nsource = self.__params.pop(\"-video_source\", \"\")\n# Check if input is valid string\nif source and isinstance(source, str) and len(source) &gt; 1:\n# Differentiate input\nif os.path.isfile(source):\nself.__video_source = os.path.abspath(source)\nelif is_valid_url(self.__ffmpeg, url=source, logging=self.__logging):\nself.__video_source = source\nelse:\n# discard the value otherwise\nself.__video_source = \"\"\n# Validate input\nif self.__video_source:\nvalidation_results = validate_video(\nself.__ffmpeg, video_path=self.__video_source\n)\nassert not (\nvalidation_results is None\n), \"[StreamGear:ERROR] :: Given `{}` video_source is Invalid, Check Again!\".format(\nself.__video_source\n)\nself.__aspect_source = validation_results[\"resolution\"]\nself.__fps_source = validation_results[\"framerate\"]\n# log it\nself.__logging and logger.debug(\n\"Given video_source is valid and has {}x{} resolution, and a framerate of {} fps.\".format(\nself.__aspect_source[0],\nself.__aspect_source[1],\nself.__fps_source,\n)\n)\nelse:\nlogger.warning(\"No valid video_source provided.\")\nelse:\n# discard the value otherwise\nself.__video_source = \"\"\n# handle user-defined framerate\nself.__inputframerate = self.__params.pop(\"-input_framerate\", 0.0)\nif isinstance(self.__inputframerate, (float, int)):\n# must be float\nself.__inputframerate = float(self.__inputframerate)\nelse:\n# reset improper values\nself.__inputframerate = 0.0\n# handle old assests\nself.__clear_assets = self.__params.pop(\"-clear_prev_assets\", False)\nif not isinstance(self.__clear_assets, bool):\n# reset improper values\nself.__clear_assets = False\n# handle whether to livestream?\nself.__livestreaming = self.__params.pop(\"-livestream\", False)\nif not isinstance(self.__livestreaming, bool):\n# reset improper values\nself.__livestreaming = False\n# handle Streaming formats\nsupported_formats = [\"dash\", \"hls\"]  # will be extended in future\n# Validate\nif not (format is None) and format and isinstance(format, str):\n_format = format.strip().lower()\nif _format in supported_formats:\nself.__format = _format\nlogger.info(\n\"StreamGear will generate files for {} HTTP streaming format.\".format(\nself.__format.upper()\n)\n)\nelif difflib.get_close_matches(_format, supported_formats):\nraise ValueError(\n\"[StreamGear:ERROR] :: Incorrect format! Did you mean `{}`?\".format(\ndifflib.get_close_matches(_format, supported_formats)[0]\n)\n)\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: format value `{}` not valid/supported!\".format(\nformat\n)\n)\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: format value is Missing/Incorrect. Check vidgear docs!\"\n)\n# handles output name\nif not output:\nraise ValueError(\n\"[StreamGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more information.\"\n)\nelse:\n# validate this class has the access rights to specified directory or not\nabs_path = os.path.abspath(output)\nif check_WriteAccess(\nos.path.dirname(abs_path),\nis_windows=self.__os_windows,\nlogging=self.__logging,\n):\n# check if given path is directory\nvalid_extension = \"mpd\" if self.__format == \"dash\" else \"m3u8\"\n# get all assets extensions\nassets_exts = [\n(\"chunk-stream\", \".m4s\"),  # filename prefix, extension\n(\"chunk-stream\", \".ts\"),  # filename prefix, extension\n\".{}\".format(valid_extension),\n]\n# add source file extension too\nif self.__video_source:\nassets_exts.append(\n(\n\"chunk-stream\",\nos.path.splitext(self.__video_source)[1],\n)  # filename prefix, extension\n)\nif os.path.isdir(abs_path):\nif self.__clear_assets:\ndelete_ext_safe(abs_path, assets_exts, logging=self.__logging)\nabs_path = os.path.join(\nabs_path,\n\"{}-{}.{}\".format(\nself.__format,\ntime.strftime(\"%Y%m%d-%H%M%S\"),\nvalid_extension,\n),\n)  # auto-assign valid name and adds it to path\nelif self.__clear_assets and os.path.isfile(abs_path):\ndelete_ext_safe(\nos.path.dirname(abs_path),\nassets_exts,\nlogging=self.__logging,\n)\n# check if path has valid file extension\nassert abs_path.endswith(\nvalid_extension\n), \"Given `{}` path has invalid file-extension w.r.t selected format: `{}`!\".format(\noutput, self.__format.upper()\n)\nself.__logging and logger.debug(\n\"Path:`{}` is sucessfully configured for streaming.\".format(\nabs_path\n)\n)\n# assign it\nself.__out_file = abs_path.replace(\n\"\\\\\", \"/\"\n)  # workaround for Windows platform only, others will not be affected\nelif platform.system() == \"Linux\" and pathlib.Path(output).is_char_device():\n# check if linux video device path (such as `/dev/video0`)\nself.__logging and logger.debug(\n\"Path:`{}` is a valid Linux Video Device path.\".format(output)\n)\nself.__out_file = output\n# check if given output is a valid URL\nelif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\nself.__logging and logger.debug(\n\"URL:`{}` is valid and sucessfully configured for streaming.\".format(\noutput\n)\n)\nself.__out_file = output\nelse:\nraise ValueError(\n\"[StreamGear:ERROR] :: Output value:`{}` is not valid/supported!\".format(\noutput\n)\n)\n# log Mode of operation\nlogger.info(\n\"StreamGear has been successfully configured for {} Mode.\".format(\n\"Single-Source\" if self.__video_source else \"Real-time Frames\"\n)\n)\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.stream","title":"<code>stream(self, frame, rgb_mode=False)</code>","text":"<p>Pipelines <code>ndarray</code> frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>a valid numpy frame</p> required <code>rgb_mode</code> <code>boolean</code> <p>enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format instead of default BGR).</p> <code>False</code> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def stream(self, frame, rgb_mode=False):\n\"\"\"\n    Pipelines `ndarray` frames to FFmpeg Pipeline for transcoding into multi-bitrate streamable assets.\n    Parameters:\n        frame (ndarray): a valid numpy frame\n        rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format instead of default BGR)_.\n    \"\"\"\n# check if function is called in correct context\nif self.__video_source:\nraise RuntimeError(\n\"[StreamGear:ERROR] :: `stream()` function cannot be used when streaming from a `-video_source` input file. Kindly refer vidgear docs!\"\n)\n# None-Type frames will be skipped\nif frame is None:\nreturn\n# extract height, width and number of channels of frame\nheight, width = frame.shape[:2]\nchannels = frame.shape[-1] if frame.ndim == 3 else 1\n# assign values to class variables on first run\nif self.__initiate_stream:\nself.__inputheight = height\nself.__inputwidth = width\nself.__inputchannels = channels\nself.__sourceframerate = (\n25.0 if not (self.__inputframerate) else self.__inputframerate\n)\nself.__logging and logger.debug(\n\"InputFrame =&gt; Height:{} Width:{} Channels:{}\".format(\nself.__inputheight, self.__inputwidth, self.__inputchannels\n)\n)\n# validate size of frame\nif height != self.__inputheight or width != self.__inputwidth:\nraise ValueError(\"[StreamGear:ERROR] :: All frames must have same size!\")\n# validate number of channels\nif channels != self.__inputchannels:\nraise ValueError(\n\"[StreamGear:ERROR] :: All frames must have same number of channels!\"\n)\n# initiate FFmpeg process on first run\nif self.__initiate_stream:\n# launch pre-processing\nself.__PreProcess(channels=channels, rgb=rgb_mode)\n# Check status of the process\nassert self.__process is not None\n# write the frame to pipeline\ntry:\nself.__process.stdin.write(frame.tobytes())\nexcept (OSError, IOError):\n# log something is wrong!\nlogger.error(\n\"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe, Kindly Refer Docs!\"\n)\nraise ValueError  # for testing purpose only\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.terminate","title":"<code>terminate(self)</code>","text":"<p>Safely terminates StreamGear.</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def terminate(self):\n\"\"\"\n    Safely terminates StreamGear.\n    \"\"\"\n# return if no process was initiated at first place\nif self.__process is None or not (self.__process.poll() is None):\nreturn\n# close `stdin` output\nif self.__process.stdin:\nself.__process.stdin.close()\n# force terminate if external audio source\nif isinstance(self.__audio, list):\nself.__process.terminate()\n# wait if still process is still processing some information\nself.__process.wait()\nself.__process = None\n# log it\nlogger.critical(\n\"Transcoding Ended. {} Streaming assets are successfully generated at specified path.\".format(\nself.__format.upper()\n)\n)\n</code></pre>"},{"location":"bonus/reference/streamgear/#vidgear.gears.streamgear.StreamGear.transcode_source","title":"<code>transcode_source(self)</code>","text":"<p>Transcodes entire Video Source (with audio) into multi-bitrate streamable assets</p> Source code in <code>vidgear/gears/streamgear.py</code> <pre><code>def transcode_source(self):\n\"\"\"\n    Transcodes entire Video Source _(with audio)_ into multi-bitrate streamable assets\n    \"\"\"\n# check if function is called in correct context\nif not (self.__video_source):\nraise RuntimeError(\n\"[StreamGear:ERROR] :: `transcode_source()` function cannot be used without a valid `-video_source` input. Kindly refer vidgear docs!\"\n)\n# assign height, width and framerate\nself.__inputheight = int(self.__aspect_source[1])\nself.__inputwidth = int(self.__aspect_source[0])\nself.__sourceframerate = float(self.__fps_source)\n# launch pre-processing\nself.__PreProcess()\n</code></pre>"},{"location":"bonus/reference/videogear/","title":"VideoGear API","text":"<p>VideoGear API usage examples can be found here \u27b6</p> <p>VideoGear API parameters are explained here \u27b6</p> <p>VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag.</p> <p>VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not) with minimum effort and writing way fewer lines of code.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>class VideoGear:\n\"\"\"\n    VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class.\n    VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive enablePiCamera boolean flag.\n    VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not)\n    with minimum effort and writing way fewer lines of code.\n    \"\"\"\ndef __init__(\nself,\n# VideoGear parameters\nenablePiCamera=False,\nstabilize=False,\n# PiGear parameters\ncamera_num=0,\nresolution=(640, 480),\nframerate=30,\n# CamGear parameters\nsource=0,\nstream_mode=False,\nbackend=0,\n# common parameters\ntime_delay=0,\ncolorspace=None,\nlogging=False,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the VideoGear class.\n        Parameters:\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# initialize stabilizer\nself.__stablization_mode = stabilize\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\nif self.__stablization_mode:\nfrom .stabilizer import Stabilizer\ns_radius = options.pop(\"SMOOTHING_RADIUS\", 25)\nif not isinstance(s_radius, int):\ns_radius = 25\nborder_size = options.pop(\"BORDER_SIZE\", 0)\nif not isinstance(border_size, int):\nborder_size = 0\nborder_type = options.pop(\"BORDER_TYPE\", \"black\")\nif not isinstance(border_type, str):\nborder_type = \"black\"\ncrop_n_zoom = options.pop(\"CROP_N_ZOOM\", False)\nif not isinstance(crop_n_zoom, bool):\ncrop_n_zoom = False\nself.__stabilizer_obj = Stabilizer(\nsmoothing_radius=s_radius,\nborder_type=border_type,\nborder_size=border_size,\ncrop_n_zoom=crop_n_zoom,\nlogging=logging,\n)\nself.__logging and logger.debug(\n\"Enabling Stablization Mode for the current video source!\"\n)  # log info\nif enablePiCamera:\n# only import the pigear module only if required\nfrom .pigear import PiGear\n# initialize the picamera stream by enabling PiGear API\nself.stream = PiGear(\ncamera_num=camera_num,\nresolution=resolution,\nframerate=framerate,\ncolorspace=colorspace,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\nelse:\n# otherwise, we are using OpenCV so initialize the webcam\n# stream by activating CamGear API\nself.stream = CamGear(\nsource=source,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# initialize framerate variable\nself.framerate = self.stream.framerate\ndef start(self):\n\"\"\"\n        Launches the internal *Threaded Frames Extractor* daemon of API in use.\n        **Returns:** A reference to the selected class object.\n        \"\"\"\nself.stream.start()\nreturn self\ndef read(self):\n\"\"\"\n        Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame\n        buffer in the memory, and blocks the thread if the deque is full.\n        **Returns:** A n-dimensional numpy array.\n        \"\"\"\nwhile self.__stablization_mode:\nframe = self.stream.read()\nif frame is None:\nbreak\nframe_stab = self.__stabilizer_obj.stabilize(frame)\nif not (frame_stab is None):\nreturn frame_stab\nreturn self.stream.read()\ndef stop(self):\n\"\"\"\n        Safely terminates the thread, and release the respective VideoStream resources.\n        \"\"\"\nself.stream.stop()\n# logged\nself.__logging and logger.debug(\"Terminating VideoGear.\")\n# clean queue\nif self.__stablization_mode:\nself.__stabilizer_obj.clean()\n</code></pre> <p> </p>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.__init__","title":"<code>__init__(self, enablePiCamera=False, stabilize=False, camera_num=0, resolution=(640, 480), framerate=30, source=0, stream_mode=False, backend=0, time_delay=0, colorspace=None, logging=False, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the VideoGear class.</p> <p>Parameters:</p> Name Type Description Default <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>30</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>0</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def __init__(\nself,\n# VideoGear parameters\nenablePiCamera=False,\nstabilize=False,\n# PiGear parameters\ncamera_num=0,\nresolution=(640, 480),\nframerate=30,\n# CamGear parameters\nsource=0,\nstream_mode=False,\nbackend=0,\n# common parameters\ntime_delay=0,\ncolorspace=None,\nlogging=False,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the VideoGear class.\n    Parameters:\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# initialize stabilizer\nself.__stablization_mode = stabilize\n# enable logging if specified\nself.__logging = False\nif logging:\nself.__logging = logging\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\nif self.__stablization_mode:\nfrom .stabilizer import Stabilizer\ns_radius = options.pop(\"SMOOTHING_RADIUS\", 25)\nif not isinstance(s_radius, int):\ns_radius = 25\nborder_size = options.pop(\"BORDER_SIZE\", 0)\nif not isinstance(border_size, int):\nborder_size = 0\nborder_type = options.pop(\"BORDER_TYPE\", \"black\")\nif not isinstance(border_type, str):\nborder_type = \"black\"\ncrop_n_zoom = options.pop(\"CROP_N_ZOOM\", False)\nif not isinstance(crop_n_zoom, bool):\ncrop_n_zoom = False\nself.__stabilizer_obj = Stabilizer(\nsmoothing_radius=s_radius,\nborder_type=border_type,\nborder_size=border_size,\ncrop_n_zoom=crop_n_zoom,\nlogging=logging,\n)\nself.__logging and logger.debug(\n\"Enabling Stablization Mode for the current video source!\"\n)  # log info\nif enablePiCamera:\n# only import the pigear module only if required\nfrom .pigear import PiGear\n# initialize the picamera stream by enabling PiGear API\nself.stream = PiGear(\ncamera_num=camera_num,\nresolution=resolution,\nframerate=framerate,\ncolorspace=colorspace,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\nelse:\n# otherwise, we are using OpenCV so initialize the webcam\n# stream by activating CamGear API\nself.stream = CamGear(\nsource=source,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# initialize framerate variable\nself.framerate = self.stream.framerate\n</code></pre>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.read","title":"<code>read(self)</code>","text":"<p>Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame buffer in the memory, and blocks the thread if the deque is full.</p> <p>Returns: A n-dimensional numpy array.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def read(self):\n\"\"\"\n    Extracts frames synchronously from selected API's monitored deque, while maintaining a fixed-length frame\n    buffer in the memory, and blocks the thread if the deque is full.\n    **Returns:** A n-dimensional numpy array.\n    \"\"\"\nwhile self.__stablization_mode:\nframe = self.stream.read()\nif frame is None:\nbreak\nframe_stab = self.__stabilizer_obj.stabilize(frame)\nif not (frame_stab is None):\nreturn frame_stab\nreturn self.stream.read()\n</code></pre>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.start","title":"<code>start(self)</code>","text":"<p>Launches the internal Threaded Frames Extractor daemon of API in use.</p> <p>Returns: A reference to the selected class object.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def start(self):\n\"\"\"\n    Launches the internal *Threaded Frames Extractor* daemon of API in use.\n    **Returns:** A reference to the selected class object.\n    \"\"\"\nself.stream.start()\nreturn self\n</code></pre>"},{"location":"bonus/reference/videogear/#vidgear.gears.videogear.VideoGear.stop","title":"<code>stop(self)</code>","text":"<p>Safely terminates the thread, and release the respective VideoStream resources.</p> Source code in <code>vidgear/gears/videogear.py</code> <pre><code>def stop(self):\n\"\"\"\n    Safely terminates the thread, and release the respective VideoStream resources.\n    \"\"\"\nself.stream.stop()\n# logged\nself.__logging and logger.debug(\"Terminating VideoGear.\")\n# clean queue\nif self.__stablization_mode:\nself.__stabilizer_obj.clean()\n</code></pre>"},{"location":"bonus/reference/webgear/","title":"WebGear API","text":"<p>WebGear API usage examples can be found here \u27b6</p> <p>WebGear API parameters are explained here \u27b6</p> <p>WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser.</p> <p>WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.</p> <p>WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video.</p> <p>In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>class WebGear:\n\"\"\"\n    WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser.\n    WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can\n    flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating\n    engine(with Jinja2), etc.\n    WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression)\n    and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality\n    is not the best, since JPEG compression is not very efficient for motion video.\n    In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal\n    wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.\n    \"\"\"\ndef __init__(\nself,\nenablePiCamera=False,\nstabilize=False,\nsource=None,\ncamera_num=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nresolution=(640, 480),\nframerate=25,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the WebGear class.\n        Parameters:\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\"starlette\" if starlette is None else \"\")\nimport_dependency_safe(\n\"simplejpeg\" if simplejpeg is None else \"\", min_version=\"1.6.1\"\n)\n# initialize global params\nself.__skip_generate_webdata = False  # generate webgear data by default\n# define frame-compression handler\nself.__jpeg_compression_quality = 90  # 90% quality\nself.__jpeg_compression_fastdct = True  # fastest DCT on by default\nself.__jpeg_compression_fastupsample = False  # fastupsample off by default\nself.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\nself.__logging = logging\nself.__frame_size_reduction = 25  # use 25% reduction\n# retrieve interpolation for reduction\nself.__interpolation = retrieve_best_interpolation(\n[\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n)\ncustom_data_location = \"\"  # path to save data-files to custom location\ndata_path = \"\"  # path to WebGear data-files\noverwrite_default = False\nself.__enable_inf = False  # continue frames even when video ends.\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# assign values to global variables if specified and valid\nif options:\n# check whether to disable Data-Files Auto-Generation WorkFlow\nif \"skip_generate_webdata\" in options:\nvalue = options[\"skip_generate_webdata\"]\n# enable jpeg fastdct\nif isinstance(value, bool):\nself.__skip_generate_webdata = value\nelse:\nlogger.warning(\"Skipped invalid `skip_generate_webdata` value!\")\ndel options[\"skip_generate_webdata\"]  # clean\nif \"jpeg_compression_colorspace\" in options:\nvalue = options[\"jpeg_compression_colorspace\"]\nif isinstance(value, str) and value.strip().upper() in [\n\"RGB\",\n\"BGR\",\n\"RGBX\",\n\"BGRX\",\n\"XBGR\",\n\"XRGB\",\n\"GRAY\",\n\"RGBA\",\n\"BGRA\",\n\"ABGR\",\n\"ARGB\",\n\"CMYK\",\n]:\n# set encoding colorspace\nself.__jpeg_compression_colorspace = value.strip().upper()\nelse:\nlogger.warning(\n\"Skipped invalid `jpeg_compression_colorspace` value!\"\n)\ndel options[\"jpeg_compression_colorspace\"]  # clean\nif \"jpeg_compression_quality\" in options:\nvalue = options[\"jpeg_compression_quality\"]\n# set valid jpeg quality\nif isinstance(value, (int, float)) and value &gt;= 10 and value &lt;= 100:\nself.__jpeg_compression_quality = int(value)\nelse:\nlogger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\ndel options[\"jpeg_compression_quality\"]  # clean\nif \"jpeg_compression_fastdct\" in options:\nvalue = options[\"jpeg_compression_fastdct\"]\n# enable jpeg fastdct\nif isinstance(value, bool):\nself.__jpeg_compression_fastdct = value\nelse:\nlogger.warning(\"Skipped invalid `jpeg_compression_fastdct` value!\")\ndel options[\"jpeg_compression_fastdct\"]  # clean\nif \"jpeg_compression_fastupsample\" in options:\nvalue = options[\"jpeg_compression_fastupsample\"]\n# enable jpeg  fastupsample\nif isinstance(value, bool):\nself.__jpeg_compression_fastupsample = value\nelse:\nlogger.warning(\n\"Skipped invalid `jpeg_compression_fastupsample` value!\"\n)\ndel options[\"jpeg_compression_fastupsample\"]  # clean\nif \"frame_size_reduction\" in options:\nvalue = options[\"frame_size_reduction\"]\nif isinstance(value, (int, float)) and value &gt;= 0 and value &lt;= 90:\nself.__frame_size_reduction = value\nelse:\nlogger.warning(\"Skipped invalid `frame_size_reduction` value!\")\ndel options[\"frame_size_reduction\"]  # clean\nif \"custom_data_location\" in options:\nvalue = options[\"custom_data_location\"]\nif isinstance(value, str):\nassert os.access(\nvalue, os.W_OK\n), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to '{}' directory!\".format(\nvalue\n)\nassert os.path.isdir(\nos.path.abspath(value)\n), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\ncustom_data_location = os.path.abspath(value)\nelse:\nlogger.warning(\"Skipped invalid `custom_data_location` value!\")\ndel options[\"custom_data_location\"]  # clean\nif \"overwrite_default_files\" in options:\nvalue = options[\"overwrite_default_files\"]\nif isinstance(value, bool):\noverwrite_default = value\nelse:\nlogger.warning(\"Skipped invalid `overwrite_default_files` value!\")\ndel options[\"overwrite_default_files\"]  # clean\nif \"enable_infinite_frames\" in options:\nvalue = options[\"enable_infinite_frames\"]\nif isinstance(value, bool):\nself.__enable_inf = value\nelse:\nlogger.warning(\"Skipped invalid `enable_infinite_frames` value!\")\ndel options[\"enable_infinite_frames\"]  # clean\n# check if disable Data-Files Auto-Generation WorkFlow is disabled\nif not self.__skip_generate_webdata:\n# check if custom data path is specified\nif custom_data_location:\ndata_path = generate_webdata(\ncustom_data_location,\nc_name=\"webgear\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\nelse:\n# otherwise generate suitable path\ndata_path = generate_webdata(\nos.path.join(expanduser(\"~\"), \".vidgear\"),\nc_name=\"webgear\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\n# log it\nself.__logging and logger.debug(\n\"`{}` is the default location for saving WebGear data-files.\".format(\ndata_path\n)\n)\n# define Jinja2 templates handler\nself.__templates = Jinja2Templates(\ndirectory=\"{}/templates\".format(data_path)\n)\n# define routing tables\nself.routes = [\nRoute(\"/\", endpoint=self.__homepage),\nRoute(\"/video\", endpoint=self.__video),\nMount(\n\"/static\",\napp=StaticFiles(directory=\"{}/static\".format(data_path)),\nname=\"static\",\n),\n]\nelse:\n# log it\nself.__logging and logger.critical(\n\"WebGear Data-Files Auto-Generation WorkFlow has been manually disabled.\"\n)\n# define routing tables\nself.routes = [\nRoute(\"/video\", endpoint=self.__video),\n]\n# log exceptions\nself.__logging and logger.warning(\n\"Only `/video` route is available for this instance.\"\n)\n# define custom exception handlers\nself.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n# define middleware support\nself.middleware = []\n# Handle video source\nif source is None:\nself.config = {\"generator\": None}\nself.__stream = None\nelse:\n# define stream with necessary params\nself.__stream = VideoGear(\nenablePiCamera=enablePiCamera,\nstabilize=stabilize,\nsource=source,\ncamera_num=camera_num,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nresolution=resolution,\nframerate=framerate,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# define default frame generator in configuration\nself.config = {\"generator\": self.__producer}\n# log if specified\nif self.__logging:\nif source is None:\nlogger.warning(\n\"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\"\n)\nelse:\nlogger.debug(\n\"Enabling JPEG Frame-Compression with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\nself.__jpeg_compression_colorspace,\nself.__jpeg_compression_quality,\n\"enabled\" if self.__jpeg_compression_fastdct else \"disabled\",\n\"enabled\"\nif self.__jpeg_compression_fastupsample\nelse \"disabled\",\n)\n)\n# copying original routing tables for further validation\nself.__rt_org_copy = self.routes[:]\n# initialize blank frame\nself.blank_frame = None\n# keeps check if producer loop should be running\nself.__isrunning = True\ndef __call__(self):\n\"\"\"\n        Implements a custom Callable method for WebGear application.\n        \"\"\"\n# validate routing tables\nassert not (self.routes is None), \"Routing tables are NoneType!\"\nif not isinstance(self.routes, list) or not all(\nx in self.routes for x in self.__rt_org_copy\n):\nraise RuntimeError(\"[WebGear:ERROR] :: Routing tables are not valid!\")\n# validate middlewares\nassert not (self.middleware is None), \"Middlewares are NoneType!\"\nif self.middleware and (\nnot isinstance(self.middleware, list)\nor not all(isinstance(x, Middleware) for x in self.middleware)\n):\nraise RuntimeError(\"[WebGear:ERROR] :: Middlewares are not valid!\")\n# validate assigned frame generator in WebGear configuration\nif isinstance(self.config, dict) and \"generator\" in self.config:\n# check if its  assigned value is a asynchronous generator\nif self.config[\"generator\"] is None or not inspect.isasyncgen(\nself.config[\"generator\"]()\n):\n# otherwise raise error\nraise ValueError(\n\"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\"\n)\nelse:\n# raise error if validation fails\nraise RuntimeError(\"[WebGear:ERROR] :: Assigned configuration is invalid!\")\n# initiate stream\nself.__logging and logger.debug(\"Initiating Video Streaming.\")\nif not (self.__stream is None):\nself.__stream.start()\n# return Starlette application\nself.__logging and logger.debug(\"Running Starlette application.\")\nreturn Starlette(\ndebug=(True if self.__logging else False),\nroutes=self.routes,\nmiddleware=self.middleware,\nexception_handlers=self.__exception_handlers,\non_shutdown=[self.shutdown],\n)\nasync def __producer(self):\n\"\"\"\n        WebGear's default asynchronous frame producer/generator.\n        \"\"\"\n# loop over frames\nwhile self.__isrunning:\n# read frame\nframe = self.__stream.read()\n# display blank if NoneType\nif frame is None:\nframe = (\nself.blank_frame\nif self.blank_frame is None\nelse self.blank_frame[:]\n)\nif not self.__enable_inf:\nself.__isrunning = False\nelse:\n# create blank\nif self.blank_frame is None:\nself.blank_frame = create_blank_frame(\nframe=frame,\ntext=\"No Input\" if self.__enable_inf else \"The End\",\nlogging=self.__logging,\n)\n# reducer frames size if specified\nif self.__frame_size_reduction:\nframe = await reducer(\nframe,\npercentage=self.__frame_size_reduction,\ninterpolation=self.__interpolation,\n)\n# handle JPEG encoding\nif self.__jpeg_compression_colorspace == \"GRAY\":\nif frame.ndim == 2:\n# patch for https://gitlab.com/jfolz/simplejpeg/-/issues/11\nframe = np.expand_dims(frame, axis=2)\nencodedImage = simplejpeg.encode_jpeg(\nframe,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\nfastdct=self.__jpeg_compression_fastdct,\n)\nelse:\nencodedImage = simplejpeg.encode_jpeg(\nframe,\nquality=self.__jpeg_compression_quality,\ncolorspace=self.__jpeg_compression_colorspace,\ncolorsubsampling=\"422\",\nfastdct=self.__jpeg_compression_fastdct,\n)\n# yield frame in byte format\nyield (\nb\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\"\n)\n# sleep for sometime.\nawait asyncio.sleep(0)\nasync def __video(self, scope):\n\"\"\"\n        Returns a async video streaming response.\n        \"\"\"\nassert scope[\"type\"] in [\"http\", \"https\"]\nreturn StreamingResponse(\nself.config[\"generator\"](),\nmedia_type=\"multipart/x-mixed-replace; boundary=frame\",\n)\nasync def __homepage(self, request):\n\"\"\"\n        Returns an HTML index page.\n        \"\"\"\nreturn (\nself.__templates.TemplateResponse(\"index.html\", {\"request\": request})\nif not self.__skip_generate_webdata\nelse JSONResponse(\n{\"detail\": \"WebGear Data-Files Auto-Generation WorkFlow is disabled!\"},\nstatus_code=404,\n)\n)\nasync def __not_found(self, request, exc):\n\"\"\"\n        Returns an HTML 404 page.\n        \"\"\"\nreturn (\nself.__templates.TemplateResponse(\n\"404.html\", {\"request\": request}, status_code=404\n)\nif not self.__skip_generate_webdata\nelse JSONResponse(\n{\"detail\": \"WebGear Data-Files Auto-Generation WorkFlow is disabled!\"},\nstatus_code=404,\n)\n)\nasync def __server_error(self, request, exc):\n\"\"\"\n        Returns an HTML 500 page.\n        \"\"\"\nreturn (\nself.__templates.TemplateResponse(\n\"500.html\", {\"request\": request}, status_code=500\n)\nif not self.__skip_generate_webdata\nelse JSONResponse(\n{\"detail\": \"WebGear Data-Files Auto-Generation WorkFlow is disabled!\"},\nstatus_code=500,\n)\n)\ndef shutdown(self):\n\"\"\"\n        Implements a Callable to be run on application shutdown\n        \"\"\"\nif not (self.__stream is None):\nself.__logging and logger.debug(\"Closing Video Streaming.\")\n# stops producer\nself.__isrunning = False\n# stops VideoGear stream\nself.__stream.stop()\n# prevent any re-iteration\nself.__stream = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__call__","title":"<code>__call__(self)</code>  <code>special</code>","text":"<p>Implements a custom Callable method for WebGear application.</p> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>def __call__(self):\n\"\"\"\n    Implements a custom Callable method for WebGear application.\n    \"\"\"\n# validate routing tables\nassert not (self.routes is None), \"Routing tables are NoneType!\"\nif not isinstance(self.routes, list) or not all(\nx in self.routes for x in self.__rt_org_copy\n):\nraise RuntimeError(\"[WebGear:ERROR] :: Routing tables are not valid!\")\n# validate middlewares\nassert not (self.middleware is None), \"Middlewares are NoneType!\"\nif self.middleware and (\nnot isinstance(self.middleware, list)\nor not all(isinstance(x, Middleware) for x in self.middleware)\n):\nraise RuntimeError(\"[WebGear:ERROR] :: Middlewares are not valid!\")\n# validate assigned frame generator in WebGear configuration\nif isinstance(self.config, dict) and \"generator\" in self.config:\n# check if its  assigned value is a asynchronous generator\nif self.config[\"generator\"] is None or not inspect.isasyncgen(\nself.config[\"generator\"]()\n):\n# otherwise raise error\nraise ValueError(\n\"[WebGear:ERROR] :: Invalid configuration. Assigned generator must be a asynchronous generator function/method only!\"\n)\nelse:\n# raise error if validation fails\nraise RuntimeError(\"[WebGear:ERROR] :: Assigned configuration is invalid!\")\n# initiate stream\nself.__logging and logger.debug(\"Initiating Video Streaming.\")\nif not (self.__stream is None):\nself.__stream.start()\n# return Starlette application\nself.__logging and logger.debug(\"Running Starlette application.\")\nreturn Starlette(\ndebug=(True if self.__logging else False),\nroutes=self.routes,\nmiddleware=self.middleware,\nexception_handlers=self.__exception_handlers,\non_shutdown=[self.shutdown],\n)\n</code></pre>"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.__init__","title":"<code>__init__(self, enablePiCamera=False, stabilize=False, source=None, camera_num=0, stream_mode=False, backend=0, colorspace=None, resolution=(640, 480), framerate=25, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the WebGear class.</p> <p>Parameters:</p> Name Type Description Default <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>25</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>None</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>def __init__(\nself,\nenablePiCamera=False,\nstabilize=False,\nsource=None,\ncamera_num=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nresolution=(640, 480),\nframerate=25,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the WebGear class.\n    Parameters:\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of WebGear, CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# raise error(s) for critical Class imports\nimport_dependency_safe(\"starlette\" if starlette is None else \"\")\nimport_dependency_safe(\n\"simplejpeg\" if simplejpeg is None else \"\", min_version=\"1.6.1\"\n)\n# initialize global params\nself.__skip_generate_webdata = False  # generate webgear data by default\n# define frame-compression handler\nself.__jpeg_compression_quality = 90  # 90% quality\nself.__jpeg_compression_fastdct = True  # fastest DCT on by default\nself.__jpeg_compression_fastupsample = False  # fastupsample off by default\nself.__jpeg_compression_colorspace = \"BGR\"  # use BGR colorspace by default\nself.__logging = logging\nself.__frame_size_reduction = 25  # use 25% reduction\n# retrieve interpolation for reduction\nself.__interpolation = retrieve_best_interpolation(\n[\"INTER_LINEAR_EXACT\", \"INTER_LINEAR\", \"INTER_AREA\"]\n)\ncustom_data_location = \"\"  # path to save data-files to custom location\ndata_path = \"\"  # path to WebGear data-files\noverwrite_default = False\nself.__enable_inf = False  # continue frames even when video ends.\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# assign values to global variables if specified and valid\nif options:\n# check whether to disable Data-Files Auto-Generation WorkFlow\nif \"skip_generate_webdata\" in options:\nvalue = options[\"skip_generate_webdata\"]\n# enable jpeg fastdct\nif isinstance(value, bool):\nself.__skip_generate_webdata = value\nelse:\nlogger.warning(\"Skipped invalid `skip_generate_webdata` value!\")\ndel options[\"skip_generate_webdata\"]  # clean\nif \"jpeg_compression_colorspace\" in options:\nvalue = options[\"jpeg_compression_colorspace\"]\nif isinstance(value, str) and value.strip().upper() in [\n\"RGB\",\n\"BGR\",\n\"RGBX\",\n\"BGRX\",\n\"XBGR\",\n\"XRGB\",\n\"GRAY\",\n\"RGBA\",\n\"BGRA\",\n\"ABGR\",\n\"ARGB\",\n\"CMYK\",\n]:\n# set encoding colorspace\nself.__jpeg_compression_colorspace = value.strip().upper()\nelse:\nlogger.warning(\n\"Skipped invalid `jpeg_compression_colorspace` value!\"\n)\ndel options[\"jpeg_compression_colorspace\"]  # clean\nif \"jpeg_compression_quality\" in options:\nvalue = options[\"jpeg_compression_quality\"]\n# set valid jpeg quality\nif isinstance(value, (int, float)) and value &gt;= 10 and value &lt;= 100:\nself.__jpeg_compression_quality = int(value)\nelse:\nlogger.warning(\"Skipped invalid `jpeg_compression_quality` value!\")\ndel options[\"jpeg_compression_quality\"]  # clean\nif \"jpeg_compression_fastdct\" in options:\nvalue = options[\"jpeg_compression_fastdct\"]\n# enable jpeg fastdct\nif isinstance(value, bool):\nself.__jpeg_compression_fastdct = value\nelse:\nlogger.warning(\"Skipped invalid `jpeg_compression_fastdct` value!\")\ndel options[\"jpeg_compression_fastdct\"]  # clean\nif \"jpeg_compression_fastupsample\" in options:\nvalue = options[\"jpeg_compression_fastupsample\"]\n# enable jpeg  fastupsample\nif isinstance(value, bool):\nself.__jpeg_compression_fastupsample = value\nelse:\nlogger.warning(\n\"Skipped invalid `jpeg_compression_fastupsample` value!\"\n)\ndel options[\"jpeg_compression_fastupsample\"]  # clean\nif \"frame_size_reduction\" in options:\nvalue = options[\"frame_size_reduction\"]\nif isinstance(value, (int, float)) and value &gt;= 0 and value &lt;= 90:\nself.__frame_size_reduction = value\nelse:\nlogger.warning(\"Skipped invalid `frame_size_reduction` value!\")\ndel options[\"frame_size_reduction\"]  # clean\nif \"custom_data_location\" in options:\nvalue = options[\"custom_data_location\"]\nif isinstance(value, str):\nassert os.access(\nvalue, os.W_OK\n), \"[WebGear:ERROR] :: Permission Denied!, cannot write WebGear data-files to '{}' directory!\".format(\nvalue\n)\nassert os.path.isdir(\nos.path.abspath(value)\n), \"[WebGear:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\ncustom_data_location = os.path.abspath(value)\nelse:\nlogger.warning(\"Skipped invalid `custom_data_location` value!\")\ndel options[\"custom_data_location\"]  # clean\nif \"overwrite_default_files\" in options:\nvalue = options[\"overwrite_default_files\"]\nif isinstance(value, bool):\noverwrite_default = value\nelse:\nlogger.warning(\"Skipped invalid `overwrite_default_files` value!\")\ndel options[\"overwrite_default_files\"]  # clean\nif \"enable_infinite_frames\" in options:\nvalue = options[\"enable_infinite_frames\"]\nif isinstance(value, bool):\nself.__enable_inf = value\nelse:\nlogger.warning(\"Skipped invalid `enable_infinite_frames` value!\")\ndel options[\"enable_infinite_frames\"]  # clean\n# check if disable Data-Files Auto-Generation WorkFlow is disabled\nif not self.__skip_generate_webdata:\n# check if custom data path is specified\nif custom_data_location:\ndata_path = generate_webdata(\ncustom_data_location,\nc_name=\"webgear\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\nelse:\n# otherwise generate suitable path\ndata_path = generate_webdata(\nos.path.join(expanduser(\"~\"), \".vidgear\"),\nc_name=\"webgear\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\n# log it\nself.__logging and logger.debug(\n\"`{}` is the default location for saving WebGear data-files.\".format(\ndata_path\n)\n)\n# define Jinja2 templates handler\nself.__templates = Jinja2Templates(\ndirectory=\"{}/templates\".format(data_path)\n)\n# define routing tables\nself.routes = [\nRoute(\"/\", endpoint=self.__homepage),\nRoute(\"/video\", endpoint=self.__video),\nMount(\n\"/static\",\napp=StaticFiles(directory=\"{}/static\".format(data_path)),\nname=\"static\",\n),\n]\nelse:\n# log it\nself.__logging and logger.critical(\n\"WebGear Data-Files Auto-Generation WorkFlow has been manually disabled.\"\n)\n# define routing tables\nself.routes = [\nRoute(\"/video\", endpoint=self.__video),\n]\n# log exceptions\nself.__logging and logger.warning(\n\"Only `/video` route is available for this instance.\"\n)\n# define custom exception handlers\nself.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n# define middleware support\nself.middleware = []\n# Handle video source\nif source is None:\nself.config = {\"generator\": None}\nself.__stream = None\nelse:\n# define stream with necessary params\nself.__stream = VideoGear(\nenablePiCamera=enablePiCamera,\nstabilize=stabilize,\nsource=source,\ncamera_num=camera_num,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nresolution=resolution,\nframerate=framerate,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# define default frame generator in configuration\nself.config = {\"generator\": self.__producer}\n# log if specified\nif self.__logging:\nif source is None:\nlogger.warning(\n\"Given source is of NoneType. Therefore, JPEG Frame-Compression is disabled!\"\n)\nelse:\nlogger.debug(\n\"Enabling JPEG Frame-Compression with Colorspace:`{}`, Quality:`{}`%, Fastdct:`{}`, and Fastupsample:`{}`.\".format(\nself.__jpeg_compression_colorspace,\nself.__jpeg_compression_quality,\n\"enabled\" if self.__jpeg_compression_fastdct else \"disabled\",\n\"enabled\"\nif self.__jpeg_compression_fastupsample\nelse \"disabled\",\n)\n)\n# copying original routing tables for further validation\nself.__rt_org_copy = self.routes[:]\n# initialize blank frame\nself.blank_frame = None\n# keeps check if producer loop should be running\nself.__isrunning = True\n</code></pre>"},{"location":"bonus/reference/webgear/#vidgear.gears.asyncio.webgear.WebGear.shutdown","title":"<code>shutdown(self)</code>","text":"<p>Implements a Callable to be run on application shutdown</p> Source code in <code>vidgear/gears/asyncio/webgear.py</code> <pre><code>def shutdown(self):\n\"\"\"\n    Implements a Callable to be run on application shutdown\n    \"\"\"\nif not (self.__stream is None):\nself.__logging and logger.debug(\"Closing Video Streaming.\")\n# stops producer\nself.__isrunning = False\n# stops VideoGear stream\nself.__stream.stop()\n# prevent any re-iteration\nself.__stream = None\n</code></pre>"},{"location":"bonus/reference/webgear_rtc/","title":"WebGear_RTC API","text":"<p>WebGear_RTC API usage examples can be found here \u27b6</p> <p>WebGear_RTC API parameters are explained here \u27b6</p> <p>WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms.</p> <p>WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.</p> <p>WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to easily establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom Server as a source to transform frames easily before sending them across the network(see this doc example).</p> <p>WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.</p> <p>Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs.</p> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>class WebGear_RTC:\n\"\"\"\n    WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which\n    makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on\n    all major platforms.\n    WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time\n    Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive\n    Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.\n    WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment)\n    protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to easily\n    establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom Server\n    as a source to transform frames easily before sending them across the network(see this doc example).\n    WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of\n    shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.\n    Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both\n    CamGear and PiGear APIs.\n    \"\"\"\ndef __init__(\nself,\nenablePiCamera=False,\nstabilize=False,\nsource=None,\ncamera_num=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nresolution=(640, 480),\nframerate=25,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the WebGear_RTC class.\n        Parameters:\n            enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n            stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n            camera_num (int): selects the camera module index which will be used as Rpi source.\n            resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n            framerate (int/float): sets the framerate of the Rpi source.\n            source (based on input): defines the source for the input stream.\n            stream_mode (bool): controls the exclusive YouTube Mode.\n            backend (int): selects the backend for OpenCV's VideoCapture class.\n            colorspace (str): selects the colorspace of the input stream.\n            logging (bool): enables/disables logging.\n            time_delay (int): time delay (in sec) before start reading the frames.\n            options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear &amp; Stabilizer.\n        \"\"\"\n# raise error(s) for critical Class imports\nimport_dependency_safe(\"starlette\" if starlette is None else \"\")\nimport_dependency_safe(\"aiortc\" if aiortc is None else \"\")\n# initialize global params\nself.__logging = logging\ncustom_data_location = \"\"  # path to save data-files to custom location\ndata_path = \"\"  # path to WebGear_RTC data-files\noverwrite_default = False\nself.__relay = None  # act as broadcaster\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# assign values to global variables if specified and valid\nif options:\nif \"custom_data_location\" in options:\nvalue = options[\"custom_data_location\"]\nif isinstance(value, str):\nassert os.access(\nvalue, os.W_OK\n), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to '{}' directory!\".format(\nvalue\n)\nassert os.path.isdir(\nos.path.abspath(value)\n), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\ncustom_data_location = os.path.abspath(value)\nelse:\nlogger.warning(\"Skipped invalid `custom_data_location` value!\")\ndel options[\"custom_data_location\"]  # clean\nif \"overwrite_default_files\" in options:\nvalue = options[\"overwrite_default_files\"]\nif isinstance(value, bool):\noverwrite_default = value\nelse:\nlogger.warning(\"Skipped invalid `overwrite_default_files` value!\")\ndel options[\"overwrite_default_files\"]  # clean\nif \"enable_live_broadcast\" in options:\nvalue = options[\"enable_live_broadcast\"]\nif isinstance(value, bool):\nif value:\nself.__relay = MediaRelay()\noptions[\n\"enable_infinite_frames\"\n] = True  # enforce infinite frames\nlogger.critical(\n\"Enabled live broadcasting for Peer connection(s).\"\n)\nelse:\nNone\nelse:\nlogger.warning(\"Skipped invalid `enable_live_broadcast` value!\")\ndel options[\"enable_live_broadcast\"]  # clean\n# check if custom certificates path is specified\nif custom_data_location:\ndata_path = generate_webdata(\ncustom_data_location,\nc_name=\"webgear_rtc\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\nelse:\n# otherwise generate suitable path\ndata_path = generate_webdata(\nos.path.join(expanduser(\"~\"), \".vidgear\"),\nc_name=\"webgear_rtc\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\n# log it\nself.__logging and logger.debug(\n\"`{}` is the default location for saving WebGear_RTC data-files.\".format(\ndata_path\n)\n)\n# define Jinja2 templates handler\nself.__templates = Jinja2Templates(directory=\"{}/templates\".format(data_path))\n# define custom exception handlers\nself.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n# define routing tables\nself.routes = [\nRoute(\"/\", endpoint=self.__homepage),\nRoute(\"/offer\", self.__offer, methods=[\"GET\", \"POST\"]),\nMount(\n\"/static\",\napp=StaticFiles(directory=\"{}/static\".format(data_path)),\nname=\"static\",\n),\n]\n# define middleware support\nself.middleware = []\n# Handle RTC video server\nif \"custom_stream\" in options or not (source is None):\n# Handle video source\nself.__default_rtc_server = RTC_VideoServer(\nenablePiCamera=enablePiCamera,\nstabilize=stabilize,\nsource=source,\ncamera_num=camera_num,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nresolution=resolution,\nframerate=framerate,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# add exclusive reset connection node\nself.routes.append(\nRoute(\"/close_connection\", self.__reset_connections, methods=[\"POST\"])\n)\nelse:\nraise ValueError(\n\"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\"\n)\n# copying original routing tables for further validation\nself.__rt_org_copy = self.routes[:]\n# collects peer RTC connections\nself.__pcs = set()\ndef __call__(self):\n\"\"\"\n        Implements a custom Callable method for WebGear_RTC application.\n        \"\"\"\n# validate routing tables\nassert not (self.routes is None), \"Routing tables are NoneType!\"\nif not isinstance(self.routes, list) or not all(\nx in self.routes for x in self.__rt_org_copy\n):\nraise RuntimeError(\"[WebGear_RTC:ERROR] :: Routing tables are not valid!\")\n# validate middlewares\nassert not (self.middleware is None), \"Middlewares are NoneType!\"\nif self.middleware and (\nnot isinstance(self.middleware, list)\nor not all(isinstance(x, Middleware) for x in self.middleware)\n):\nraise RuntimeError(\"[WebGear_RTC:ERROR] :: Middlewares are not valid!\")\n# return Starlette application\nself.__logging and logger.debug(\"Running Starlette application.\")\nreturn Starlette(\ndebug=(True if self.__logging else False),\nroutes=self.routes,\nmiddleware=self.middleware,\nexception_handlers=self.__exception_handlers,\non_shutdown=[self.__on_shutdown],\n)\nasync def __offer(self, request):\n\"\"\"\n        Generates JSON Response with a WebRTC Peer Connection of Video Server.\n        \"\"\"\n# get offer from params\nparams = await request.json()\noffer = RTCSessionDescription(sdp=params[\"sdp\"], type=params[\"type\"])\n# initiate stream\nif not (self.__default_rtc_server is None) and not (\nself.__default_rtc_server.is_launched\n):\nself.__logging and logger.debug(\"Initiating Video Streaming.\")\nself.__default_rtc_server.launch()\n# setup RTC peer connection - interface represents a WebRTC connection\n# between the local computer and a remote peer.\npc = RTCPeerConnection()\nself.__pcs.add(pc)\nself.__logging and logger.info(\"Created WebRTC Peer Connection.\")\n# track ICE connection state changes\n@pc.on(\"iceconnectionstatechange\")\nasync def on_iceconnectionstatechange():\nlogger.debug(\"ICE connection state is %s\" % pc.iceConnectionState)\nif pc.iceConnectionState == \"failed\":\nlogger.error(\"ICE connection state failed.\")\n# check if Live Broadcasting is enabled\nif self.__relay is None:\n# if not, close connection.\nawait pc.close()\nself.__pcs.discard(pc)\n# Change the remote description associated with the connection.\nawait pc.setRemoteDescription(offer)\n# retrieve list of RTCRtpTransceiver objects that are currently attached to the connection\nfor t in pc.getTransceivers():\n# Increments performance significantly, IDK why this works as H265 codec is not even supported :D\ncapabilities = RTCRtpSender.getCapabilities(\"video\")\npreferences = list(filter(lambda x: x.name == \"H265\", capabilities.codecs))\nt.setCodecPreferences(preferences)\n# add video server to peer track\nif t.kind == \"video\":\npc.addTrack(\nself.__relay.subscribe(self.__default_rtc_server)\nif not (self.__relay is None)\nelse self.__default_rtc_server\n)\n# Create an SDP answer to an offer received from a remote peer\nanswer = await pc.createAnswer()\n# Change the local description for the answer\nawait pc.setLocalDescription(answer)\n# return Starlette json response\nreturn JSONResponse(\n{\"sdp\": pc.localDescription.sdp, \"type\": pc.localDescription.type}\n)\nasync def __homepage(self, request):\n\"\"\"\n        Return an HTML index page.\n        \"\"\"\nreturn self.__templates.TemplateResponse(\"index.html\", {\"request\": request})\nasync def __not_found(self, request, exc):\n\"\"\"\n        Return an HTML 404 page.\n        \"\"\"\nreturn self.__templates.TemplateResponse(\n\"404.html\", {\"request\": request}, status_code=404\n)\nasync def __server_error(self, request, exc):\n\"\"\"\n        Return an HTML 500 page.\n        \"\"\"\nreturn self.__templates.TemplateResponse(\n\"500.html\", {\"request\": request}, status_code=500\n)\nasync def __reset_connections(self, request):\n\"\"\"\n        Resets all connections and recreates VideoServer timestamps\n        \"\"\"\n# get additional parameter\nparameter = await request.json()\n# check if Live Broadcasting is enabled\nif (\nself.__relay is None\nand not (self.__default_rtc_server is None)\nand (self.__default_rtc_server.is_running)\n):\nlogger.critical(\"Resetting Server\")\n# close old peer connections\nif parameter != 0:  # disable if specified explicitly\ncoros = [pc.close() for pc in self.__pcs]\nawait asyncio.gather(*coros)\nself.__pcs.clear()\nawait self.__default_rtc_server.reset()\nreturn PlainTextResponse(\"OK\")\nelse:\n# if does, then do nothing\nreturn PlainTextResponse(\"DISABLED\")\nasync def __on_shutdown(self):\n\"\"\"\n        Implements a Callable to be run on application shutdown\n        \"\"\"\n# close Video Server\nself.shutdown()\n# collects peer RTC connections\ncoros = [pc.close() for pc in self.__pcs]\nawait asyncio.gather(*coros)\nself.__pcs.clear()\ndef shutdown(self):\n\"\"\"\n        Gracefully shutdown video-server\n        \"\"\"\nif not (self.__default_rtc_server is None):\nself.__logging and logger.debug(\"Closing Video Server.\")\nself.__default_rtc_server.terminate()\nself.__default_rtc_server = None\n# terminate internal server aswell.\nself.__default_rtc_server = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.__call__","title":"<code>__call__(self)</code>  <code>special</code>","text":"<p>Implements a custom Callable method for WebGear_RTC application.</p> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>def __call__(self):\n\"\"\"\n    Implements a custom Callable method for WebGear_RTC application.\n    \"\"\"\n# validate routing tables\nassert not (self.routes is None), \"Routing tables are NoneType!\"\nif not isinstance(self.routes, list) or not all(\nx in self.routes for x in self.__rt_org_copy\n):\nraise RuntimeError(\"[WebGear_RTC:ERROR] :: Routing tables are not valid!\")\n# validate middlewares\nassert not (self.middleware is None), \"Middlewares are NoneType!\"\nif self.middleware and (\nnot isinstance(self.middleware, list)\nor not all(isinstance(x, Middleware) for x in self.middleware)\n):\nraise RuntimeError(\"[WebGear_RTC:ERROR] :: Middlewares are not valid!\")\n# return Starlette application\nself.__logging and logger.debug(\"Running Starlette application.\")\nreturn Starlette(\ndebug=(True if self.__logging else False),\nroutes=self.routes,\nmiddleware=self.middleware,\nexception_handlers=self.__exception_handlers,\non_shutdown=[self.__on_shutdown],\n)\n</code></pre>"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.__init__","title":"<code>__init__(self, enablePiCamera=False, stabilize=False, source=None, camera_num=0, stream_mode=False, backend=0, colorspace=None, resolution=(640, 480), framerate=25, logging=False, time_delay=0, **options)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the WebGear_RTC class.</p> <p>Parameters:</p> Name Type Description Default <code>enablePiCamera</code> <code>bool</code> <p>provide access to PiGear(if True) or CamGear(if False) APIs respectively.</p> <code>False</code> <code>stabilize</code> <code>bool</code> <p>enable access to Stabilizer Class for stabilizing frames.</p> <code>False</code> <code>camera_num</code> <code>int</code> <p>selects the camera module index which will be used as Rpi source.</p> <code>0</code> <code>resolution</code> <code>tuple</code> <p>sets the resolution (i.e. <code>(width,height)</code>) of the Rpi source.</p> <code>(640, 480)</code> <code>framerate</code> <code>int/float</code> <p>sets the framerate of the Rpi source.</p> <code>25</code> <code>source</code> <code>based on input</code> <p>defines the source for the input stream.</p> <code>None</code> <code>stream_mode</code> <code>bool</code> <p>controls the exclusive YouTube Mode.</p> <code>False</code> <code>backend</code> <code>int</code> <p>selects the backend for OpenCV's VideoCapture class.</p> <code>0</code> <code>colorspace</code> <code>str</code> <p>selects the colorspace of the input stream.</p> <code>None</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>time_delay</code> <code>int</code> <p>time delay (in sec) before start reading the frames.</p> <code>0</code> <code>options</code> <code>dict</code> <p>provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear &amp; Stabilizer.</p> <code>{}</code> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>def __init__(\nself,\nenablePiCamera=False,\nstabilize=False,\nsource=None,\ncamera_num=0,\nstream_mode=False,\nbackend=0,\ncolorspace=None,\nresolution=(640, 480),\nframerate=25,\nlogging=False,\ntime_delay=0,\n**options\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the WebGear_RTC class.\n    Parameters:\n        enablePiCamera (bool): provide access to PiGear(if True) or CamGear(if False) APIs respectively.\n        stabilize (bool): enable access to Stabilizer Class for stabilizing frames.\n        camera_num (int): selects the camera module index which will be used as Rpi source.\n        resolution (tuple): sets the resolution (i.e. `(width,height)`) of the Rpi source.\n        framerate (int/float): sets the framerate of the Rpi source.\n        source (based on input): defines the source for the input stream.\n        stream_mode (bool): controls the exclusive YouTube Mode.\n        backend (int): selects the backend for OpenCV's VideoCapture class.\n        colorspace (str): selects the colorspace of the input stream.\n        logging (bool): enables/disables logging.\n        time_delay (int): time delay (in sec) before start reading the frames.\n        options (dict): provides ability to alter Tweak Parameters of WebGear_RTC, CamGear, PiGear &amp; Stabilizer.\n    \"\"\"\n# raise error(s) for critical Class imports\nimport_dependency_safe(\"starlette\" if starlette is None else \"\")\nimport_dependency_safe(\"aiortc\" if aiortc is None else \"\")\n# initialize global params\nself.__logging = logging\ncustom_data_location = \"\"  # path to save data-files to custom location\ndata_path = \"\"  # path to WebGear_RTC data-files\noverwrite_default = False\nself.__relay = None  # act as broadcaster\n# reformat dictionary\noptions = {str(k).strip(): v for k, v in options.items()}\n# assign values to global variables if specified and valid\nif options:\nif \"custom_data_location\" in options:\nvalue = options[\"custom_data_location\"]\nif isinstance(value, str):\nassert os.access(\nvalue, os.W_OK\n), \"[WebGear_RTC:ERROR] :: Permission Denied!, cannot write WebGear_RTC data-files to '{}' directory!\".format(\nvalue\n)\nassert os.path.isdir(\nos.path.abspath(value)\n), \"[WebGear_RTC:ERROR] :: `custom_data_location` value must be the path to a directory and not to a file!\"\ncustom_data_location = os.path.abspath(value)\nelse:\nlogger.warning(\"Skipped invalid `custom_data_location` value!\")\ndel options[\"custom_data_location\"]  # clean\nif \"overwrite_default_files\" in options:\nvalue = options[\"overwrite_default_files\"]\nif isinstance(value, bool):\noverwrite_default = value\nelse:\nlogger.warning(\"Skipped invalid `overwrite_default_files` value!\")\ndel options[\"overwrite_default_files\"]  # clean\nif \"enable_live_broadcast\" in options:\nvalue = options[\"enable_live_broadcast\"]\nif isinstance(value, bool):\nif value:\nself.__relay = MediaRelay()\noptions[\n\"enable_infinite_frames\"\n] = True  # enforce infinite frames\nlogger.critical(\n\"Enabled live broadcasting for Peer connection(s).\"\n)\nelse:\nNone\nelse:\nlogger.warning(\"Skipped invalid `enable_live_broadcast` value!\")\ndel options[\"enable_live_broadcast\"]  # clean\n# check if custom certificates path is specified\nif custom_data_location:\ndata_path = generate_webdata(\ncustom_data_location,\nc_name=\"webgear_rtc\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\nelse:\n# otherwise generate suitable path\ndata_path = generate_webdata(\nos.path.join(expanduser(\"~\"), \".vidgear\"),\nc_name=\"webgear_rtc\",\noverwrite_default=overwrite_default,\nlogging=logging,\n)\n# log it\nself.__logging and logger.debug(\n\"`{}` is the default location for saving WebGear_RTC data-files.\".format(\ndata_path\n)\n)\n# define Jinja2 templates handler\nself.__templates = Jinja2Templates(directory=\"{}/templates\".format(data_path))\n# define custom exception handlers\nself.__exception_handlers = {404: self.__not_found, 500: self.__server_error}\n# define routing tables\nself.routes = [\nRoute(\"/\", endpoint=self.__homepage),\nRoute(\"/offer\", self.__offer, methods=[\"GET\", \"POST\"]),\nMount(\n\"/static\",\napp=StaticFiles(directory=\"{}/static\".format(data_path)),\nname=\"static\",\n),\n]\n# define middleware support\nself.middleware = []\n# Handle RTC video server\nif \"custom_stream\" in options or not (source is None):\n# Handle video source\nself.__default_rtc_server = RTC_VideoServer(\nenablePiCamera=enablePiCamera,\nstabilize=stabilize,\nsource=source,\ncamera_num=camera_num,\nstream_mode=stream_mode,\nbackend=backend,\ncolorspace=colorspace,\nresolution=resolution,\nframerate=framerate,\nlogging=logging,\ntime_delay=time_delay,\n**options\n)\n# add exclusive reset connection node\nself.routes.append(\nRoute(\"/close_connection\", self.__reset_connections, methods=[\"POST\"])\n)\nelse:\nraise ValueError(\n\"[WebGear_RTC:ERROR] :: Source cannot be NoneType without Custom Stream(`custom_stream`) defined!\"\n)\n# copying original routing tables for further validation\nself.__rt_org_copy = self.routes[:]\n# collects peer RTC connections\nself.__pcs = set()\n</code></pre>"},{"location":"bonus/reference/webgear_rtc/#vidgear.gears.asyncio.webgear_rtc.WebGear_RTC.shutdown","title":"<code>shutdown(self)</code>","text":"<p>Gracefully shutdown video-server</p> Source code in <code>vidgear/gears/asyncio/webgear_rtc.py</code> <pre><code>def shutdown(self):\n\"\"\"\n    Gracefully shutdown video-server\n    \"\"\"\nif not (self.__default_rtc_server is None):\nself.__logging and logger.debug(\"Closing Video Server.\")\nself.__default_rtc_server.terminate()\nself.__default_rtc_server = None\n# terminate internal server aswell.\nself.__default_rtc_server = None\n</code></pre>"},{"location":"bonus/reference/writegear/","title":"WriteGear API","text":"<p>WriteGear API usage examples for: Compression Mode \u27b6 and Non-Compression Mode \u27b6</p> <p>WriteGear API parameters are explained for: Compression Mode \u27b6 and Non-Compression Mode \u27b6</p> <p>WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data.</p> <p>WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specification (such asbitrate, codec, framerate, resolution, subtitles, etc.). It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code.</p> <p>Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function without relying on any third-party API.</p> <p>In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.</p> Modes of Operation <p>WriteGear primarily operates in following modes:</p> <ul> <li> <p>Compression Mode: In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files.                         This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly,                         and while doing that it robustly handles all errors/warnings quietly.</p> </li> <li> <p>Non-Compression Mode: In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all                             parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters                             and other important features like video compression, audio encoding, etc.</p> </li> </ul> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>class WriteGear:\n\"\"\"\n    WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data.\n    WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless\n    compressed video-file with any suitable specification (such asbitrate, codec, framerate, resolution, subtitles, etc.). It is powerful enough to perform complex tasks such as\n    Live-Streaming (such as for Twitch) and Multiplexing Video-Audio with real-time frames in way fewer lines of code.\n    Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function without relying on any\n    third-party API.\n    In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.\n    ??? tip \"Modes of Operation\"\n        WriteGear primarily operates in following modes:\n        * **Compression Mode**: In this mode, WriteGear utilizes powerful **FFmpeg** inbuilt encoders to encode lossless multimedia files.\n                                This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly,\n                                and while doing that it robustly handles all errors/warnings quietly.\n        * **Non-Compression Mode**: In this mode, WriteGear utilizes basic **OpenCV's inbuilt VideoWriter API** tools. This mode also supports all\n                                    parameters manipulation available within VideoWriter API, but it lacks the ability to manipulate encoding parameters\n                                    and other important features like video compression, audio encoding, etc.\n    \"\"\"\ndef __init__(\nself,\noutput=\"\",\ncompression_mode=True,\ncustom_ffmpeg=\"\",\nlogging=False,\n**output_params\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the WriteGear class.\n        Parameters:\n            output (str): sets the valid filename/path/URL for encoding.\n            compression_mode (bool): selects the WriteGear's Primary Mode of Operation.\n            custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n            logging (bool): enables/disables logging.\n            output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities.\n        \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# check if user not using depreciated `output_filename` parameter\nassert (\nnot \"output_filename\" in output_params\n), \"[WriteGear:ERROR] :: The `output_filename` parameter has been renamed to `output`. Refer Docs for more info.\"\n# assign parameter values to class variables\n# enables compression if enabled\nself.__compression = (\ncompression_mode if isinstance(compression_mode, bool) else False\n)\n# specifies if machine in-use is running Windows OS or not\nself.__os_windows = True if os.name == \"nt\" else False\n# enable logging if specified\nself.__logging = logging if isinstance(logging, bool) else False\n# initialize various important class variables\nself.__output_parameters = {}  # handles output parameters\nself.__inputheight = None  # handles input frames height\nself.__inputwidth = None  # handles input frames width\nself.__inputchannels = None  # handles input frames channels\nself.__inputdtype = None  # handles input frames dtype\nself.__process = None  # handles Encoding class/process\nself.__ffmpeg = \"\"  # handles valid FFmpeg binaries location\nself.__initiate_process = (\nTrue  # handles initiate one-time process for generating pipeline\n)\nself.__out_file = None  # handles output\ngstpipeline_mode = False  # handles GStreamer Pipeline Mode\n# handles output\nif not output:\n# raise error otherwise\nraise ValueError(\n\"[WriteGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more info.\"\n)\nelse:\n# validate output is a system file/directory\n# and Whether WriteGear has the write rights\n# to specified file/directory or not\nabs_path = os.path.abspath(output)\nif check_WriteAccess(\nos.path.dirname(abs_path),\nis_windows=self.__os_windows,\nlogging=self.__logging,\n):\n# check if given path is directory\nif os.path.isdir(abs_path):\n# then, auto-assign valid name and adds it to path\nabs_path = os.path.join(\nabs_path,\n\"VidGear-{}.mp4\".format(time.strftime(\"%Y%m%d-%H%M%S\")),\n)\n# assign output file absolute\n# path to class variable if valid\nself.__out_file = abs_path\nelse:\n# log note otherwise\nlogger.info(\n\"`{}` isn't a valid system path or directory. Skipped!\".format(\noutput\n)\n)\n# cleans and reformat output parameters\nself.__output_parameters = {\nstr(k).strip(): str(v).strip()\nif not isinstance(v, (list, tuple, int, float))\nelse v\nfor k, v in output_params.items()\n}\n# log it if specified\nself.__logging and logger.debug(\n\"Output Parameters: `{}`\".format(self.__output_parameters)\n)\n# handles FFmpeg binaries validity\n# in Compression mode\nif self.__compression:\n# log it if specified\nself.__logging and logger.debug(\n\"Compression Mode is enabled therefore checking for valid FFmpeg executable.\"\n)\n# handles where to save the downloaded FFmpeg Static Binaries\n# on Windows(if specified)\n__ffmpeg_download_path = self.__output_parameters.pop(\n\"-ffmpeg_download_path\", \"\"\n)\n# check if value is valid\nif not isinstance(__ffmpeg_download_path, (str)):\n# reset improper values\n__ffmpeg_download_path = \"\"\n# handle user-defined output resolution (must be a tuple or list)\n# in Compression Mode only.\nself.__output_dimensions = self.__output_parameters.pop(\n\"-output_dimensions\", None\n)\n# check if value is valid\nif not isinstance(self.__output_dimensions, (list, tuple)):\n# reset improper values\nself.__output_dimensions = None\n# handle user defined input framerate of encoding pipeline\n# in Compression Mode only.\nself.__inputframerate = self.__output_parameters.pop(\n\"-input_framerate\", 0.0\n)\n# check if value is valid\nif not isinstance(self.__inputframerate, (float, int)):\n# reset improper values\nself.__inputframerate = 0.0\nelse:\n# must be float\nself.__inputframerate = float(self.__inputframerate)\n# handle user-defined input frames pixel-format in Compression Mode only.\nself.__inputpixfmt = self.__output_parameters.pop(\"-input_pixfmt\", None)\n# check if value is valid\nif not isinstance(self.__inputpixfmt, str):\n# reset improper values\nself.__inputpixfmt = None\nelse:\n# must be exact\nself.__inputpixfmt = self.__inputpixfmt.strip()\n# handle user-defined FFmpeg command pre-headers(must be a list)\n# in Compression Mode only.\nself.__ffmpeg_preheaders = self.__output_parameters.pop(\"-ffpreheaders\", [])\n# check if value is valid\nif not isinstance(self.__ffmpeg_preheaders, list):\n# reset improper values\nself.__ffmpeg_preheaders = []\n# handle the special-case of forced-termination (only for Compression mode)\ndisable_force_termination = self.__output_parameters.pop(\n\"-disable_force_termination\",\nFalse if (\"-i\" in self.__output_parameters) else True,\n)\n# check if value is valid\nif isinstance(disable_force_termination, bool):\nself.__forced_termination = not (disable_force_termination)\nelse:\n# handle improper values\nself.__forced_termination = (\nTrue if (\"-i\" in self.__output_parameters) else False\n)\n# validate the FFmpeg path/binaries and returns valid executable FFmpeg\n# location/path (also auto-downloads static binaries on Windows OS)\nself.__ffmpeg = get_valid_ffmpeg_path(\ncustom_ffmpeg,\nself.__os_windows,\nffmpeg_download_path=__ffmpeg_download_path,\nlogging=self.__logging,\n)\n# check if valid executable FFmpeg location/path\nif self.__ffmpeg:\n# log it if found\nself.__logging and logger.debug(\n\"Found valid FFmpeg executable: `{}`.\".format(self.__ffmpeg)\n)\nelse:\n# otherwise disable Compression Mode\n# and switch to Non-compression mode\nlogger.warning(\n\"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\"\n)\nif self.__logging and not self.__os_windows:\nlogger.debug(\n\"Kindly install a working FFmpeg module or provide a valid custom FFmpeg binary path. See docs for more info.\"\n)\n# compression mode disabled\nself.__compression = False\nelse:\n# handle GStreamer Pipeline Mode (only for Non-compression mode)\nif \"-gst_pipeline_mode\" in self.__output_parameters:\n# check if value is valid\nif isinstance(self.__output_parameters[\"-gst_pipeline_mode\"], bool):\ngstpipeline_mode = self.__output_parameters[\n\"-gst_pipeline_mode\"\n] and check_gstreamer_support(logging=logging)\nself.__logging and logger.debug(\n\"GStreamer Pipeline Mode successfully activated!\"\n)\nelse:\n# reset improper values\ngstpipeline_mode = False\n# log it\nself.__logging and logger.warning(\n\"GStreamer Pipeline Mode failed to activate!\"\n)\n# handle output differently in Compression/Non-compression Modes\nif self.__compression and self.__ffmpeg:\n# check if output falls in exclusive cases\nif self.__out_file is None:\nif (\nplatform.system() == \"Linux\"\nand pathlib.Path(output).is_char_device()\n):\n# check whether output is a Linux video device path (such as `/dev/video0`)\nself.__logging and logger.debug(\n\"Path:`{}` is a valid Linux Video Device path.\".format(output)\n)\nself.__out_file = output\nelif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\n# check whether output is a valid URL instead\nself.__logging and logger.debug(\n\"URL:`{}` is valid and successfully configured for streaming.\".format(\noutput\n)\n)\nself.__out_file = output\nelse:\n# raise error otherwise\nraise ValueError(\n\"[WriteGear:ERROR] :: output value:`{}` is not supported in Compression Mode.\".format(\noutput\n)\n)\n# log if forced termination is enabled\nself.__forced_termination and logger.debug(\n\"Forced termination is enabled for this FFmpeg process.\"\n)\n# log Compression is enabled\nself.__logging and logger.debug(\n\"Compression Mode with FFmpeg backend is configured properly.\"\n)\nelse:\n# raise error if not valid input\nif self.__out_file is None and not gstpipeline_mode:\nraise ValueError(\n\"[WriteGear:ERROR] :: output value:`{}` is not supported in Non-Compression Mode.\".format(\noutput\n)\n)\n# check if GStreamer Pipeline Mode is enabled\nif gstpipeline_mode:\n# enforce GStreamer backend\nself.__output_parameters[\"-backend\"] = \"CAP_GSTREAMER\"\n# enforce original output value\nself.__out_file = output\n# log it\nself.__logging and logger.debug(\n\"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\"\n)\n# log if Compression is disabled\nlogger.critical(\n\"Compression Mode is disabled, Activating OpenCV built-in Writer!\"\n)\ndef write(self, frame, rgb_mode=False):\n\"\"\"\n        Pipelines `ndarray` frames to respective API _(**FFmpeg** in Compression Mode &amp; **OpenCV's VideoWriter API** in Non-Compression Mode)_.\n        Parameters:\n            frame (ndarray): a valid numpy frame\n            rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_.\n        \"\"\"\nif frame is None:  # None-Type frames will be skipped\nreturn\n# get height, width, number of channels, and dtype of current frame\nheight, width = frame.shape[:2]\nchannels = frame.shape[-1] if frame.ndim == 3 else 1\ndtype = frame.dtype\n# assign values to class variables on first run\nif self.__initiate_process:\nself.__inputheight = height\nself.__inputwidth = width\nself.__inputchannels = channels\nself.__inputdtype = dtype\nself.__logging and logger.debug(\n\"InputFrame =&gt; Height:{} Width:{} Channels:{} Datatype:{}\".format(\nself.__inputheight,\nself.__inputwidth,\nself.__inputchannels,\nself.__inputdtype,\n)\n)\n# validate frame size\nif height != self.__inputheight or width != self.__inputwidth:\nraise ValueError(\n\"[WriteGear:ERROR] :: All video-frames must have same size!\"\n)\n# validate number of channels in frame\nif channels != self.__inputchannels:\nraise ValueError(\n\"[WriteGear:ERROR] :: All video-frames must have same number of channels!\"\n)\n# validate frame datatype\nif dtype != self.__inputdtype:\nraise ValueError(\n\"[WriteGear:ERROR] :: All video-frames must have same datatype!\"\n)\n# checks if compression mode is enabled\nif self.__compression:\n# initiate FFmpeg process on first run\nif self.__initiate_process:\n# start pre-processing of FFmpeg parameters, and initiate process\nself.__PreprocessFFParams(channels, dtype=dtype, rgb=rgb_mode)\n# Check status of the process\nassert self.__process is not None\ntry:\n# try writing the frame bytes to the subprocess pipeline\nself.__process.stdin.write(frame.tobytes())\nexcept (OSError, IOError):\n# log if something is wrong!\nlogger.error(\n\"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe. Kindly Refer Docs!\"\n)\nraise ValueError  # for testing purpose only\nelse:\n# otherwise initiate OpenCV's VideoWriter Class process\nif self.__initiate_process:\n# start VideoWriter Class process\nself.__start_CVProcess()\n# Check status of the process\nassert self.__process is not None\n# log one-time OpenCV warning\nself.__logging and logger.info(\n\"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet. Kindly switch on `compression_mode` to use them!\"\n)\n# write frame directly to\n# VideoWriter Class process\nself.__process.write(frame)\ndef __PreprocessFFParams(self, channels, dtype=None, rgb=False):\n\"\"\"\n        Internal method that pre-processes FFmpeg Parameters before beginning to pipeline frames.\n        Parameters:\n            channels (int): Number of channels in input frame.\n            dtype (str): Datatype of input frame.\n            rgb_mode (boolean): Whether to activate `RGB mode`?\n        \"\"\"\n# turn off initiate flag\nself.__initiate_process = False\n# initialize input parameters\ninput_parameters = {}\n# handle output frames dimensions\ndimensions = \"\"\nif self.__output_dimensions is None:  # check if dimensions are given\ndimensions += \"{}x{}\".format(\nself.__inputwidth, self.__inputheight\n)  # auto derive from frame\nelse:\ndimensions += \"{}x{}\".format(\nself.__output_dimensions[0], self.__output_dimensions[1]\n)  # apply if defined\ninput_parameters[\"-s\"] = str(dimensions)\n# handles user-defined and auto-assigned input pixel-formats\nif not (\nself.__inputpixfmt is None\n) and self.__inputpixfmt in get_supported_pixfmts(self.__ffmpeg):\n# assign directly if valid\ninput_parameters[\"-pix_fmt\"] = self.__inputpixfmt\nelse:\n# handles pix_fmt based on channels and dtype(HACK)\nif dtype.kind == \"u\" and dtype.itemsize == 2:\n# handle pix_fmt for frames with higher than 8-bit depth\npix_fmt = None\nif channels == 1:\npix_fmt = \"gray16\"\nelif channels == 2:\npix_fmt = \"ya16\"\nelif channels == 3:\npix_fmt = \"rgb48\" if rgb else \"bgr48\"\nelif channels == 4:\npix_fmt = \"rgba64\" if rgb else \"bgra64\"\nelse:\n# raise error otherwise\nraise ValueError(\n\"[WriteGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\"\n)\n# Add endianness suffix (w.r.t byte-order)\ninput_parameters[\"-pix_fmt\"] = pix_fmt + (\n\"be\" if dtype.byteorder == \"&gt;\" else \"le\"\n)\nelse:\n# handle pix_fmt for frames with exactly 8-bit depth(`uint8`)\nif channels == 1:\ninput_parameters[\"-pix_fmt\"] = \"gray\"\nelif channels == 2:\ninput_parameters[\"-pix_fmt\"] = \"ya8\"\nelif channels == 3:\ninput_parameters[\"-pix_fmt\"] = \"rgb24\" if rgb else \"bgr24\"\nelif channels == 4:\ninput_parameters[\"-pix_fmt\"] = \"rgba\" if rgb else \"bgra\"\nelse:\n# raise error otherwise\nraise ValueError(\n\"[WriteGear:ERROR] :: Frames with channels outside range 1-to-4 are not supported!\"\n)\n# handles user-defined output video framerate\nif self.__inputframerate &gt; 0.0:\n# assign input framerate if valid\nself.__logging and logger.debug(\n\"Setting Input framerate: {}\".format(self.__inputframerate)\n)\ninput_parameters[\"-framerate\"] = str(self.__inputframerate)\n# initiate FFmpeg process\nself.__start_FFProcess(\ninput_params=input_parameters, output_params=self.__output_parameters\n)\ndef __start_FFProcess(self, input_params, output_params):\n\"\"\"\n        An Internal method that launches FFmpeg subprocess pipeline in Compression Mode\n        for pipelining frames to `stdin`.\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# convert input parameters to argument list\ninput_parameters = dict2Args(input_params)\n# handle output video encoder.\n# get list of supported video-encoders\nsupported_vcodecs = get_supported_vencoders(self.__ffmpeg)\n# dynamically select default encoder\ndefault_vcodec = [\nvcodec\nfor vcodec in [\"libx264\", \"libx265\", \"libxvid\", \"mpeg4\"]\nif vcodec in supported_vcodecs\n][0] or \"unknown\"\n# extract any user-defined encoder\nif \"-c:v\" in output_params:\n# assign it to the pipeline\noutput_params[\"-vcodec\"] = output_params.pop(\"-c:v\", default_vcodec)\nif not \"-vcodec\" in output_params:\n# auto-assign default video-encoder (if not assigned by user).\noutput_params[\"-vcodec\"] = default_vcodec\nif (\ndefault_vcodec != \"unknown\"\nand not output_params[\"-vcodec\"] in supported_vcodecs\n):\n# reset to default if not supported\nlogger.critical(\n\"Provided FFmpeg does not support `{}` video-encoder. Switching to default supported `{}` encoder!\".format(\noutput_params[\"-vcodec\"], default_vcodec\n)\n)\noutput_params[\"-vcodec\"] = default_vcodec\n# assign optimizations based on selected video encoder(if any)\nif output_params[\"-vcodec\"] in supported_vcodecs:\nif output_params[\"-vcodec\"] in [\"libx265\", \"libx264\"]:\nif not \"-crf\" in output_params:\noutput_params[\"-crf\"] = \"18\"\nif not \"-preset\" in output_params:\noutput_params[\"-preset\"] = \"fast\"\nif output_params[\"-vcodec\"] in [\"libxvid\", \"mpeg4\"]:\nif not \"-qscale:v\" in output_params:\noutput_params[\"-qscale:v\"] = \"3\"\nelse:\n# raise error otherwise\nraise RuntimeError(\n\"[WriteGear:ERROR] :: Provided FFmpeg does not support any suitable/usable video-encoders for compression.\"\n\" Kindly disable compression mode or switch to another FFmpeg binaries(if available).\"\n)\n# convert output parameters to argument list\noutput_parameters = dict2Args(output_params)\n# format FFmpeg command\ncmd = (\n[self.__ffmpeg, \"-y\"]\n+ self.__ffmpeg_preheaders\n+ [\"-f\", \"rawvideo\", \"-vcodec\", \"rawvideo\"]\n+ input_parameters\n+ [\"-i\", \"-\"]\n+ output_parameters\n+ [self.__out_file]\n)\n# Launch the process with FFmpeg command\nif self.__logging:\n# log command in logging mode\nlogger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n# In logging mode\nself.__process = sp.Popen(cmd, stdin=sp.PIPE, stdout=sp.PIPE, stderr=None)\nelse:\n# In silent mode\nself.__process = sp.Popen(\ncmd, stdin=sp.PIPE, stdout=sp.DEVNULL, stderr=sp.STDOUT\n)\ndef __enter__(self):\n\"\"\"\n        Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        **Returns:** Returns a reference to the WriteGear Class\n        \"\"\"\nreturn self\ndef __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"\n        Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        \"\"\"\nself.close()\ndef execute_ffmpeg_cmd(self, command=None):\n\"\"\"\n        Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only).\n        Parameters:\n            command (list): inputs list data-type command.\n        \"\"\"\n# check if valid command\nif command is None or not (command):\nlogger.warning(\"Input command is empty, Nothing to execute!\")\nreturn\nelse:\nif not (isinstance(command, list)):\nraise ValueError(\n\"[WriteGear:ERROR] :: Invalid input command datatype! Kindly read docs.\"\n)\n# check if Compression Mode is enabled\nif not (self.__compression):\n# raise error otherwise\nraise RuntimeError(\n\"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\"\n)\n# add configured FFmpeg path\ncmd = [self.__ffmpeg] + command\ntry:\n# write frames to pipeline\nif self.__logging:\n# log command in logging mode\nlogger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n# In logging mode\nsp.run(cmd, stdin=sp.PIPE, stdout=sp.PIPE, stderr=None)\nelse:\n# In silent mode\nsp.run(cmd, stdin=sp.PIPE, stdout=sp.DEVNULL, stderr=sp.STDOUT)\nexcept (OSError, IOError):\n# raise error and log if something is wrong.\nlogger.error(\n\"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\"\n)\nraise ValueError  # for testing purpose only\ndef __start_CVProcess(self):\n\"\"\"\n        An Internal method that launches OpenCV VideoWriter process in Non-Compression\n        Mode with given settings.\n        \"\"\"\n# turn off initiate flag\nself.__initiate_process = False\n# initialize essential variables\nFPS = 0\nBACKEND = \"\"\nFOURCC = 0\nCOLOR = True\n# pre-assign default parameters (if not assigned by user).\nif \"-fourcc\" not in self.__output_parameters:\nFOURCC = cv2.VideoWriter_fourcc(*\"MJPG\")\nif \"-fps\" not in self.__output_parameters:\nFPS = 25\n# auto-assign frame dimensions\nHEIGHT = self.__inputheight\nWIDTH = self.__inputwidth\n# assign dict parameter values to variables\ntry:\nfor key, value in self.__output_parameters.items():\nif key == \"-fourcc\":\nFOURCC = cv2.VideoWriter_fourcc(*(value.upper()))\nelif key == \"-fps\":\nFPS = int(value)\nelif key == \"-backend\":\nBACKEND = capPropId(value.upper())\nelif key == \"-color\":\nCOLOR = bool(value)\nelse:\npass\nexcept Exception as e:\n# log and raise error if something is wrong\nself.__logging and logger.exception(str(e))\nraise ValueError(\n\"[WriteGear:ERROR] :: Wrong Values passed to OpenCV Writer, Kindly Refer Docs!\"\n)\n# log values for debugging\nself.__logging and logger.debug(\n\"FILE_PATH: {}, FOURCC = {}, FPS = {}, WIDTH = {}, HEIGHT = {}, BACKEND = {}\".format(\nself.__out_file, FOURCC, FPS, WIDTH, HEIGHT, BACKEND\n)\n)\n# start different OpenCV VideoCapture processes\n# for with and without Backend.\nif BACKEND:\nself.__process = cv2.VideoWriter(\nself.__out_file,\napiPreference=BACKEND,\nfourcc=FOURCC,\nfps=FPS,\nframeSize=(WIDTH, HEIGHT),\nisColor=COLOR,\n)\nelse:\nself.__process = cv2.VideoWriter(\nself.__out_file,\nfourcc=FOURCC,\nfps=FPS,\nframeSize=(WIDTH, HEIGHT),\nisColor=COLOR,\n)\n# check if OpenCV VideoCapture is opened successfully\nassert (\nself.__process.isOpened()\n), \"[WriteGear:ERROR] :: Failed to intialize OpenCV Writer!\"\ndef close(self):\n\"\"\"\n        Safely terminates various WriteGear process.\n        \"\"\"\n# log termination\nif self.__logging:\nlogger.debug(\"Terminating WriteGear Processes.\")\n# handle termination separately\nif self.__compression:\n# when Compression Mode is enabled\nif self.__process is None or not (self.__process.poll() is None):\n# return if no process initiated\n# at first place\nreturn\n# close `stdin` output\nself.__process.stdin and self.__process.stdin.close()\n# close `stdout` output\nself.__process.stdout and self.__process.stdout.close()\n# forced termination if specified.\nself.__forced_termination and self.__process.terminate()\n# wait if process is still processing\nself.__process.wait()\nelse:\n# when Compression Mode is disabled\nif self.__process is None:\n# return if no process initiated\n# at first place\nreturn\n# close it\nself.__process.release()\n# discard process\nself.__process = None\n</code></pre> <p> </p>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__enter__","title":"<code>__enter__(self)</code>  <code>special</code>","text":"<p>Handles entry with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> <p>Returns: Returns a reference to the WriteGear Class</p> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def __enter__(self):\n\"\"\"\n    Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    **Returns:** Returns a reference to the WriteGear Class\n    \"\"\"\nreturn self\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__exit__","title":"<code>__exit__(self, exc_type, exc_val, exc_tb)</code>  <code>special</code>","text":"<p>Handles exit with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"\n    Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    \"\"\"\nself.close()\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.__init__","title":"<code>__init__(self, output='', compression_mode=True, custom_ffmpeg='', logging=False, **output_params)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the WriteGear class.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>str</code> <p>sets the valid filename/path/URL for encoding.</p> <code>''</code> <code>compression_mode</code> <code>bool</code> <p>selects the WriteGear's Primary Mode of Operation.</p> <code>True</code> <code>custom_ffmpeg</code> <code>str</code> <p>assigns the location of custom path/directory for custom FFmpeg executables.</p> <code>''</code> <code>logging</code> <code>bool</code> <p>enables/disables logging.</p> <code>False</code> <code>output_params</code> <code>dict</code> <p>provides the flexibility to control supported internal parameters and FFmpeg properities.</p> <code>{}</code> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def __init__(\nself,\noutput=\"\",\ncompression_mode=True,\ncustom_ffmpeg=\"\",\nlogging=False,\n**output_params\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the WriteGear class.\n    Parameters:\n        output (str): sets the valid filename/path/URL for encoding.\n        compression_mode (bool): selects the WriteGear's Primary Mode of Operation.\n        custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executables.\n        logging (bool): enables/disables logging.\n        output_params (dict): provides the flexibility to control supported internal parameters and FFmpeg properities.\n    \"\"\"\n# print current version\nlogcurr_vidgear_ver(logging=logging)\n# check if user not using depreciated `output_filename` parameter\nassert (\nnot \"output_filename\" in output_params\n), \"[WriteGear:ERROR] :: The `output_filename` parameter has been renamed to `output`. Refer Docs for more info.\"\n# assign parameter values to class variables\n# enables compression if enabled\nself.__compression = (\ncompression_mode if isinstance(compression_mode, bool) else False\n)\n# specifies if machine in-use is running Windows OS or not\nself.__os_windows = True if os.name == \"nt\" else False\n# enable logging if specified\nself.__logging = logging if isinstance(logging, bool) else False\n# initialize various important class variables\nself.__output_parameters = {}  # handles output parameters\nself.__inputheight = None  # handles input frames height\nself.__inputwidth = None  # handles input frames width\nself.__inputchannels = None  # handles input frames channels\nself.__inputdtype = None  # handles input frames dtype\nself.__process = None  # handles Encoding class/process\nself.__ffmpeg = \"\"  # handles valid FFmpeg binaries location\nself.__initiate_process = (\nTrue  # handles initiate one-time process for generating pipeline\n)\nself.__out_file = None  # handles output\ngstpipeline_mode = False  # handles GStreamer Pipeline Mode\n# handles output\nif not output:\n# raise error otherwise\nraise ValueError(\n\"[WriteGear:ERROR] :: Kindly provide a valid `output` value. Refer Docs for more info.\"\n)\nelse:\n# validate output is a system file/directory\n# and Whether WriteGear has the write rights\n# to specified file/directory or not\nabs_path = os.path.abspath(output)\nif check_WriteAccess(\nos.path.dirname(abs_path),\nis_windows=self.__os_windows,\nlogging=self.__logging,\n):\n# check if given path is directory\nif os.path.isdir(abs_path):\n# then, auto-assign valid name and adds it to path\nabs_path = os.path.join(\nabs_path,\n\"VidGear-{}.mp4\".format(time.strftime(\"%Y%m%d-%H%M%S\")),\n)\n# assign output file absolute\n# path to class variable if valid\nself.__out_file = abs_path\nelse:\n# log note otherwise\nlogger.info(\n\"`{}` isn't a valid system path or directory. Skipped!\".format(\noutput\n)\n)\n# cleans and reformat output parameters\nself.__output_parameters = {\nstr(k).strip(): str(v).strip()\nif not isinstance(v, (list, tuple, int, float))\nelse v\nfor k, v in output_params.items()\n}\n# log it if specified\nself.__logging and logger.debug(\n\"Output Parameters: `{}`\".format(self.__output_parameters)\n)\n# handles FFmpeg binaries validity\n# in Compression mode\nif self.__compression:\n# log it if specified\nself.__logging and logger.debug(\n\"Compression Mode is enabled therefore checking for valid FFmpeg executable.\"\n)\n# handles where to save the downloaded FFmpeg Static Binaries\n# on Windows(if specified)\n__ffmpeg_download_path = self.__output_parameters.pop(\n\"-ffmpeg_download_path\", \"\"\n)\n# check if value is valid\nif not isinstance(__ffmpeg_download_path, (str)):\n# reset improper values\n__ffmpeg_download_path = \"\"\n# handle user-defined output resolution (must be a tuple or list)\n# in Compression Mode only.\nself.__output_dimensions = self.__output_parameters.pop(\n\"-output_dimensions\", None\n)\n# check if value is valid\nif not isinstance(self.__output_dimensions, (list, tuple)):\n# reset improper values\nself.__output_dimensions = None\n# handle user defined input framerate of encoding pipeline\n# in Compression Mode only.\nself.__inputframerate = self.__output_parameters.pop(\n\"-input_framerate\", 0.0\n)\n# check if value is valid\nif not isinstance(self.__inputframerate, (float, int)):\n# reset improper values\nself.__inputframerate = 0.0\nelse:\n# must be float\nself.__inputframerate = float(self.__inputframerate)\n# handle user-defined input frames pixel-format in Compression Mode only.\nself.__inputpixfmt = self.__output_parameters.pop(\"-input_pixfmt\", None)\n# check if value is valid\nif not isinstance(self.__inputpixfmt, str):\n# reset improper values\nself.__inputpixfmt = None\nelse:\n# must be exact\nself.__inputpixfmt = self.__inputpixfmt.strip()\n# handle user-defined FFmpeg command pre-headers(must be a list)\n# in Compression Mode only.\nself.__ffmpeg_preheaders = self.__output_parameters.pop(\"-ffpreheaders\", [])\n# check if value is valid\nif not isinstance(self.__ffmpeg_preheaders, list):\n# reset improper values\nself.__ffmpeg_preheaders = []\n# handle the special-case of forced-termination (only for Compression mode)\ndisable_force_termination = self.__output_parameters.pop(\n\"-disable_force_termination\",\nFalse if (\"-i\" in self.__output_parameters) else True,\n)\n# check if value is valid\nif isinstance(disable_force_termination, bool):\nself.__forced_termination = not (disable_force_termination)\nelse:\n# handle improper values\nself.__forced_termination = (\nTrue if (\"-i\" in self.__output_parameters) else False\n)\n# validate the FFmpeg path/binaries and returns valid executable FFmpeg\n# location/path (also auto-downloads static binaries on Windows OS)\nself.__ffmpeg = get_valid_ffmpeg_path(\ncustom_ffmpeg,\nself.__os_windows,\nffmpeg_download_path=__ffmpeg_download_path,\nlogging=self.__logging,\n)\n# check if valid executable FFmpeg location/path\nif self.__ffmpeg:\n# log it if found\nself.__logging and logger.debug(\n\"Found valid FFmpeg executable: `{}`.\".format(self.__ffmpeg)\n)\nelse:\n# otherwise disable Compression Mode\n# and switch to Non-compression mode\nlogger.warning(\n\"Disabling Compression Mode since no valid FFmpeg executable found on this machine!\"\n)\nif self.__logging and not self.__os_windows:\nlogger.debug(\n\"Kindly install a working FFmpeg module or provide a valid custom FFmpeg binary path. See docs for more info.\"\n)\n# compression mode disabled\nself.__compression = False\nelse:\n# handle GStreamer Pipeline Mode (only for Non-compression mode)\nif \"-gst_pipeline_mode\" in self.__output_parameters:\n# check if value is valid\nif isinstance(self.__output_parameters[\"-gst_pipeline_mode\"], bool):\ngstpipeline_mode = self.__output_parameters[\n\"-gst_pipeline_mode\"\n] and check_gstreamer_support(logging=logging)\nself.__logging and logger.debug(\n\"GStreamer Pipeline Mode successfully activated!\"\n)\nelse:\n# reset improper values\ngstpipeline_mode = False\n# log it\nself.__logging and logger.warning(\n\"GStreamer Pipeline Mode failed to activate!\"\n)\n# handle output differently in Compression/Non-compression Modes\nif self.__compression and self.__ffmpeg:\n# check if output falls in exclusive cases\nif self.__out_file is None:\nif (\nplatform.system() == \"Linux\"\nand pathlib.Path(output).is_char_device()\n):\n# check whether output is a Linux video device path (such as `/dev/video0`)\nself.__logging and logger.debug(\n\"Path:`{}` is a valid Linux Video Device path.\".format(output)\n)\nself.__out_file = output\nelif is_valid_url(self.__ffmpeg, url=output, logging=self.__logging):\n# check whether output is a valid URL instead\nself.__logging and logger.debug(\n\"URL:`{}` is valid and successfully configured for streaming.\".format(\noutput\n)\n)\nself.__out_file = output\nelse:\n# raise error otherwise\nraise ValueError(\n\"[WriteGear:ERROR] :: output value:`{}` is not supported in Compression Mode.\".format(\noutput\n)\n)\n# log if forced termination is enabled\nself.__forced_termination and logger.debug(\n\"Forced termination is enabled for this FFmpeg process.\"\n)\n# log Compression is enabled\nself.__logging and logger.debug(\n\"Compression Mode with FFmpeg backend is configured properly.\"\n)\nelse:\n# raise error if not valid input\nif self.__out_file is None and not gstpipeline_mode:\nraise ValueError(\n\"[WriteGear:ERROR] :: output value:`{}` is not supported in Non-Compression Mode.\".format(\noutput\n)\n)\n# check if GStreamer Pipeline Mode is enabled\nif gstpipeline_mode:\n# enforce GStreamer backend\nself.__output_parameters[\"-backend\"] = \"CAP_GSTREAMER\"\n# enforce original output value\nself.__out_file = output\n# log it\nself.__logging and logger.debug(\n\"Non-Compression Mode is successfully configured in GStreamer Pipeline Mode.\"\n)\n# log if Compression is disabled\nlogger.critical(\n\"Compression Mode is disabled, Activating OpenCV built-in Writer!\"\n)\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.close","title":"<code>close(self)</code>","text":"<p>Safely terminates various WriteGear process.</p> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def close(self):\n\"\"\"\n    Safely terminates various WriteGear process.\n    \"\"\"\n# log termination\nif self.__logging:\nlogger.debug(\"Terminating WriteGear Processes.\")\n# handle termination separately\nif self.__compression:\n# when Compression Mode is enabled\nif self.__process is None or not (self.__process.poll() is None):\n# return if no process initiated\n# at first place\nreturn\n# close `stdin` output\nself.__process.stdin and self.__process.stdin.close()\n# close `stdout` output\nself.__process.stdout and self.__process.stdout.close()\n# forced termination if specified.\nself.__forced_termination and self.__process.terminate()\n# wait if process is still processing\nself.__process.wait()\nelse:\n# when Compression Mode is disabled\nif self.__process is None:\n# return if no process initiated\n# at first place\nreturn\n# close it\nself.__process.release()\n# discard process\nself.__process = None\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.execute_ffmpeg_cmd","title":"<code>execute_ffmpeg_cmd(self, command=None)</code>","text":"<p>Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only).</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>list</code> <p>inputs list data-type command.</p> <code>None</code> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def execute_ffmpeg_cmd(self, command=None):\n\"\"\"\n    Executes user-defined FFmpeg Terminal command, formatted as a python list(in Compression Mode only).\n    Parameters:\n        command (list): inputs list data-type command.\n    \"\"\"\n# check if valid command\nif command is None or not (command):\nlogger.warning(\"Input command is empty, Nothing to execute!\")\nreturn\nelse:\nif not (isinstance(command, list)):\nraise ValueError(\n\"[WriteGear:ERROR] :: Invalid input command datatype! Kindly read docs.\"\n)\n# check if Compression Mode is enabled\nif not (self.__compression):\n# raise error otherwise\nraise RuntimeError(\n\"[WriteGear:ERROR] :: Compression Mode is disabled, Kindly enable it to access this function.\"\n)\n# add configured FFmpeg path\ncmd = [self.__ffmpeg] + command\ntry:\n# write frames to pipeline\nif self.__logging:\n# log command in logging mode\nlogger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n# In logging mode\nsp.run(cmd, stdin=sp.PIPE, stdout=sp.PIPE, stderr=None)\nelse:\n# In silent mode\nsp.run(cmd, stdin=sp.PIPE, stdout=sp.DEVNULL, stderr=sp.STDOUT)\nexcept (OSError, IOError):\n# raise error and log if something is wrong.\nlogger.error(\n\"BrokenPipeError caught, Wrong command passed to FFmpeg Pipe, Kindly Refer Docs!\"\n)\nraise ValueError  # for testing purpose only\n</code></pre>"},{"location":"bonus/reference/writegear/#vidgear.gears.writegear.WriteGear.write","title":"<code>write(self, frame, rgb_mode=False)</code>","text":"<p>Pipelines <code>ndarray</code> frames to respective API (FFmpeg in Compression Mode &amp; OpenCV's VideoWriter API in Non-Compression Mode).</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>a valid numpy frame</p> required <code>rgb_mode</code> <code>boolean</code> <p>enable this flag to activate RGB mode (i.e. specifies that incoming frames are of RGB format(instead of default BGR).</p> <code>False</code> Source code in <code>vidgear/gears/writegear.py</code> <pre><code>def write(self, frame, rgb_mode=False):\n\"\"\"\n    Pipelines `ndarray` frames to respective API _(**FFmpeg** in Compression Mode &amp; **OpenCV's VideoWriter API** in Non-Compression Mode)_.\n    Parameters:\n        frame (ndarray): a valid numpy frame\n        rgb_mode (boolean): enable this flag to activate RGB mode _(i.e. specifies that incoming frames are of RGB format(instead of default BGR)_.\n    \"\"\"\nif frame is None:  # None-Type frames will be skipped\nreturn\n# get height, width, number of channels, and dtype of current frame\nheight, width = frame.shape[:2]\nchannels = frame.shape[-1] if frame.ndim == 3 else 1\ndtype = frame.dtype\n# assign values to class variables on first run\nif self.__initiate_process:\nself.__inputheight = height\nself.__inputwidth = width\nself.__inputchannels = channels\nself.__inputdtype = dtype\nself.__logging and logger.debug(\n\"InputFrame =&gt; Height:{} Width:{} Channels:{} Datatype:{}\".format(\nself.__inputheight,\nself.__inputwidth,\nself.__inputchannels,\nself.__inputdtype,\n)\n)\n# validate frame size\nif height != self.__inputheight or width != self.__inputwidth:\nraise ValueError(\n\"[WriteGear:ERROR] :: All video-frames must have same size!\"\n)\n# validate number of channels in frame\nif channels != self.__inputchannels:\nraise ValueError(\n\"[WriteGear:ERROR] :: All video-frames must have same number of channels!\"\n)\n# validate frame datatype\nif dtype != self.__inputdtype:\nraise ValueError(\n\"[WriteGear:ERROR] :: All video-frames must have same datatype!\"\n)\n# checks if compression mode is enabled\nif self.__compression:\n# initiate FFmpeg process on first run\nif self.__initiate_process:\n# start pre-processing of FFmpeg parameters, and initiate process\nself.__PreprocessFFParams(channels, dtype=dtype, rgb=rgb_mode)\n# Check status of the process\nassert self.__process is not None\ntry:\n# try writing the frame bytes to the subprocess pipeline\nself.__process.stdin.write(frame.tobytes())\nexcept (OSError, IOError):\n# log if something is wrong!\nlogger.error(\n\"BrokenPipeError caught, Wrong values passed to FFmpeg Pipe. Kindly Refer Docs!\"\n)\nraise ValueError  # for testing purpose only\nelse:\n# otherwise initiate OpenCV's VideoWriter Class process\nif self.__initiate_process:\n# start VideoWriter Class process\nself.__start_CVProcess()\n# Check status of the process\nassert self.__process is not None\n# log one-time OpenCV warning\nself.__logging and logger.info(\n\"RGBA and 16-bit grayscale video frames are not supported by OpenCV yet. Kindly switch on `compression_mode` to use them!\"\n)\n# write frame directly to\n# VideoWriter Class process\nself.__process.write(frame)\n</code></pre>"},{"location":"contribution/PR/","title":"Submitting Pull Request(PR) Guidelines:","text":"<p>The following guidelines tells you how to submit a valid PR for vidGear:</p> <p>Working on your first Pull Request for VidGear?</p> <ul> <li> <p>If you don't know how to contribute to an Open Source Project on GitHub, then You can learn about it from here \u27b6</p> </li> <li> <p>If you're stuck at something, please join our Gitter community channel. We will help you get started!</p> </li> <li> <p>Kindly follow the EXEMPLARY  tag for some finest PR examples.</p> </li> </ul> <p> </p>"},{"location":"contribution/PR/#clone-testing-branch","title":"Clone Testing branch","text":"<p>Base Branch must be <code>testing</code> in your Pull Request</p> <p>Every PR MUST be pushed against VidGear's <code>testing</code> branch only, in order to trigger must needed CI testing workflows. If your's not, then change the base branch to <code>testing</code> \u27b6</p> <p>Make sure the <code>testing</code> branch of your Forked repository is up-to-date with VidGear, before starting working on Pull Request.</p> <p>You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest <code>testing</code> branch as follows:</p> Functions of different VidGear's Github Branches <p>Following are the base branches for VidGear's code in its Github Repository:</p> Master/MainTestingDevelopment <p>Branch Features:</p> <ul> <li>Most-Stable </li> <li>Includes the latest stable-release. </li> <li>Lacks any latest bug-fixes and changes.</li> <li>Everything CI tested.</li> </ul> <p>Cloning:</p> <pre><code># clone your forked repository and `cd` inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n</code></pre> <p>Branch Features:</p> <ul> <li>Stable.</li> <li>Includes latest stable bug-fixes and changes.</li> <li>Used for pushing PR commits. </li> <li>Everything CI tested.</li> </ul> <p>Cloning:</p> <pre><code># clone your forked repository and `cd` inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest testing branch\ngit checkout testing\n</code></pre> <p>Branch Features:</p> <ul> <li> Unstable.</li> <li>Includes latest experimental changes.</li> <li>Used for pushing experimental commits. </li> <li>Nothing CI tested.</li> </ul> <p>Cloning:</p> <pre><code># clone your forked repository and `cd` inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest development branch\ngit checkout development\n</code></pre> <p>Workflow: </p> <p>Typically any feature/improvement/bug-fix code flows as follows:</p> <p> </p> <pre><code># clone your forked repository(change with your username) and get inside\ngit clone https://github.com/{YOUR USERNAME}/vidgear.git &amp;&amp; cd vidgear\n\n# pull any recent updates\ngit pull\n\n# checkout the latest testing branch\ngit checkout testing\n\n# Now create your new branch with suitable name(such as \"subbranch_of_testing\")\ngit checkout -b subbranch_of_testing\n</code></pre> <p>Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.</p> <p> </p> <p> </p>"},{"location":"contribution/PR/#pr-submission-checklist","title":"PR Submission Checklist","text":"<p>There are some important checks you need to perform while submitting your Pull Request(s) for VidGear library:</p> <ul> <li> <p> Submit a Related Issue:</p> </li> <li> <p>The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request.</p> </li> <li> <p> Submit a Draft Pull Request:</p> </li> <li> <p>Submit the draft pull request from the first day of your development.</p> </li> <li>Add a brief but descriptive title for your PR.</li> <li>Explain what the PR adds, fixes, or improves.</li> <li>In case of bug fixes, add a new unit test case that would fail against your bug fix.</li> <li>Provide output or screenshots, if you can.</li> <li>Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against testing branch). If it's somehow failing, then ask the maintainer for a review.</li> <li> <p>Click \"ready for review\" when finished.</p> </li> <li> <p> Test, Format &amp; lint code locally:</p> </li> <li> <p>Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6</p> </li> <li> <p> Make sensible commit messages:</p> </li> <li> <p>If your pull request fixes a separate issue number, remember to include <code>\"resolves #issue_number\"</code> in the commit message. Learn more about it here \u27b6.</p> </li> <li> <p>Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with <code>git commit --amend</code> command.</p> </li> <li> <p> Perform Integrity Checks: </p> <p>Any duplicate pull request will be Rejected!</p> </li> <li> <p>Search GitHub if there's a similar open or closed PR that relates to your submission.</p> </li> <li>Check if your purpose code matches the overall direction, simplicity, and structure of the VidGear and improves it.</li> <li> <p>Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6.</p> </li> <li> <p> Link your Issues:</p> <p>For more information on Linking a pull request to an issue, See this wiki doc\u27b6</p> </li> <li> <p>Finally, when you're confident enough, make your pull request public. </p> </li> <li>You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. </li> </ul> <p> </p> <p> </p>"},{"location":"contribution/PR/#testing-formatting-linting","title":"Testing, Formatting &amp; Linting","text":"<p>All Pull Request(s) must be tested, formatted &amp; linted against our library standards as discussed below:</p>"},{"location":"contribution/PR/#requirements","title":"Requirements","text":"<p>Testing VidGear requires additional test dependencies and dataset, which can be handled manually as follows:</p> <ul> <li> <p> Install additional python libraries:</p> <p>You can easily install these dependencies via pip:</p> MPEGDASH for Windows  <p>The <code>mpegdash</code> library has not yet been updated and bugs on windows machines. Therefore install the forked DEV-version of <code>mpegdash</code> as follows:</p> <pre><code>python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev2/mpegdash-0.3.0.dev2-py3-none-any.whl\n</code></pre> <pre><code>pip install --upgrade six flake8 black pytest pytest-asyncio mpegdash paramiko m3u8 async-asgi-testclient\n</code></pre> </li> <li> <p> Download Tests Dataset: </p> <p>To perform tests, you also need to download additional dataset (to your temp dir) by running <code>prepare_dataset.sh</code>  bash script as follows:</p> <pre><code>chmod +x scripts/bash/prepare_dataset.sh\n# On linux and MacOS\n.scripts/bash/prepare_dataset.sh\n# On Windows \nsh scripts/bash/prepare_dataset.sh\n</code></pre> </li> </ul>"},{"location":"contribution/PR/#running-tests","title":"Running Tests","text":"<p>All tests can be run with <code>pytest</code>(in VidGear's root folder) as follows:</p> <pre><code> pytest -sv  #-sv for verbose output.\n</code></pre>"},{"location":"contribution/PR/#formatting-linting","title":"Formatting &amp; Linting","text":"<p>For formatting and linting, following libraries are used:</p> <ul> <li> <p> Flake8: You must run <code>flake8</code> linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity:</p> <pre><code>flake8 {source_file_or_directory} --count --select=E9,F63,F7,F82 --show-source --statistics\n</code></pre> </li> <li> <p> Black:  Vidgear follows <code>black</code> formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: </p> <pre><code>black {source_file_or_directory}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"contribution/PR/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Q1. Why do my changes taking so long to be Reviewed and/or Merged?</p> <p>Submission Aftermaths</p> <ul> <li>After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.</li> <li>The changes will remain in <code>testing</code> branch until next VidGear version is released, then it will be merged into <code>master</code> branch.</li> <li>After a successful Merge, your newer contributions will be given priority over others. </li> </ul> <p>Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request.</p> <p>Q2. Would you accept a huge Pull Request with Lots of Changes?</p> <p>First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the VidGear Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!</p> <p> </p>"},{"location":"contribution/issue/","title":"Submitting an Issue Guidelines","text":"<p>If you've found a new bug or you've come up with some new feature which can improve the quality of the VidGear, then related issues are welcomed! But, Before you do, please read the following guidelines:</p> First Issue on GitHub? <p>You can easily learn about it from creating an issue wiki.</p> <p>Info</p> <p>Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.</p>"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","title":"Search the Docs and Previous Issues","text":"<ul> <li>Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. </li> <li>For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel.</li> <li>Also, go comprehensively through our dedicated FAQ &amp; Troubleshooting section.</li> </ul>"},{"location":"contribution/issue/#gather-required-information","title":"Gather Required Information","text":"<ul> <li>All VidGear APIs provides a <code>logging</code> boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter <code>True</code> in the respective API for getting debug output, and paste it with your Issue. </li> <li>In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. </li> <li>Check and paste, exact VidGear version by running command <code>python -c \"import vidgear; print(vidgear.__version__)\"</code>.</li> </ul>"},{"location":"contribution/issue/#follow-the-issue-template","title":"Follow the Issue Template","text":"<ul> <li>Please format your issue by choosing the appropriate template. </li> <li>Any improper/insufficient reports will be marked with MISSING : INFORMATION  and MISSING : TEMPLATE  like labels, and if we don't hear back from you we may close the issue.</li> </ul>"},{"location":"contribution/issue/#raise-the-issue","title":"Raise the Issue","text":"<ul> <li>Add a brief but descriptive title for your issue.</li> <li>Keep the issue phrasing in context of the problem.</li> <li>Attach source-code/screenshots if you have one.</li> <li>Finally, raise it by choosing the appropriate Issue Template: Bug report \ud83d\udc1b, Proposal \ud83d\udca1, Question \u2754.</li> </ul>"},{"location":"gears/camgear/overview/","title":"CamGear API","text":"CamGear API's generalized workflow"},{"location":"gears/camgear/overview/#overview","title":"Overview","text":"<p>CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras,  multimedia video file format (upto 4k tested), any network stream URL such as <code>http(s), rtp, rtsp, rtmp, mms, etc.</code> In addition to this, it also supports Gstreamer's RAW pipelines and various live video streaming sites like YouTube, Twitch, Dailymotion etc.</p> <p>CamGear API provides a flexible, high-level multi-threaded wrapper around OpenCV's VideoCapture API with direct access to almost all of its available parameters. It relies on Threaded Queue mode for threaded, error-free and synchronized frame handling.</p> <p>CamGear internally implements <code>yt_dlp</code> backend class for seamlessly pipelining live video-frames and metadata from various streaming services like YouTube, Twitch, and many more \u27b6</p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> <li> <p>You can use <code>framerate</code> class variable to retrieve framerate of the input source. Its usage example can be found here \u27b6</p> </li> </ul> <p> </p>"},{"location":"gears/camgear/overview/#importing","title":"Importing","text":"<p>You can import CamGear API in your program as follows:</p> <pre><code>from vidgear.gears import CamGear\n</code></pre> <p> </p>"},{"location":"gears/camgear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through CamGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/camgear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/camgear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/camgear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/camgear/params/","title":"CamGear API Parameters","text":""},{"location":"gears/camgear/params/#source","title":"<code>source</code>","text":"<p>CamGear API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>CamGear(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>CamGear(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>): </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>CamGear(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>GStreamer Pipelining in WriteGear your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>CamGear(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/camgear/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/camgear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the input stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>CamGear(source=0, colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/camgear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>CamGear(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/camgear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to CamGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nCamGear(source=0, **options)\n</code></pre> <p> </p>"},{"location":"gears/camgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>CamGear(source=0, logging=True)\n</code></pre> <p> </p>"},{"location":"gears/camgear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the CamGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>CamGear(source=0, time_delay=1) # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/","title":"CamGear API Usage Examples:","text":"<p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/camgear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with CamGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = CamGear(source=\"myvideo.avi\").start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-streaming-websites","title":"Using Camgear with Streaming Websites","text":"<p>CamGear internally implements <code>yt_dlp</code> backend class for seamlessly pipelining live video-frames and metadata from various streaming services like Twitch, Vimeo, Dailymotion, and many more \u27b6. All you have to do is to provide the desired Video's URL to its <code>source</code> parameter, and enable its <code>stream_mode</code> parameter. </p> <p>The complete usage example for Dailymotion and Twitch URLs are as follows:</p> Bug in OpenCV's FFmpeg <p>To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos.</p> <p>Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support.</p> <p>Not all resolutions are supported with GStreamer Backend. See issue #244</p> Exclusive CamGear Attributes for <code>yt_dlp</code> backend <p>CamGear also provides exclusive attributes: </p> <ul> <li><code>STREAM_RESOLUTION</code> (for specifying stream resolution)</li> <li><code>STREAM_PARAMS</code> (for specifying  <code>yt_dlp</code> parameters) </li> </ul> <p>with its <code>options</code> dictionary parameter. More information can be found here \u27b6</p> Supported Streaming Websites <p>The list of all supported Streaming Websites URLs can be found here \u27b6</p> Accessing Stream's Metadata  <p>CamGear now provides <code>ytv_metadata</code> global parameter for accessing given Video's metadata as JSON Object. It can used as follows:</p> New in v0.2.4 <p><code>ytv_metadata</code> global parameter was added in <code>v0.2.4</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\n# Add YouTube Video URL as input source (for e.g https://www.dailymotion.com/video/x2yrnum)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\nsource=\"https://www.dailymotion.com/video/x2yrnum\", stream_mode=True, logging=True, **options\n).start()\n# get Video's metadata as JSON object\nvideo_metadata =  stream.ytv_metadata\n# print all available keys\nprint(video_metadata.keys())\n# get data like `title`\nprint(video_metadata[\"title\"])\n</code></pre> Dailymotion Twitch  <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# set desired quality as 720p\noptions = {\"STREAM_RESOLUTION\": \"720p\"}\n# Add any desire Video URL as input source\n# for e.g https://vimeo.com/151666798\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\nsource=\"https://www.dailymotion.com/video/x2yrnum\",\nstream_mode=True,\nlogging=True,\n**options\n).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p>If Twitch user is offline, CamGear will throw ValueError.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# set desired quality as 720p\noptions = {\"STREAM_RESOLUTION\": \"720p\"}\n# Add any desire Video URL as input source\n# for e.g hhttps://www.twitch.tv/shroud\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\nsource=\"https://www.twitch.tv/shroud\",\nstream_mode=True,\nlogging=True,\n**options\n).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-youtube-videos","title":"Using Camgear with Youtube Videos","text":"<p>CamGear API also provides out-of-the-box support for pipelining live video-frames and metadata from  YouTube (Livestream + Normal) Videos. </p> <p>YouTube Playlists  are not supported yet.</p> <p>The complete usage example is as follows:</p> Bug in OpenCV's FFmpeg <p>To workaround a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for Livestream videos.</p> <p>Checkout this FAQ \u27b6 for compiling OpenCV with GStreamer support.</p> <p>Not all resolutions are supported with GStreamer Backend. See issue #244</p> Exclusive CamGear Attributes for <code>yt_dlp</code> backend <p>CamGear also provides exclusive attributes: </p> <ul> <li><code>STREAM_RESOLUTION</code> (for specifying stream resolution)</li> <li><code>STREAM_PARAMS</code> (for specifying  <code>yt_dlp</code> parameters) </li> </ul> <p>with its <code>options</code> dictionary parameter. More information can be found here \u27b6</p> Accessing Stream's Metadata  <p>CamGear now provides <code>ytv_metadata</code> global parameter for accessing given Video's metadata as JSON Object. It can used as follows:</p> New in v0.2.4 <p><code>ytv_metadata</code> global parameter was added in <code>v0.2.4</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\n# Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\nsource=\"https://youtu.be/uCy5OuSQnyA\", stream_mode=True, logging=True, **options\n).start()\n# get Video's metadata as JSON object\nvideo_metadata =  stream.ytv_metadata\n# print all available keys\nprint(video_metadata.keys())\n# get data like `title`\nprint(video_metadata[\"title\"])\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# Add YouTube Video URL as input source (for e.g https://youtu.be/uCy5OuSQnyA)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\nsource=\"https://youtu.be/uCy5OuSQnyA\", \nstream_mode=True,\nlogging=True\n).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-variable-camera-properties","title":"Using CamGear with Variable Camera Properties","text":"<p>CamGear API also flexibly support various Source Tweak Parameters available within OpenCV's VideoCapture API. These tweak parameters can be used to transform input source Camera-Device properties (such as its brightness, saturation, framerate, resolution, gain etc.) seamlessly, and can be easily applied in CamGear API through its <code>options</code> dictionary parameter by formatting them as its attributes. </p> <p>The complete usage example is as follows:</p> <p>All the supported Source Tweak Parameters can be found here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# define suitable tweak parameters for your stream.\noptions = {\n\"CAP_PROP_FRAME_WIDTH\": 320, # resolution 320x240\n\"CAP_PROP_FRAME_HEIGHT\": 240,\n\"CAP_PROP_FPS\": 60, # framerate 60fps\n}\n# To open live video stream on webcam at first index(i.e. 0) \n# device and apply source tweak parameters\nstream = CamGear(source=0, logging=True, **options).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/usage/#using-camgear-with-direct-colorspace-manipulation","title":"Using Camgear with Direct Colorspace Manipulation","text":"<p>CamGear API also supports Direct Colorspace Manipulation, which is ideal for changing source colorspace on the run. </p> <p>A more detailed  information on colorspace manipulation can be found here \u27b6</p> <p>In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY  colorspace when <code>w</code> key is pressed, and then LAB colorspace when <code>e</code> key is pressed, finally default colorspace (i.e. BGR) when <code>s</code> key is pressed. Also, quit when <code>q</code> key is pressed:</p> <p>Any incorrect or None-type value, will immediately revert the colorspace to default i.e. <code>BGR</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# Open any source of your choice, like Webcam first index(i.e. 0)\n# and change its colorspace to `HSV`\nstream = CamGear(source=0, colorspace=\"COLOR_BGR2HSV\", logging=True).start()\n# loop over\nwhile True:\n# read HSV frames\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the HSV frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\n# check if 'w' key is pressed\nif key == ord(\"w\"):\n# directly change colorspace at any instant\nstream.color_space = cv2.COLOR_BGR2GRAY  # Now colorspace is GRAY\n# check for 'e' key is pressed\nif key == ord(\"e\"):\nstream.color_space = cv2.COLOR_BGR2LAB  # Now colorspace is CieLAB\n# check for 's' key is pressed\nif key == ord(\"s\"):\nstream.color_space = None  # Now colorspace is default(ie BGR)\n# check for 'q' key is pressed\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/camgear/advanced/source_params/","title":"Source Tweak Parameters for CamGear API","text":""},{"location":"gears/camgear/advanced/source_params/#overview","title":"Overview","text":"<p>With CamGear's <code>options</code> dictionary parameter, the user has the ability to alter various tweak parameters available within OpenCV's VideoCapture Class by formatting them as its attributes. </p> <p>These tweak parameters can be used to transform input Camera-Source properties (such as its brightness, saturation, resolution, iso, gain etc.) seamlessly. All parameters supported by CamGear API are disscussed in this document.</p> <p> </p>"},{"location":"gears/camgear/advanced/source_params/#exclusive-camgear-attributes","title":"Exclusive CamGear Attributes","text":"CamGear's Exclusive Attributes <p>In addition to Source Tweak Parameters, CamGear also provides some exclusive attributes for its <code>options</code> dictionary parameters. </p> <p>These attributes are as follows:</p> <ul> <li> <p> <code>STREAM_RESOLUTION</code> (string): This attribute can be used in CamGear's Stream Mode (<code>stream_mode=True</code>) for specifying supported stream resolution. Its possible values can be: <code>144p</code>, <code>240p</code>, <code>360p</code>, <code>480p</code>, <code>720p</code>, <code>1080p</code>, <code>1440p</code>, <code>2160p</code>, <code>4320p</code>, <code>worst</code>, <code>best</code>, and its default value is <code>best</code>. Its usage is as follows:</p> <p>In case specificed <code>STREAM_RESOLUTION</code> value is unavailable within Source Stream, it defaults to <code>best</code>!</p> <pre><code>options = {\"STREAM_RESOLUTION\": \"720p\"} # 720p stream will be used. \n</code></pre> <p>Its complete usage example is given here \u27b6</p> </li> <li> <p> <code>STREAM_PARAMS</code> (dict): This dictionary attribute can be used in CamGear's Stream Mode (<code>stream_mode=True</code>) for specifying parameters for its internal <code>yt_dlp</code> backend class. Its usage is as follows:</p> <p>All <code>STREAM_PARAMS</code> Supported Parameters</p> <ul> <li>All yt_dlp parameter can be found here \u27b6</li> </ul> <pre><code>options = {\"STREAM_PARAMS\": {\"nocheckcertificate\": True}} # disables verifying SSL certificates in yt_dlp\n</code></pre> </li> <li> <p> <code>THREADED_QUEUE_MODE</code> (boolean): This attribute can be used to override Threaded-Queue-Mode mode to manually disable it:</p> <p>Disabling Threaded-Queue-Mode can be dangerous! Read more here \u27b6</p> <pre><code>options = {\"THREADED_QUEUE_MODE\": False} # disable Threaded Queue Mode. \n</code></pre> </li> <li> <p> <code>THREAD_TIMEOUT</code> (int/float): This attribute can be used to override the timeout value(positive number), that blocks the video-thread for at most timeout seconds if no video-frame was available within that time, and otherwise raises the Empty exception to prevent any never-ending deadlocks. Its default value is <code>None</code>, meaning no timeout at all.  Its usage is as follows:</p> New in v0.2.1 <p><code>THREAD_TIMEOUT</code> attribute added in <code>v0.2.1</code>.</p> <pre><code>options = {\"THREAD_TIMEOUT\": 300} # set Video-Thread Timeout for 5mins. \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/camgear/advanced/source_params/#supported-source-tweak-parameters","title":"Supported Source Tweak Parameters","text":"<p>All Source Tweak Parameters supported by CamGear API are as follows:</p> <p>Remember, Not all parameters are supported by all cameras devices, which is one of the most troublesome thing with OpenCV library. Each camera type, from android cameras, to USB cameras , to professional ones, offers a different interface to modify its parameters. Therefore, there are many branches in OpenCV code to support as many of them, but of course, not all possible devices are covered, and thereby works. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error.</p> <p>You can easily check parameter values supported by your webcam, by hooking it to a Linux machine, and using the command <code>v4l2-ctl -d 0 --list-formats-ext</code> (where 0 is an index of the given camera) to list the supported video parameters and their values. If that doesn't works, refer to its datasheet (if available).</p> <p>These parameters can be passed to CamGear's <code>options</code> dictionary parameter by formatting them as its string attributes. Its complete usage example is here \u27b6</p> <p> </p> Values Description CAP_PROP_POS_MSEC Current position of the video file in milliseconds. CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next. CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0=start of the film, 1=end of the film. CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream. CAP_PROP_FPS Frame rate. CAP_PROP_FOURCC 4-character code of codec. see VideoWriter::fourcc. CAP_PROP_FRAME_COUNT Number of frames in the video file. CAP_PROP_FORMAT Format of the Mat objects returned by VideoCapture::retrieve(). CAP_PROP_MODE Backend-specific value indicating the current capture mode. CAP_PROP_BRIGHTNESS Brightness of the image (only for those cameras that support). CAP_PROP_CONTRAST Contrast of the image (only for cameras). CAP_PROP_SATURATION Saturation of the image (only for cameras). CAP_PROP_HUE Hue of the image (only for cameras). CAP_PROP_GAIN Gain of the image (only for those cameras that support). CAP_PROP_EXPOSURE Exposure (only for those cameras that support). CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB. CAP_PROP_WHITE_BALANCE_BLUE_U Currently unsupported. CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently). CAP_PROP_MONOCHROME CAP_PROP_SHARPNESS CAP_PROP_AUTO_EXPOSURE DC1394: exposure control done by camera, user can adjust reference level using this feature. CAP_PROP_GAMMA CAP_PROP_TEMPERATURE CAP_PROP_TRIGGER CAP_PROP_TRIGGER_DELAY CAP_PROP_WHITE_BALANCE_RED_V CAP_PROP_ZOOM CAP_PROP_FOCUS CAP_PROP_GUID CAP_PROP_ISO_SPEED CAP_PROP_BACKLIGHT CAP_PROP_PAN CAP_PROP_TILT CAP_PROP_ROLL CAP_PROP_IRIS CAP_PROP_SETTINGS Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored) CAP_PROP_BUFFERSIZE CAP_PROP_AUTOFOCUS CAP_PROP_SAR_NUM Sample aspect ratio: num/den (num) CAP_PROP_SAR_DEN Sample aspect ratio: num/den (den) CAP_PROP_BACKEND Current backend (enum VideoCapture APIs). Read-only property. CAP_PROP_CHANNEL Video input or Channel Number (only for those cameras that support) CAP_PROP_AUTO_WB enable/ disable auto white-balance CAP_PROP_WB_TEMPERATURE white-balance color temperature <p> </p>"},{"location":"gears/netgear/overview/","title":"NetGear API","text":"NetGear API generalized"},{"location":"gears/netgear/overview/#overview","title":"Overview","text":"<p>NetGear is exclusively designed to transfer video frames synchronously and asynchronously between interconnecting systems over the network in real-time.</p> <p>NetGear implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. </p> <p>NetGear also enables real-time JPEG Frame Compression capabilities for boosting performance significantly while sending video-frames over the network in real-time.</p> <p>Lazy Pirate pattern in NetGear API</p> <p>NetGear API now internally implements robust Lazy Pirate pattern (auto-reconnection) for its synchronous messaging patterns(<code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) at both Server and Client ends, where its API instead of doing a blocking receive, will:</p> <ul> <li>Poll the socket and receive from it only when it's sure a reply has arrived.</li> <li>Attempt to reconnect, if no reply has arrived within a timeout period.</li> <li>Abandon the connection if there is still no reply after several requests.</li> </ul> <p>Netgear API also provides <code>max_retries</code> and <code>request_timeout</code> like attributes for controlling this polling.</p> <p>NetGear as of now seamlessly supports three ZeroMQ messaging patterns:</p> <ul> <li> zmq.PAIR (ZMQ Pair Pattern) </li> <li> zmq.REQ/zmq.REP (ZMQ Request/Reply Pattern)</li> <li> zmq.PUB/zmq.SUB (ZMQ Publish/Subscribe Pattern)</li> </ul> <p>whereas the supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> <p> </p>"},{"location":"gears/netgear/overview/#modes-of-operation","title":"Modes of Operation","text":""},{"location":"gears/netgear/overview/#primary-modes","title":"Primary Modes","text":"<p>NetGear API primarily has two modes of operations:</p> <ul> <li> <p>Send Mode: which employs <code>send()</code> function to send video frames over the network in real-time. Activate this mode by setting parameter <code>receive_mode = False</code>.</p> </li> <li> <p>Receive Mode: which employs <code>recv()</code> function to receive frames, sent over the network with Send Mode in real-time. Activate this mode by setting parameter <code>receive_mode = True</code>.</p> </li> </ul>"},{"location":"gears/netgear/overview/#exclusive-modes","title":"Exclusive Modes","text":"<p>In addition to the primary modes, NetGear API also offers application-specific Exclusive Modes:</p> <p>Also, checkout this compatibility chart for these modes interoperability.</p>"},{"location":"gears/netgear/overview/#a-multi-servers-mode","title":"A. Multi-Servers Mode","text":"<ul> <li>In this exclusive mode, NetGear API robustly handles multiple servers at once, thereby providing seamless access to frames and unidirectional data transfer from multiple Servers/Publishers across the network in real-time. </li> <li>Each new Server on the network can be identified on the client's end by using its unique port address. </li> <li>You can learn about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#b-multi-clients-mode","title":"B. Multi-Clients Mode","text":"<ul> <li>In this exclusive mode, NetGear API robustly handles multiple clients at once, thereby providing seamless access to frames and unidirectional data transfer to multiple Client/Consumers across the network in real-time. </li> <li>Each new Client on the network can be uniquely identified on the Server's end by using its unique port address. </li> <li>You can learn about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#c-bidirectional-mode","title":"C. Bidirectional Mode","text":"<ul> <li>This exclusive mode provides seamless support for bidirectional data transmission between between Server and Client along with video frames. </li> <li>Using this mode, the user can now send or receive any data(of any datatype) between Server and Client easily in real-time. </li> <li>You can learn more about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#d-ssh-tunneling-mode","title":"D. SSH Tunneling Mode","text":"<ul> <li>This exclusive mode allows you to connect NetGear via secure SSH connection over the untrusted network and access its intranet services across firewalls. </li> <li>This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. </li> <li>You can learn more about this mode here \u27b6</li> </ul>"},{"location":"gears/netgear/overview/#e-secure-mode","title":"E. Secure Mode","text":"<ul> <li>In this exclusive mode, NetGear API provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers that enables strong encryption on data, and unbreakable authentication between the Server and Client with the help of custom certificates/keys that brings cheap, standardized privacy and authentication for distributed systems over the network. </li> <li>You can learn more about this mode here \u27b6</li> </ul> <p>Important Information</p> <ul> <li> <p>When compiling/installing pyzmq on UNIX systems, it is generally recommended that zeromq binaries to be installed separately, via <code>homebrew, apt, yum, etc.</code> as follows:</p> <pre><code># Debian-based\nsudo apt-get install libzmq3-dev\n\n# RHEL-based\nsudo yum install libzmq3-devel\n\n# OSX-based\nbrew install zeromq\n</code></pre> <p>If zeromq binaries are not found, pyzmq will try to build <code>libzmq</code> as a Python Extension, though this is not guaranteed to work!</p> </li> <li> <p>It is advised to enable logging (<code>logging = True</code>) on the first run, to easily identify any runtime errors.</p> </li> <li> <p>Kindly go through each given Usage Examples thoroughly, any incorrect settings/parameter may result in errors or no output at all.</p> </li> <li> <p>Only either of two functions (i.e. <code>send()</code> and <code>recv()</code>) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using <code>send()</code> function in Receive Mode), will result in <code>ValueError</code>.</p> </li> <li> <p>Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90% in all connections.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/overview/#importing","title":"Importing","text":"<p>You can import NetGear API in your program as follows:</p> <pre><code>from vidgear.gears import NetGear\n</code></pre> <p> </p>"},{"location":"gears/netgear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through NetGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/netgear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/netgear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/netgear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/netgear/params/","title":"NetGear API Parameters","text":""},{"location":"gears/netgear/params/#address","title":"<code>address</code>","text":"<p>This parameter sets the valid Network IP address for Server/Client. Network addresses are unique identifiers across the network. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is based on selected primary mode, i.e <code>'localhost'</code> for Send Mode and <code>'*'</code> for Receive Mode on a local machine.</p> <p>Usage:</p> <pre><code>NetGear(address=\"192.168.0.145\")\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#port","title":"<code>port</code>","text":"<p>This parameter sets the valid Network Port for Server/Client. Network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered.</p> <p>Exception for Exclusive Modes</p> <p>In Multi-Servers Mode:</p> <ul> <li>A unique port number MUST be assigned to each Server on the network using this parameter. </li> <li>At Client end, a List/Tuple of all available Server(s) ports MUST be assigned using this same parameter. </li> <li>See its usage example here \u27b6.</li> </ul> <p>In Multi-Client Mode:</p> <ul> <li>A unique port number MUST be assigned to each Client on the network using this parameter. </li> <li>At Server end, a List/Tuple of all available Client(s) ports MUST be assigned using this same parameter. </li> <li>See its usage example here \u27b6.</li> </ul> <p>Data-Type: String or List/Tuple</p> <p>Default Value: Its default value is <code>'5555'</code></p> <p>Usage:</p> <pre><code>NetGear(port=\"5575\")\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#protocol","title":"<code>protocol</code>","text":"<p>This parameter sets the valid messaging protocol between server and client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: <code>'tcp'</code> and <code>'ipc'</code>.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'tcp'</code></p> <p>Usage:</p> <pre><code>NetGear(protocol=\"ipc\")\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#pattern","title":"<code>pattern</code>","text":"<p>This parameter sets the supported messaging pattern(flow of communication) between server and client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> (i.e <code>zmq.PAIR</code>). </p> <p>Supported ZMQ patterns</p> <p>All supported ZMQ patterns for NetGear are:</p> <ul> <li><code>0</code> (.i.e. zmq.PAIR): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it.</li> <li><code>1</code> (.i.e. zmq.REQ/zmq.REP): In this pattern, it employs <code>ZMQ REQ</code> sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket <code>zmq.REQ</code> will block send unless it has successfully received a reply back and socket <code>zmq.REP</code> will block on recv() unless it has received a request.</li> <li><code>2</code> (.i.e. zmq.PUB/zmq.SUB): It is an another classic pattern where senders of messages, called publishers, do not program the messages to be sent directly to specific receivers, called subscribers. Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A <code>ZMQ.SUB</code> can connect to multiple <code>ZMQ.PUB</code> (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved.</li> </ul> <p>Usage:</p> <pre><code>NetGear(pattern=1) # sets zmq.REQ/zmq.REP pattern\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#receive_mode","title":"<code>receive_mode</code>","text":"<p>This parameter select the Netgear's Mode of operation. It basically activates <code>Receive Mode</code>(if <code>True</code>) and <code>Send Mode</code>(if <code>False</code>). Furthermore, <code>recv()</code> method will only work when this flag is enabled(i.e. <code>Receive Mode</code>), whereas <code>send()</code> method will only work when this flag is disabled(i.e.<code>Send Mode</code>). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>(i.e. Send Mode is activated by default).</p> <p>Usage:</p> <pre><code>NetGear(receive_mode=True) # activates Recieve Mode\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the flexibility to alter various NetGear API's internal properties, modes, and some PyZMQ flags.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code></p> <p>Usage:</p> <p>Supported dictionary attributes for NetGear API</p> <ul> <li> <p><code>multiserver_mode</code> (boolean) : This internal attribute activates the exclusive Multi-Servers Mode, if enabled(<code>True</code>).</p> </li> <li> <p><code>multiclient_mode</code> (boolean) : This internal attribute activates the exclusive Multi-Clients Mode, if enabled(<code>True</code>).</p> </li> <li> <p><code>secure_mode</code> (integer) : This internal attribute selects the exclusive Secure Mode. Its possible values are: <code>0</code>(i.e. Grassland(no security)) or <code>1</code>(i.e. StoneHouse) or <code>2</code>(i.e. IronHouse).</p> </li> <li> <p><code>bidirectional_mode</code> (boolean) : This internal attribute activates the exclusive Bidirectional Mode, if enabled(<code>True</code>).</p> </li> <li> <p><code>ssh_tunnel_mode</code> (string) : This internal attribute activates the exclusive SSH Tunneling Mode at the Server-end only.</p> </li> <li> <p><code>ssh_tunnel_pwd</code> (string): In SSH Tunneling Mode, This internal attribute sets the password required to authorize Host for SSH Connection at the Server-end only. More information can be found here \u27b6</p> </li> <li> <p><code>ssh_tunnel_keyfile</code> (string): In SSH Tunneling Mode, This internal attribute sets path to Host key that provide another way to authenticate host for SSH Connection at the Server-end only. More information can be found here \u27b6</p> </li> <li> <p><code>custom_cert_location</code> (string) : In Secure Mode, This internal attribute assigns user-defined location/path to directory for generating/storing Public+Secret Keypair necessary for encryption. More information can be found here \u27b6</p> </li> <li> <p><code>overwrite_cert</code> (boolean) : In Secure Mode, This internal attribute decides whether to overwrite existing Public+Secret Keypair/Certificates or not, at the Server-end only. More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression</code>(bool/str): This internal attribute is used to activate(if <code>True</code>)/deactivate(if <code>False</code>) JPEG Frame Compression as well as to specify incoming frames colorspace with compression. By default colorspace is <code>BGR</code> and compression is enabled(<code>True</code>). More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression_quality</code>(int/float): This internal attribute controls the JPEG quantization factor in JPEG Frame Compression. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression_fastdct</code>(bool): This internal attributee if True, use fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality in JPEG Frame Compression. Its default value is also <code>True</code>. More information can be found here \u27b6</p> </li> <li> <p><code>jpeg_compression_fastupsample</code>(bool): This internal attribute if True, use fastest color upsampling method. Its default value is <code>False</code>. More information can be found here \u27b6</p> </li> <li> <p><code>max_retries</code>(integer): This internal attribute controls the maximum retries before Server/Client exit itself, if it's unable to get any response/reply from the socket before a certain amount of time, when synchronous messaging patterns like (<code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) are being used. It's value can anything greater than <code>0</code>, and its default value is <code>3</code>.</p> </li> <li> <p><code>request_timeout</code>(integer): This internal attribute controls the timeout value (in seconds), after which the Server/Client exit itself if it's unable to get any response/reply from the socket, when synchronous messaging patterns like (<code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code>) are being used. It's value can anything greater than <code>0</code>, and its default value is <code>10</code> seconds.</p> </li> <li> <p><code>flag</code>(integer): This PyZMQ attribute value can be either <code>0</code> or <code>zmq.NOBLOCK</code>( i.e. 1). More information can be found here \u27b6.</p> </li> <li> <p><code>copy</code>(boolean): This PyZMQ attribute selects if message be received in a copying or non-copying manner. If <code>False</code> a object is returned, if <code>True</code> a string copy of the message is returned.</p> </li> <li> <p><code>track</code>(boolean): This PyZMQ attribute check if the message is tracked for notification that ZMQ has finished with it. (ignored if copy=True).</p> </li> </ul> <p>The desired attributes can be passed to NetGear API as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"secure_mode\": 2,\n\"custom_cert_location\": \"/home/foo/foo1/foo2\",\n\"overwrite_cert\": True,\n\"flag\": 0,\n\"copy\": False,\n\"track\": False,\n}\n# assigning it\nNetGear(logging=True, **options)\n</code></pre> <p> </p>"},{"location":"gears/netgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/","title":"NetGear API Usage Examples:","text":"<p>Danger</p> <ul> <li> <p>Kindly go through each given examples thoroughly, any incorrect settings/parameter may result in errors or no output at all.</p> </li> <li> <p>NetGear provides auto-termination feature, where if you terminate server end manually, the connected client(s) end will also terminate themselves to save resources.</p> </li> <li> <p>Only either of two functions (i.e. <code>send()</code> and <code>recv()</code>) can be accessed at any given instance based on activated primary mode selected during NetGear API initialization. Trying to access wrong function in incorrect mode (for e.g using <code>send()</code> function in Receive Mode), will result in <code>ValueError</code>.</p> </li> </ul> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/netgear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with NetGear API:</p>"},{"location":"gears/netgear/usage/#servers-end","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n# Define Netgear Server with default parameters\nserver = NetGear()\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre>"},{"location":"gears/netgear/usage/#clients-end","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# define Netgear Client with `receive_mode = True` and default parameter\nclient = NetGear(receive_mode=True)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/#using-netgear-with-variable-parameters","title":"Using NetGear with Variable Parameters","text":""},{"location":"gears/netgear/usage/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/usage/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define Netgear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/#using-netgear-with-opencv","title":"Using NetGear with OpenCV","text":"<p>You can easily use NetGear directly with any Video Processing library such as OpenCV itself. The complete usage example is as follows:</p>"},{"location":"gears/netgear/usage/#clients-end_2","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# define tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=0,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the received frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/usage/#servers-end_2","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n# define tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=0,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/usage/#using-netgear-with-other-videocapture-gears","title":"Using NetGear with Other VideoCapture Gears","text":"<p>You can use any VideoCapture Gear in the similar manner. Let's implement given usage example with ScreenGear:</p>"},{"location":"gears/netgear/usage/#clients-end_3","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear/usage/#servers-end_3","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (let's say you want to transmit Monitor Screen Frames from a Laptop), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears import NetGear\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Start capturing live Monitor screen frames with default settings\nstream = ScreenGear().start()\n# Define Netgear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/","title":"Bidirectional Mode for NetGear API","text":"NetGear's Bidirectional Mode"},{"location":"gears/netgear/advanced/bidirectional_mode/#overview","title":"Overview","text":"<p>Bidirectional Mode enables seamless support for Bidirectional data transmission between Client/Consumer and Sender/Publisher along with video-frames through its synchronous messaging patterns such as <code>zmq.PAIR</code> (ZMQ Pair Pattern) &amp; <code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern).</p> <p>In Bidirectional Mode, we utilizes the NetGear API's <code>message</code> parameter of <code>send()</code> method for sending data from Server-to-Client, and <code>return_data</code> parameter of <code>recv()</code> method to return data back from Client-to-Server all while transferring frames in real-time. </p> <p>This mode can be easily activated in NetGear through <code>bidirectional_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Important Information regarding Bidirectional Mode</p> <ul> <li> <p>In Bidirectional Mode, <code>zmq.PAIR</code>(ZMQ Pair) &amp; <code>zmq.REQ/zmq.REP</code>(ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in <code>ValueError</code>.</p> </li> <li> <p>Bidirectional Mode enables you to send data of ANY1 Data-type along with frame bidirectionally.</p> </li> <li> <p>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</p> </li> <li> <p>Bidirectional Mode is smart enough to sense data (if available or not), and DOES NOT interfere with transferring of video-frames (unless data is huge), as both mechanisms works independently.</p> </li> <li> <p>Bidirectional Mode is now compatibile with both Multi-Servers mode and Multi-Clients mode exclusive modes.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#features-of-bidirectional-mode","title":"Features of Bidirectional Mode","text":"<ul> <li> <p> Enables easy-to-use seamless Bidirectional data transmission between two systems.</p> </li> <li> <p> Supports <code>zmq.PAIR</code> &amp; <code>zmq.REQ/zmq.REP</code> messaging patterns.</p> </li> <li> <p> Support for sending data of almost any1 datatype.</p> </li> <li> <p> Auto-enables reconnection if Server or Client disconnects prematurely.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#exclusive-parameters","title":"Exclusive Parameters","text":"<p>To send data bidirectionally, NetGear API provides two exclusive parameters for its methods:</p> <ul> <li> <p><code>message</code>: It enables user to send data to Client, directly through <code>send()</code> method at Server's end. </p> </li> <li> <p><code>return_data</code>: It enables user to send data back to Server, directly through <code>recv()</code> method at Client's end.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#usage-examples","title":"Usage Examples","text":""},{"location":"gears/netgear/advanced/bidirectional_mode/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with Bidirectional Mode in NetGear API:</p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# Define NetGear Server with defined parameters\nserver = NetGear(logging=True, **options)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# send frame &amp; data and also receive data from Client\nrecv_data = server.send(frame, message=target_data) # (1)\n# print data just received from Client\nif not (recv_data is None):\nprint(recv_data)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol>"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, logging=True, **options)\n# loop over\nwhile True:\n# prepare data to be sent\ntarget_data = \"Hi, I am a Client here.\"\n# receive data from server and also send our data\ndata = client.recv(return_data=target_data)\n# check for data if None\nif data is None:\nbreak\n# extract server_data &amp; frame from data\nserver_data, frame = data\n# again check for frame if None\nif frame is None:\nbreak\n# {do something with the extracted frame and data here}\n# lets print extracted server data\nif not (server_data is None):\nprint(server_data)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","title":"Using Bidirectional Mode with Variable Parameters","text":""},{"location":"gears/netgear/advanced/bidirectional_mode/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# Define NetGear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# prepare data to be sent\ntarget_data = \"Hi, I am a Client here.\"\n# receive data from server and also send our data\ndata = client.recv(return_data=target_data)\n# check for data if None\nif data is None:\nbreak\n# extract server_data &amp; frame from data\nserver_data, frame = data\n# again check for frame if None\nif frame is None:\nbreak\n# {do something with the extracted frame and data here}\n# lets print received server data\nif not (server_data is None):\nprint(server_data)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_1","title":"Server End","text":"<p>Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# send frame &amp; data and also receive data from Client\nrecv_data = server.send(frame, message=target_data) # (1)\n# print data just received from Client\nif not (recv_data is None):\nprint(recv_data)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","title":"Using Bidirectional Mode for Video-Frames Transfer","text":"<p>In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. </p> <p>This example is useful for building applications like Real-Time Video Chat.</p> <p>We're also using <code>reducer()</code> method for reducing frame-size on-the-go for additional performance.</p> <p>Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!</p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#server-end_2","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport numpy as np\nimport cv2\n# open any valid video stream(for e.g `test.mp4` file)\nstream = cv2.VideoCapture(\"test.mp4\")\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# reducer frames size if you want more performance, otherwise comment this line\nframe = reducer(frame, percentage=30)  # reduce frame by 30%\n# {do something with the frame here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# send frame &amp; data and also receive data from Client\nrecv_data = server.send(frame, message=target_data) # (1)\n# check data just received from Client is of numpy datatype\nif not (recv_data is None) and isinstance(recv_data, np.ndarray):\n# {do something with received numpy array here}\n# Let's show it on output window\ncv2.imshow(\"Received Frame\", recv_data)\nkey = cv2.waitKey(1) &amp; 0xFF\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#client-end_1","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport cv2\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# again open the same video stream\nstream = cv2.VideoCapture(\"test.mp4\")\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True, **options)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# reducer frames size if you want more performance, otherwise comment this line\nframe = reducer(frame, percentage=30)  # reduce frame by 30%\n# receive data from server and also send our data\ndata = client.recv(return_data=frame)\n# check for data if None\nif data is None:\nbreak\n# extract server_data &amp; frame from data\nserver_data, frame = data\n# again check for frame if None\nif frame is None:\nbreak\n# {do something with the extracted frame and data here}\n# lets print extracted server data\nif not (server_data is None):\nprint(server_data)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression","text":"<p>This usage examples can be found here \u27b6</p> <p> </p> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray data-type is ONLY SUPPORTED at Client's end with its <code>return_data</code> parameter.</p> <p>\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/netgear/advanced/compression/","title":"Frame Compression for NetGear API","text":""},{"location":"gears/netgear/advanced/compression/#overview","title":"Overview","text":"<p>NetGear API enables real-time JPEG Frame Compression capabilities for optimizing performance significantly while sending frames over the network. </p> <p>For enabling Frame Compression, NetGear uses powerful <code>simplejpeg</code> library at its backend, which is based on recent versions of libjpeg-turbo JPEG image codec, to accelerate baseline JPEG compression and decompression on all modern systems. NetGear API employs its exposed <code>decode_jpeg</code> and <code>encode_jpeg</code> methods to encode video-frames to JFIF format  before sending it at Server, and cleverly decode it at the Client(s) all in real-time, thereby leveraging performance at cost of minor loss in frame quality.</p> <p>Frame Compression is enabled by default in NetGear, and can be easily controlled through <code>jpeg_compression_quality</code>, <code>jpeg_compression_fastdct</code>, <code>jpeg_compression_fastupsample</code> like attributes of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Useful Information about Frame Compression</p> <ul> <li>Frame Compression is enabled by default in NetGear along with fast dct and compression-quality at 90%.</li> <li>Exclusive <code>jpeg_compression</code> attribute can also be used to disable Frame Compression.</li> <li>Frame Compression can leverage performance up-to 5-10% with exclusive performance attributes.</li> <li>Frame Compression is compatible with all messaging pattern and modes.</li> </ul> <p>Frame Compression is primarily controlled by Server end. That means, if Frame Compression is enabled at Server, then Client(s) will automatically enforce the Frame Compression with defined performance attributes. Otherwise if it is disabled, then Client(s) disables it too.</p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#exclusive-attributes","title":"Exclusive Attributes","text":"<p>For implementing Frame Compression, NetGear API currently provide following exclusive attribute for its <code>options</code> dictionary parameter to leverage performance with Frame Compression:</p> <ul> <li> <p><code>jpeg_compression</code>:  (bool/str) This internal attribute is used to activate/deactivate JPEG Frame Compression as well as to specify incoming frames colorspace with compression. Its usage is as follows:</p> <ul> <li> <p> For activating JPEG Frame Compression (Boolean):</p> <p>In this case, colorspace will default to <code>BGR</code>.</p> <p>You can set <code>jpeg_compression</code> value to <code>False</code> at Server end to completely disable Frame Compression.</p> <pre><code># enable jpeg encoding\noptions = {\"jpeg_compression\": True}\n</code></pre> </li> <li> <p> For specifying Input frames colorspace (String):</p> <p>In this case, JPEG Frame Compression is activated automatically.</p> <p>Supported colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p> <pre><code># Specify incoming frames are `grayscale`\noptions = {\"jpeg_compression\": \"GRAY\"}\n</code></pre> </li> </ul> </li> <li> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#performance-attributes","title":"Performance Attributes","text":"<ul> <li> <p><code>jpeg_compression_quality</code>: (int/float) This attribute controls the JPEG quantization factor. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. Its usage is as follows:</p> <pre><code># activate jpeg encoding and set quality 95%\noptions = {\"jpeg_compression\": True, \"jpeg_compression_quality\": 95}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastdct</code>: (bool) This attribute if True, NetGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also <code>True</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast dct\noptions = {\"jpeg_compression\": True, \"jpeg_compression_fastdct\": True}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastupsample</code>: (bool) This attribute if True, NetGear API use fastest color upsampling method. Its default value is <code>False</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast upsampling\noptions = {\"jpeg_compression\": True, \"jpeg_compression_fastupsample\": True}\n</code></pre> </li> </ul>"},{"location":"gears/netgear/advanced/compression/#usage-examples","title":"Usage Examples","text":""},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with Frame Compression in NetGear API:</p>"},{"location":"gears/netgear/advanced/compression/#server-end","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n# activate jpeg encoding and specify other related parameters\noptions = {\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/compression/#client-end","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <p>If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes.</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#bare-minimum-usage-with-variable-colorspace","title":"Bare-Minimum Usage with Variable Colorspace","text":"<p>Frame Compression also supports specify incoming frames colorspace with compression. In following bare-minimum code, we will be sending GRAY frames from Server to Client:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6</p> <p>Supported colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p>"},{"location":"gears/netgear/advanced/compression/#server-end_1","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n# open any valid video stream(for e.g `test.mp4` file) and change its colorspace to grayscale\nstream = VideoGear(source=\"test.mp4\", colorspace=\"COLOR_BGR2GRAY\").start()\n# activate jpeg encoding and specify other related parameters\noptions = {\n\"jpeg_compression\": \"GRAY\", # set grayscale\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read grayscale frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# send grayscale frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/compression/#client-end_1","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <p>If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes.</p> <p>Client's end also automatically enforces Server's colorspace, there's no need to define it again.</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True)\n# loop over\nwhile True:\n# receive grayscale frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the grayscale frame here}\n# Show output window\ncv2.imshow(\"Output Grayscale Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#using-frame-compression-with-variable-parameters","title":"Using Frame Compression with Variable Parameters","text":""},{"location":"gears/netgear/advanced/compression/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>If compression is enabled at Server, then Client will automatically enforce Frame Compression with its performance attributes.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# Define NetGear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n#  loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/compression/#server-end_2","title":"Server End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n# activate jpeg encoding and specify other related parameters\noptions = {\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/compression/#using-bidirectional-mode-for-video-frames-transfer-with-frame-compression","title":"Using Bidirectional Mode for Video-Frames Transfer with Frame Compression","text":"<p>NetGear now supports Dual Frame Compression for transferring video-frames with its exclusive Bidirectional Mode for achieving unmatchable performance bidirectionally. You can easily enable Frame Compression with its performance attributes at both ends to boost performance bidirectionally.</p> <p>In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time for testing the real-time performance and synchronization between the Server and Client using Bidirectional Mode. Furthermore, we're going to use optimal Dual Frame Compression Setting for Sending and Receiving frames at both Server and Client end.</p> <p>This example is great for building applications like Real-time Video Chat System.</p> <p>This Dual Frame Compression feature also available for Multi-Clients Mode.</p> <p>We're also using <code>reducer()</code> Helper method for reducing frame-size on-the-go for additional performance.</p> <p>Remember to define Frame Compression's performance attributes both on Server and Client ends in Dual Frame Compression to boost performance bidirectionally!</p>"},{"location":"gears/netgear/advanced/compression/#server-end_3","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport numpy as np\nimport cv2\n# open any valid video stream(for e.g `test.mp4` file)\nstream = cv2.VideoCapture(\"test.mp4\")\n# activate Bidirectional mode and Frame Compression\noptions = {\n\"bidirectional_mode\": True,\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 95,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# reducer frames size if you want even more performance, otherwise comment this line\nframe = reducer(frame, percentage=20)  # reduce frame by 20%\n# {do something with the frame here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# send frame &amp; data and also receive data from Client\nrecv_data = server.send(frame, message=target_data) # (1)\n# check data just received from Client is of numpy datatype\nif not (recv_data is None) and isinstance(recv_data, np.ndarray):\n# {do something with received numpy array here}\n# Let's show it on output window\ncv2.imshow(\"Received Frame\", recv_data)\nkey = cv2.waitKey(1) &amp; 0xFF\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/compression/#client-end_2","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nimport cv2\n# activate Bidirectional mode and Frame Compression\noptions = {\n\"bidirectional_mode\": True,\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 95,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# again open the same video stream\nstream = cv2.VideoCapture(\"test.mp4\")\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(receive_mode=True, pattern=1, logging=True, **options)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# reducer frames size if you want even more performance, otherwise comment this line\nframe = reducer(frame, percentage=20)  # reduce frame by 20%\n# receive data from server and also send our data\ndata = client.recv(return_data=frame)\n# check for data if None\nif data is None:\nbreak\n# extract server_data &amp; frame from data\nserver_data, frame = data\n# again check for frame if None\nif frame is None:\nbreak\n# {do something with the extracted frame and data here}\n# lets print extracted server data\nif not (server_data is None):\nprint(server_data)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/","title":"Multi-Clients Mode for NetGear API","text":"NetGear's Multi-Clients Mode"},{"location":"gears/netgear/advanced/multi_client/#overview","title":"Overview","text":"<p>In Multi-Clients Mode, NetGear robustly handles Multiple Clients at once thereby able to broadcast frames and data across multiple Clients/Consumers in the network at same time. This mode works contrary to Multi-Servers Mode such that every new Client that connects to single Server can be identified by its unique port address on the network. </p> <p>The supported patterns for this mode are Publish/Subscribe (<code>zmq.PUB/zmq.SUB</code>) and Request/Reply(<code>zmq.REQ/zmq.REP</code>) and can be easily activated in NetGear API through <code>multiclient_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p>Multi-Clients Mode is best for broadcasting Meta-Data with Video-frames to specific limited number of clients in real time. But if you're looking to scale broadcast to a very large pool of clients, then see our WebGear or WebGear_RTC APIs.</p> <p> </p> <p>Important Information regarding Multi-Clients Mode</p> <ul> <li> <p>A unique PORT address MUST be assigned to each Client on the network using its <code>port</code> parameter.</p> </li> <li> <p>A list/tuple of PORT addresses of all unique Clients MUST be assigned at Server's end using its <code>port</code> parameter for a successful connection.</p> </li> <li> <p>Patterns <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>) and <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>) are the only supported pattern values for this Mode. Therefore, calling any other pattern value with is mode will result in <code>ValueError</code>.</p> </li> <li> <p>Multi-Clients and Multi-Servers exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw <code>ValueError</code>.</p> </li> <li> <p>The <code>address</code> parameter value of each Client MUST exactly match the Server. </p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#features-of-multi-clients-mode","title":"Features of Multi-Clients Mode","text":"<ul> <li> <p> Enables Multiple Client(s) connection with a single Server.</p> </li> <li> <p> Ability to send any additional data of any datatype along with frames in real-time.</p> </li> <li> <p> Number of Clients can be extended to several numbers depending upon your system's hardware limit.</p> </li> <li> <p> Employs powerful Publish/Subscribe &amp; Request/Reply messaging patterns.</p> </li> <li> <p> Each new Client on the network can be identified at Server's end by their unique port addresses.</p> </li> <li> <p> NetGear API actively tracks the state of each connected Client.</p> </li> <li> <p> If the server gets disconnected, all the clients will automatically exit to save resources.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#usage-examples","title":"Usage Examples","text":"<p>Important</p> <ul> <li> <p>Frame/Data transmission will NOT START until all given Client(s) are connected to the Server.</p> </li> <li> <p>For sake of simplicity, in these examples we will use only two unique Clients, but the number of these Clients can be extended to SEVERAL numbers depending upon your Network bandwidth and System Capabilities.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>In this example, we will capturing live video-frames from a source (a.k.a Server) with a webcam connected to it. Afterwards, those captured frame will be sent over the network to two independent system (a.k.a Clients) using this Multi-Clients Mode in NetGear API. Finally, both Clients will be displaying received frames in Output Windows in real time.</p> <p>This example is useful for building applications like Real-Time Video Broadcasting to multiple clients in local network.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import CamGear\n# Open suitable video stream (webcam on first index in our case)\nstream = CamGear(source=0).start()\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of\n# all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\",\nport=(5567, 5577),\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# Define received data dictionary\ndata_dict = {}\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if not None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame and also receive data from Client(s)\nrecv_data = server.send(frame)\n# check if valid data received\nif not (recv_data is None):\n# extract unique port address and its respective data\nunique_address, data = recv_data\n# update the extracted data in the data dictionary\ndata_dict[unique_address] = data\nif data_dict:\n# print data just received from Client(s)\nfor key, value in data_dict.items():\nprint(\"Client at port {} said: {}\".format(key, value))\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5567\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n) \n# loop over\nwhile True:\n# receive data from server\nframe = client.recv()\n# check for frame if None\nif frame is None:\nbreak\n# {do something with frame here}\n# Show output window\ncv2.imshow(\"Client 5567 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5577\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# receive data from server\nframe = client.recv()\n# check for frame if None\nif frame is None:\nbreak\n# {do something with frame here}\n# Show output window\ncv2.imshow(\"Client 5577 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# Open suitable video stream (webcam on first index in our case)\nstream = cv2.VideoCapture(0)\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\",\nport=(5567, 5577),\nprotocol=\"tcp\",\npattern=2,\nlogging=True,\n**options\n)\n# Define received data dictionary\ndata_dict = {}\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# send frame and also receive data from Client(s)\nrecv_data = server.send(frame)\n# check if valid data received\nif not (recv_data is None):\n# extract unique port address and its respective data\nunique_address, data = recv_data\n# update the extracted data in the data dictionary\ndata_dict[unique_address] = data\nif data_dict:\n# print data just received from Client(s)\nfor key, value in data_dict.items():\nprint(\"Client at port {} said: {}\".format(key, value))\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_1","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5567\",\nprotocol=\"tcp\",\npattern=2,\nreceive_mode=True,\nlogging=True,\n**options\n) \n# loop over\nwhile True:\n# receive data from server\nframe = client.recv()\n# check for frame if None\nif frame is None:\nbreak\n# {do something with frame here}\n# Show output window\ncv2.imshow(\"Client 5567 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_1","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5577\",\nprotocol=\"tcp\",\npattern=2,\nreceive_mode=True,\nlogging=True,\n**options\n) \n# loop over\nwhile True:\n# receive data from server\nframe = client.recv()\n# check for frame if None\nif frame is None:\nbreak\n# {do something with frame here}\n# Show output window\ncv2.imshow(\"Client 5577 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-for-unidirectional-custom-data-transfer","title":"Using Multi-Clients Mode for Unidirectional Custom Data Transfer","text":"<p>Abstract</p> <p>With Multi-Clients Mode, you can also send additional data of any data-type (such as list, tuple, string, int, ndarray etc.) along with frame, from all connected Clients(s) back to  a Server unidirectionally.</p> <p>In Multi-Clients Mode, unidirectional data transfer ONLY works with pattern <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>), and NOT with pattern <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>)!</p> <p>In this example, We will be transferring video-frames from a single Server (consisting of  Raspberry Pi with Camera Module) over the network to two independent Client for displaying them in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) from both the Client(s) back to our Server, which will be printed onto the terminal.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end_2","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import NetGear\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# activate multiclient_mode mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\nserver = NetGear(\naddress=\"192.168.x.x\",\nport=(5577, 5578),\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)  # !!! change following IP address '192.168.x.xxx' with yours !!!\n# Define received data dictionary\ndata_dict = {}\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame and also receive data from Client(s)\nrecv_data = server.send(frame)\n# check if valid data received\nif not (recv_data is None):\n# extract unique port address and its respective data\nunique_address, data = recv_data\n# update the extracted data in the data dictionary\ndata_dict[unique_address] = data\nif data_dict:\n# print data just received from Client(s)\nfor key, value in data_dict.items():\nprint(\"Client at port {} said: {}\".format(key, value))\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_2","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5577\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# prepare data to be sent\ntarget_data = \"Hi, I am 5577 Client here.\"\n# receive data from server and also send our data\nframe = client.recv(return_data=target_data)\n# check for frame if None\nif frame is None:\nbreak\n# {do something with frame here}\n# Show output window\ncv2.imshow(\"Client 5577 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_2","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate Multi-Clients mode\noptions = {\"multiclient_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5578\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n) \n# loop over\nwhile True:\n# prepare data to be sent\ntarget_data = \"Hi, I am 5578 Client here.\"\n# receive data from server and also send our data\nframe = client.recv(return_data=target_data)\n# check for frame if None\nif frame is None:\nbreak\n# {do something with frame here}\n# Show output window\ncv2.imshow(\"Client 5578 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#using-multi-clients-mode-with-bidirectional-mode","title":"Using Multi-Clients Mode with Bidirectional Mode","text":"<p>Abstract</p> <p>Multi-Clients Mode now also compatible with Bidirectional Mode, which lets you send additional data of any datatype1  along with frame in real-time bidirectionally between a single Server and all connected Client(s).</p> <p>Important Information</p> <ul> <li>Bidirectional data transfer ONLY works with pattern <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>), and NOT with pattern <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>)</li> <li>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its <code>message</code> parameter.</li> <li>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</li> </ul> New in v0.2.5 <p>This example was added in <code>v0.2.5</code>.</p> <p>In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from a single Server (In this case, Raspberry Pi with Camera Module) over the network to two independent Clients for displaying them both in real-time. At the same time, we will be sending data (a Text String, for the sake of simplicity) back from both the Client(s) to our Server, which will be printed onto the terminal.</p>"},{"location":"gears/netgear/advanced/multi_client/#servers-end_3","title":"Server's End","text":"<p>Now, Open the terminal on a Server System (with a webcam connected to it at index <code>0</code>). Now execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Client(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Client you are going to connect to this system. </li> </ul> <p>Frame/Data transmission will NOT START untill all given Client(s) are connected to this Server.</p> <p>You can terminate streaming anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import NetGear\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of \n# all unique Server((5577,5578) in our case) and other parameters\nserver = NetGear(\naddress=\"192.168.x.x\",\nport=(5577, 5578),\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)  # !!! change following IP address '192.168.x.xxx' with yours !!!\n# Define received data dictionary\ndata_dict = {}\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# send frame &amp; data and also receive data from Client(s)\nrecv_data = server.send(frame, message=target_data) # (1)\n# check if valid data received\nif not (recv_data is None):\n# extract unique port address and its respective data\nunique_address, data = recv_data\n# update the extracted data in the data dictionary\ndata_dict[unique_address] = data\nif data_dict:\n# print data just received from Client(s)\nfor key, value in data_dict.items():\nprint(\"Client at port {} said: {}\".format(key, value))\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-1s-end_3","title":"Client-1's End","text":"<p>Now, Open a terminal on another Client System (where you want to display the input frames received from Server), let's name it Client-1. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5577\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# prepare data to be sent\ntarget_data = \"Hi, I am 5577 Client here.\"\n# receive data from server and also send our data\ndata = client.recv(return_data=target_data)\n# check for data if None\nif data is None:\nbreak\n# extract server_data &amp; frame from data\nserver_data, frame = data\n# again check for frame if None\nif frame is None:\nbreak\n# {do something with the extracted frame and data here}\n# lets print extracted server data\nif not (server_data is None):\nprint(server_data)\n# Show output window\ncv2.imshow(\"Client 5577 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_client/#client-2s-end_3","title":"Client-2's End","text":"<p>Finally, Open a terminal on another Client System (also, where you want to display the input frames received from Server), let's name it Client-2. Execute the following python code: </p> <p>Replace the IP address in the following code with Server's IP address you noted earlier and also assign a unique port address (required by Server to identify this system).</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate both multiclient and bidirectional modes\noptions = {\"multiclient_mode\": True, \"bidirectional_mode\": True}\n# Define NetGear Client at Server's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=\"5578\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n) \n# loop over\nwhile True:\n# prepare data to be sent\ntarget_data = \"Hi, I am 5578 Client here.\"\n# receive data from server and also send our data\ndata = client.recv(return_data=target_data)\n# check for data if None\nif data is None:\nbreak\n# extract server_data &amp; frame from data\nserver_data, frame = data\n# again check for frame if None\nif frame is None:\nbreak\n# {do something with the extracted frame and data here}\n# lets print extracted server data\nif not (server_data is None):\nprint(server_data)\n# Show output window\ncv2.imshow(\"Client 5578 Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server's end with its <code>message</code> parameter.</p> <p>\u21a9</p> </li> </ol>"},{"location":"gears/netgear/advanced/multi_server/","title":"Multi-Servers Mode for NetGear API","text":"NetGear's Multi-Servers Mode"},{"location":"gears/netgear/advanced/multi_server/#overview","title":"Overview","text":"<p>In Multi-Servers Mode, NetGear API robustly handles Multiple Servers at once, thereby providing seamless access to frames and unidirectional data transfer across multiple Publishers/Servers in the network at the same time. Each new server connects to a single client can be identified by its unique port address on the network. </p> <p>The supported patterns for this mode are Publish/Subscribe (<code>zmq.PUB/zmq.SUB</code>) and Request/Reply(<code>zmq.REQ/zmq.REP</code>) and can be easily activated in NetGear API through <code>multiserver_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Important Information regarding Multi-Servers Mode</p> <ul> <li> <p>A unique PORT address MUST be assigned to each Server on the network using its <code>port</code> parameter.</p> </li> <li> <p>A list/tuple of PORT addresses of all unique Servers MUST be assigned at Client's end using its <code>port</code> parameter for a successful connection.</p> </li> <li> <p>Patterns <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>) and <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>) are the only supported values for this Mode. Therefore, calling any other pattern value with is mode will result in <code>ValueError</code>.</p> </li> <li> <p>Multi-Servers and Multi-Clients exclusive modes CANNOT be enabled simultaneously, Otherwise NetGear API will throw <code>ValueError</code>.</p> </li> <li> <p>The <code>address</code> parameter value of each Server MUST exactly match the Client. </p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#key-features","title":"Key Features","text":"<ul> <li> <p> Enables Multiple Server(s) connection with a single Client.</p> </li> <li> <p> Ability to send any additional data of any1 datatype along with frames in real-time.</p> </li> <li> <p> Number of Servers can be extended to several numbers depending upon your system's hardware limit.</p> </li> <li> <p> Employs powerful Publish/Subscribe &amp; Request/Reply messaging patterns.</p> </li> <li> <p> Each new Server on the network can be identified at Client's end by their unique port addresses.</p> </li> <li> <p> NetGear API actively tracks the state of each connected Server.</p> </li> <li> <p> If all the connected servers on the network get disconnected, the client itself automatically exits to save resources.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#usage-examples","title":"Usage Examples","text":"<p>Example Assumptions</p> <ul> <li> <p>For sake of simplicity, in these examples we will use only two unique Servers, but, the number of these Servers can be extended to several numbers depending upon your system hardware limits.</p> </li> <li> <p>All of Servers will be transferring frames to a single Client system at the same time, which will be displaying received frames as a live montage (multiple frames concatenated together).</p> </li> <li> <p>For building Frames Montage at Client's end, We are going to use <code>imutils</code> python library function to build montages, by concatenating  together frames received from different servers. Therefore, Kindly install this library with <code>pip install imutils</code> terminal command.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>In this example, we will capturing live video-frames on two independent sources (a.k.a Servers), each with a webcam connected to it. Afterwards, these frames will be sent over the network to a single system (a.k.a Client) using this Multi-Servers Mode in NetGear API in real time, and will be displayed as a live montage.</p> <p>This example is useful for building applications like Real-Time Security System with multiple cameras.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Multiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple \n# of all unique Server((5566,5567) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=(5566, 5567),\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\n**options\n)\n# Define received frame dictionary\nframe_dict = {}\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# receive data from network\ndata = client.recv()\n# check if data received isn't None\nif data is None:\nbreak\n# extract unique port address and its respective frame\nunique_address, frame = data\n# {do something with the extracted frame here}\n# get extracted frame's shape\n(h, w) = frame.shape[:2]\n# update the extracted frame in the received frame dictionary\nframe_dict[unique_address] = frame\n# build a montage using data dictionary\nmontages = build_montages(frame_dict.values(), (w, h), (2, 1))\n# display the montage(s) on the screen\nfor (i, montage) in enumerate(montages):\ncv2.imshow(\"Montage Footage {}\".format(i), montage)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\nexcept KeyboardInterrupt:\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import CamGear\n# Open suitable video stream (webcam on first index in our case)\nstream = CamGear(source=0).start()\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\", port=\"5566\", protocol=\"tcp\", pattern=1, **options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if not None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (also with a webcam connected to it at index <code>0</code>), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import CamGear\n# Open suitable video stream (webcam on first index in our case)\nstream = CamGear(source=0).start()\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\", port=\"5567\", protocol=\"tcp\", pattern=1, **options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if not None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>In this example, we will be re-implementing previous bare-minimum example with OpenCV and NetGear API.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of all \n# unique Server((5566,5567) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=(5566, 5567),\nprotocol=\"tcp\",\npattern=2,\nreceive_mode=True,\n**options\n)\n# Define received frame dictionary\nframe_dict = {}\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# receive data from network\ndata = client.recv()\n# check if data received isn't None\nif data is None:\nbreak\n# extract unique port address and its respective frame\nunique_address, frame = data\n# {do something with the extracted frame here}\n# get extracted frame's shape\n(h, w) = frame.shape[:2]\n# update the extracted frame in the received frame dictionary\nframe_dict[unique_address] = frame\n# build a montage using data dictionary\nmontages = build_montages(frame_dict.values(), (w, h), (2, 1))\n# display the montage(s) on the screen\nfor (i, montage) in enumerate(montages):\ncv2.imshow(\"Montage Footage {}\".format(i), montage)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\nexcept KeyboardInterrupt:\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_1","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# Open suitable video stream (webcam on first index in our case)\nstream = cv2.VideoCapture(0)\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameter\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\", port=\"5566\", protocol=\"tcp\", pattern=2, **options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_1","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (also with a webcam connected to it at index <code>0</code>), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# Open suitable video stream (webcam on first index in our case)\nstream = cv2.VideoCapture(0)\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\", port=\"5567\", protocol=\"tcp\", pattern=2, **options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.release()\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-for-unidirectional-custom-data-transfer","title":"Using Multi-Servers Mode for Unidirectional Custom Data Transfer","text":"<p>Abstract</p> <p>With Multi-Servers Mode, you can send additional data of any datatype1 along with frame with frame in real-time, from all connected Server(s) to a single Client unidirectionally.</p> <p>But <code>numpy.ndarray</code> data-type is NOT supported as data.</p> <p>In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module &amp; a Laptop with webcam) to a single Client over the network in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end_2","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=(5577, 5578),\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)  \n# Define received frame dictionary\nframe_dict = {}\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# receive data from network\ndata = client.recv()\n# check if data received isn't None\nif data is None:\nbreak\n# extract unique port address and its respective frame and received data\nunique_address, extracted_data, frame = data\n# {do something with the extracted frame and data here}\n# let's display extracted data on our extracted frame\ncv2.putText(\nframe,\nextracted_data,\n(10, frame.shape[0] - 10),\ncv2.FONT_HERSHEY_SIMPLEX,\n0.6,\n(0, 255, 0),\n2,\n)\n# get extracted frame's shape\n(h, w) = frame.shape[:2]\n# update the extracted frame in the frame dictionary\nframe_dict[unique_address] = frame\n# build a montage using data dictionary\nmontages = build_montages(frame_dict.values(), (w, h), (2, 1))\n# display the montage(s) on the screen\nfor (i, montage) in enumerate(montages):\ncv2.imshow(\"Montage Footage {}\".format(i), montage)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\nexcept KeyboardInterrupt:\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_2","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import VideoGear\nimport cv2\n# Open suitable video stream (webcam on first index in our case)\nstream = VideoGear(source=0).start()\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\",\nport=\"5577\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with frame and data(to be sent) here}\n# let's prepare a text string as data\ntarget_data = \"I'm Server-1 at Port: 5577\"\n# send frame and data through server\nserver.send(frame, message=target_data) # (1)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_2","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# activate multiserver_mode\noptions = {\"multiserver_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.1.xxx\",\nport=\"5578\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with frame and data(to be sent) here}\n# let's prepare a text string as data\ntext = \"I'm Server-2 at Port: 5578\"\n# send frame and data through server\nserver.send(frame, message=text)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream.\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#using-multi-servers-mode-with-bidirectional-mode","title":"Using Multi-Servers Mode with Bidirectional Mode","text":"<p>Abstract</p> <p>Multi-Servers Mode now also compatible with Bidirectional Mode, which lets you send additional data of any datatype1  along with frame in real-time bidirectionally between a single Client and all connected Server(s).</p> <p>Important Information</p> <ul> <li>Bidirectional data transfer ONLY works with pattern <code>1</code> (i.e. Request/Reply <code>zmq.REQ/zmq.REP</code>), and NOT with pattern <code>2</code> (i.e. Publish/Subscribe <code>zmq.PUB/zmq.SUB</code>)</li> <li>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their <code>message</code> parameter.</li> <li>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</li> </ul> New in v0.2.5 <p>This example was added in <code>v0.2.5</code>.</p> <p>In this example, We will be transferring video-frames and data (a Text String, for the sake of simplicity) from two Servers (consisting of a Raspberry Pi with Camera Module &amp; a Laptop with webcam) to a single Client, and at same time sending back data (a Text String, for the sake of simplicity) to them over the network all in real-time. The received video-frames at Client's end will displayed as a live montage, whereas the received data will be printed to the terminal.</p>"},{"location":"gears/netgear/advanced/multi_server/#clients-end_3","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from Mutiple Servers) and execute the following python code: </p> <p>Important Notes</p> <ul> <li>Note down the local IP-address of this system(required at all Server(s) end) and also replace it in the following code. You can follow this FAQ for this purpose.</li> <li>Also, assign the tuple/list of port address of all Servers you are going to connect to this system. </li> </ul> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom imutils import build_montages # (1)\nimport cv2\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n# Define NetGear Client at given IP address and assign list/tuple of all unique Server((5577,5578) in our case) and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.x\",\nport=(5577, 5578),\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)  \n# Define received frame dictionary\nframe_dict = {}\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# prepare data to be sent\ntarget_data = \"Hi, I am a Client here.\"\n# receive data from server(s) and also send our data\ndata = client.recv(return_data=target_data)\n# check if data received isn't None\nif data is None:\nbreak\n# extract unique port address and its respective frame and received data\nunique_address, extracted_data, frame = recv_data\n# {do something with the extracted frame and data here}\n# let's display extracted data on our extracted frame\ncv2.putText(\nframe,\nextracted_data,\n(10, frame.shape[0] - 10),\ncv2.FONT_HERSHEY_SIMPLEX,\n0.6,\n(0, 255, 0),\n2,\n)\n# get extracted frame's shape\n(h, w) = frame.shape[:2]\n# update the extracted frame in the frame dictionary\nframe_dict[unique_address] = frame\n# build a montage using data dictionary\nmontages = build_montages(frame_dict.values(), (w, h), (2, 1))\n# display the montage(s) on the screen\nfor (i, montage) in enumerate(montages):\ncv2.imshow(\"Montage Footage {}\".format(i), montage)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\nexcept KeyboardInterrupt:\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <ol> <li>For building Frames Montage you'll need <code>imutils</code> python library. Install it with <code>pip install imutils</code> command.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-1s-end_3","title":"Server-1's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and let's called it Server-1. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import VideoGear\nimport cv2\n# Open suitable video stream (webcam on first index in our case)\nstream = VideoGear(source=0).start()\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.x.x\",\nport=\"5577\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with frame and data(to be sent) here}\n# let's prepare a text string as data\ntarget_data = \"I'm Server-1 at Port: 5577\"\n# send frame &amp; data and also receive data from Client\nrecv_data = server.send(frame, message=target_data) # (1)\n# print data just received from Client\nif not (recv_data is None):\nprint(recv_data)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p>"},{"location":"gears/netgear/advanced/multi_server/#server-2s-end_3","title":"Server-2's End","text":"<p>Finally, Open the terminal on another Server System (this time a Raspberry Pi with Camera Module connected to it), and let's called it Server-2. Now execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier and also assign a unique port address (required by Client to identify this system).</p> <p>You can terminate stream anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import PiGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# activate both multiserver and bidirectional modes\noptions = {\"multiserver_mode\": True, \"bidirectional_mode\": True}\n# Define NetGear Server at Client's IP address and assign a unique port address and other parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nserver = NetGear(\naddress=\"192.168.1.xxx\",\nport=\"5578\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until Keyboard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with frame and data(to be sent) here}\n# let's prepare a text string as data\ntarget_data = \"I'm Server-2 at Port: 5578\"\n# send frame &amp; data and also receive data from Client\nrecv_data = server.send(frame, message=target_data) # (1)\n# print data just received from Client\nif not (recv_data is None):\nprint(recv_data)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream.\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted as <code>target_data</code> in <code>message</code> parameter.</li> </ol> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray data-type is NOT SUPPORTED at Server(s) with their <code>message</code> parameter.</p> <p>\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/netgear/advanced/secure_mode/","title":"Secure Mode for NetGear API","text":""},{"location":"gears/netgear/advanced/secure_mode/#overview","title":"Overview","text":"<p>Secure Mode provides easy access to powerful, smart &amp; secure ZeroMQ's Security Layers in NetGear API that enables strong encryption on data, and unbreakable authentication between the Server and the Client with the help of custom Certificates/keys and brings cheap, standardized privacy and authentication for distributed systems over the network.</p> <p>Secure Mode uses a new wire protocol, ZMTP 3.0 that adds a security handshake to all ZeroMQ connections and a new security protocol, CurveZMQ, that implements \"perfect forward security\" between two ZeroMQ peers over a TCP connection. </p> <p>Secure Mode can be easily activated in NetGear API through <code>secure_mode</code> attribute of its <code>options</code> dictionary parameter, during initialization. Furthermore, for managing this mode, NetGear API provides additional <code>custom_cert_location</code> &amp; <code>overwrite_cert</code> like attribute too.</p> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#supported-zmq-security-layers","title":"Supported ZMQ Security Layers","text":"<p>Secure mode supports the two most powerful ZMQ security layers:</p> <ul> <li> <p>Stonehouse: which switches to the CURVE security protocol that provides strong encryption on data, and almost unbreakable authentication. Stonehouse is the minimum you would use over public networks and assures clients that they are speaking to an authentic server while allowing any client to connect. This security layer is less secure but at the same time faster than IronHouse security mechanism.</p> </li> <li> <p>Ironhouse: which further extends Stonehouse layer with client public key authentication. This is the strongest security model present in ZeroMQ, protecting against every attack we know about except end-point attacks. This security layer enhanced security comes at a price of additional latency.</p> </li> </ul> <p> </p> <p>Important Information regarding Secure Mode</p> <ul> <li> <p>The <code>secure_mode</code> attribute value at the Client's end MUST match exactly the Server's end (i.e. IronHouse security layer is only compatible with IronHouse, and NOT with StoneHouse).</p> </li> <li> <p>The Public+Secret Keypairs generated at the Server end MUST be made available at the Client's end too for successful authentication. If mismatched, connection failure will occur.</p> </li> <li> <p>By Default, the Public+Secret Keypairs will be generated/stored at the <code>$HOME/.vidgear/keys</code> directory of your machine (e.g. <code>/home/foo/.vidgear/keys</code> on Linux). But you can also use <code>custom_cert_location</code> attribute to set your own Custom-Path for a directory to generate/store these Keypairs.</p> </li> <li> <p>DO NOT share generated public+secret Keypairs with anyone else on the network to avoid any potential security breach. At the Server End, You can easily use the <code>'overwrite_cert'</code> attribute for regenerating New-Keypairs on initialization. But make sure those newly generated Keypairs at the Server-End MUST be made available at Client's End for successful authentication.</p> </li> <li> <p>IronHouse is the strongest Security Layer available, but it involves certain security checks that lead to  ADDITIONAL LATENCY.</p> </li> <li> <p>Secure Mode only supports <code>libzmq</code> library version <code>&gt;= 4.0</code>.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#features","title":"Features","text":"<ul> <li> <p> Supports the two most powerful ZMQ security layers: StoneHouse &amp; IronHouse.</p> </li> <li> <p> Auto-generates, auto-validates &amp; auto-stores the required Public+Secret Keypairs safely.</p> </li> <li> <p> Compatible with all messaging pattern, primary and exclusive modes.</p> </li> <li> <p> Strong data encryption &amp; Unbreakable authentication.</p> </li> <li> <p> Able to protect against many man-in-the-middle (MITM) attacks.</p> </li> <li> <p> Minimum hassle and very easy to enable and integrate.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#exclusive-attributes","title":"Exclusive Attributes","text":"<p>For implementing Secure Mode, NetGear API currently provide following exclusive attribute for its <code>options</code> dictionary parameter:</p> <ul> <li> <p><code>secure_mode</code> (integer) : This attribute activates and sets the ZMQ security Mechanism. Its possible values are: <code>1</code>(StoneHouse) &amp; <code>2</code>(IronHouse), and its default value is <code>0</code>(Grassland(no security)). Its usage is as follows:</p> <pre><code>#activates IronHouse Security Mechanism\noptions = {'secure_mode':2}\n</code></pre> </li> <li> <p><code>custom_cert_location</code> (string): This attribute sets a custom location/path to directory to generate/store Public+Secret Keypair/Certificates for enabling encryption. This attribute will force NetGear to create <code>.vidgear</code> folder (only if not available) at the assigned custom path (instead of home directory), and then use that directory for storing new Keypairs/Certificates. It can be used as follows:</p> <pre><code># set custom Keypair location to '/home/foo/foo1/foo2'\noptions = {\n\"secure_mode\": 2,\n\"custom_cert_location\": \"/home/foo/foo1/foo2\",\n} \n</code></pre> </li> <li> <p><code>overwrite_cert</code> (bool): [For Server-end only] This attribute sets whether to overwrite existing Public+Secret Keypair/Certificates and re-generate new ones, to protect against any potential security breach. If set to <code>True</code> a new Keypair/Certificates will be generated during NetGear initialization in place of old ones. Its usage is as follows:</p> <p><code>overwrite_cert</code> parameter is disabled for Client's end!</p> <pre><code># a new Keypair will be generated\noptions = {\"secure_mode\": 2, \"overwrite_cert\": True} \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#usage-examples","title":"Usage Examples","text":""},{"location":"gears/netgear/advanced/secure_mode/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with Secure Mode in NetGear API:</p>"},{"location":"gears/netgear/advanced/secure_mode/#servers-end","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n# open any valid video stream(for e.g `test.mp4` file)\nstream = VideoGear(source=\"test.mp4\").start()\n# activate StoneHouse security mechanism\noptions = {\"secure_mode\": 1}\n# Define NetGear Server with defined parameters\nserver = NetGear(pattern=1, logging=True, **options)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre>"},{"location":"gears/netgear/advanced/secure_mode/#clients-end","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate StoneHouse security mechanism\noptions = {\"secure_mode\": 1}\n# define NetGear Client with `receive_mode = True` and defined parameter\nclient = NetGear(pattern=1, receive_mode=True, logging=True, **options)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#using-secure-mode-with-variable-parameters","title":"Using Secure Mode with Variable Parameters","text":""},{"location":"gears/netgear/advanced/secure_mode/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You need to paste the Public+Secret Keypairs (generated at the Server End) at the <code>$HOME/.vidgear/keys</code> directory of your Client machine for a successful authentication!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# activate IronHouse security mechanism\noptions = {\"secure_mode\": 2}\n# Define NetGear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=2,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/secure_mode/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You also need to copy the Public+Secret Keypairs (generated on running this example code) present in the <code>$HOME/.vidgear/keys</code> directory, and make available at Client's end for a successful authentication.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n# activate IronHouse security mechanism, and \n# [BEWARE!!!] generating new Keypairs for this example !!!\noptions = {\"secure_mode\": 2, \"overwrite_cert\": True}\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=2,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/","title":"SSH Tunneling Mode for NetGear API","text":"NetGear's Bidirectional Mode"},{"location":"gears/netgear/advanced/ssh_tunnel/#overview","title":"Overview","text":"New in v0.2.2 <p>This document was added in <code>v0.2.2</code>.</p> <p>SSH Tunneling Mode allows you to connect NetGear client and server via secure SSH connection over the untrusted network and access its intranet services across firewalls. This mode works with pyzmq's <code>zmq.ssh</code> module for tunneling ZeroMQ connections over ssh.</p> <p>This mode implements SSH Remote Port Forwarding which enables accessing Host(client) machine outside the network by exposing port to the public Internet. Thereby, once you have established the tunnel, connections to local machine will actually be connections to remote machine as seen from the server.</p> Beware \u2620\ufe0f <p>Cybercriminals or malware could exploit SSH tunnels to hide their unauthorized communications, or to exfiltrate stolen data from the network. More information can be found here \u27b6</p> <p>All patterns are valid for this mode and it can be easily activated in NetGear API at server end through <code>ssh_tunnel_mode</code> string attribute of its <code>options</code> dictionary parameter during initialization.</p> <p>Important</p> <ul> <li>SSH tunneling mode can only be enabled on Server-end to establish remote SSH connection with Client.</li> <li>SSH tunneling mode requires Client's SSH Port(default <code>22</code>) to be TCP Port Forwarded by its Router, which allows Server machine to connect to it remotely.   </li> <li>SSH tunneling mode is NOT compatible with Multi-Servers and Multi-Clients Exclusive Modes yet.</li> </ul> <p>Useful Tips</p> <ul> <li>It is advise to use <code>pattern=2</code> to overcome random disconnection due to delays in network.</li> <li>SSH tunneling Mode is fully supports Bidirectional Mode, Secure Mode and JPEG-Frame Compression.</li> <li>It is advised to enable logging (<code>logging = True</code>) on the first run, to easily identify any runtime errors.</li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#prerequisites","title":"Prerequisites","text":"<p>SSH Tunnel Mode requires <code>pexpect</code> or <code>paramiko</code> as an additional dependency which is not part of standard VidGear package. It can be easily installed via pypi as follows:</p> PramikoPexpect <p><code>paramiko</code> is compatible with all platforms.</p> <p><code>paramiko</code> support is automatically enabled in ZeroMQ if installed.</p> <pre><code># install paramiko\npip install paramiko\n</code></pre> <p><code>pexpect</code> is NOT compatible with Windows Machines.</p> <pre><code># install pexpect\npip install pexpect\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#exclusive-attributes","title":"Exclusive Attributes","text":"<p>All these attributes will work on Server end only whereas Client end will simply discard them.</p> <p>For implementing SSH Tunneling Mode, NetGear API currently provide following exclusive attribute for its <code>options</code> dictionary parameter:</p> <ul> <li> <p><code>ssh_tunnel_mode</code> (string) : This attribute activates SSH Tunneling Mode and assigns the <code>\"&lt;ssh-username&gt;@&lt;client-public-ip-address&gt;:&lt;tcp-forwarded-port&gt;\"</code> SSH URL for tunneling at Server end. Its usage is as follows:</p> <p>On Server end, NetGear automatically validates if the <code>port</code> is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed), NetGear will throw <code>AssertionError</code>!</p> With Default PortWith Custom Port <p>The default port value in SSH URL is <code>22</code>, meaning Server assumes TCP Port <code>22</code> is forwarded on Client's end by default.</p> <pre><code># activate SSH Tunneling and assign SSH URL\noptions = {\"ssh_tunnel_mode\":\"userid@52.194.1.73\"}\n# i.e. only connections from the Public IP address `52.194.1.73` \n# on default port 22 are allowed.\n</code></pre> <p>But, you can also define your own custom TCP forwarded port instead:</p> <p>Here we're defining our own TCP Port <code>8080</code>, meaning Server assumes TCP Port <code>8080</code> is forwarded on Client's end.</p> <pre><code># activate SSH Tunneling and assign SSH URL\noptions = {\"ssh_tunnel_mode\":\"userid@52.194.1.73:8080\"}\n# i.e. only connections from the Public IP address `52.194.1.73` \n# on custom port 8080 are allowed.\n</code></pre> </li> <li> <p><code>ssh_tunnel_pwd</code> (string): This attribute sets the password required to authorize Host(client) for SSH Connection at Server end. This password grant access and controls SSH user can access what. It can be used as follows:</p> <pre><code># set password for our SSH conection\noptions = {\n\"ssh_tunnel_mode\":\"userid@52.194.1.73\",\n\"ssh_tunnel_pwd\":\"mypasswordstring\",\n} \n</code></pre> </li> <li> <p><code>ssh_tunnel_keyfile</code> (string): This attribute sets path to Host key that provide another way to authenticate Host(client) for SSH Connection at Server end. Its purpose is to prevent man-in-the-middle attacks. It allows device authentication keys to be rotated and managed conveniently and every connection to be secured. It can be used as follows:</p> <p>You can use Ssh-keygen tool for creating new authentication key pairs for SSH Tunneling.</p> <pre><code># set keyfile path for our SSH conection\noptions = {\n\"ssh_tunnel_mode\":\"userid@52.194.1.73\",\n\"ssh_tunnel_keyfile\":\"/home/foo/.ssh/id_rsa\",\n} \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#usage-example","title":"Usage Example","text":"Assumptions for this Example <p>In this particular example, we assume that:</p> <ul> <li> <p>Server: </p> <ul> <li> Server end is a Raspberry Pi with USB camera connected to it. </li> <li> Server is located at remote location and outside the Client's network.  </li> </ul> </li> <li> <p>Client:</p> <ul> <li> Client end is a Regular PC/Computer located at <code>52.155.1.89</code> public IP address for displaying frames received from the remote Server.</li> <li> Client's SSH Port(default <code>22</code>) is TCP Port Forwarded by its Router, which allows Server to connect to it remotely. This connection will then be tunneled back to our PC/Computer(Client) and makes TCP connection to it again via port <code>22</code> on localhost(<code>127.0.0.1</code>).</li> <li> Also, there's a username <code>test</code> present on the PC/Computer(Client) to SSH login with password <code>pas$wd</code>.</li> </ul> </li> <li> <p>Setup Diagram:</p> <p>Assumed setup can be visualized throw diagram as follows:</p> <p> Setup Diagram </p> </li> </ul>"},{"location":"gears/netgear/advanced/ssh_tunnel/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (A Regular PC where you want to display the input frames received from the Server) and execute the following python code: </p> Requirements for Client's End <p>To ensure a successful Remote NetGear Connection with Server:</p> <ul> <li> <p> Install OpenSSH Server: (Tested)</p>  Linux Windows MacOS <pre><code># Debian-based\nsudo apt-get install openssh-server\n\n# RHEL-based\nsudo yum install openssh-server\n</code></pre> <p>See this official Microsoft doc \u27b6</p> <pre><code>brew install openssh\n</code></pre> </li> <li> <p> Make sure to note down the Client's public IP address required by Server end.</p> </li> <li> <p> Make sure that Client's SSH Port(default <code>22</code>) is TCP Port Forwarded by its Router to expose it to the public Internet. Also, this forwarded TCP port value is needed at Server end.</p> </li> </ul> Finding Public IP Address <p>Only IPv4 IP-addresses are supported</p> Enabling Dynamic DNS <p>SSH tunneling requires public IP address to able to access host on public Internet. Thereby, if it's troublesome to remember Public IP address or your IP address change constantly, then you can use dynamic DNS services like https://www.noip.com/</p> <ul> <li>A Public IP address is a globally routable IP address that is assigned to a network device, allowing it direct access to the Internet. They are assigned to the device by its ISP, and each device has a unique public IP address.</li> <li>Determining the public IP address involves contacting a remote server over the HTTP/HTTPS or DNS protocol and obtaining the IP address from the remote server response.</li> <li>On Desktop machines, the easiest way to find out your public IP address is to google \"what is my IP\" in your browser:</li> </ul> <p></p> How to TCP Port Forward in your Router <p>For more information on Forwarding Port in Popular Home Routers. See this document \u27b6</p> Secsh channel X open FAILED: open failed: Administratively prohibited <p>Error: This error means that installed OpenSSH is preventing connections to forwarded ports from outside your Client Machine. </p> <p>Solution: You need to change <code>GatewayPorts no</code> option to <code>GatewayPorts yes</code> in the OpenSSH server configuration file <code>sshd_config</code> to allows anyone to connect to the forwarded ports on Client Machine. </p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nimport cv2\n# Define NetGear Client at given IP address and define parameters \nclient = NetGear(\naddress=\"127.0.0.1\", # don't change this\nport=\"5454\",\npattern=2,\nreceive_mode=True,\nlogging=True,\n)\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear/advanced/ssh_tunnel/#servers-end","title":"Server's End","text":"<p>Now, Open the terminal on Remote Server System (A Raspberry Pi with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Make sure to replace the Client's Public IP Address and Forwarded TCP port(default is 22) in SSH URL with yours in the following example.</p> <p>On Server end, NetGear automatically validates if the <code>port</code> is open at specified Client's Public IP Address or not, and if it fails (i.e. port is closed), NetGear will throw <code>AssertionError</code>!</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\n# activate SSH tunneling with SSH URL, and\n# [BEWARE!!!] Change SSH URL and SSH password with yours for this example !!!\noptions = {\n\"ssh_tunnel_mode\": \"test@52.155.1.89\", # defaults to port 22\n\"ssh_tunnel_pwd\": \"pas$wd\",\n}\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define NetGear server at given IP address and define parameters\nserver = NetGear(\naddress=\"127.0.0.1\", # don't change this\nport=\"5454\",\npattern=2, \nlogging=True, \n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/overview/","title":"NetGear_Async API","text":""},{"location":"gears/netgear_async/overview/#overview","title":"Overview","text":"<p>NetGear_Async can generate the same performance as NetGear API at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few NetGear's Exclusive Modes.</p> <p>NetGear_Async is built on <code>zmq.asyncio</code>, and powered by a high-performance asyncio event loop called <code>uvloop</code> to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system. </p> <p>NetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to NetGear API. Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network(see this doc example).</p> <p>NetGear_Async now supports additional bidirectional data transmission between receiver(client) and sender(server) while transferring frames. Users can easily build complex applications such as like Real-Time Video Chat in just few lines of code.</p> <p>In addition to all this, NetGear_Async API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> <p>NetGear_Async as of now supports four ZeroMQ messaging patterns:</p> <ul> <li> <code>zmq.PAIR</code> (ZMQ Pair Pattern)</li> <li> <code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern)</li> <li> <code>zmq.PUB/zmq.SUB</code> (ZMQ Publish/Subscribe Pattern) </li> <li> <code>zmq.PUSH/zmq.PULL</code> (ZMQ Push/Pull Pattern)</li> </ul> <p>Whereas supported protocol are: <code>tcp</code> and <code>ipc</code>.</p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> <li> <p>It is advised to comprehend NetGear API before using this API.</p> </li> </ul> <p> </p>"},{"location":"gears/netgear_async/overview/#importing","title":"Importing","text":"<p>You can import NetGear_Async API in your program as follows:</p> <pre><code>from vidgear.gears.asyncio import NetGear_Async\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through NetGear_Async Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/netgear_async/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/netgear_async/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/netgear_async/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/netgear_async/params/","title":"NetGear_Async API Parameters","text":"<p>NetGear_Async provides a special internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/netgear_async/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide access to PiGear or CamGear APIs respectively. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#address","title":"<code>address</code>","text":"<p>This parameter sets the valid network address of the Server/Client. Network addresses unique identifiers across the network. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is based on selected primary mode, i.e <code>'localhost'</code> for Send Mode and <code>'*'</code> for Receive Mode.</p> <p>Usage:</p> <pre><code>NetGear_Async(address=\"192.168.0.145\")\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#port","title":"<code>port</code>","text":"<p>This parameter sets the valid Network Port of the Server/Client. A network port is a number that identifies one side of a connection between two devices on the network and is used determine to which process or application a message should be delivered. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'5555'</code></p> <p>Usage:</p> <pre><code>NetGear_Async(port=\"5575\")\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#protocol","title":"<code>protocol</code>","text":"<p>This parameter sets the valid messaging protocol between Server/Client. A network protocol is a set of established rules that dictates how to format, transmit and receive data so computer network devices - from servers and routers to endpoints - can communicate regardless of the differences in their underlying infrastructures, designs or standards. Supported protocol are: <code>'tcp'</code> and <code>'ipc'</code>.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'tcp'</code></p> <p>Usage:</p> <pre><code>NetGear_Async(protocol=\"ipc\")\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#pattern","title":"<code>pattern</code>","text":"<p>This parameter sets the supported messaging pattern(flow of communication) between Server/Client. Messaging patterns are the network-oriented architectural pattern that describes the flow of communication between interconnecting systems. NetGear provides access to ZeroMQ's pre-optimized sockets which enables you to take advantage of these patterns.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> (i.e <code>zmq.PAIR</code>). </p> <p>All supported ZMQ patterns for NetGear_Async are:</p> <ul> <li><code>0</code> (.i.e. zmq.PAIR): In this pattern, the communication is bidirectional. There is no specific state stored within the socket. There can only be one connected peer. The server listens on a certain port and a client connects to it.</li> <li><code>1</code> (.i.e. zmq.REQ/zmq.REP): In this pattern, it employs <code>ZMQ REQ</code> sockets that can connect to many servers. The requests will be interleaved or distributed to both the servers. socket <code>zmq.REQ</code> will block send unless it has successfully received a reply back and socket <code>zmq.REP</code> will block on recv() unless it has received a request.</li> <li><code>2</code> (.i.e. zmq.PUB/zmq.SUB): It is an another classic pattern where senders of messages, called publishers, do not program the messages to be sent directly to specific receivers, called subscribers. Messages are published without the knowledge of what or if any subscriber of that knowledge exists. A <code>ZMQ.SUB</code> can connect to multiple <code>ZMQ.PUB</code> (publishers). No single publisher overwhelms the subscriber. The messages from both publishers are interleaved.</li> <li><code>3</code> (.i.e. zmq.PUSH/zmq.PULL): Its sockets let you distribute messages to multiple workers, arranged in a pipeline. A Push socket will distribute sent messages to its Pull clients evenly. This is equivalent to the producer/consumer model but the results computed by the consumer are not sent upstream but downstream to another pull/consumer socket.</li> </ul> <p>Usage:</p> <pre><code>NetGear_Async(pattern=1) # sets zmq.REQ/zmq.REP pattern\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#receive_mode","title":"<code>receive_mode</code>","text":"<p>This parameter select the Netgear's Mode of operation. It basically activates <code>Receive Mode</code>(if <code>True</code>) and <code>Send Mode</code>(if <code>False</code>). Furthermore, <code>recv()</code> method will only work when this flag is enabled(i.e. <code>Receive Mode</code>), whereas <code>send()</code> method will only work when this flag is disabled(i.e.<code>Send Mode</code>). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>(i.e. Send Mode is activated by default).</p> <p>Usage:</p> <pre><code>NetGear_Async(receive_mode=True) # activates Recieve Mode\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#timeout","title":"<code>timeout</code>","text":"<p>In NetGear_Async, the Receiver-end keeps tracks if frames are received from Server-end within this specified timeout value (in seconds), Otherwise <code>TimeoutError</code> will be raised, which helps to close the Receiver-end safely if the Server has lost connection prematurely. This parameter controls that  timeout value (i.e. the maximum waiting time (in seconds)) after which Client exit itself with a <code>TimeoutError</code> to save resources. Its minimum value is <code>0.0</code> but no max limit.</p> <p>Data-Type: Float/Integer</p> <p>Default Value: Its default value is <code>10.0</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(timeout=5.0) # sets 5secs timeout\n</code></pre>"},{"location":"gears/netgear_async/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the flexibility to alter various NetGear_Async API's internal properties and modes.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code></p> <p>Usage:</p> <p>Supported dictionary attributes for NetGear_Async API</p> <ul> <li> <p><code>bidirectional_mode</code> (boolean) : This internal attribute activates the exclusive Bidirectional Mode, if enabled(<code>True</code>).</p> <p>The desired attributes can be passed to NetGear_Async API as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"bidirectional_mode\": True,\n}\n# assigning it\nNetGear_Async(logging=True, **options)\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in NetGear_Async.</p>"},{"location":"gears/netgear_async/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#options_1","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in NetGear_Async. Default is also <code>False</code>.</p>"},{"location":"gears/netgear_async/params/#source","title":"<code>source</code>","text":"<p>NetGear_Async API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>NetGear_Async(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>NetGear_Async(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>NetGear_Async(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>NetGear_Async(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/netgear_async/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>NetGear_Async(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/netgear_async/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>NetGear_Async(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nNetGear_Async(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in NetGear_Async.</p>"},{"location":"gears/netgear_async/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw <code>ValueError</code> for any negative value.</p> <p>This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board.\"</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True, camera_num=0)\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter sets the resolution (i.e. <code>(width,height)</code>) of the source. </p> <p>For more information read here \u27b6</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter sets the framerate of the source.</p> <p>For more information read here \u27b6</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>NetGear_Async(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#options_3","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Tweak Parameters <code>like brightness, saturation, senor_mode, resolution, etc.</code> available within Picamera library.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed in PiCamera Docs</p> <p>The desired parameters can be passed to NetGear_Async API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# assigning it\nNetGear_Async(enablePiCamera=True, logging=True, **options)\n</code></pre> <p>User-specific attributes:</p> <p>Additionally, <code>options</code> parameter also support some User-specific attributes, which are as follows:</p> <ul> <li> <p><code>HWFAILURE_TIMEOUT</code> (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a <code>SystemError</code> to save resources. Its value can only be between <code>1.0</code> (min) and <code>10.0</code> (max) and its default value is <code>2.0</code>. Its usage is as follows: </p> <pre><code>options = {\"HWFAILURE_TIMEOUT\": 2.5}  # sets timeout to 2.5 seconds\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in NetGear_Async.</p>"},{"location":"gears/netgear_async/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>NetGear_Async(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/netgear_async/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the NetGear_Async API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>NetGear_Async(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/","title":"NetGear_Async API Usage Examples:","text":"<p>Helpful Tips</p> <ul> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> <li> <p>It is advised to comprehend NetGear API before using this API.</p> </li> </ul> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/netgear_async/usage/#requirement","title":"Requirement","text":"<p>NetGear_Async API is the part of <code>asyncio</code> package of VidGear, thereby you need to install VidGear with asyncio support as follows:</p> <pre><code>pip install vidgear[asyncio]\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with NetGear_Async API:</p>"},{"location":"gears/netgear_async/usage/#servers-end","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport asyncio\n# initialize Server with suitable source\nserver = NetGear_Async(source=\"/home/foo/foo1.mp4\").launch()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#clients-end","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True).launch()\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# loop over Client's Asynchronous Frame Generator\nasync for frame in client.recv_generator():\n# do something with received frames here\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\nkey = cv2.waitKey(1) &amp; 0xFF\n# await before continuing\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-variable-parameters","title":"Using NetGear_Async with Variable Parameters","text":""},{"location":"gears/netgear_async/usage/#clients-end_1","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# define and launch Client with `receive_mode=True`. #change following IP address '192.168.x.xxx' with yours\nclient = NetGear_Async(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=2,\nreceive_mode=True,\nlogging=True,\n).launch()\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# loop over Client's Asynchronous Frame Generator\nasync for frame in client.recv_generator():\n# do something with received frames here\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\nkey = cv2.waitKey(1) &amp; 0xFF\n# await before continuing\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#servers-end_1","title":"Server's End","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index <code>0</code>), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport asyncio\n# initialize Server with suitable source\nserver = NetGear_Async(\nsource=0,\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=2,\nlogging=True,\n).launch()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-a-custom-sourceopencv","title":"Using NetGear_Async with a Custom Source(OpenCV)","text":"<p>NetGear_Async allows you to easily define your own custom Source at Server-end that you want to use to transform your frames before sending them onto the network. </p> <p>Let's implement a bare-minimum example with a Custom Source using NetGear_Async API and OpenCV:</p>"},{"location":"gears/netgear_async/usage/#servers-end_2","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# initialize Server without any source\nserver = NetGear_Async(source=None, logging=True)\n# !!! define your own video source here !!!\n# Open any video stream such as live webcam\n# video stream on first index(i.e. 0) device\nstream = cv2.VideoCapture(0)\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n# loop over stream until its terminated\nwhile True:\n# read frames\n(grabbed, frame) = stream.read()\n# check if frame empty\nif not grabbed:\nbreak\n# do something with the frame to be sent here\n# yield frame\nyield frame\n# sleep for sometime\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\n# Add your custom source generator to Server configuration\nserver.config[\"generator\"] = my_frame_generator()\n# Launch the Server\nserver.launch()\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# close stream\nstream.release()\n# finally close the server\nserver.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#clients-end_2","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True, logging=True).launch()\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# loop over Client's Asynchronous Frame Generator\nasync for frame in client.recv_generator():\n# {do something with received frames here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\nkey = cv2.waitKey(1) &amp; 0xFF\n# await before continuing\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/usage/#using-netgear_async-with-other-gears","title":"Using NetGear_Async with Other Gears","text":"<p>NetGear_Async can be used with any other Gears without any compatibility issues. </p> <p>Let's implement a bare-minimum example where we are sending Stabilized frames from Server-end and saving them at Client's end with WriteGear as follows:</p>"},{"location":"gears/netgear_async/usage/#servers-end_3","title":"Server's End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport asyncio\n# initialize Server with suitable source and enable stabilization\nserver = NetGear_Async(\nsource=\"/home/foo/foo1.mp4\", stabilize=True, logging=True\n).launch()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre>"},{"location":"gears/netgear_async/usage/#clients-end_3","title":"Client's End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>Client will throw TimeoutError if it fails to connect to the Server in given <code>timeout</code> value!</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears import WriteGear\nimport cv2, asyncio\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True).launch()\n# Define writer with output filename 'Output.mp4'\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# loop over Client's Asynchronous Frame Generator\nasync for frame in client.recv_generator():\n# {do something with received frames here}\n# write a modified frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\nkey = cv2.waitKey(1) &amp; 0xFF\n# await before continuing\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/","title":"Bidirectional Mode for NetGear_Async API","text":"NetGear_Async's Bidirectional Mode"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#overview","title":"Overview","text":"New in v0.2.2 <p>This document was added in <code>v0.2.2</code>.</p> <p>Bidirectional Mode enables seamless support for Bidirectional data transmission between Client and Sender along with video-frames through its synchronous messaging patterns such as <code>zmq.PAIR</code> (ZMQ Pair Pattern) &amp; <code>zmq.REQ/zmq.REP</code> (ZMQ Request/Reply Pattern) in NetGear_Async API.</p> <p>In Bidirectional Mode, we utilizes the NetGear_Async API's <code>transceive_data</code> method for transmitting data (at Client's end) and receiving data (in Server's end)  all while transferring frames in real-time. </p> <p>This mode can be easily activated in NetGear_Async through <code>bidirectional_mode</code> attribute of its <code>options</code> dictionary parameter during initialization.</p> <p> </p> <p>Important</p> <ul> <li> <p>In Bidirectional Mode, <code>zmq.PAIR</code>(ZMQ Pair) &amp; <code>zmq.REQ/zmq.REP</code>(ZMQ Request/Reply) are ONLY Supported messaging patterns. Accessing this mode with any other messaging pattern, will result in <code>ValueError</code>.</p> </li> <li> <p>Bidirectional Mode only works with User-defined Custom Source on Server end. Otherwise, NetGear_Async API will throw <code>ValueError</code>.</p> </li> <li> <p>Bidirectional Mode enables you to send data of ANY1 Data-type along with frame bidirectionally.</p> </li> <li> <p>NetGear_Async API will throw <code>RuntimeError</code> if Bidirectional Mode is disabled at Server end or Client end but not both.</p> </li> <li> <p>Bidirectional Mode may lead to additional LATENCY depending upon the size of data being transfer bidirectionally. User discretion is advised!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#exclusive-method-and-parameter","title":"Exclusive Method and Parameter","text":"<p>To send data bidirectionally, NetGear_Async API provides following exclusive method and parameter:</p> <p><code>transceive_data</code> only works when Bidirectional Mode is enabled.</p> <ul> <li> <p><code>transceive_data</code>: It's a bidirectional mode exclusive method to transmit data (in Receive mode) and receive data (in Send mode), all while transferring frames in real-time. </p> <ul> <li><code>data</code>: In <code>transceive_data</code> method, this parameter enables user to inputs data (of ANY1 datatype) for sending back to Server at Client's end. </li> </ul> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#usage-examples","title":"Usage Examples","text":"<p>For Bidirectional Mode, NetGear_Async must need User-defined Custom Source at its Server end otherwise it will throw ValueError.</p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>Following is the bare-minimum code you need to get started with Bidirectional Mode over Custom Source Server built using OpenCV and NetGear_Async API:</p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both sides anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# initialize Server without any source\nserver = NetGear_Async(source=None, logging=True, **options)\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n# !!! define your own video source here !!!\n# Open any valid video stream(for e.g `foo.mp4` file)\nstream = cv2.VideoCapture(\"foo.mp4\")\n# loop over stream until its terminated\nwhile True:\n# read frames\n(grabbed, frame) = stream.read()\n# check for empty frame\nif not grabbed:\nbreak\n# {do something with the frame to be sent here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# receive data from Client\nrecv_data = await server.transceive_data()\n# print data just received from Client\nif not (recv_data is None):\nprint(recv_data)\n# send our frame &amp; data\nyield (target_data, frame) # (1)\n# sleep for sometime\nawait asyncio.sleep(0)\n# safely close video stream\nstream.release()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\n# Add your custom source generator to Server configuration\nserver.config[\"generator\"] = my_frame_generator()\n# Launch the Server\nserver.launch()\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#client-end","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(receive_mode=True, logging=True, **options).launch()\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# loop over Client's Asynchronous Frame Generator\nasync for (data, frame) in client.recv_generator():\n# do something with receive data from server\nif not (data is None):\n# let's print it\nprint(data)\n# {do something with received frames here}\n# Show output window(comment these lines if not required)\ncv2.imshow(\"Output Frame\", frame)\ncv2.waitKey(1) &amp; 0xFF\n# prepare data to be sent\ntarget_data = \"Hi, I am a Client here.\"\n# send our data to server\nawait client.transceive_data(data=target_data)\n# await before continuing\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-with-variable-parameters","title":"Using Bidirectional Mode with Variable Parameters","text":""},{"location":"gears/netgear_async/advanced/bidirectional_mode/#clients-end","title":"Client's End","text":"<p>Open a terminal on Client System (where you want to display the input frames received from the Server) and execute the following python code: </p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# Define NetGear_Async Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear_Async(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# loop over Client's Asynchronous Frame Generator\nasync for (data, frame) in client.recv_generator():\n# do something with receive data from server\nif not (data is None):\n# let's print it\nprint(data)\n# {do something with received frames here}\n# Show output window(comment these lines if not required)\ncv2.imshow(\"Output Frame\", frame)\ncv2.waitKey(1) &amp; 0xFF\n# prepare data to be sent\ntarget_data = \"Hi, I am a Client here.\"\n# send our data to server\nawait client.transceive_data(data=target_data)\n# await before continuing\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end_1","title":"Server End","text":"<p>Now, Open the terminal on another Server System (a Raspberry Pi with Camera Module), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears import VideoGear\nimport cv2, asyncio\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# initialize Server without any source at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear_Async(\nsource=None,\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n# !!! define your own video source here !!!\n# Open any video stream such as live webcam\n# video stream on first index(i.e. 0) device\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# loop over stream until its terminated\nwhile True:\n# read frames\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame to be sent here}\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# receive data from Client\nrecv_data = await server.transceive_data()\n# print data just received from Client\nif not (recv_data is None):\nprint(recv_data)\n# send our frame &amp; data\nyield (target_data, frame) # (1)\n# sleep for sometime\nawait asyncio.sleep(0)\n# safely close video stream\nstream.stop()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\n# Add your custom source generator to Server configuration\nserver.config[\"generator\"] = my_frame_generator()\n# Launch the Server\nserver.launch()\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol> <p> </p> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer","title":"Using Bidirectional Mode for Video-Frames Transfer","text":"<p>In this example we are going to implement a bare-minimum example, where we will be sending video-frames (3-Dimensional numpy arrays) of the same Video bidirectionally at the same time, for testing the real-time performance and synchronization between the Server and the Client using this(Bidirectional) Mode. </p> <p>This feature is great for building applications like Real-Time Video Chat.</p> <p>We're also using <code>reducer()</code> method for reducing frame-size on-the-go for additional performance.</p> <p>Remember, Sending large HQ video-frames may required more network bandwidth and packet size which may lead to video latency!</p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#server-end_2","title":"Server End","text":"<p>Open your favorite terminal and execute the following python code:</p> <p>You can terminate both side anytime by pressing Ctrl+C on your keyboard!</p> <p>Server end can only send numpy.ndarray datatype as frame but not as data.</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears.asyncio.helper import reducer\nimport cv2, asyncio\nimport numpy as np\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# Define NetGear Server without any source and with defined parameters\nserver = NetGear_Async(source=None, pattern=1, logging=True, **options)\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n# !!! define your own video source here !!!\n# Open any valid video stream(for e.g `foo.mp4` file)\nstream = cv2.VideoCapture(\"foo.mp4\")\n# loop over stream until its terminated\nwhile True:\n# read frames\n(grabbed, frame) = stream.read()\n# check for empty frame\nif not grabbed:\nbreak\n# reducer frames size if you want more performance, otherwise comment this line\nframe = await reducer(frame, percentage=30)  # reduce frame by 30%\n# {do something with the frame to be sent here}\n# send frame &amp; data and also receive data from Client\nrecv_data = await server.transceive_data()\n# receive data from Client\nif not (recv_data is None):\n# check data is a numpy frame\nif isinstance(recv_data, np.ndarray):\n# {do something with received numpy frame here}\n# Let's show it on output window\ncv2.imshow(\"Received Frame\", recv_data)\ncv2.waitKey(1) &amp; 0xFF\nelse:\n# otherwise just print data\nprint(recv_data)\n# prepare data to be sent(a simple text in our case)\ntarget_data = \"Hello, I am a Server.\"\n# send our frame &amp; data to client\nyield (target_data, frame) # (1)\n# sleep for sometime\nawait asyncio.sleep(0)\n# safely close video stream\nstream.release()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\n# Add your custom source generator to Server configuration\nserver.config[\"generator\"] = my_frame_generator()\n# Launch the Server\nserver.launch()\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre> <ol> <li> Everything except numpy.ndarray datatype data is accepted in <code>target_data</code>.</li> </ol> <p> </p>"},{"location":"gears/netgear_async/advanced/bidirectional_mode/#client-end_1","title":"Client End","text":"<p>Then open another terminal on the same system and execute the following python code and see the output:</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears.asyncio.helper import reducer\nimport cv2, asyncio\n# activate Bidirectional mode\noptions = {\"bidirectional_mode\": True}\n# define and launch Client with `receive_mode=True`\nclient = NetGear_Async(pattern=1, receive_mode=True, logging=True, **options).launch()\n# Create a async function where you want to show/manipulate your received frames\nasync def main():\n# !!! define your own video source here !!!\n# again open the same video stream for comparison\nstream = cv2.VideoCapture(\"foo.mp4\")\n# loop over Client's Asynchronous Frame Generator\nasync for (server_data, frame) in client.recv_generator():\n# check for server data\nif not (server_data is None):\n# {do something with the server data here}\n# lets print extracted server data\nprint(server_data)\n# {do something with received frames here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\nkey = cv2.waitKey(1) &amp; 0xFF\n# read frame target data from stream to be sent to server\n(grabbed, target_data) = stream.read()\n# check for frame\nif grabbed:\n# reducer frames size if you want more performance, otherwise comment this line\ntarget_data = await reducer(\ntarget_data, percentage=30\n)  # reduce frame by 30%\n# send our frame data\nawait client.transceive_data(data=target_data)\n# await before continuing\nawait asyncio.sleep(0)\n# safely close video stream\nstream.release()\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\ntry:\n# run your main function task until it is complete\nclient.loop.run_until_complete(main())\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\n# close all output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n</code></pre> <p> </p> <p> </p> <ol> <li> <p>Additional data of numpy.ndarray datatype is ONLY SUPPORTED at Client's end with <code>transceive_data</code> method using its <code>data</code> parameter. Whereas Server end can only send numpy.ndarray datatype as frame but not as data.</p> <p>\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/pigear/overview/","title":"PiGear API","text":"Raspberry Pi Camera Module"},{"location":"gears/pigear/overview/#overview","title":"Overview","text":"<p>PiGear is similar to CamGear API but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module).</p> <p>PiGear provides a flexible multi-threaded framework around complete picamera python library, and provide us the ability to exploit almost all of its parameters like <code>brightness, saturation, sensor_mode, iso, exposure, etc.</code> effortlessly. Furthermore, PiGear also supports multiple camera modules, such as in the case of Raspberry-Pi Compute Module IO boards.</p> <p>Best of all, PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources.</p> <p>Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work.</p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/pigear/overview/#importing","title":"Importing","text":"<p>You can import PiGear API in your program as follows:</p> <pre><code>from vidgear.gears import PiGear\n</code></pre> <p> </p>"},{"location":"gears/pigear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through PiGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/pigear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/pigear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/pigear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/pigear/params/","title":"PiGear API Parameters","text":""},{"location":"gears/pigear/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw <code>ValueError</code> for any negative value.</p> <p>This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board.\"</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code>PiGear(camera_num=0)\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter sets the resolution (i.e. <code>(width,height)</code>) of the source. </p> <p>For more information read here \u27b6</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>PiGear(resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter sets the framerate of the source.</p> <p>For more information read here \u27b6</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>PiGear(framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>PiGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/pigear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Tweak Parameters <code>like brightness, saturation, senor_mode, resolution, etc.</code> available within Picamera library.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed in PiCamera Docs</p> <p>The desired parameters can be passed to PiGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# assigning it\nPiGear(logging=True, **options)\n</code></pre> <p>User-specific attributes:</p> <p>Additionally, <code>options</code> parameter also support some User-specific attributes, which are as follows:</p> <ul> <li> <p><code>HWFAILURE_TIMEOUT</code> (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a <code>SystemError</code> to save resources. Its value can only be between <code>1.0</code> (min) and <code>10.0</code> (max) and its default value is <code>2.0</code>. Its usage is as follows: </p> <pre><code>options = {\"HWFAILURE_TIMEOUT\": 2.5}  # sets timeout to 2.5 seconds\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/pigear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>PiGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/pigear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the PiGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>PiGear(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/","title":"PiGear API Usage Examples:","text":"<p>Make sure to enable Raspberry Pi hardware-specific settings prior using this API, otherwise nothing will work.</p> <p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/pigear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with PiGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n# open pi video stream with default parameters\nstream = PiGear().start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/#using-pigear-with-variable-camera-module-properties","title":"Using PiGear with Variable Camera Module Properties","text":"<p>PiGear supports almost every parameter available within Picamera library. These parameters can be easily applied to the source stream in PiGear API through its <code>options</code> dictionary parameter by formatting them as its attributes. The complete usage example is as follows:</p> <p>All supported parameters are listed in PiCamera Docs \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/#using-pigear-with-direct-colorspace-manipulation","title":"Using PiGear with Direct Colorspace Manipulation","text":"<p>PiGear API also supports Direct Colorspace Manipulation, which is ideal for changing source colorspace on the run. </p> <p>A more detailed  information on colorspace manipulation can be found here \u27b6</p> <p>In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY  colorspace when <code>w</code> key is pressed, and then LAB colorspace when <code>e</code> key is pressed, finally default colorspace (i.e. BGR) when <code>s</code> key is pressed. Also, quit when <code>q</code> key is pressed:</p> <p>Any incorrect or None-Type value will immediately revert the colorspace to default (i.e. <code>BGR</code>).</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters and change colorspace to `HSV`\nstream = PiGear(\nresolution=(640, 480),\nframerate=60,\ncolorspace=\"COLOR_BGR2HSV\",\nlogging=True,\n**options\n).start()\n# loop over\nwhile True:\n# read HSV frames\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the HSV frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\n# check if 'w' key is pressed\nif key == ord(\"w\"):\n# directly change colorspace at any instant\nstream.color_space = cv2.COLOR_BGR2GRAY  # Now colorspace is GRAY\n# check for 'e' key is pressed\nif key == ord(\"e\"):\nstream.color_space = cv2.COLOR_BGR2LAB  # Now colorspace is CieLAB\n# check for 's' key is pressed\nif key == ord(\"s\"):\nstream.color_space = None  # Now colorspace is default(ie BGR)\n# check for 'q' key is pressed\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/pigear/usage/#using-pigear-with-writegear-api","title":"Using PiGear with WriteGear API","text":"<p>PiGear can be easily used with WriteGear API directly without any compatibility issues. The suitable example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# write gray frame to writer\nwriter.write(gray)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/screengear/overview/","title":"ScreenGear API","text":"ScreenGear API in action"},{"location":"gears/screengear/overview/#overview","title":"Overview","text":"<p>ScreenGear is designed exclusively for ultra-fast Screencasting, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends.</p> <p>ScreenGear API implements a multi-threaded wrapper around pyscreenshot &amp; python-mss python library, and also flexibly supports its internal parameter. </p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV Library \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/screengear/overview/#importing","title":"Importing","text":"<p>You can import ScreenGear API in your program as follows:</p> <pre><code>from vidgear.gears import ScreenGear\n</code></pre> <p> </p>"},{"location":"gears/screengear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/screengear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/screengear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/screengear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/screengear/params/","title":"ScreenGear API Parameters","text":""},{"location":"gears/screengear/params/#monitor","title":"<code>monitor</code>","text":"<p>This parameter enables <code>mss</code> usage and is most suitable for selecting index of a specific screen (from where you want retrieve frames) in multi-monitor setup. For example, its value can be assign to <code>2</code>, to fetch frames from a secondary monitor screen. More information can be found here \u27b6</p> <p>You can assign <code>monitor</code> value to <code>-1</code> to fetch frames from all connected multiple monitor screens.</p> <p>Implication of using <code>monitor</code> parameter</p> <p>Any value on <code>monitor</code> parameter other than <code>None</code> in ScreenGear API: </p> <ul> <li>Will force <code>mss</code> library backend.</li> <li>Will output <code>BGRA</code> colorspace frames instead of default <code>BGR</code>. </li> <li>Will disable the <code>backend</code> parameter.</li> </ul> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>None</code> (i.e. disabled by default).</p> <p>Usage:</p> <pre><code>ScreenGear(monitor=-1) # to fetch frames from all connected multiple screens\n</code></pre> <p> </p>"},{"location":"gears/screengear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter enables <code>pyscreenshot</code> usage and select suitable backend for extracting frames in ScreenGear. The user have the authority of selecting suitable backend which generates best performance as well as the most compatible with their machines. The possible values are: <code>pil</code>, <code>mss</code>, <code>scrot</code>, <code>maim</code>, <code>imagemagick</code>, <code>pyqt5</code>, <code>pyqt</code>, <code>pyside2</code>, <code>pyside</code>, <code>wx</code>, <code>pygdk3</code>, <code>mac_screencapture</code>, <code>mac_quartz</code>, <code>gnome_dbus</code>, <code>gnome-screenshot</code>, <code>kwin_dbus</code>. More information on these backends can be found here \u27b6</p> <p>Performance Benchmarking of each backend can be found here \u27b6</p> <p>Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API.</p> <p>Any value on <code>monitor</code> parameter will disable the <code>backend</code> parameter. You cannot use both parameters at same time.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>\"\"</code> (i.e. default backend).</p> <p>Usage:</p> <pre><code>ScreenGear(backend=\"mss\") # to enforce `mss` as backend for extracting frames.\n</code></pre> <p> </p>"},{"location":"gears/screengear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6.</p> <pre><code>ScreenGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/screengear/params/#options","title":"<code>options</code>","text":"<p>This parameter provides the flexibility to manually set the dimensions of capture screen area. </p> <p>Supported Dimensional Parameters</p> <p>Supported Dimensional Parameters are as follows: </p> <ul> <li><code>left</code>: the x-coordinate of the upper-left corner of the region</li> <li><code>top</code>: the y-coordinate of the upper-left corner of the region</li> <li><code>width</code>: the width of the region</li> <li><code>height</code>: the height of the region</li> </ul> <p>Additional Exclusive Attribute such as <code>THREAD_TIMEOUT</code> is also supported for this parameter.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>The desired dimensional parameters can be passed to ScreenGear API by formatting them as attributes, as follows:</p> <p>More information about screen dimensioning can be found here \u27b6</p> <pre><code># formatting dimensional parameters as dictionary attributes\noptions = {'top': 40, 'left': 0, 'width': 100, 'height': 100}\n# assigning it w.r.t monitor=1\nScreenGear(monitor=1, **options)\n</code></pre> <p> </p>"},{"location":"gears/screengear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>ScreenGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/","title":"ScreenGear API Usage Examples:","text":"<p>After going through ScreenGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/screengear/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with ScreenGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n# open video stream with default parameters\nstream = ScreenGear().start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-variable-screen-dimensions","title":"Using ScreenGear with Variable Screen Dimensions","text":"<p>ScreenGear API provides us the flexibility to directly set the dimensions of capturing-area of the screen. These dimensions can be easily applied to ScreenGear API through its <code>options</code> dictionary parameter by formatting them as its attributes. </p> <p>The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n# define dimensions of screen w.r.t to given monitor to be captured\noptions = {\"top\": 40, \"left\": 0, \"width\": 100, \"height\": 100}\n# open video stream with defined parameters\nstream = ScreenGear(logging=True, **options).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-multiple-screens","title":"Using ScreenGear with Multiple Screens","text":"<p>ScreenGear API provides us the flexibility to select any connected display for fetching frames, with its <code>monitor</code> parameter:</p> <p>You can assign <code>monitor</code> value to <code>-1</code> to fetch frames from all connected multiple monitor screens.</p> <p>Implication of using <code>monitor</code> parameter</p> <p>Any value on <code>monitor</code> parameter other than <code>None</code> in ScreenGear API: </p> <ul> <li>Will force <code>mss</code> library backend.</li> <li>Will output <code>BGRA</code> colorspace frames instead of default <code>BGR</code>. </li> <li>Will disable the <code>backend</code> parameter.</li> </ul> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n# open video stream with defined parameters with monitor at index `1` selected\nstream = ScreenGear(monitor=1, logging=True).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-variable-backend","title":"Using ScreenGear with Variable Backend","text":"<p>With ScreenGear API, you can select from many different backends that generates best performance as well as the most compatible with our machine by employing its <code>backend</code> parameter that supports many different backends:</p> <p>Supported <code>backend</code> values</p> <p>Its possible values are: <code>pil</code>, <code>mss</code>, <code>scrot</code>, <code>maim</code>, <code>imagemagick</code>, <code>pyqt5</code>, <code>pyqt</code>, <code>pyside2</code>, <code>pyside</code>, <code>wx</code>, <code>pygdk3</code>, <code>mac_screencapture</code>, <code>mac_quartz</code>, <code>gnome_dbus</code>, <code>gnome-screenshot</code>, <code>kwin_dbus</code>. </p> <p>More information on these backends can be found here \u27b6</p> <p>Remember to install backend library and all of its dependencies you're planning to use with ScreenGear API. More information on these backends can be found here \u27b6</p> <p>Any value on <code>monitor</code> parameter will disable the <code>backend</code> parameter. You cannot use them simultaneously.</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n# open video stream with defined parameters and `mss` backend for extracting frames.\nstream = ScreenGear(backend=\"mss\", logging=True).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-direct-colorspace-manipulation","title":"Using ScreenGear with Direct Colorspace Manipulation","text":"<p>ScreenGear API also supports Direct Colorspace Manipulation, which is ideal for changing source colorspace on the run. </p> <p>A more detailed  information on colorspace manipulation can be found here \u27b6</p> <p>In following example code, we will start with HSV as source colorspace, and then we will switch to GRAY  colorspace when <code>w</code> key is pressed, and then LAB colorspace when <code>e</code> key is pressed, finally default colorspace (i.e. BGR) when <code>s</code> key is pressed. Also, quit when <code>q</code> key is pressed:</p> <p>Any incorrect or None-type value, will immediately revert the colorspace to default i.e. <code>BGR</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n# Change colorspace to `HSV`\nstream = ScreenGear(colorspace=\"COLOR_BGR2HSV\", logging=True).start()\n# loop over\nwhile True:\n# read HSV frames\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the HSV frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\n# check if 'w' key is pressed\nif key == ord(\"w\"):\n# directly change colorspace at any instant\nstream.color_space = cv2.COLOR_BGR2GRAY  # Now colorspace is GRAY\n# check for 'e' key is pressed\nif key == ord(\"e\"):\nstream.color_space = cv2.COLOR_BGR2LAB  # Now colorspace is CieLAB\n# check for 's' key is pressed\nif key == ord(\"s\"):\nstream.color_space = None  # Now colorspace is default(ie BGR)\n# check for 'q' key is pressed\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/screengear/usage/#using-screengear-with-writegear-api","title":"Using ScreenGear with WriteGear API","text":"<p>ScreenGear can be used in conjunction with WriteGear API directly without any compatibility issues. The suitable example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# define dimensions of screen w.r.t to given monitor to be captured\noptions = {\"top\": 40, \"left\": 0, \"width\": 100, \"height\": 100}\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n# open video stream with defined parameters\nstream = ScreenGear(monitor=1, logging=True, **options).start()\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# write gray frame to writer\nwriter.write(gray)\n# Show output window\ncv2.imshow(\"Output Gray Frame\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/overview/","title":"Stabilizer Class","text":"<p>VidGear's Stabilizer in Action(Video Credits @SIGGRAPH2013)</p> <p>This video is transcoded with StreamGear API and hosted on GitHub Repository and served with raw.githack.com</p>"},{"location":"gears/stabilizer/overview/#overview","title":"Overview","text":"<p>Stabilizer is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. </p> <p>The basic idea behind it is to tracks and save the salient feature array for the given number of frames and then uses these anchor point to cancel out all perturbations relative to it for the incoming frames in the queue. This class relies on Fixed-Size Python Queues for error-free &amp; ultra-fast frame handling. </p> <p>For more detailed information on Stabilizer working, See this blogpost \u27b6</p> <p> </p>"},{"location":"gears/stabilizer/overview/#features","title":"Features","text":"<ul> <li> <p> Real-time stabilization with low latency and no extra resources.</p> </li> <li> <p> Works exceptionally well with low-frequency jitter.</p> </li> <li> <p> Integrated with VideoGear, therefore, can be applied to any incoming stream.</p> </li> <li> <p> Also seamlessly works standalone.</p> </li> </ul> <p> </p> <p>Important</p> <ul> <li> <p>The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk!</p> </li> <li> <p> The stabilizer might be slower for High-Quality videos-frames.</p> </li> <li> <p>It is advised to enable logging on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/stabilizer/overview/#importing","title":"Importing","text":"<p>You can import Stabilizer Class in your program as follows:</p> <pre><code>from vidgear.gears.stabilizer import Stabilizer\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/stabilizer/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/stabilizer/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/stabilizer/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/stabilizer/params/","title":"Stabilizer Class Parameters","text":""},{"location":"gears/stabilizer/params/#smoothing_radius","title":"<code>smoothing_radius</code>","text":"<p>This parameter can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa.</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>25</code>. </p> <p>Usage: </p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(smoothing_radius=30)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#border_size","title":"<code>border_size</code>","text":"<p>This parameter enables and set the value for extended border size that compensates for reduction of black borders during stabilization. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>(no borders).</p> <p>Usage:</p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(border_size=10)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#crop_n_zoom","title":"<code>crop_n_zoom</code>","text":"<p>This parameter enables cropping and zooming of frames (to original size) to reduce the black borders from being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects) during stabilization. It simply works in conjunction with the <code>border_size</code> parameter, i.e. when this parameter is enabled,  <code>border_size</code> will be used for cropping border instead of extending them. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(border_size=10, crop_n_zoom=True)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#border_type","title":"<code>border_type</code>","text":"<p>This parameter can be used to change the extended border type. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. </p> <p>Altering <code>border_type</code> parameter is DISABLED when <code>crop_n_zoom</code> is enabled!</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>'black'</code>.</p> <p>Usage:</p> <p>You can easily pass this parameter as follows:</p> <pre><code>Stabilizer(border_type='reflect')\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>Stabilizer(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/","title":"Stabilizer Class Usage Examples:","text":"<p>The stabilizer may not perform well against High-frequency jitter in video. Use at your own risk!</p> <p>The stabilizer might be slower  for High-Quality/Resolution  videos-frames.</p> <p>It is advised to enable logging on the first run for easily identifying any runtime errors.</p> <p>After going through Stabilizer Class Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p> <p> </p>"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-videocapture-gears","title":"Bare-Minimum Usage with VideoCapture Gears","text":"<p>Following is the bare-minimum code you need to get started with Stabilizer Class and various VideoCapture Gears:</p> <p>You can use any VideoCapture Gear instead of CamGear in the similar manner, as shown in this usage example.</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nfrom vidgear.gears import CamGear\nimport cv2\n# To open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n# initiate stabilizer object with default parameters\nstab = Stabilizer()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# send current frame to stabilizer for processing\nstabilized_frame = stab.stabilize(frame)\n# wait for stabilizer which still be initializing\nif stabilized_frame is None:\ncontinue\n# {do something with the stabilized frame here}\n# Show output window\ncv2.imshow(\"Output Stabilized Frame\", stabilized_frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# clear stabilizer resources\nstab.clean()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>The VidGear's stabilizer class can also work standalone easily with any Computer Vision library such as OpenCV itself. Following is the bare-minimum code you need to get started with Stabilizer Class and OpenCV:</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n# initiate stabilizer object with default parameters\nstab = Stabilizer()\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# send current frame to stabilizer for processing\nstabilized_frame = stab.stabilize(frame)\n# wait for stabilizer which still be initializing\nif stabilized_frame is None:\ncontinue\n# {do something with the stabilized frame here}\n# Show output window\ncv2.imshow(\"Stabilized Frame\", stabilized_frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# clear stabilizer resources\nstab.clean()\n# safely close video stream\nstream.release()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-variable-parameters","title":"Using Stabilizer with Variable Parameters","text":"<p>Stabilizer class provide certain parameters which you can use to tweak its internal properties. The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nfrom vidgear.gears import CamGear\nimport cv2\n# To open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n# initiate stabilizer object with defined parameters\nstab = Stabilizer(smoothing_radius=30, crop_n_zoom=True, border_size=5, logging=True)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# send current frame to stabilizer for processing\nstabilized_frame = stab.stabilize(frame)\n# wait for stabilizer which still be initializing\nif stabilized_frame is None:\ncontinue\n# {do something with the stabilized frame here}\n# Show output window\ncv2.imshow(\"Output Stabilized Frame\", stabilized_frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# clear stabilizer resources\nstab.clean()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#using-stabilizer-with-writegear","title":"Using Stabilizer with WriteGear","text":"<p>VideoGear's stabilizer can be used in conjunction with WriteGear API directly without any compatibility issues. The complete usage example is as follows:</p> <p>You can also add live audio input to WriteGear pipeline. See this bonus example</p> <pre><code># import required libraries\nfrom vidgear.gears.stabilizer import Stabilizer\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open suitable video stream\nstream = CamGear(source=\"unstabilized_stream.mp4\").start()\n# initiate stabilizer object with default parameters\nstab = Stabilizer()\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if not None-type\nif frame is None:\nbreak\n# send current frame to stabilizer for processing\nstabilized_frame = stab.stabilize(frame)\n# wait for stabilizer which still be initializing\nif stabilized_frame is None:\ncontinue\n# {do something with the stabilized frame here}\n# write stabilized frame to writer\nwriter.write(stabilized_frame)\n# Show output window\ncv2.imshow(\"Stabilized Frame\", stabilized_frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# clear stabilizer resources\nstab.clean()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/stabilizer/usage/#using-videogear-with-stabilizer-backend","title":"Using VideoGear with Stabilizer backend","text":"<p>VideoGear API provides a special internal wrapper around Stabilizer class that enables easy stabilization for various video-streams (real-time or not)  with minimum effort and writing way fewer lines of code.</p> <p>The complete usage example can be found here \u27b6</p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/","title":"FFmpeg Installation Instructions","text":"<p>StreamGear must requires FFmpeg executables for transcoding Media Chunks. You can following machine-specific instructions for its installation:</p> <p>StreamGear API will throw RuntimeError, if it fails to detect valid FFmpeg executables on your system.</p> <p>Enable logging (<code>logging=True</code>) for debugging FFmpeg validation process.</p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/#linux-ffmpeg-installation","title":"Linux FFmpeg Installation","text":"<p>The StreamGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:</p>"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection","title":"A. Auto-Detection","text":"<p>This is a recommended approach on Linux Machines</p> <p>If StreamGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module. </p> <p>Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6</p>"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Linux Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Linux Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>)  or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the StreamGear API.</p> <p>If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/#windows-ffmpeg-installation","title":"Windows FFmpeg Installation","text":"<p>The StreamGear API supports Auto-Installation and Manual Configuration methods on Windows systems.</p>"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-installation","title":"A. Auto-Installation","text":"<p>This is a recommended approach on Windows Machines</p> <p>If StreamGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Windows system StreamGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. <code>C:\\Temp</code>) of your machine.</p> <p>Warning</p> <ul> <li> <p>The files downloaded to temporary directory (for e.g. <code>C:\\TEMP</code>), may get erased if your machine shutdowns/restarts.</p> </li> <li> <p>You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through <code>-ffmpeg_download_path</code> parameter.</p> </li> <li> <p>If binaries were found at the specified path, StreamGear automatically skips the auto-installation step.</p> </li> <li> <p>If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then StreamGear API will exit with RuntimeError!</p> </li> </ul>"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_1","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Windows Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Windows Static Binaries: https://ffmpeg.org/download.html#build-windows</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'C:/foo/Downloads/ffmpeg/bin'</code>) or path of <code>ffmpeg.exe</code> executable itself to the <code>custom_ffmpeg</code> parameter in the StreamGear API.</p> <p>If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/streamgear/ffmpeg_install/#macos-ffmpeg-installation","title":"MacOS FFmpeg Installation","text":"<p>The StreamGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.</p>"},{"location":"gears/streamgear/ffmpeg_install/#a-auto-detection_1","title":"A. Auto-Detection","text":"<p>This is a recommended approach on MacOS Machines</p> <p>If StreamGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module.</p> <p>Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6</p>"},{"location":"gears/streamgear/ffmpeg_install/#b-manual-configuration_2","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest macOS Static Binaries(only x64 Binaries) from the link below:</p> <p>MacOS Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>) or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the StreamGear API.</p> <p>If binaries were not found at the manually specified path, StreamGear API will throw RuntimeError!</p> </li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/","title":"StreamGear API","text":"StreamGear API's generalized workflow"},{"location":"gears/streamgear/introduction/#overview","title":"Overview","text":"<p>StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH and Apple HLS) in just few lines of python code. </p> <p>StreamGear provides a standalone, highly extensible, and flexible wrapper around FFmpeg multimedia framework for generating chunked-encoded media segments of the content.</p> <p>SteamGear is an out-of-the-box solution for transcoding source videos/audio files &amp; real-time video frames and breaking them into a sequence of multiple smaller chunks/segments of suitable lengths. These segments make it possible to stream videos at different quality levels (different bitrates or spatial resolutions) and can be switched in the middle of a video from one quality level to another \u2013 if bandwidth permits \u2013 on a per-segment basis. A user can serve these segments on a web server that makes it easier to download them through HTTP standard-compliant GET requests.</p> <p>SteamGear currently supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)  and Apple HLS (HTTP Live Streaming). </p> <p>SteamGear also creates a Manifest file (such as MPD in-case of DASH) or a Master Playlist (such as M3U8 in-case of Apple HLS) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and adaptive bit rates) and is provided to the client before the streaming session.</p> <p>For streaming with older traditional protocols such as RTMP, RTSP/RTP you could use WriteGear API instead.</p> <p> </p> New in v0.2.2 <p>Apple HLS support was added in <code>v0.2.2</code>.</p> <p>Important</p> <ul> <li> <p>StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation.</p> </li> <li> <p> StreamGear API will throw RuntimeError, if it fails to detect valid FFmpeg executable on your system.</p> </li> <li> <p>It is advised to enable logging (<code>logging=True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p>Useful Links</p> <ul> <li>Checkout this detailed blogpost on how MPEG-DASH works.</li> <li>Checkout this detailed blogpost on how HLS works.</li> <li>Checkout this detailed blogpost for HLS vs. MPEG-DASH comparison.</li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/#mode-of-operations","title":"Mode of Operations","text":"<p>StreamGear primarily operates in following independent modes for transcoding:</p> Real-time Frames Mode is NOT Live-Streaming. <p>Rather, you can enable live-streaming in Real-time Frames Mode by using the exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter in StreamGear API. Checkout this usage example for more information.</p> <ul> <li> <p>Single-Source Mode: In this mode, StreamGear transcodes entire video file (as opposed to frame-by-frame) into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) for streaming that required no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. </p> </li> <li> <p>Real-time Frames Mode: In this mode, StreamGear directly transcodes frame-by-frame (as opposed to a entire video file), into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform <code>numpy.ndarray</code> frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, audio has to added manually (as separate source) for streams. </p> </li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/#importing","title":"Importing","text":"<p>You can import StreamGear API in your program as follows:</p> <pre><code>from vidgear.gears import StreamGear\n</code></pre> <p> </p>"},{"location":"gears/streamgear/introduction/#watch-demo","title":"Watch Demo","text":"Watch MPEG-DASH StreamWatch APPLE HLS Stream <p>Watch StreamGear transcoded MPEG-DASH Stream:</p> <p> <p>Powered by clappr &amp; shaka-player</p></p> <p>This video assets (Manifest and segments) are hosted on GitHub Repository and served with raw.githack.com</p> <p>Video Credits: \"Tears of Steel\" - Project Mango Teaser</p> <p>Watch StreamGear transcoded APPLE HLS Stream:</p> <p> <p>Powered by clappr &amp; HlsjsPlayback</p></p> <p>This video assets (Playlist and segments) are hosted on GitHub Repository and served with raw.githack.com</p> <p>Video Credits: \"Sintel\" - Project Durian Teaser</p> <p> </p>"},{"location":"gears/streamgear/introduction/#recommended-players","title":"Recommended Players","text":"GUI PlayersCommand-Line PlayersOnline Players <ul> <li> MPV Player: (recommended) MPV is a free, open source, and cross-platform media player. It supports a wide variety of media file formats, audio and video codecs, and subtitle types. </li> <li> VLC Player: VLC is a free and open source cross-platform multimedia player and framework that plays most multimedia files as well as DVDs, Audio CDs, VCDs, and various streaming protocols.</li> <li> Parole: (UNIX only)  Parole is a modern simple media player based on the GStreamer framework for Unix and Unix-like operating systems. </li> </ul> <ul> <li> MP4Client: GPAC provides a highly configurable multimedia player called MP4Client. GPAC itself is an open source multimedia framework developed for research and academic purposes, and used in many media production chains.</li> <li> ffplay: FFplay is a very simple and portable media player using the FFmpeg libraries and the SDL library. It is mostly used as a testbed for the various FFmpeg APIs. </li> </ul> <p>To run Online players locally, you'll need a HTTP server. For creating one yourself, See this well-curated list  \u27b6</p> <ul> <li> Clapper: Clappr is an extensible media player for the web.</li> <li> Shaka Player: Shaka Player is an open-source JavaScript library for playing adaptive media in a browser.</li> <li> MediaElementPlayer: MediaElementPlayer is a complete HTML/CSS audio/video player.</li> <li> Native MPEG-Dash + HLS Playback(Chrome Extension): Allow the browser to play HLS (m3u8) or MPEG-Dash (mpd) video urls 'natively' on chrome browsers.</li> </ul> <p> </p>"},{"location":"gears/streamgear/introduction/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/introduction/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/introduction/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/params/","title":"StreamGear API Parameters","text":""},{"location":"gears/streamgear/params/#output","title":"<code>output</code>","text":"<p>This parameter sets the valid filename/path for storing the StreamGear assets (Manifest file (such as MPD in-case of DASH) or a Master Playlist (such as M3U8 in-case of Apple HLS) &amp; Transcoded sequence of segments).</p> <p>StreamGear API will throw <code>ValueError</code> if <code>output</code> provided is empty or invalid.</p> <p>Make sure to provide valid filename with valid file-extension for selected <code>format</code> value (such as <code>.mpd</code> in case of MPEG-DASH and <code>.m3u8</code> in case of APPLE-HLS), otherwise StreamGear will throw <code>AssertionError</code>.</p> <p>StreamGear generated sequence of multiple chunks/segments are also stored in the same directory.</p> <p>You can easily delete all previous assets at <code>output</code> location, by using <code>-clear_prev_assets</code> attribute of <code>stream_params</code> dictionary parameter.</p> <p>Data-Type: String</p> <p>Usage:</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p>Path to directory: Valid path of the directory. In this case, StreamGear API will automatically assign a unique filename for Manifest file. This can be defined as follows:</p> DASHHLS <pre><code>streamer = StreamGear(output = \"/home/foo/foo1\") # Define streamer with manifest saving directory path \n</code></pre> <pre><code>streamer = StreamGear(output = \"/home/foo/foo1\", format=\"hls\") # Define streamer with playlist saving directory path \n</code></pre> </li> <li> <p>Filename (with/without path): Valid filename(with valid extension) of the output Manifest file. In case filename is provided without path, then current working directory will be used.</p> DASHHLS <pre><code>streamer = StreamGear(output = \"output_foo.mpd\") # Define streamer with manifest file name\n</code></pre> <pre><code>streamer = StreamGear(output = \"output_foo.m3u8\", format=\"hls\") # Define streamer with playlist file name\n</code></pre> </li> <li> <p>URL: Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command <code>ffmpeg -protocols</code>) only. This is useful for directly storing assets to a network server. For example, you can use a <code>http</code> protocol URL as follows:</p> DASHHLS <pre><code>streamer = StreamGear(output = \"http://195.167.1.101/live/test.mpd\") #Define streamer \n</code></pre> <pre><code>streamer = StreamGear(output = \"http://195.167.1.101/live/test.m3u8\", format=\"hls\") #Define streamer \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/streamgear/params/#format","title":"<code>format</code>","text":"<p>This parameter select the adaptive HTTP streaming formats. For now, the supported format are: <code>dash</code> (i.e MPEG-DASH) and  <code>hls</code> (i.e Apple HLS).</p> <p>Any invalid value to <code>format</code> parameter will result in ValueError!</p> <p>Make sure to provide valid filename with valid file-extension in <code>output</code> for selected <code>format</code> value (such as <code>.mpd</code> in case of MPEG-DASH and <code>.m3u8</code> in case of APPLE-HLS), otherwise StreamGear will throw <code>AssertionError</code>.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>dash</code></p> <p>Usage:</p> DASHHLS <pre><code>StreamGear(output = \"output_foo.mpd\", format=\"dash\")\n</code></pre> <pre><code>StreamGear(output = \"output_foo.m3u8\", format=\"hls\")\n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>This parameter assigns the custom path/directory where the custom/downloaded FFmpeg executables are located.</p> <p>Behavior on Windows</p> <p>If a custom FFmpeg executable's path | directory is not provided through <code>custom_ffmpeg</code> parameter on Windows machine, then StreamGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine. More information can be found here \u27b6.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># If ffmpeg executables are located at \"/foo/foo1/ffmpeg\"\nStreamGear(output = 'output_foo.mpd', custom_ffmpeg=\"/foo/foo1/ffmpeg\")\n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#stream_params","title":"<code>stream_params</code>","text":"<p>This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly change its internal settings for transcoding and seamlessly generating high-quality streams. All supported parameters can formatting as attributes for this dictionary parameter:</p> <p>Kindly read FFmpeg Docs carefully, before passing any additional values to <code>stream_params</code> parameter. Wrong values may result in undesired errors or no output at all.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p>"},{"location":"gears/streamgear/params/#supported-parameters","title":"Supported Parameters","text":""},{"location":"gears/streamgear/params/#a-exclusive-parameters","title":"A. Exclusive Parameters","text":"<p>StreamGear API provides some exclusive internal parameters to easily generate Streaming Assets and effortlessly tweak its internal properties. These parameters are discussed below:</p> <ul> <li> <p><code>-streams</code> (list of dicts): This important attribute makes it simple and pretty straight-forward to define additional multiple streams as list of dictionaries of different quality levels (i.e. different bitrates or spatial resolutions) for streaming. </p> <p>Important <code>-streams</code> attribute facts</p> <ul> <li>On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate1 as the input Video, at the index <code>0</code>. </li> <li>You MUST need to define <code>-resolution</code> value for your stream, otherwise stream will be discarded!</li> <li>You only need either of <code>-video_bitrate</code> or <code>-framerate</code> for defining a valid stream. Since with <code>-framerate</code> value defined, video-bitrate is calculated automatically using <code>-bpps</code> and <code>-resolution</code> values.</li> <li>If you define both <code>-video_bitrate</code> and <code>-framerate</code> values at the same time, StreamGear will discard the <code>-framerate</code> value automatically.</li> </ul> <p>To construct the additional stream dictionaries, you'll will need following sub-attributes:</p> <ul> <li> <p><code>-resolution</code> (string): It is compulsory to define the required resolution/dimension/size for the stream, otherwise given stream will be rejected. Its value can be a <code>\"{width}x{height}\"</code> as follows: </p> <pre><code>\"-streams\" = [{\"-resolution\": \"1280x720\"}] # to produce a 1280x720 resolution/scale \n</code></pre> </li> <li> <p><code>-video_bitrate</code> (string): It is an optional (can be ignored if <code>-framerate</code> parameter is defined) sub-attribute that generally determines the bandwidth and quality of stream, i.e. the higher the bitrate, the better the quality and the larger will be bandwidth and more will be strain on network. It value is generally in <code>kbps</code> (kilobits per second) for OBS (Open Broadcasting Softwares). You can easily define this attribute as follows:</p> <pre><code>\"-streams\" : [{\"-resolution\": \"1280x720\", \"-video_bitrate\": \"2000k\"}] # to produce a 1280x720 resolution and 2000kbps bitrate stream\n</code></pre> </li> <li> <p><code>-framerate</code> (float/int): It is another optional (can be ignored if <code>-video_bitrate</code> parameter is defined) sub-attribute that defines the assumed framerate for the stream. It's value can be float/integer as follows:</p> <pre><code>\"-streams\" : [{\"-resolution\": \"1280x720\", \"-framerate\": \"60.0\"}] # to produce a 1280x720 resolution and 60fps framerate stream\n</code></pre> </li> </ul> <p>Usage: You can easily define any number of streams using <code>-streams</code> attribute as follows:</p> <p>Usage example can be found here \u27b6</p> <pre><code>stream_params = \n{\"-streams\": \n[{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"}, # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": \"30.0\"}, # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": \"60.0\"},  # Stream3: 640x360 at 60fps \n]}\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-video_source</code> (string): This attribute takes valid Video path as input and activates Single-Source Mode, for transcoding it into multiple smaller chunks/segments for streaming after successful validation. Its value be one of the following:</p> <p>Usage example can be found here \u27b6</p> <ul> <li>Video Filename: Valid path to Video file as follows:     <pre><code>stream_params = {\"-video_source\": \"/home/foo/foo1.mp4\"} # set input video source: /home/foo/foo1.mp4\n</code></pre></li> <li> <p>Video URL: Valid URL of a network video stream as follows:</p> <p>Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with <code>ffmpeg -protocols</code> terminal command)</p> <pre><code>stream_params = {\"-video_source\": \"http://livefeed.com:5050\"} # set input video source: http://livefeed.com:5050\n</code></pre> </li> </ul> </li> </ul> <p> </p> <ul> <li> <p><code>-audio</code> (string/list): This attribute takes external custom audio path (as <code>string</code>) or audio device name followed by suitable demuxer (as <code>list</code>) as audio source input for all StreamGear streams. Its value be one of the following:</p> <p>Make sure this audio-source is compatible with provided video -source, otherwise you could encounter multiple errors, or even no output at all!</p> <ul> <li> <p>Audio Filename (string): Valid path to Audio file as follows:     <pre><code>stream_params = {\"-audio\": \"/home/foo/foo1.aac\"} # set input audio source: /home/foo/foo1.aac\n</code></pre>     !!! tip \"Usage example can be found here \u27b6\"</p> </li> <li> <p>Audio URL (string): Valid URL of a network audio stream as follows:</p> <p>Make sure given Video URL has protocol that is supported by installed FFmpeg. (verify with <code>ffmpeg -protocols</code> terminal command)</p> <pre><code>stream_params = {\"-audio\": \"https://exampleaudio.org/example-160.mp3\"} # set input audio source: https://exampleaudio.org/example-160.mp3\n</code></pre> </li> <li> <p>Device name and Demuxer (list): Valid audio device name followed by suitable demuxer as follows:</p> <pre><code>stream_params = {\"-audio\": \"https://exampleaudio.org/example-160.mp3\"} # set input audio source: https://exampleaudio.org/example-160.mp3\n</code></pre> <p>Usage example can be found here \u27b6</p> </li> </ul> </li> </ul> <p> </p> <ul> <li> <p><code>-livestream</code> (bool): (optional) specifies whether to enable Livestream Support(chunks will contain information for new frames only) for the selected mode, or not. You can easily set it to <code>True</code> to enable this feature, and default value is <code>False</code>. It can be used as follows: </p> <p>Use <code>window_size</code> &amp; <code>extra_window_size</code> FFmpeg parameters for controlling number of frames to be kept in New Chunks.</p> <pre><code>stream_params = {\"-livestream\": True} # enable livestreaming\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-input_framerate</code> (float/int) :  (optional) specifies the assumed input video source framerate, and only works in Real-time Frames Mode. It can be used as follows:</p> <p>Usage example can be found here \u27b6</p> <pre><code>stream_params = {\"-input_framerate\": 60.0} # set input video source framerate to 60fps\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-bpp</code> (float/int): (optional) This attribute controls constant Bits-Per-Pixel(BPP) value, which is kind of a constant value to ensure good quality of high motion scenes ,and thereby used in calculating desired video-bitrate for streams. Higher the BPP, better will be motion quality. Its default value is <code>0.1</code>. Going over <code>0.1</code>helps to fill gaps between current bitrate and upload limit/ingest cap. Its value can be anything above <code>0.001</code>, can be used as follows:</p> <p>Important BPP tips for streaming</p> <ul> <li><code>-bpp</code> a sensitive value, try 0.001, and then make increments in 0.0001 to fine tune</li> <li>If your desired resolution/fps/audio combination is below maximum service bitrate, raise BPP to match it for extra quality.  </li> <li>It is generally better to lower resolution (and/or fps) and raise BPP than raise resolution and loose on BPP.</li> </ul> <pre><code>stream_params = {\"-bpp\": 0.05} # sets BPP to 0.05\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-gop</code> (float/int) : (optional) specifies the number of frames between two I-frames for accurate GOP length. By increasing the length of the GOP, there will be fewer I-frames per time frame, which minimizes bandwidth consumption. So, for example, with extremely complex subjects such as water sports or action mode, you\u2019ll want to use a shorter GOP length such as 15 or below that results in excellent video quality. For more static video such as talking heads, then much longer GOP sizes are not only sufficient but also more efficient. It can be used as follows:</p> <p>The larger the GOP size, the more efficient the compression and the less bandwidth you will need</p> <p>By default, StreamGear automatically sets recommended fixed GOP value (i.e. every two seconds) w.r.t input framerate and selected encoder.</p> <pre><code>stream_params = {\"-gop\": 70} # set GOP length to 70\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-clones</code> (list): (optional) sets the special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue) as list only. Usage is as follows: </p> <pre><code>stream_params = {\"-clones\": ['-map', '0:v:0', '-map', '1:a?']}\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-ffmpeg_download_path</code> (string): (optional) sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. <code>C:/User/temp</code>) on your windows machine. It can be used as follows: </p> <pre><code>stream_params = {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"} # will be saved to \"C:/User/foo/foo1\"\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-clear_prev_assets</code> (bool): (optional) specify whether to force-delete any previous copies of StreamGear Assets (i.e. Manifest files(.mpd) &amp; streaming chunks(.m4s) etc.) present at path specified by <code>output</code> parameter. You can easily set it to <code>True</code> to enable this feature, and default value is <code>False</code>. It can be used as follows: </p> <p>In Single-Source Mode, additional segments (such as <code>.webm</code>, <code>.mp4</code> chunks) are also cleared automatically.</p> <pre><code>stream_params = {\"-clear_prev_assets\": True} # will delete all previous assets\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/streamgear/params/#b-ffmpeg-parameters","title":"B. FFmpeg Parameters","text":"<p>Almost all FFmpeg parameter can be passed as dictionary attributes in <code>stream_params</code>. For example, for using <code>libx264 encoder</code> to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows:</p> <p>Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters</p> <p>All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs.</p> <p>In addition to these parameters, almost any FFmpeg parameter (supported by installed FFmpeg) is also supported. But make sure to read FFmpeg Docs carefully first.</p> <pre><code>stream_params = {\"-vcodec\":\"libx264\", \"-crf\": 0, \"-preset\": \"fast\", \"-tune\": \"zerolatency\"} \n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#supported-encoders-and-decoders","title":"Supported Encoders and Decoders","text":"<p>All the encoders and decoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal:</p> <p>Similarily, supported demuxers and filters depends upons compiled FFmpeg in use.</p> <pre><code># for checking encoder\nffmpeg -encoders           # use `ffmpeg.exe -encoders` on windows\n# for checking decoders\nffmpeg -decoders           # use `ffmpeg.exe -decoders` on windows\n</code></pre> <p> </p>"},{"location":"gears/streamgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>StreamGear(logging=True)\n</code></pre> <p> </p> <ol> <li> <p> In Real-time Frames Mode, the Primary Stream's framerate defaults to <code>-input_framerate</code> attribute value, if defined, else it will be 25fps.\u00a0\u21a9</p> </li> </ol>"},{"location":"gears/streamgear/rtfm/overview/","title":"StreamGear API: Real-time Frames Mode","text":"Real-time Frames Mode generalized workflow"},{"location":"gears/streamgear/rtfm/overview/#overview","title":"Overview","text":"<p>When no valid input is received on <code>-video_source</code> attribute of <code>stream_params</code> dictionary parameter, StreamGear API activates this mode where it directly transcodes real-time <code>numpy.ndarray</code> video-frames (as opposed to a entire video file) into a sequence of multiple smaller chunks/segments for adaptive streaming. </p> <p>This mode works exceptionally well when you desire to flexibility manipulate or transform video-frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, StreamGear DOES NOT automatically maps video-source's audio to generated streams with this mode. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> <p>SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)  and Apple HLS (HTTP Live Streaming) with this mode.</p> <p>For this mode, StreamGear API provides exclusive <code>stream()</code> method for directly trancoding video-frames into streamable chunks. </p> <p> </p> New in v0.2.2 <p>Apple HLS support was added in <code>v0.2.2</code>.</p> <p>Real-time Frames Mode is NOT Live-Streaming.</p> <p>Rather, you can easily enable live-streaming in Real-time Frames Mode by using StreamGear API's exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter. Checkout its usage example here.</p> <p>Danger</p> <ul> <li> <p>Using <code>transcode_source()</code> function instead of <code>stream()</code> in Real-time Frames Mode will instantly result in <code>RuntimeError</code>!</p> </li> <li> <p>NEVER assign anything to <code>-video_source</code> attribute of <code>stream_params</code> dictionary parameter, otherwise Single-Source Mode may get activated, and as a result, using <code>stream()</code> function will throw <code>RuntimeError</code>!</p> </li> <li> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in this mode, otherwise audio delay will occur in output streams.</p> </li> <li> <p>Input framerate defaults to <code>25.0</code> fps if <code>-input_framerate</code> attribute value not defined. </p> </li> </ul> <p> </p>"},{"location":"gears/streamgear/rtfm/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/streamgear/rtfm/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/rtfm/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/rtfm/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/rtfm/usage/","title":"StreamGear API Usage Examples: Real-time Frames Mode","text":"<p>Real-time Frames Mode is NOT Live-Streaming.</p> <p>Rather you can easily enable live-streaming in Real-time Frames Mode by using StreamGear API's exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter. Checkout following usage example.</p> <p>Important Information</p> <ul> <li> <p>StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>StreamGear API will throw RuntimeError, if it fails to detect valid FFmpeg executables on your system.</p> </li> <li> <p>By default, StreamGear generates a primary stream of same resolution and framerate1 as the input video  (at the index <code>0</code>).</p> </li> <li> <p>Always use <code>terminate()</code> function at the very end of the main code.</p> </li> </ul> <p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with StreamGear API in Real-time Frames Mode:</p> <p>We are using CamGear in this Bare-Minimum example, but any VideoCapture Gear will work in the similar manner.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p>After running this bare-minimum example, StreamGear will produce a Manifest file (<code>dash.mpd</code>) with streamable chunks that contains information about a Primary Stream of same resolution and framerate1 as input (without any audio).</p> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-live-streaming","title":"Bare-Minimum Usage with Live-Streaming","text":"<p>You can easily activate Low-latency Livestreaming in Real-time Frames Mode, where chunks will contain information for few new frames only and forgets all previous ones), using exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter as follows:</p> <p>Use <code>-window_size</code> &amp; <code>-extra_window_size</code> FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency.</p> <p>After every few chunks (equal to the sum of <code>-window_size</code> &amp; <code>-extra_window_size</code> values), all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames.</p> <p>In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(from web-camera attached at index `0`)\nstream = CamGear(source=0).start()\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(from web-camera attached at index `0`)\nstream = CamGear(source=0).start()\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-rgb-mode","title":"Bare-Minimum Usage with RGB Mode","text":"<p>In Real-time Frames Mode, StreamGear API provide <code>rgb_mode</code> boolean parameter with its <code>stream()</code> function, which if enabled (i.e. <code>rgb_mode=True</code>), specifies that incoming frames are of RGB format (instead of default BGR format), thereby also known as RGB Mode.</p> <p>The complete usage example is as follows:</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {simulating RGB frame for this example}\nframe_rgb = frame[:,:,::-1]\n# send frame to streamer\nstreamer.stream(frame_rgb, rgb_mode = True) #activate RGB Mode\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {simulating RGB frame for this example}\nframe_rgb = frame[:,:,::-1]\n# send frame to streamer\nstreamer.stream(frame_rgb, rgb_mode = True) #activate RGB Mode\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-controlled-input-framerate","title":"Bare-Minimum Usage with controlled Input-framerate","text":"<p>In Real-time Frames Mode, StreamGear API provides exclusive <code>-input_framerate</code>  attribute for its <code>stream_params</code> dictionary parameter, that allow us to set the assumed constant framerate for incoming frames. </p> <p>In this example, we will retrieve framerate from webcam video-stream, and set it as value for <code>-input_framerate</code> attribute in StreamGear:</p> <p>Remember, Input framerate default to <code>25.0</code> fps if <code>-input_framerate</code> attribute value not defined in Real-time Frames mode.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n# retrieve framerate from CamGear Stream and pass it as `-input_framerate` value\nstream_params = {\"-input_framerate\":stream.framerate}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n# retrieve framerate from CamGear Stream and pass it as `-input_framerate` value\nstream_params = {\"-input_framerate\":stream.framerate}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#bare-minimum-usage-with-opencv","title":"Bare-Minimum Usage with OpenCV","text":"<p>You can easily use StreamGear API directly with any other Video Processing library(For e.g. OpenCV itself) in Real-time Frames Mode. </p> <p>The complete usage example is as follows:</p> <p>This just a bare-minimum example with OpenCV, but any other Real-time Frames Mode feature/example will work in the similar manner.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\")\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# send frame to streamer\nstreamer.stream(gray)\n# Show output window\ncv2.imshow(\"Output Gray Frame\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0) \n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# send frame to streamer\nstreamer.stream(gray)\n# Show output window\ncv2.imshow(\"Output Gray Frame\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-additional-streams","title":"Usage with Additional Streams","text":"<p>Similar to Single-Source Mode, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive <code>-streams</code> attribute of <code>stream_params</code> dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically.</p> <p>A more detailed information on <code>-streams</code> attribute can be found here \u27b6</p> <p>The complete example is as follows:</p> Important <code>-streams</code> attribute Information <ul> <li>On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate1 as the input, at the index <code>0</code>.</li> <li> Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! </li> <li>You MUST need to define <code>-resolution</code> value for your stream, otherwise stream will be discarded!</li> <li>You only need either of <code>-video_bitrate</code> or <code>-framerate</code> for defining a valid stream. Since with <code>-framerate</code> value defined, video-bitrate is calculated automatically.</li> <li>If you define both <code>-video_bitrate</code> and <code>-framerate</code> values at the same time, StreamGear will discard the <code>-framerate</code> value automatically.</li> </ul> <p>Always use <code>-stream</code> attribute to define additional streams safely, any duplicate or incorrect definition can break things!</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n# define various streams\nstream_params = {\n\"-streams\": [\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps framerate\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps framerate\n{\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n],\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = CamGear(source=0).start() \n# define various streams\nstream_params = {\n\"-streams\": [\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps framerate\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps framerate\n{\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n],\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-file-audio-input","title":"Usage with File Audio-Input","text":"<p>In Real-time Frames Mode, if you want to add audio to your streams, you've to use exclusive <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter. You just need to input the path of your audio file to this attribute as <code>string</code> value, and the API will automatically validate as well as maps it to all generated streams. </p> <p>The complete example is as follows:</p> <p>Make sure this <code>-audio</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n# add various streams, along with custom audio\nstream_params = {\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n],\n\"-input_framerate\": stream.framerate, # controlled framerate for audio-video sync !!! don't forget this line !!!\n\"-audio\": \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\"\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source='foo1.mp4').start() \n# add various streams, along with custom audio\nstream_params = {\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n],\n\"-input_framerate\": stream.framerate, # controlled framerate for audio-video sync !!! don't forget this line !!!\n\"-audio\": \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\"\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-device-audio-input","title":"Usage with Device Audio-Input","text":"<p>In Real-time Frames Mode, you've can also use exclusive <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter for streaming live audio from external device. You just need to format your audio device name followed by suitable demuxer as <code>list</code> and assign to this attribute, and the API will automatically validate as well as map it to all generated streams. </p> <p>The complete example is as follows:</p> <p>Example Assumptions</p> <ul> <li>You're running are Windows machine with all neccessary audio drivers and software installed.</li> <li>There's a audio device with named <code>\"Microphone (USB2.0 Camera)\"</code> connected to your windows machine.</li> </ul> Using devices with <code>-audio</code> attribute on different OS platforms  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details.</p> </li> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg -list_devices true -f dshow -i dummy\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source device and demuxer device and demuxer\nstream_params = {\"-audio\": [\"-f\",\"dshow\", \"-i\", \"audio=Microphone (USB2.0 Camera)\"]}\n</code></pre> </li> </ul> <p>If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel</p> <p>Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> Identify Sound Card: To get the list of all installed cards on your machine, you can type <code>arecord -l</code> or <code>arecord -L</code> (longer output).</p> <pre><code>arecord -l\n\n**** List of CAPTURE Hardware Devices ****\ncard 0: ICH5 [Intel ICH5], device 0: Intel ICH [Intel ICH5]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 1: Intel ICH - MIC ADC [Intel ICH5 - MIC ADC]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 2: Intel ICH - MIC2 ADC [Intel ICH5 - MIC2 ADC]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 3: Intel ICH - ADC2 [Intel ICH5 - ADC2]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: U0x46d0x809 [USB Device 0x46d:0x809], device 0: USB Audio [USB Audio]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <p>The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as <code>hw:0</code> or <code>hw:1</code></p> <pre><code># assign appropriate input audio-source device and demuxer device and demuxer \nstream_params = {\"-audio\": [\"-f\",\"alsa\", \"-i\", \"hw:1\"]}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines:</p> <ul> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>avfoundation</code> as follows:</p> <pre><code>ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source device and demuxer\nstream_params = {\"-audio\": [\"-f\",\"avfoundation\", \"-audio_device_index\", \"0\"]}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>Make sure this <code>-audio</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>It is advised to use this example with live-streaming enabled(True) by using StreamGear API's exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source=\"foo1.mp4\").start()\n# add various streams, along with custom audio\nstream_params = {\n\"-streams\": [\n{\n\"-resolution\": \"1280x720\",\n\"-video_bitrate\": \"4000k\",\n},  # Stream1: 1280x720 at 4000kbs bitrate\n{\"-resolution\": \"640x360\", \"-framerate\": 30.0},  # Stream2: 640x360 at 30fps\n],\n\"-input_framerate\": stream.framerate,  # controlled framerate for audio-video sync !!! don't forget this line !!!\n\"-audio\": [\n\"-f\",\n\"dshow\",\n\"-i\",\n\"audio=Microphone (USB2.0 Camera)\",\n],  # assign appropriate input audio-source device and demuxer\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# open any valid video stream(for e.g `foo1.mp4` file)\nstream = CamGear(source=\"foo1.mp4\").start()\n# add various streams, along with custom audio\nstream_params = {\n\"-streams\": [\n{\n\"-resolution\": \"1280x720\",\n\"-video_bitrate\": \"4000k\",\n},  # Stream1: 1280x720 at 4000kbs bitrate\n{\"-resolution\": \"640x360\", \"-framerate\": 30.0},  # Stream2: 640x360 at 30fps\n],\n\"-input_framerate\": stream.framerate,  # controlled framerate for audio-video sync !!! don't forget this line !!!\n\"-audio\": [\n\"-f\",\n\"dshow\",\n\"-i\",\n\"audio=Microphone (USB2.0 Camera)\",\n],  # assign appropriate input audio-source device and demuxer\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.m3u8\", format=\"hls\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/rtfm/usage/#usage-with-hardware-video-encoder","title":"Usage with Hardware Video-Encoder","text":"<p>In Real-time Frames Mode, you can also easily change encoder as per your requirement just by passing <code>-vcodec</code> FFmpeg parameter as an attribute in <code>stream_params</code> dictionary parameter. In addition to this, you can also specify the additional properties/features/optimizations for your system's GPU similarly. </p> <p>In this example, we will be using <code>h264_vaapi</code> as our hardware encoder and also optionally be specifying our device hardware's location (i.e. <code>'-vaapi_device':'/dev/dri/renderD128'</code>) and other features such as <code>'-vf':'format=nv12,hwupload'</code> like properties by formatting them as <code>option</code> dictionary parameter's attributes, as follows:</p> <p>Check VAAPI support</p> <p>This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY-NOT suit your system. Kindly use suitable parameters based your supported system and FFmpeg configurations only.</p> <p>To use <code>h264_vaapi</code> encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows:</p> <pre><code>ffmpeg  -hide_banner -encoders | grep vaapi V..... h264_vaapi           H.264/AVC (VAAPI) (codec h264)\nV..... hevc_vaapi           H.265/HEVC (VAAPI) (codec hevc)\nV..... mjpeg_vaapi          MJPEG (VAAPI) (codec mjpeg)\nV..... mpeg2_vaapi          MPEG-2 (VAAPI) (codec mpeg2video)\nV..... vp8_vaapi            VP8 (VAAPI) (codec vp8)\n</code></pre> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = VideoGear(source=0).start() \n# add various streams with custom Video Encoder and optimizations\nstream_params = {\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n],\n\"-vcodec\": \"h264_vaapi\", # define custom Video encoder\n\"-vaapi_device\": \"/dev/dri/renderD128\", # define device location\n\"-vf\": \"format=nv12,hwupload\",  # define video pixformat\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = VideoGear(source=0).start() \n# add various streams with custom Video Encoder and optimizations\nstream_params = {\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n],\n\"-vcodec\": \"h264_vaapi\", # define custom Video encoder\n\"-vaapi_device\": \"/dev/dri/renderD128\", # define device location\n\"-vf\": \"format=nv12,hwupload\",  # define video pixformat\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p> <ol> <li> <p> In Real-time Frames Mode, the Primary Stream's framerate defaults to <code>-input_framerate</code> attribute value, if defined, else it will be 25fps.\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"gears/streamgear/ssm/overview/","title":"StreamGear API: Single-Source Mode","text":"Single-Source Mode generalized workflow"},{"location":"gears/streamgear/ssm/overview/#overview","title":"Overview","text":"<p>In this mode, StreamGear transcodes entire audio-video file (as opposed to frames-by-frame) into a sequence of multiple smaller chunks/segments for adaptive streaming. </p> <p>This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) files for streaming that requires no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing.</p> <p>SteamGear supports both MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)  and Apple HLS (HTTP Live Streaming) with this mode.</p> <p>For this mode, StreamGear API provides exclusive <code>transcode_source()</code> method to easily process audio-video files into streamable chunks.</p> <p>This mode can be easily activated by assigning suitable video path as input to <code>-video_source</code> attribute of <code>stream_params</code> dictionary parameter, during StreamGear initialization.</p> <p> </p> New in v0.2.2 <p>Apple HLS support was added in <code>v0.2.2</code>.</p> <p>Warning</p> <ul> <li>Using <code>stream()</code> function instead of <code>transcode_source()</code> in Single-Source Mode will instantly result in <code>RuntimeError</code>!</li> <li>Any invalid value to the <code>-video_source</code> attribute will result in <code>AssertionError</code>! </li> </ul> <p> </p>"},{"location":"gears/streamgear/ssm/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through StreamGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/streamgear/ssm/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/ssm/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/ssm/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/streamgear/ssm/usage/","title":"StreamGear API Usage Examples: Single-Source Mode","text":"<p>Important Information</p> <ul> <li> <p>StreamGear MUST requires FFmpeg executables for its core operations. Follow these dedicated Platform specific Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>StreamGear API will throw RuntimeError, if it fails to detect valid FFmpeg executables on your system.</p> </li> <li> <p>By default, StreamGear generates a primary stream of same resolution and framerate1 as the input video  (at the index <code>0</code>).</p> </li> <li> <p>Always use <code>terminate()</code> function at the very end of the main code.</p> </li> </ul> <p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with StreamGear API in Single-Source Mode:</p> <p>If input video-source (i.e. <code>-video_source</code>) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode with valid video input\nstream_params = {\"-video_source\": \"foo.mp4\"}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode with valid video input\nstream_params = {\"-video_source\": \"foo.mp4\"}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <p>After running this bare-minimum example, StreamGear will produce a Manifest file (<code>dash.mpd</code>) with streamable chunks that contains information about a Primary Stream of same resolution and framerate as the input.</p> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#bare-minimum-usage-with-live-streaming","title":"Bare-Minimum Usage with Live-Streaming","text":"<p>You can easily activate Low-latency Livestreaming in Single-Source Mode, where chunks will contain information for few new frames only and forgets all previous ones), using exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter as follows:</p> <p>Use <code>-window_size</code> &amp; <code>-extra_window_size</code> FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency.</p> <p>After every few chunks (equal to the sum of <code>-window_size</code> &amp; <code>-extra_window_size</code> values), all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames.</p> <p>If input video-source (i.e. <code>-video_source</code>) contains any audio stream/channel, then it automatically gets mapped to all generated streams without any extra efforts.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode with valid video input and enable livestreaming\nstream_params = {\"-video_source\": 0, \"-livestream\": True}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode with valid video input and enable livestreaming\nstream_params = {\"-video_source\": 0, \"-livestream\": True}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#usage-with-additional-streams","title":"Usage with Additional Streams","text":"<p>In addition to Primary Stream, you can easily generate any number of additional Secondary Streams of variable bitrates or spatial resolutions, using exclusive <code>-streams</code> attribute of <code>stream_params</code> dictionary parameter. You just need to add each resolution and bitrate/framerate as list of dictionaries to this attribute, and rest is done automatically.</p> <p>A more detailed information on <code>-streams</code> attribute can be found here \u27b6</p> <p>The complete example is as follows:</p> <p>If input video-source contains any audio stream/channel, then it automatically gets assigned to all generated streams without any extra efforts.</p> Important <code>-streams</code> attribute Information <ul> <li>On top of these additional streams, StreamGear by default, generates a primary stream of same resolution and framerate as the input, at the index <code>0</code>.</li> <li> Make sure your System/Machine/Server/Network is able to handle these additional streams, discretion is advised! </li> <li>You MUST need to define <code>-resolution</code> value for your stream, otherwise stream will be discarded!</li> <li>You only need either of <code>-video_bitrate</code> or <code>-framerate</code> for defining a valid stream. Since with <code>-framerate</code> value defined, video-bitrate is calculated automatically.</li> <li>If you define both <code>-video_bitrate</code> and <code>-framerate</code> values at the same time, StreamGear will discard the <code>-framerate</code> value automatically.</li> </ul> <p>Always use <code>-stream</code> attribute to define additional streams safely, any duplicate or incorrect definition can break things!</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode and also define various streams\nstream_params = {\n\"-video_source\": \"foo.mp4\",\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps framerate\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps framerate\n{\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n],\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode and also define various streams\nstream_params = {\n\"-video_source\": \"foo.mp4\",\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps framerate\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps framerate\n{\"-resolution\": \"320x240\", \"-video_bitrate\": \"500k\"},  # Stream3: 320x240 at 500kbs bitrate\n],\n}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#usage-with-custom-audio","title":"Usage with Custom Audio","text":"<p>By default, if input video-source (i.e. <code>-video_source</code>) contains any audio, then it gets automatically mapped to all generated streams. But, if you want to add any custom audio, you can easily do it by using exclusive <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter. You just need to input the path of your audio file to this attribute as <code>string</code>, and the API will automatically validate as well as map it to all generated streams. </p> <p>The complete example is as follows:</p> <p>Make sure this <code>-audio</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You can also assign a valid Audio URL as input, rather than filepath. More details can be found here \u27b6</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode and various streams, along with custom audio\nstream_params = {\n\"-video_source\": \"foo.mp4\",\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n],\n\"-audio\": \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\"\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode and various streams, along with custom audio\nstream_params = {\n\"-video_source\": \"foo.mp4\",\n\"-streams\": [\n{\"-resolution\": \"1920x1080\", \"-video_bitrate\": \"4000k\"},  # Stream1: 1920x1080 at 4000kbs bitrate\n{\"-resolution\": \"1280x720\", \"-framerate\": 30.0},  # Stream2: 1280x720 at 30fps\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream3: 640x360 at 60fps\n],\n\"-audio\": \"/home/foo/foo1.aac\" # assigns input audio-source: \"/home/foo/foo1.aac\"\n}\n# describe a suitable master playlist location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"gears/streamgear/ssm/usage/#usage-with-variable-ffmpeg-parameters","title":"Usage with Variable FFmpeg Parameters","text":"<p>For seamlessly generating these streaming assets, StreamGear provides a highly extensible and flexible wrapper around FFmpeg and access to almost all of its parameter. Thereby, you can access almost any parameter available with FFmpeg itself as dictionary attributes in <code>stream_params</code> dictionary parameter, and use it to manipulate transcoding as you like. </p> <p>For this example, let us use our own H.265/HEVC video and AAC audio encoder, and set custom audio bitrate, and various other optimizations:</p> <p>This example is just conveying the idea on how to use FFmpeg's encoders/parameters with StreamGear API. You can use any FFmpeg parameter in the similar manner.</p> <p>Kindly read FFmpeg Docs carefully, before passing any FFmpeg values to <code>stream_params</code> parameter. Wrong values may result in undesired errors or no output at all.</p> <p>Always use <code>-streams</code> attribute to define additional streams safely, any duplicate or incorrect stream definition can break things!</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode and various other parameters\nstream_params = {\n\"-video_source\": \"foo.mp4\", # define Video-Source\n\"-vcodec\": \"libx265\", # assigns H.265/HEVC video encoder\n\"-x265-params\": \"lossless=1\", # enables Lossless encoding\n\"-crf\": 25, # Constant Rate Factor: 25\n\"-bpp\": \"0.15\", # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes\n\"-streams\": [\n{\"-resolution\": \"1280x720\", \"-video_bitrate\": \"4000k\"}, # Stream1: 1280x720 at 4000kbs bitrate\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps\n],\n\"-audio\": \"/home/foo/foo1.aac\",  # define input audio-source: \"/home/foo/foo1.aac\",\n\"-acodec\": \"libfdk_aac\", # assign lossless AAC audio encoder\n\"-vbr\": 4, # Variable Bit Rate: `4`\n}\n# describe a suitable manifest-file location/name and assign params\nstreamer = StreamGear(output=\"dash_out.mpd\", logging=True, **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import StreamGear\n# activate Single-Source Mode and various other parameters\nstream_params = {\n\"-video_source\": \"foo.mp4\", # define Video-Source\n\"-vcodec\": \"libx265\", # assigns H.265/HEVC video encoder\n\"-x265-params\": \"lossless=1\", # enables Lossless encoding\n\"-crf\": 25, # Constant Rate Factor: 25\n\"-bpp\": \"0.15\", # Bits-Per-Pixel(BPP), an Internal StreamGear parameter to ensure good quality of high motion scenes\n\"-streams\": [\n{\"-resolution\": \"1280x720\", \"-video_bitrate\": \"4000k\"}, # Stream1: 1280x720 at 4000kbs bitrate\n{\"-resolution\": \"640x360\", \"-framerate\": 60.0},  # Stream2: 640x360 at 60fps\n],\n\"-audio\": \"/home/foo/foo1.aac\",  # define input audio-source: \"/home/foo/foo1.aac\",\n\"-acodec\": \"libfdk_aac\", # assign lossless AAC audio encoder\n\"-vbr\": 4, # Variable Bit Rate: `4`\n}\n# describe a suitable master playlist file location/name and assign params\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", logging=True, **stream_params)\n# trancode source\nstreamer.transcode_source()\n# terminate\nstreamer.terminate()\n</code></pre> <p> </p> <ol> <li> <p> In Real-time Frames Mode, the Primary Stream's framerate defaults to <code>-input_framerate</code> attribute value, if defined, else it will be 25fps.\u00a0\u21a9</p> </li> </ol>"},{"location":"gears/videogear/overview/","title":"VideoGear API","text":"VideoGear API's generalized workflow"},{"location":"gears/videogear/overview/#overview","title":"Overview","text":"<p>VideoGear API provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. </p> <p>VideoGear also acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters with an exclusive <code>enablePiCamera</code> boolean flag.</p> <p>VideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not)  with minimum effort and writing way fewer lines of code.</p> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/videogear/overview/#importing","title":"Importing","text":"<p>You can import VideoGear API in your program as follows:</p> <pre><code>from vidgear.gears import VideoGear\n</code></pre> <p> </p>"},{"location":"gears/videogear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through VideoGear Usage Examples, Checkout more of its advanced configurations here \u27b6</p>"},{"location":"gears/videogear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/videogear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/videogear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/videogear/params/","title":"VideoGear API Parameters","text":"<p>VideoGear acts as a Common Video-Capture API that provides internal access for both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/videogear/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide direct access to PiGear or CamGear APIs respectively in VideoGear. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in VideoGear.</p>"},{"location":"gears/videogear/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>VideoGear(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/videogear/params/#options","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in VideoGear. Default is also <code>False</code>.</p>"},{"location":"gears/videogear/params/#source","title":"<code>source</code>","text":"<p>VideoGear API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>VideoGear(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>VideoGear(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>VideoGear(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>VideoGear(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/videogear/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the VideoGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend (<code>backend=cv2.CAP_GSTREAMER</code>) for any livestreams (such as Twitch).</p> <p>VideoGear automatically enforce GStreamer backend (backend=<code>cv2.CAP_GSTREAMER</code>) for YouTube-livestreams!</p> <p>VideoGear will exit with <code>RuntimeError</code> for YouTube livestreams, if OpenCV is not compiled with GStreamer(<code>&gt;=v1.0.0</code>) support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>VideoGear(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/videogear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>VideoGear(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#options_1","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nVideoGear(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in VideoGear.</p>"},{"location":"gears/videogear/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw <code>ValueError</code> for any negative value.</p> <p>This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board.\"</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True, camera_num=0)\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter sets the resolution (i.e. <code>(width,height)</code>) of the source. </p> <p>For more information read here \u27b6</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter sets the framerate of the source.</p> <p>For more information read here \u27b6</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>VideoGear(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Tweak Parameters <code>like brightness, saturation, senor_mode, resolution, etc.</code> available within Picamera library.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed in PiCamera Docs</p> <p>The desired parameters can be passed to VideoGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# assigning it\nVideoGear(enablePiCamera=True, logging=True, **options)\n</code></pre> <p>User-specific attributes:</p> <p>Additionally, <code>options</code> parameter also support some User-specific attributes, which are as follows:</p> <ul> <li> <p><code>HWFAILURE_TIMEOUT</code> (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a <code>SystemError</code> to save resources. Its value can only be between <code>1.0</code> (min) and <code>10.0</code> (max) and its default value is <code>2.0</code>. Its usage is as follows: </p> <pre><code>options = {\"HWFAILURE_TIMEOUT\": 2.5}  # sets timeout to 2.5 seconds\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/videogear/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in VideoGear.</p>"},{"location":"gears/videogear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>VideoGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/videogear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>VideoGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/videogear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the VideoGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>VideoGear(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/","title":"VideoGear API Usage Examples:","text":"<p>After going through following Usage Examples, Checkout more of its advanced configurations here \u27b6</p> <p> </p>"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-camgear-backend","title":"Bare-Minimum Usage with CamGear backend","text":"<p>VideoGear by default provides direct internal access to CamGear API.</p> <p>Following is the bare-minimum code you need to access CamGear API with VideoGear:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = VideoGear(source=\"myvideo.avi\").start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#bare-minimum-usage-with-pigear-backend","title":"Bare-Minimum Usage with PiGear backend","text":"<p>VideoGear contains a special <code>enablePiCamera</code> flag that when <code>True</code> provides internal access to PiGear API.</p> <p>Following is the bare-minimum code you need to access PiGear API with VideoGear:</p> <p>Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear Backend, otherwise nothing will work.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n# enable enablePiCamera boolean flag to access PiGear API backend\nstream = VideoGear(enablePiCamera=True).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#using-videogear-with-video-stabilizer-backend","title":"Using VideoGear with Video Stabilizer backend","text":"<p>VideoGear API provides a special internal wrapper around VidGear's Exclusive Video Stabilizer class and provides easy way of activating stabilization for various video-streams (real-time or not) with its <code>stabilize</code> boolean parameter during initialization.</p> <p>The usage example is as follows:</p> <p>For a more detailed information on Video-Stabilizer Class, Read here \u27b6</p> <p>The stabilizer might be slower for High-Quality/Resolution videos-frames.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport numpy as np\nimport cv2\n# open any valid video stream with stabilization enabled(`stabilize = True`)\nstream_stab = VideoGear(source=\"test.mp4\", stabilize=True).start()\n# loop over\nwhile True:\n# read stabilized frames\nframe_stab = stream_stab.read()\n# check for stabilized frame if None-type\nif frame_stab is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Stabilized Output\", frame_stab)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close streams\nstream_stab.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#advanced-videogear-usage-with-camgear-backend","title":"Advanced VideoGear usage with CamGear Backend","text":"<p>VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API.</p> <p>The usage example of VideoGear API with Variable Camera Properties is as follows:</p> Info <p>This example is basically a VideoGear API implementation of this CamGear usage example for controlling its properties (such as its brightness, saturation, resolution, framerate, gain etc.). Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner.</p> <p>All the supported Source Tweak Parameters can be found here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n# define suitable tweak parameters for your stream.\noptions = {\n\"CAP_PROP_FRAME_WIDTH\": 320, # resolution 320x240\n\"CAP_PROP_FRAME_HEIGHT\": 240,\n\"CAP_PROP_FPS\": 60, # framerate 60fps\n}\n# To open live video stream on webcam at first index(i.e. 0) \n# device and apply source tweak parameters\nstream = VideoGear(source=0, logging=True, **options).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#advanced-videogear-usage-with-pigear-backend","title":"Advanced VideoGear usage with PiGear Backend","text":"<p>VideoGear provides internal access to both CamGear and PiGear APIs, and thereby all additional parameters of PiGear API or CamGear API are also easily accessible within VideoGear API.</p> <p>The usage example of VideoGear API with Variable PiCamera Properties is as follows:</p> Info <p>This example is basically a VideoGear API implementation of this PiGear usage example. Thereby, any CamGear or PiGear usage examples can be implemented with VideoGear API in the similar manner.</p> <p>Make sure to enable Raspberry Pi hardware-specific settings prior using PiGear Backend, otherwise nothing will work.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# activate enablePiCamera and open pi video stream with defined parameters\nstream = VideoGear(\nenablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#using-videogear-with-colorspace-manipulation","title":"Using VideoGear with Colorspace Manipulation","text":"<p>VideoGear API also supports Colorspace Manipulation but NOT Direct like other VideoCapture Gears. </p> <p>Important</p> <ul> <li> <p><code>color_space</code> global variable is NOT Supported in VideoGear API, calling it will result in <code>AttribueError</code>. More details can be found here \u27b6</p> </li> <li> <p>Any incorrect or None-type value on <code>colorspace</code> parameter will be skipped automatically.</p> </li> </ul> <p>In following example code, we will convert source colorspace to HSV on initialization:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nimport cv2\n# Open any source of your choice, like Webcam first index(i.e. 0) and change its colorspace to `HSV`\nstream = VideoGear(source=0, colorspace=\"COLOR_BGR2HSV\", logging=True).start()\n# loop over\nwhile True:\n# read HSV frames\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the HSV frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\n# check for 'q' key is pressed\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"gears/videogear/usage/#bonus-examples","title":"Bonus Examples","text":"<p>Checkout more advanced VideoGear examples with unusual configuration here \u27b6</p> <p> </p>"},{"location":"gears/webgear/advanced/","title":"WebGear API Advanced Usage:","text":"<p>This is a continuation of the WebGear doc \u27b6. Thereby, It's advised to first get familiarize with this API, and its requirements.</p> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-variable-colorspace","title":"Using WebGear with Variable Colorspace","text":"<p>WebGear by default only supports \"BGR\" colorspace frames as input, but you can use <code>jpeg_compression_colorspace</code> string attribute through its options dictionary parameter to specify incoming frames colorspace. </p> <p>Let's implement a bare-minimum example using WebGear, where we will be sending GRAY frames to client browser:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example works in conjunction with Source ColorSpace manipulation for VideoCapture Gears \u27b6</p> <p>Supported <code>jpeg_compression_colorspace</code> colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n# various performance tweaks and enable grayscale input\noptions = {\n\"frame_size_reduction\": 25,\n\"jpeg_compression_colorspace\": \"GRAY\",  # set grayscale\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# initialize WebGear app and change its colorspace to grayscale\nweb = WebGear(\nsource=\"foo.mp4\", colorspace=\"COLOR_BGR2GRAY\", logging=True, **options\n)\n# run this app on Uvicorn server at address http://0.0.0.0:8000/\nuvicorn.run(web(), host=\"0.0.0.0\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address on your local machine.</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-a-custom-sourceopencv","title":"Using WebGear with a Custom Source(OpenCV)","text":"New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <p>WebGear allows you to easily define your own custom Source that you want to use to transform your frames before sending them onto the browser. </p> <p>JPEG Frame-Compression and all of its performance enhancing attributes are disabled with a Custom Source!</p> <p>Let's implement a bare-minimum example with a Custom Source using WebGear API and OpenCV:</p> <pre><code># import necessary libs\nimport uvicorn, asyncio, cv2\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\n# initialize WebGear app without any source\nweb = WebGear(logging=True)\n# create your own custom frame producer\nasync def my_frame_producer():\n# !!! define your own video source here !!!\n# Open any video stream such as live webcam \n# video stream on first index(i.e. 0) device\nstream = cv2.VideoCapture(0)\n# loop over frames\nwhile True:\n# read frame from provided source\n(grabbed, frame) = stream.read()\n# break if NoneType\nif not grabbed:\nbreak\n# do something with your OpenCV frame here\n# reducer frames size if you want more performance otherwise comment this line\nframe = await reducer(frame, percentage=30, interpolation=cv2.INTER_AREA)  # reduce frame by 30%\n# handle JPEG encoding\nencodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n# yield frame in byte format\nyield (b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\nawait asyncio.sleep(0)\n# close stream\nstream.release()\n# add your custom frame producer to config\nweb.config[\"generator\"] = my_frame_producer\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address.</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-mounting-points","title":"Using WebGear with Custom Mounting Points","text":"<p>With our highly extensible WebGear API, you can add your own mounting points, where additional files located, as follows:</p> <pre><code># import libs\nimport uvicorn\nfrom starlette.routing import Mount\nfrom starlette.staticfiles import StaticFiles\nfrom vidgear.gears.asyncio import WebGear\n# various performance tweaks\noptions = {\n\"frame_size_reduction\": 40,\n\"jpeg_compression_quality\": 80,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": False,\n}\n# initialize WebGear app\nweb = WebGear(\nsource=\"foo.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n# append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory\nweb.routes.append(\nMount(\"/test\", app=StaticFiles(directory=\"/home/foo/.vidgear/test\"), name=\"test\")\n)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script <code>jquery-3.3.1.slim.min.js</code> in this folder and  want to integrate it, then, we can do something like this:</p> <pre><code>&lt;script src=\"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\"&gt;&lt;/script&gt;\n</code></pre> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-custom-webpage-routes","title":"Using WebGear with Custom Webpage Routes","text":"<p>With Webgear's flexible API, you can even add your additional HTML Static webpages without any extra efforts.</p> <p>Suppose we want to add a simple <code>hello world</code> webpage to our WebGear server. So let's create a bare-minimum <code>hello.html</code> file with HTML code as follows:</p> <pre><code>&lt;html&gt;\n&lt;header&gt;\n&lt;title&gt;This is Hello world page&lt;/title&gt;\n&lt;/header&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello World&lt;/h1&gt;\n&lt;p&gt;how ya doing?&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Then in our application code, we can integrate this webpage route, as follows:</p> <p><pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.templating import Jinja2Templates\nfrom starlette.routing import Route\nfrom vidgear.gears.asyncio import WebGear\n# Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located\ntemplate = Jinja2Templates(directory=\"/home/foo/.vidgear/custom_template\")\n# render and return our webpage template\nasync def hello_world(request):\npage = \"hello.html\"\ncontext = {\"request\": request}\nreturn template.TemplateResponse(page, context)\n# add various performance tweaks as usual\noptions = {\n\"frame_size_reduction\": 40,\n\"jpeg_compression_quality\": 80,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": False,\n}\n# initialize WebGear app with a valid source\nweb = WebGear(\nsource=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n# append new route to point our rendered webpage\nweb.routes.append(Route(\"/hello\", endpoint=hello_world))\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> And that's all, Now you can see output at <code>http://localhost:8000/hello</code> address.</p> <p> </p>"},{"location":"gears/webgear/advanced/#using-webgear-with-middlewares","title":"Using WebGear with MiddleWares","text":"<p>WebGear natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>All supported middlewares can be found here \u27b6</p> <p>For this example, let's use <code>CORSMiddleware</code> for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows:</p> <p>The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context.</p> <p>Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6</p> <p><pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.cors import CORSMiddleware\nfrom vidgear.gears.asyncio import WebGear\n# add various performance tweaks as usual\noptions = {\n\"frame_size_reduction\": 40,\n\"jpeg_compression_quality\": 80,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": False,\n}\n# initialize WebGear app with a valid source\nweb = WebGear(\nsource=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n# define and assign suitable cors middlewares\nweb.middleware = [\nMiddleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\n]\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> And that's all, Now you can see output at <code>http://localhost:8000</code> address.</p> <p> </p>"},{"location":"gears/webgear/advanced/#rules-for-altering-webgear-files-and-folders","title":"Rules for Altering WebGear Files and Folders","text":"<p>WebGear gives us complete freedom of altering data files generated in Auto-Generation Process, But you've to  keep the following rules in mind:</p>"},{"location":"gears/webgear/advanced/#rules-for-altering-data-files","title":"Rules for Altering Data Files","text":"<ul> <li> You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions.</li> <li> You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) present in <code>templates</code> folder inside the <code>webgear</code> directory at the default location, otherwise, it will trigger Auto-generation process, and it will overwrite the existing files with Server ones.</li> <li> You're allowed to add your own additional <code>.html</code>, <code>.css</code>, <code>.js</code>, etc. files in the respective folders at the default location and custom mounted Data folders.</li> </ul>"},{"location":"gears/webgear/advanced/#rules-for-altering-data-folders","title":"Rules for Altering Data Folders","text":"<ul> <li> You're allowed to add/mount any number of additional folder as shown in this example above.</li> <li> You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename <code>templates</code> folder in the <code>webgear</code> directory where critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) are located, otherwise, it will trigger Auto-generation process.</li> </ul>"},{"location":"gears/webgear/advanced/#bonus-examples","title":"Bonus Examples","text":"<p>Checkout more advanced WebGear examples with unusual configuration here \u27b6</p> <p> </p>"},{"location":"gears/webgear/overview/","title":"WebGear API","text":"WebGear API's Video Server running at http://localhost:8000/ address."},{"location":"gears/webgear/overview/#overview","title":"Overview","text":"<p>WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser.</p> <p>WebGear API works on Starlette's ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc.</p> <p>WebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart Streaming Response and a Uvicorn ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video.</p> <p>In layman's terms, WebGear acts as a powerful Video Broadcaster that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs, thereby granting it exclusive power for transferring frames incoming from any source to the network.</p> <p> </p>"},{"location":"gears/webgear/overview/#data-files-auto-generation-workflow-for-webgear","title":"Data-Files Auto-Generation WorkFlow for WebGear","text":"Disabling Auto-Generation process in WebGear <p>Starting with vidgear <code>v0.3.0</code>, you can now completely disable Auto-Generation process in WebGear API using <code>skip_generate_webdata</code> dictionary boolean attribute. When <code>{skip_generate_webdata:True}</code>, no default data files will be downloaded or validated during initialization.</p> <p>Only <code>/video</code> route is available when <code>{skip_generate_webdata:True}</code> in WebGear API. All other default routes will be JSONResponses with <code>404</code>/<code>500</code> status codes.</p> <p>On initializing WebGear API, it automatically checks for three critical data files(i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) inside the <code>templates</code> folder of the <code>webgear</code> directory at the default location which gives rise to the following two possible scenario:</p> <ul> <li> If data-files found: it will proceed normally for instantiating the Starlette application.</li> <li> If data-files not found: it will trigger the Auto-Generation process</li> </ul>"},{"location":"gears/webgear/overview/#default-location","title":"Default Location","text":"<ul> <li>A default location is the path of the directory where data files/folders are downloaded/generated/saved.</li> <li>By default, the <code>.vidgear</code> the folder at the home directory of your machine (for e.g <code>/home/foo/.vidgear</code> on Linux) serves as the default location.</li> <li> <p>But you can also use WebGear's <code>custom_data_location</code> dictionary attribute to change/alter default location path to somewhere else.</p> <p>Tip<p>You can set <code>logging=True</code> during initialization, for easily identifying the selected default location, which will be something like this (on a Linux machine)</p> <pre><code>WebGear :: DEBUG :: `/home/foo/.vidgear` is the default location for saving WebGear data-files.\n</code></pre> </p> </li> </ul>"},{"location":"gears/webgear/overview/#auto-generation-process","title":"Auto-Generation process","text":"<p>Info</p> <ul> <li> <p>You can also force trigger the Auto-generation process to overwrite existing data-files using <code>overwrite_default_files</code> dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected.</p> </li> <li> <p>It is advised to enable logging(<code>logging=True</code>) on the first run for easily identifying any runtime errors</p> </li> </ul> <ul> <li>On triggering this process, WebGear API creates <code>webgear</code> directory, and <code>templates</code> and <code>static</code> folders inside along with <code>js</code>, <code>css</code>, <code>img</code> sub-folders at the assigned default location.</li> <li> <p>Thereby at this default location, the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order:</p> <pre><code>.vidgear\n\u2514\u2500\u2500 webgear\n    \u251c\u2500\u2500 static\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 css\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 custom.css\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 img\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 favicon-32x32.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 js\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 custom.js\n    \u2514\u2500\u2500 templates\n        \u251c\u2500\u2500 404.html\n        \u251c\u2500\u2500 500.html\n        \u251c\u2500\u2500 base.html\n        \u2514\u2500\u2500 index.html\n6 directories, 7 files\n</code></pre> </li> <li> <p>Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear/overview/#importing","title":"Importing","text":"<p>You can import WebGear API in your program as follows:</p> <pre><code>from vidgear.gears.asyncio import WebGear\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear/overview/#webgears-default-template","title":"WebGear's Default Template","text":"New in v0.2.1 <p>New Standalone WebGear's Default Theme was added in <code>v0.2.1</code>.</p> <p>The WebGear API by default uses simple &amp; elegant WebGear's Default Theme which looks like something as follows:</p>"},{"location":"gears/webgear/overview/#indexhtml","title":"Index.html","text":"<p>Can be accessed by visiting WebGear app server, running at http://localhost:8000/:</p>"},{"location":"gears/webgear/overview/#404html","title":"404.html","text":"<p>Appears when respective URL is not found, for example http://localhost:8000/ok:</p>"},{"location":"gears/webgear/overview/#500html","title":"500.html","text":"<p>Appears when an API Error is encountered:</p> <p>If <code>logging</code> is enabled and an error occurs, then instead of displaying this 500 handler, WebGear will respond with a traceback response.</p> <p> </p>"},{"location":"gears/webgear/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WebGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/webgear/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/webgear/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/webgear/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/webgear/params/","title":"WebGear API Parameters","text":"<p>WebGear provides a special internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/webgear/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#options","title":"<code>options</code>","text":"<p>This parameter can be used to pass user-defined parameter to WebGear API by formatting them as this parameter's attribute. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p>"},{"location":"gears/webgear/params/#webgear-specific-attributes","title":"WebGear Specific attributes","text":"<ul> <li> <p><code>custom_data_location</code> (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows:</p> <pre><code># set default location to '/home/foo/foo1'\noptions = {\"custom_data_location\": \"/home/foo/foo1\"}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>overwrite_default_files</code> (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows:</p> <p>Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten.</p> <pre><code># force trigger the Auto-generation process\noptions = {\"overwrite_default_files\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>frame_size_reduction</code> (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the  most significant effect on performance. The value defaults to <code>25</code>, and must be no higher than <code>90</code> (fastest, max compression, Barely Visible frame-size) and no lower than <code>0</code> (slowest, no compression, Original frame-size). Its recommended value is between <code>40-60</code>. Its usage is as follows:</p> <pre><code># frame-size will be reduced by 50%\noptions = {\"frame_size_reduction\": 50} \n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_quality</code>: (int/float) This attribute controls the JPEG quantization factor. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. Its usage is as follows:</p> New in v0.2.2 <p><code>jpeg_compression_quality</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># activate jpeg encoding and set quality 95%\noptions = {\"jpeg_compression_quality\": 95}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_fastdct</code>: (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also <code>True</code>, and its usage is as follows:</p> New in v0.2.2 <p><code>jpeg_compression_fastdct</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># activate jpeg encoding and enable fast dct\noptions = {\"jpeg_compression_fastdct\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_fastupsample</code>: (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is <code>False</code>, and its usage is as follows:</p> New in v0.2.2 <p><code>jpeg_compression_fastupsample</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># activate jpeg encoding and enable fast upsampling\noptions = {\"jpeg_compression_fastupsample\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>jpeg_compression_colorspace</code>: (str) This internal attribute is used to specify incoming frames colorspace with compression. Its usage is as follows:</p> <p>Supported <code>jpeg_compression_colorspace</code> colorspace values are <code>RGB</code>, <code>BGR</code>, <code>RGBX</code>, <code>BGRX</code>, <code>XBGR</code>, <code>XRGB</code>, <code>GRAY</code>, <code>RGBA</code>, <code>BGRA</code>, <code>ABGR</code>, <code>ARGB</code>, <code>CMYK</code>. More information can be found here \u27b6</p> New in v0.2.2 <p><code>jpeg_compression_colorspace</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># Specify incoming frames are `grayscale`\noptions = {\"jpeg_compression\": \"GRAY\"}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>enable_infinite_frames</code> (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is <code>False</code>. Its usage is as follows:</p> New in v0.2.1 <p><code>enable_infinite_frames</code> attribute was added in <code>v0.2.1</code>.</p> <pre><code># emulate infinite frames\noptions = {\"enable_infinite_frames\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> <li> <p><code>skip_generate_webdata</code> (boolean) : Can be used to completely disable Data-Files Auto-Generation WorkFlow in WebGear API, and thereby no default data files will be downloaded or validated during its initialization. Its default value is <code>False</code>. Its usage is as follows:</p> New in v0.3.0 <p><code>skip_generate_webdata</code> attribute was added in <code>v0.3.0</code>.</p> <pre><code># completely disable Data-Files Auto-Generation WorkFlow\noptions = {\"skip_generate_webdata\": True}\n# assign it\nWebGear(logging=True, **options)\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in WebGear.</p>"},{"location":"gears/webgear/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#options_1","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in WebGear. Default is also <code>False</code>.</p>"},{"location":"gears/webgear/params/#source","title":"<code>source</code>","text":"<p>WebGear API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>WebGear(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>WebGear(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>WebGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>WebGear(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>WebGear(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/webgear/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>WebGear(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>WebGear(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nWebGear(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in WebGear.</p>"},{"location":"gears/webgear/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw <code>ValueError</code> for any negative value.</p> <p>This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board.\"</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True, camera_num=0)\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter sets the resolution (i.e. <code>(width,height)</code>) of the source. </p> <p>For more information read here \u27b6</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter sets the framerate of the source.</p> <p>For more information read here \u27b6</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>WebGear(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#options_3","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Tweak Parameters <code>like brightness, saturation, senor_mode, resolution, etc.</code> available within Picamera library.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed in PiCamera Docs</p> <p>The desired parameters can be passed to WebGear API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# assigning it\nWebGear(enablePiCamera=True, logging=True, **options)\n</code></pre> <p>User-specific attributes:</p> <p>Additionally, <code>options</code> parameter also support some User-specific attributes, which are as follows:</p> <ul> <li> <p><code>HWFAILURE_TIMEOUT</code> (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a <code>SystemError</code> to save resources. Its value can only be between <code>1.0</code> (min) and <code>10.0</code> (max) and its default value is <code>2.0</code>. Its usage is as follows: </p> <pre><code>options = {\"HWFAILURE_TIMEOUT\": 2.5}  # sets timeout to 2.5 seconds\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in WebGear.</p>"},{"location":"gears/webgear/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>WebGear(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/webgear/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WebGear(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/webgear/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the WebGear API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>WebGear(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/webgear/usage/","title":"WebGear API Usage Examples:","text":""},{"location":"gears/webgear/usage/#requirements","title":"Requirements","text":""},{"location":"gears/webgear/usage/#installation-with-asyncio-support","title":"Installation with Asyncio Support","text":"<p>WebGear API is the part of <code>asyncio</code> package of VidGear, thereby you need to install VidGear with asyncio support as follows:</p> <pre><code>pip install vidgear[asyncio]\n</code></pre>"},{"location":"gears/webgear/usage/#asgi-server","title":"ASGI Server","text":"<p>You'll also need to install an ASGI Server to run following WebGear usage examples, and by default WebGear ships the state-of-the-art <code>uvicorn</code> Server. But you can also use other ASGI server such as <code>daphne</code>, or <code>hypercorn</code> with it.</p> <p> </p>"},{"location":"gears/webgear/usage/#performance-enhancements","title":"Performance Enhancements","text":"<p>WebGear provides certain performance enhancing attributes for its <code>options</code> dictionary parameter to cope with performance-throttling.</p> <p>Performance Enhancing Attributes</p> <ul> <li> <p><code>frame_size_reduction</code>: (int/float) This attribute controls the size reduction(in percentage) of the frame to be streamed on Server. Its value has the most significant effect on WebGear performance: More its value, smaller will be frame size and faster will be live streaming. The value defaults to <code>20</code>, and must be no higher than <code>90</code> (fastest, max compression, Barely Visible frame-size) and no lower than <code>0</code> (slowest, no compression, Original frame-size). Its recommended value is between <code>40~60</code>. Its usage is as follows:</p> <pre><code>options={\"frame_size_reduction\": 50} #frame-size will be reduced by 50%\n</code></pre> </li> <li> <p>Various Encoding Parameters:</p> <p>In WebGear API, the input video frames are first encoded into Motion JPEG (M-JPEG or MJPEG) compression format, in which each video frame or interlaced field of a digital video sequence is compressed separately as a JPEG image using <code>simplejpeg</code> library, before sending onto a server. Therefore, WebGear API provides various attributes to have full control over JPEG encoding performance and quality, which are as follows:</p> <ul> <li> <p><code>jpeg_compression_quality</code>: (int/float) This attribute controls the JPEG quantization factor. Its value varies from <code>10</code> to <code>100</code> (the higher is the better quality but performance will be lower). Its default value is <code>90</code>. Its usage is as follows:</p> <pre><code># activate jpeg encoding and set quality 95%\noptions = {\"jpeg_compression_quality\": 95}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastdct</code>: (bool) This attribute if True, WebGear API uses fastest DCT method that speeds up decoding by 4-5% for a minor loss in quality. Its default value is also <code>True</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast dct\noptions = {\"jpeg_compression_fastdct\": True}\n</code></pre> </li> <li> <p><code>jpeg_compression_fastupsample</code>: (bool) This attribute if True, WebGear API use fastest color upsampling method. Its default value is <code>False</code>, and its usage is as follows:</p> <pre><code># activate jpeg encoding and enable fast upsampling\noptions = {\"jpeg_compression_fastupsample\": True}\n</code></pre> </li> </ul> </li> </ul> <p> </p>"},{"location":"gears/webgear/usage/#bare-minimum-usage-with-performance-enhancements","title":"Bare-Minimum Usage with Performance Enhancements","text":"<p>Let's implement our Bare-Minimum usage example with these Performance Enhancing Attributes \u27b6 for speeding up the output.</p>"},{"location":"gears/webgear/usage/#running-programmatically","title":"Running Programmatically","text":"<p>You can access and run WebGear VideoStreamer Server programmatically in your python script in just a few lines of code, as follows:</p> <p>For accessing WebGear on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n# various performance tweaks\noptions = {\n\"frame_size_reduction\": 40,\n\"jpeg_compression_quality\": 80,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": False,\n}\n# initialize WebGear app\nweb = WebGear(source=\"foo.mp4\", logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>which can be accessed on any browser on your machine at http://localhost:8000/.</p>"},{"location":"gears/webgear/usage/#running-from-terminal","title":"Running from Terminal","text":"<p>You can also access and run WebGear Server directly from the terminal commandline. The following command will run a WebGear VideoStreamer server at http://localhost:8000/:</p> <p>Make sure your <code>PYTHON_PATH</code> is set to python 3.7+ versions only.</p> <p>If you're using <code>--options/-op</code> flag, then kindly wrap your dictionary value in single <code>''</code> quotes.</p> <pre><code>python3 -m vidgear.gears.asyncio --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"jpeg_compression_quality\": 80, \"jpeg_compression_fastdct\": True, \"jpeg_compression_fastupsample\": False}'\n</code></pre> <p>which can also be accessed on any browser on the network at http://localhost:8000/.</p> Advanced Usage from Terminal <p>You can run <code>python3 -m vidgear.gears.asyncio -h</code> help command to see all the advanced settings, as follows:</p> <pre><code>usage: python -m vidgear.gears.asyncio [-h] [-m MODE] [-s SOURCE] [-ep ENABLEPICAMERA] [-S STABILIZE]\n[-cn CAMERA_NUM] [-yt stream_mode] [-b BACKEND] [-cs COLORSPACE]\n[-r RESOLUTION] [-f FRAMERATE] [-td TIME_DELAY]\n[-ip IPADDRESS] [-pt PORT] [-l LOGGING] [-op OPTIONS]\nRuns WebGear/WebGear_RTC Video Server through terminal.\n\noptional arguments:\n  -h, --help            show this help message and exit\n-m {mjpeg,webrtc}, --mode {mjpeg,webrtc}\nWhether to use \"MJPEG\" or \"WebRTC\" mode for streaming.\n  -s SOURCE, --source SOURCE\n                        Path to input source for CamGear API.\n  -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA\n                        Sets the flag to access PiGear(if True) or otherwise\n                        CamGear API respectively.\n  -S STABILIZE, --stabilize STABILIZE\n                        Enables/disables real-time video stabilization.\n  -cn CAMERA_NUM, --camera_num CAMERA_NUM\n                        Sets the camera module index that will be used by\n                        PiGear API.\n  -yt STREAM_MODE, --stream_mode STREAM_MODE\n                        Enables YouTube Mode in CamGear API.\n  -b BACKEND, --backend BACKEND\n                        Sets the backend of the video source in CamGear API.\n  -cs COLORSPACE, --colorspace COLORSPACE\n                        Sets the colorspace of the output video stream.\n  -r RESOLUTION, --resolution RESOLUTION\n                        Sets the resolution (width,height) for camera module\n                        in PiGear API.\n  -f FRAMERATE, --framerate FRAMERATE\n                        Sets the framerate for camera module in PiGear API.\n  -td TIME_DELAY, --time_delay TIME_DELAY\n                        Sets the time delay(in seconds) before start reading\n                        the frames.\n  -ip IPADDRESS, --ipaddress IPADDRESS\n                        Uvicorn binds the socket to this ipaddress.\n  -pt PORT, --port PORT\n                        Uvicorn binds the socket to this port.\n  -l LOGGING, --logging LOGGING\n                        Enables/disables error logging, essential for\ndebugging.\n  -op OPTIONS, --options OPTIONS\n                        Sets the parameters supported by APIs(whichever being\n                        accessed) to the input videostream, But make sure to\n                        wrap your dict value in single or double quotes.\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/advanced/","title":"WebGear_RTC API Advanced Usage:","text":"<p>This is a continuation of the WebGear_RTC doc \u27b6. Thereby, It's advised to first get familiarize with this API, and its requirements.</p> <p>After going through following Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-as-real-time-broadcaster","title":"Using WebGear_RTC as Real-time Broadcaster","text":"<p>WebGear_RTC by default only supports one-to-one peer connection with a single consumer or client. But you can use <code>enable_live_broadcast</code> boolean attribute through its options dictionary parameter to easily enable live broadcast/stream to multiple peer consumers/clients at the same time.</p> <p>Let's implement a bare-minimum example using WebGear_RTC as Real-time Broadcaster:</p> <p><code>enable_infinite_frames</code> is enforced by default with this(<code>enable_live_broadcast</code>) attribute.</p> <p>For accessing WebGear_RTC on different Client Devices on the network, we use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n# various performance tweaks and enable live broadcasting\noptions = {\n\"frame_size_reduction\": 25,\n\"enable_live_broadcast\": True,\n}\n# initialize WebGear_RTC app\nweb = WebGear_RTC(source=\"foo.mp4\", logging=True, **options)\n# run this app on Uvicorn server at address http://0.0.0.0:8000/\nuvicorn.run(web(), host=\"0.0.0.0\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address on your local machine.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-a-custom-sourceopencv","title":"Using WebGear_RTC with a Custom Source(OpenCV)","text":"<p>WebGear_RTC provides <code>custom_stream</code> attribute with its <code>options</code> parameter that allows you to easily define your own Custom Streaming Class with suitable source that you want to use to transform your frames before sending them onto the browser. </p> <p>Let's implement a bare-minimum example with a Custom Source using WebGear_RTC API and OpenCV:</p> New in v0.2.4 <p>This implementation was added in <code>v0.2.4</code>.</p> <p>Auto-Reconnection or Auto-Refresh works out-of-the-box with this implementation.</p> <p>Make sure your Custom Streaming Class at-least implements <code>read()</code> and <code>stop()</code> methods as shown in following example, otherwise WebGear_RTC will throw ValueError!</p> Using Vidgear's VideoCapture APIs instead of OpenCV <p>You can directly replace Custom Streaming Class(<code>Custom_Stream_Class</code> in following example) with any VideoCapture APIs. These APIs implements <code>read()</code> and <code>stop()</code> methods by-default, so they're also supported out-of-the-box. </p> <p>See this example \u27b6 for more information.</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears.asyncio import WebGear_RTC\n# create your own custom streaming class\nclass Custom_Stream_Class:\n\"\"\"\n    Custom Streaming using OpenCV\n    \"\"\"\ndef __init__(self, source=0):\n# !!! define your own video source here !!!\nself.source = cv2.VideoCapture(source)\n# define running flag\nself.running = True\ndef read(self):\n# don't forget this function!!!\n# check if source was initialized or not\nif self.source is None:\nreturn None\n# check if we're still running\nif self.running:\n# read frame from provided source\n(grabbed, frame) = self.source.read()\n# check if frame is available\nif grabbed:\n# do something with your OpenCV frame here\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# return our gray frame\nreturn gray\nelse:\n# signal we're not running now\nself.running = False\n# return None-type\nreturn None\ndef stop(self):\n# don't forget this function!!!\n# flag that we're not running\nself.running = False\n# close stream\nif not self.source is None:\nself.source.release()\n# assign your Custom Streaming Class with adequate source (for e.g. foo.mp4) \n# to `custom_stream` attribute in options parameter\noptions = {\"custom_stream\": Custom_Stream_Class(source=\"foo.mp4\")}\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000/</code> address.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-custom-mounting-points","title":"Using WebGear_RTC with Custom Mounting Points","text":"<p>With our highly extensible WebGear_RTC API, you can add your own mounting points, where additional files located, as follows:</p> <pre><code># import libs\nimport uvicorn\nfrom starlette.routing import Mount\nfrom starlette.staticfiles import StaticFiles\nfrom vidgear.gears.asyncio import WebGear_RTC\n# various performance tweaks\noptions = {\n\"frame_size_reduction\": 25,\n}\n# initialize WebGear_RTC app\nweb = WebGear_RTC(\nsource=\"foo.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n# append new route i.e. mount another folder called `test` located at `/home/foo/.vidgear/test` directory\nweb.routes.append(\nMount(\"/test\", app=StaticFiles(directory=\"/home/foo/.vidgear/test\"), name=\"test\")\n)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>Then you can use this folder in your HTML page, to host data-files. For example, if we have jQuery script <code>jquery-3.3.1.slim.min.js</code> in this folder and  want to integrate it, then, we can do something like this:</p> <pre><code>&lt;script src=\"{{ url_for('test', path='jquery-3.3.1.slim.min.js') }}\"&gt;&lt;/script&gt;\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-custom-webpage-routes","title":"Using WebGear_RTC with Custom Webpage Routes","text":"<p>With Webgear_RTC's flexible API, you can even add your additional HTML Static webpages without any extra efforts.</p> <p>Suppose we want to add a simple <code>hello world</code> webpage to our WebGear_RTC server. So let's create a bare-minimum <code>hello.html</code> file with HTML code as follows:</p> <pre><code>&lt;html&gt;\n&lt;header&gt;\n&lt;title&gt;This is Hello world page&lt;/title&gt;\n&lt;/header&gt;\n&lt;body&gt;\n&lt;h1&gt;Hello World&lt;/h1&gt;\n&lt;p&gt;how ya doing?&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Then in our application code, we can integrate this webpage route, as follows:</p> <p><pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.templating import Jinja2Templates\nfrom starlette.routing import Route\nfrom vidgear.gears.asyncio import WebGear_RTC\n# Build out Jinja2 template render at `/home/foo/.vidgear/custom_template` path in which our `hello.html` file is located\ntemplate = Jinja2Templates(directory=\"/home/foo/.vidgear/custom_template\")\n# render and return our webpage template\nasync def hello_world(request):\npage = \"hello.html\"\ncontext = {\"request\": request}\nreturn template.TemplateResponse(page, context)\n# add various performance tweaks as usual\noptions = {\n\"frame_size_reduction\": 25,\n}\n# initialize WebGear_RTC app with a valid source\nweb = WebGear_RTC(\nsource=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n# append new route to point our rendered webpage\nweb.routes.append(Route(\"/hello\", endpoint=hello_world))\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> And that's all, Now you can see output at <code>http://localhost:8000/hello</code> address.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#using-webgear_rtc-with-middlewares","title":"Using WebGear_RTC with MiddleWares","text":"<p>WebGear_RTC also natively supports ASGI middleware classes with Starlette for implementing behavior that is applied across your entire ASGI application easily.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>All supported middlewares can be found here \u27b6</p> <p>For this example, let's use <code>CORSMiddleware</code> for implementing appropriate CORS headers to outgoing responses in our application in order to allow cross-origin requests from browsers, as follows:</p> <p>The default parameters used by the CORSMiddleware implementation are restrictive by default, so you'll need to explicitly enable particular origins, methods, or headers, in order for browsers to be permitted to use them in a Cross-Domain context.</p> <p>Starlette provides several arguments for enabling origins, methods, or headers for CORSMiddleware API. More information can be found here \u27b6</p> <pre><code># import libs\nimport uvicorn, asyncio\nfrom starlette.middleware import Middleware\nfrom starlette.middleware.cors import CORSMiddleware\nfrom vidgear.gears.asyncio import WebGear_RTC\n# add various performance tweaks as usual\noptions = {\n\"frame_size_reduction\": 25,\n}\n# initialize WebGear_RTC app with a valid source\nweb = WebGear_RTC(\nsource=\"/home/foo/foo1.mp4\", logging=True, **options\n)  # enable source i.e. `test.mp4` and enable `logging` for debugging\n# define and assign suitable cors middlewares\nweb.middleware = [\nMiddleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\n]\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>And that's all, Now you can see output at <code>http://localhost:8000</code> address.</p> <p> </p>"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-webgear_rtc-files-and-folders","title":"Rules for Altering WebGear_RTC Files and Folders","text":"<p>WebGear_RTC gives us complete freedom of altering data files generated in Auto-Generation Process, But you've to  keep the following rules in mind:</p>"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-data-files","title":"Rules for Altering Data Files","text":"<ul> <li> You allowed to alter/change code in all existing default downloaded files at your convenience without any restrictions.</li> <li> You allowed to delete/rename all existing data files, except remember NOT to delete/rename three critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) present in <code>templates</code> folder inside the <code>webgear_rtc</code> directory at the default location, otherwise, it will trigger Auto-generation process, and it will overwrite the existing files with Server ones.</li> <li> You're allowed to add your own additional <code>.html</code>, <code>.css</code>, <code>.js</code>, etc. files in the respective folders at the default location and custom mounted Data folders.</li> </ul>"},{"location":"gears/webgear_rtc/advanced/#rules-for-altering-data-folders","title":"Rules for Altering Data Folders","text":"<ul> <li> You're allowed to add/mount any number of additional folder as shown in this example above.</li> <li> You're allowed to delete/rename existing folders at the default location except remember NOT to delete/rename <code>templates</code> folder in the <code>webgear_rtc</code> directory where critical data-files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) are located, otherwise, it will trigger Auto-generation process.</li> </ul>"},{"location":"gears/webgear_rtc/advanced/#bonus-examples","title":"Bonus Examples","text":"<p>Checkout more advanced WebGear_RTC examples with unusual configuration here \u27b6</p> <p> </p>"},{"location":"gears/webgear_rtc/overview/","title":"WebGear_RTC API","text":"WebGear_RTC API's Video Server running at http://localhost:8000/ address."},{"location":"gears/webgear_rtc/overview/#overview","title":"Overview","text":"<p>WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms.</p> New in v0.2.1 <p>WebGear_RTC API was added in <code>v0.2.1</code>.</p> <p>WebGear_RTC is implemented with the help of aiortc library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.</p> <p>WebGear_RTC can handle multiple consumers seamlessly and provides native support for ICE (Interactive Connectivity Establishment) protocol, STUN (Session Traversal Utilities for NAT), and TURN (Traversal Using Relays around NAT) servers that help us to seamlessly establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom streaming class with suitable source to transform frames easily before sending them across the network(see this doc example).</p> <p>WebGear_RTC API works in conjunction with Starlette ASGI application and can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, Response classes, Routing tables, Static Files, Templating engine(with Jinja2), etc. </p> <p>Additionally, WebGear_RTC API also provides internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs.</p> <p> </p>"},{"location":"gears/webgear_rtc/overview/#data-files-auto-generation-workflow-for-webgear_rtc","title":"Data-Files Auto-Generation WorkFlow for WebGear_RTC","text":"<p>Same as WebGear, WebGear_RTC API automatically checks for three critical data files(i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>) on initialization inside the <code>templates</code> folder of the <code>webgear_rtc</code> directory at the default location which gives rise to the following two possible scenario:</p> <ul> <li> If data-files found: it will proceed normally for instantiating the WebRTC media server through Starlette application.</li> <li> If data-files not found: it will trigger the Auto-Generation process</li> </ul>"},{"location":"gears/webgear_rtc/overview/#default-location","title":"Default Location","text":"<ul> <li>A default location is the path of the directory where data files/folders are downloaded/generated/saved.</li> <li>By default, the <code>.vidgear</code> the folder at the home directory of your machine (for e.g <code>/home/foo/.vidgear</code> on Linux) serves as the default location.</li> <li> <p>But you can also use WebGear_RTC's <code>custom_data_location</code> dictionary attribute to change/alter default location path to somewhere else.</p> <p>Tip<p>You can set <code>logging=True</code> during initialization, for easily identifying the selected default location, which will be something like this (on a Linux machine):</p> </p> <pre><code>WebGear_RTC :: DEBUG :: `/home/foo/.vidgear` is the default location for saving WebGear_RTC data-files.\n</code></pre> </li> </ul>"},{"location":"gears/webgear_rtc/overview/#auto-generation-process","title":"Auto-Generation process","text":"<p>Info</p> <ul> <li> <p>You can also force trigger the Auto-generation process to overwrite existing data-files using <code>overwrite_default_files</code> dictionary attribute. Remember, only downloaded default data files(given above) will be overwritten in this process but any other file/folder will NOT be affected.</p> </li> <li> <p>It is advised to enable logging(<code>logging=True</code>) on the first run for easily identifying any runtime errors</p> </li> </ul> <ul> <li>On triggering this process, WebGear_RTC API creates <code>webgear_rtc</code> directory, and <code>templates</code> and <code>static</code> folders inside along with <code>js</code>, <code>css</code>, <code>img</code> sub-folders at the assigned default location.</li> <li> <p>Thereby at this default location, the necessary default data files will be downloaded from a dedicated Github Server inside respective folders in the following order:</p> <pre><code>    .vidgear\n    \u2514\u2500\u2500 webgear_rtc\n        \u251c\u2500\u2500 static\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 css\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 custom.css\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 img\n        \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 favicon-32x32.png\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 js\n        \u2502\u00a0\u00a0     \u2514\u2500\u2500 custom.js\n        \u2514\u2500\u2500 templates\n            \u251c\u2500\u2500 404.html\n            \u251c\u2500\u2500 500.html\n            \u251c\u2500\u2500 base.html\n            \u2514\u2500\u2500 index.html\n    6 directories, 7 files\n</code></pre> </li> <li> <p>Finally these downloaded files thereby are verified for errors and API proceeds for instantiating the Starlette application normally.</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/overview/#importing","title":"Importing","text":"<p>You can import WebGear_RTC API in your program as follows:</p> <pre><code>from vidgear.gears.asyncio import WebGear_RTC\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/overview/#webgear_rtcs-default-template","title":"WebGear_RTC's Default Template","text":"<p>The WebGear_RTC API by default uses simple &amp; elegant WebGear_RTC's Default Theme which looks like something as follows:</p>"},{"location":"gears/webgear_rtc/overview/#indexhtml","title":"Index.html","text":"<p>Can be accessed by visiting WebGear_RTC app server, running at http://localhost:8000/:</p>"},{"location":"gears/webgear_rtc/overview/#404html","title":"404.html","text":"<p>Appears when respective URL is not found, for example http://localhost:8000/ok:</p>"},{"location":"gears/webgear_rtc/overview/#500html","title":"500.html","text":"<p>Appears when an API Error is encountered:</p> <p>If <code>logging</code> is enabled and an error occurs, then instead of displaying this 500 handler, WebGear_RTC will respond with a traceback response.</p> <p> </p>"},{"location":"gears/webgear_rtc/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WebGear_RTC Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/webgear_rtc/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/webgear_rtc/overview/#references","title":"References","text":"See here \ud83d\ude80"},{"location":"gears/webgear_rtc/overview/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/webgear_rtc/params/","title":"WebGear_RTC API Parameters","text":"<p>WebGear_RTC provides a special internal wrapper around VideoGear, which itself provides internal access to both CamGear and PiGear APIs and their parameters.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#enablepicamera","title":"<code>enablePiCamera</code>","text":"<p>This parameter provide direct access to PiGear or CamGear APIs respectively in WebGear_RTC. This means the if <code>enablePiCamera</code> flag is <code>True</code>, the PiGear API will be accessed, and if <code>False</code>, the CamGear API will be accessed. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True) # enable access to PiGear API\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#options","title":"<code>options</code>","text":"<p>This parameter can be used to pass user-defined parameter to WebGear_RTC API by formatting them as this parameter's attribute. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p>"},{"location":"gears/webgear_rtc/params/#webgear_rtc-specific-attributes","title":"WebGear_RTC Specific attributes","text":"<ul> <li> <p><code>custom_stream</code> (class) : Can be used to easily define your own Custom Streaming Class with suitable custom source(such as OpenCV) that you want to use to transform your frames before sending them onto the browser. </p> <p>Make sure your Custom Streaming Class at-least implements <code>read()</code> and <code>stop()</code> methods, otherwise WebGear_RTC will throw ValueError!</p> New in v0.2.4 <p>This attribute was added in <code>v0.2.4</code>.</p> Using Vidgear's VideoCapture APIs instead of OpenCV <p>You can directly replace Custom Streaming Class with any VideoCapture APIs. These APIs implements <code>read()</code> and <code>stop()</code> methods by-default, so they're also supported out-of-the-box. </p> <p>See this example \u27b6 for more information.</p> <p>Its complete usage example is given here \u27b6.</p> <pre><code># set CamGear as custom streaming class with adequate parameters\noptions = {\"custom_stream\": CamGear(source=\"foo.mp4\", logging=True)}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>custom_data_location</code> (string) : Can be used to change/alter default location path to somewhere else. Its usage is as follows:</p> <pre><code># set default location to '/home/foo/foo1'\noptions = {\"custom_data_location\": \"/home/foo/foo1\"}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>overwrite_default_files</code> (boolean) : Can be used to force trigger the Auto-generation process to overwrite existing data-files. Its usage is as follows:</p> <p>Remember only downloaded files will be overwritten in this process, and any other file/folder will NOT be affected/overwritten.</p> <pre><code># force trigger the Auto-generation process\noptions = {\"overwrite_default_files\": True}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>frame_size_reduction</code> (int/float) : This attribute controls the size reduction (in percentage) of the frame to be streamed on Server and it has the  most significant effect on performance. The value defaults to <code>20</code>, and must be no higher than <code>90</code> (fastest, max compression, Barely Visible frame-size) and no lower than <code>0</code> (slowest, no compression, Original frame-size). Its recommended value is between <code>40-60</code>. Its usage is as follows:</p> <pre><code># frame-size will be reduced by 50%\noptions = {\"frame_size_reduction\": 50} \n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> <li> <p><code>enable_live_broadcast</code> (boolean) : WebGear_RTC by default only supports one-to-one peer connection with a single consumer/client, Hence this boolean attribute can be used to enable live broadcast to multiple peer consumers/clients at same time. Its default value is <code>False</code>. Its usage is as follows:</p> <p><code>enable_infinite_frames</code> is enforced by default when this attribute is enabled(<code>True</code>).</p> <p>For accessing WebGear_RTC on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> New in v0.2.2 <p><code>enable_live_broadcast</code> attribute was added in <code>v0.2.2</code>.</p> <pre><code># enable live boadcast to multiple consumers.\noptions = {\"enable_live_broadcast\": True}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> </li> <li> <p><code>enable_infinite_frames</code> (boolean) : Can be used to continue streaming (instead of terminating immediately) with emulated blank frames with text \"No Input\", whenever the input source disconnects. Its default value is <code>False</code>. Its usage is as follows:</p> <p><code>enable_infinite_frames</code> is disabled when <code>enable_live_broadcast</code> attribute is enabled(<code>True</code>).</p> New in v0.2.1 <p><code>enable_infinite_frames</code> attribute was added in <code>v0.2.1</code>.</p> <pre><code># emulate infinite frames\noptions = {\"enable_infinite_frames\": True}\n# assign it\nWebGear_RTC(logging=True, **options)\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#parameters-for-stabilizer-backend","title":"Parameters for Stabilizer Backend","text":"<p>Enable this backend with <code>stabilize=True</code> in WebGear_RTC. Default is also <code>False</code>.</p>"},{"location":"gears/webgear_rtc/params/#stabilize","title":"<code>stabilize</code>","text":"<p>This parameter enable access to Stabilizer Class for stabilizing frames, i.e. can be set to <code>True</code>(to enable) or unset to <code>False</code>(to disable). </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(stabilize=True) # enable stablization\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#options_1","title":"<code>options</code>","text":"<p>This parameter can be used in addition, to pass user-defined parameters supported by Stabilizer Class. These parameters can be formatted as this parameter's attribute.</p> <p>Supported dictionary attributes for Stabilizer Class are:</p> <ul> <li> <p><code>SMOOTHING_RADIUS</code> (integer) : This attribute can be used to alter averaging window size. It basically handles the quality of stabilization at the expense of latency and sudden panning. Larger its value, less will be panning, more will be latency and vice-versa. Its default value is <code>25</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'SMOOTHING_RADIUS': 30}\n</code></pre> </li> <li> <p><code>BORDER_SIZE</code> (integer) : This attribute enables the feature to extend border size that compensates for stabilized output video frames motions. Its default value is <code>0</code>(no borders). You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10}\n</code></pre> </li> <li> <p><code>CROP_N_ZOOM</code>(boolean): This attribute enables the feature where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the Stabilized, cropped and Auto-Scaled feature available in Adobe AfterEffects). It simply works in conjunction with the <code>BORDER_SIZE</code> attribute, i.e. when this attribute is enabled,  <code>BORDER_SIZE</code> will be used for cropping border instead of extending them. Its default value is <code>False</code>. You can easily pass this attribute as follows:</p> <pre><code>options = {'BORDER_SIZE': 10, 'CROP_N_ZOOM' : True}\n</code></pre> </li> <li> <p><code>BORDER_TYPE</code> (string) : This attribute can be used to change the extended border style. Valid border types are <code>'black'</code>, <code>'reflect'</code>, <code>'reflect_101'</code>, <code>'replicate'</code> and <code>'wrap'</code>, learn more about it here. Its default value is <code>'black'</code>. You can easily pass this attribute as follows:</p> <p>Altering <code>BORDER_TYPE</code> attribute is Disabled while <code>CROP_N_ZOOM</code> is enabled.</p> <pre><code>options = {'BORDER_TYPE': 'black'}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#parameters-for-camgear-backend","title":"Parameters for CamGear backend","text":"<p>Enable this backend with <code>enablePiCamera=False</code> in WebGear_RTC.</p>"},{"location":"gears/webgear_rtc/params/#source","title":"<code>source</code>","text":"<p>WebGear_RTC API will throw <code>RuntimeError</code> if <code>source</code> provided is invalid.</p> <p>This parameter defines the source for the input stream.</p> <p>Data-Type: Based on input.</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Index (integer): Valid index of the connected video device, for e.g <code>0</code>, or <code>1</code>, or <code>2</code> etc. as follows:</p> <pre><code>WebGear_RTC(source=0)\n</code></pre> </li> <li> <p> Filepath (string): Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code>WebGear_RTC(source='/home/foo.mp4')\n</code></pre> </li> <li> <p> Streaming Services URL Address (string): Valid Video URL as input when Stream Mode is enabled(i.e. <code>stream_mode=True</code>) </p> <p>CamGear internally implements <code>yt_dlp</code> backend class for pipelining live video-frames and metadata from various streaming services. For example Twitch URL can be used as follows:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>CamGear(source='https://www.twitch.tv/shroud', stream_mode=True)\n</code></pre> </li> <li> <p> Network Address (string): Valid (<code>http(s)</code>, <code>rtp</code>, <code>rtsp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://192.168.31.163:554/'</code> as input:</p> <pre><code>WebGear_RTC(source='rtsp://192.168.31.163:554/')\n</code></pre> </li> <li> <p> GStreamer Pipeline: </p> <p>CamGear API also supports GStreamer Pipeline.</p> <p>Requirements for GStreamer Pipelining</p> <p>Successful GStreamer Pipelining needs your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Thereby, You can easily check GStreamer support by running <code>print(cv2.getBuildInformation())</code> python command and see if output contains something similar as follows:</p> <pre><code>Video I/O:\n...\n     GStreamer:                   YES (ver 1.8.3)\n...\n</code></pre> <p>Be sure convert video output into BGR colorspace before pipelining as follows:</p> <pre><code>WebGear_RTC(source='udpsrc port=5000 ! application/x-rtp,media=video,payload=96,clock-rate=90000,encoding-name=H264, ! rtph264depay ! decodebin ! videoconvert ! video/x-raw, format=BGR ! appsink')\n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/webgear_rtc/params/#stream_mode","title":"<code>stream_mode</code>","text":"<p>This parameter controls the Stream Mode, .i.e if enabled(<code>stream_mode=True</code>), the CamGear API will interpret the given <code>source</code> input as YouTube URL address. </p> <p>Due to a FFmpeg bug that causes video to freeze frequently in OpenCV, It is advised to always use GStreamer backend for any livestream videos. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>. </p> <p>Usage:</p> <p>Supported Streaming Websites</p> <p>The complete list of all supported Streaming Websites URLs can be found here \u27b6</p> <pre><code>WebGear_RTC(source='https://youtu.be/bvetuLwJIkA', stream_mode=True)\n</code></pre> <p>Its complete usage example is given here \u27b6.</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#backend","title":"<code>backend</code>","text":"<p>This parameter manually selects the backend for OpenCV's VideoCapture class (only if specified). </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code> </p> <p>Usage:</p> <p>All supported backends are listed here \u27b6</p> <p>Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> for selecting Direct Show as backend:</p> <pre><code>WebGear_RTC(source=0, backend = cv2.CAP_DSHOW)\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#options_2","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Source Tweak Parameters available within OpenCV's VideoCapture API properties. </p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed here \u27b6</p> <p>The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\"CAP_PROP_FRAME_WIDTH\":320, \"CAP_PROP_FRAME_HEIGHT\":240, \"CAP_PROP_FPS\":60}\n# assigning it\nWebGear_RTC(source=0, **options)\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#parameters-for-pigear-backend","title":"Parameters for PiGear backend","text":"<p>Enable this backend with <code>enablePiCamera=True</code> in WebGear_RTC.</p>"},{"location":"gears/webgear_rtc/params/#camera_num","title":"<code>camera_num</code>","text":"<p>This parameter selects the camera module index which will be used as source, if you're having multiple camera modules connected. Its value can only be greater than zero, otherwise, it will throw <code>ValueError</code> for any negative value.</p> <p>This parameter shouldn't be altered, until unless you using Raspberry Pi 3/3+ Compute Module IO Board.\"</p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True, camera_num=0)\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#resolution","title":"<code>resolution</code>","text":"<p>This parameter sets the resolution (i.e. <code>(width,height)</code>) of the source. </p> <p>For more information read here \u27b6</p> <p>Data-Type: Tuple</p> <p>Default Value:  Its default value is <code>(640,480)</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True, resolution=(1280,720)) # sets 1280x720 resolution\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#framerate","title":"<code>framerate</code>","text":"<p>This parameter sets the framerate of the source.</p> <p>For more information read here \u27b6</p> <p>Data-Type: integer/float</p> <p>Default Value:  Its default value is <code>30</code>. </p> <p>Usage:</p> <pre><code>WebGear_RTC(enablePiCamera=True, framerate=60) # sets 60fps framerate\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#options_3","title":"<code>options</code>","text":"<p>This parameter provides the ability to alter various Tweak Parameters <code>like brightness, saturation, senor_mode, resolution, etc.</code> available within Picamera library.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code> </p> <p>Usage:</p> <p>All supported parameters are listed in PiCamera Docs</p> <p>The desired parameters can be passed to WebGear_RTC API by formatting them as this parameter's attributes, as follows:</p> <pre><code># formatting parameters as dictionary attributes\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# assigning it\nWebGear_RTC(enablePiCamera=True, logging=True, **options)\n</code></pre> <p>User-specific attributes:</p> <p>Additionally, <code>options</code> parameter also support some User-specific attributes, which are as follows:</p> <ul> <li> <p><code>HWFAILURE_TIMEOUT</code> (float): PiGear contains Threaded Internal Timer - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur at a timeout value. This parameter can be used to control that timeout value i.e. the maximum waiting time (in seconds) after which PiGear exits with a <code>SystemError</code> to save resources. Its value can only be between <code>1.0</code> (min) and <code>10.0</code> (max) and its default value is <code>2.0</code>. Its usage is as follows: </p> <pre><code>options = {\"HWFAILURE_TIMEOUT\": 2.5}  # sets timeout to 2.5 seconds\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/webgear_rtc/params/#common-parameters","title":"Common Parameters","text":"<p>These are common parameters that works with every backend in WebGear_RTC.</p>"},{"location":"gears/webgear_rtc/params/#colorspace","title":"<code>colorspace</code>","text":"<p>This parameter selects the colorspace of the source stream. </p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>. </p> <p>Usage:</p> <p>All supported <code>colorspace</code> values are given here \u27b6</p> <pre><code>WebGear_RTC(colorspace=\"COLOR_BGR2HSV\")\n</code></pre> <p>Its complete usage example is given here \u27b6</p> <p> </p>"},{"location":"gears/webgear_rtc/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WebGear_RTC(logging=True)\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/params/#time_delay","title":"<code>time_delay</code>","text":"<p>This parameter set the time delay (in seconds) before the WebGear_RTC API start reading the frames. This delay is only required if the source required some warm-up delay before starting up. </p> <p>Data-Type: Integer</p> <p>Default Value: Its default value is <code>0</code>.</p> <p>Usage:</p> <pre><code>WebGear_RTC(time_delay=1)  # set 1 seconds time delay\n</code></pre> <p> </p>"},{"location":"gears/webgear_rtc/usage/","title":"WebGear_RTC API Usage Examples:","text":""},{"location":"gears/webgear_rtc/usage/#requirements","title":"Requirements","text":""},{"location":"gears/webgear_rtc/usage/#installation-with-asyncio-support","title":"Installation with Asyncio Support","text":"<p>WebGear_RTC API is the part of <code>asyncio</code> package of VidGear, thereby you need to install VidGear with asyncio support as follows:</p> <pre><code>pip install vidgear[asyncio]\n</code></pre>"},{"location":"gears/webgear_rtc/usage/#aiortc","title":"Aiortc","text":"<p>Must Required with WebGear_RTC API. You can easily install it via pip:</p> Microsoft Visual C++ 14.0 is required. <p>Installing <code>aiortc</code> on windows requires Microsoft Build Tools for Visual C++ libraries installed. You can easily fix this error by installing any ONE of these choices:</p> <p>While the error is calling for VC++ 14.0 - but newer versions of Visual C++ libraries works as well.</p> <ul> <li>Microsoft Build Tools for Visual Studio.</li> <li>Alternative link to Microsoft Build Tools for Visual Studio.</li> <li>Offline installer: vs_buildtools.exe</li> </ul> <p>Afterwards, Select: Workloads \u2192 Desktop development with C++, then for Individual Components, select only:</p> <ul> <li> Windows 10 SDK</li> <li> C++ x64/x86 build tools</li> </ul> <p>Finally, proceed installing <code>aiortc</code> via pip.</p> <pre><code>  pip install aiortc\n</code></pre>"},{"location":"gears/webgear_rtc/usage/#asgi-server","title":"ASGI Server","text":"<p>You'll also need to install an ASGI Server to run following WebGear_RTC usage examples, and by default WebGear_RTC ships the state-of-the-art <code>uvicorn</code> Server. But you can also use other ASGI server such as <code>daphne</code>, or <code>hypercorn</code> with it.</p> <p> </p>"},{"location":"gears/webgear_rtc/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Let's implement a Bare-Minimum usage example:</p>"},{"location":"gears/webgear_rtc/usage/#running-programmatically","title":"Running Programmatically","text":"<p>You can access and run WebGear_RTC VideoStreamer Server programmatically in your python script in just a few lines of code, as follows:</p> <p>For accessing WebGear_RTC on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. More information can be found here \u27b6</p> <p>We are using <code>frame_size_reduction</code> attribute for frame size reduction (in percentage) to be streamed with its <code>options</code> dictionary parameter to cope with performance-throttling in this example.</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n# various performance tweaks\noptions = {\n\"frame_size_reduction\": 25,\n}\n# initialize WebGear_RTC app\nweb = WebGear_RTC(source=\"foo.mp4\", logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>which can be accessed on any browser on your machine at http://localhost:8000/.</p>"},{"location":"gears/webgear_rtc/usage/#running-from-terminal","title":"Running from Terminal","text":"<p>You can also access and run WebGear_RTC Server directly from the terminal commandline. The following command will run a WebGear_RTC VideoStreamer server at http://localhost:8000/:</p> <p>Make sure your <code>PYTHON_PATH</code> is set to python 3.7+ versions only.</p> <p>If you're using <code>--options/-op</code> flag, then kindly wrap your dictionary value in single <code>''</code> quotes.</p> <pre><code>python3 -m vidgear.gears.asyncio --mode webrtc --source test.avi --logging True --options '{\"frame_size_reduction\": 50, \"frame_jpeg_quality\": 80, \"frame_jpeg_optimize\": True, \"frame_jpeg_progressive\": False}'\n</code></pre> <p>which can also be accessed on any browser on the network at http://localhost:8000/.</p> Advanced Usage from Terminal <p>You can run <code>python3 -m vidgear.gears.asyncio -h</code> help command to see all the advanced settings, as follows:</p> <pre><code>usage: python -m vidgear.gears.asyncio [-h] [-m MODE] [-s SOURCE] [-ep ENABLEPICAMERA] [-S STABILIZE]\n[-cn CAMERA_NUM] [-yt stream_mode] [-b BACKEND] [-cs COLORSPACE]\n[-r RESOLUTION] [-f FRAMERATE] [-td TIME_DELAY]\n[-ip IPADDRESS] [-pt PORT] [-l LOGGING] [-op OPTIONS]\nRuns WebGear/WebGear_RTC Video Server through terminal.\n\noptional arguments:\n  -h, --help            show this help message and exit\n-m {mjpeg,webrtc}, --mode {mjpeg,webrtc}\nWhether to use \"MJPEG\" or \"WebRTC\" mode for streaming.\n  -s SOURCE, --source SOURCE\n                        Path to input source for CamGear API.\n  -ep ENABLEPICAMERA, --enablePiCamera ENABLEPICAMERA\n                        Sets the flag to access PiGear(if True) or otherwise\n                        CamGear API respectively.\n  -S STABILIZE, --stabilize STABILIZE\n                        Enables/disables real-time video stabilization.\n  -cn CAMERA_NUM, --camera_num CAMERA_NUM\n                        Sets the camera module index that will be used by\n                        PiGear API.\n  -yt STREAM_MODE, --stream_mode STREAM_MODE\n                        Enables YouTube Mode in CamGear API.\n  -b BACKEND, --backend BACKEND\n                        Sets the backend of the video source in CamGear API.\n  -cs COLORSPACE, --colorspace COLORSPACE\n                        Sets the colorspace of the output video stream.\n  -r RESOLUTION, --resolution RESOLUTION\n                        Sets the resolution (width,height) for camera module\n                        in PiGear API.\n  -f FRAMERATE, --framerate FRAMERATE\n                        Sets the framerate for camera module in PiGear API.\n  -td TIME_DELAY, --time_delay TIME_DELAY\n                        Sets the time delay(in seconds) before start reading\n                        the frames.\n  -ip IPADDRESS, --ipaddress IPADDRESS\n                        Uvicorn binds the socket to this ipaddress.\n  -pt PORT, --port PORT\n                        Uvicorn binds the socket to this port.\n  -l LOGGING, --logging LOGGING\n                        Enables/disables error logging, essential for\ndebugging.\n  -op OPTIONS, --options OPTIONS\n                        Sets the parameters supported by APIs(whichever being\n                        accessed) to the input videostream, But make sure to\n                        wrap your dict value in single or double quotes.\n</code></pre> <p> </p>"},{"location":"gears/writegear/introduction/","title":"WriteGear API","text":"WriteGear API generalized workflow"},{"location":"gears/writegear/introduction/#overview","title":"Overview","text":"<p>WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data.</p> <p>WriteGear API provides a complete, flexible, and robust wrapper around FFmpeg, a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specifications (such as<code>bitrate, codec, framerate, resolution, subtitles,  etc.</code>). </p> <p>WriteGear also supports streaming with traditional protocols such as RTSP/RTP, RTMP. It is powerful enough to perform complex tasks such as Live-Streaming (such as for Twitch, YouTube etc.) and Multiplexing Video-Audio with real-time frames in just few lines of code.</p> <p>Best of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive Custom Commands function (see this doc) without relying on any third-party API.</p> <p>In addition to this, WriteGear also provides flexible access to OpenCV's VideoWriter API tools for video-frames encoding without compression.</p> <p> </p>"},{"location":"gears/writegear/introduction/#modes-of-operation","title":"Modes of Operation","text":"<p>WriteGear primarily operates in following modes:</p> <ul> <li> <p>Compression Mode: In this mode, WriteGear utilizes powerful FFmpeg inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly.</p> </li> <li> <p>Non-Compression Mode: In this mode, WriteGear utilizes basic OpenCV's inbuilt VideoWriter API tools. This mode also supports all parameter transformations available within OpenCV's VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc.</p> </li> </ul> <p> </p> <p>Helpful Tips</p> <ul> <li> <p>If you're already familar with OpenCV library, then see Switching from OpenCV \u27b6</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/introduction/#importing","title":"Importing","text":"<p>You can import WriteGear API in your program as follows:</p> <pre><code>from vidgear.gears import WriteGear\n</code></pre> <p> </p>"},{"location":"gears/writegear/introduction/#faqs","title":"FAQs","text":"See here \ud83d\ude80"},{"location":"gears/writegear/compression/overview/","title":"WriteGear API: Compression Mode","text":"WriteGear API's Compression Mode generalized workflow"},{"location":"gears/writegear/compression/overview/#overview","title":"Overview","text":"<p>When <code>compression_mode</code> parameter is enabled (.i.e <code>compression_mode = True</code>), WriteGear API provides a complete, flexible &amp; robust wrapper around FFmpeg to encode lossless &amp; compressed multimedia files.</p> <p>This mode can process real-time video frames into a lossless compressed format with any suitable setting video/audio properties such as bitrate, codec, framerate, resolution, subtitles, and much more in just a few easy lines of code. It can also perform complex tasks such as Live-Streaming (such as for Twitch), multiplexing video with audio in real-time (see this usage example) while handling all errors robustly.</p> <p> </p> <p>Important Information</p> <ul> <li> <p>WriteGear MUST requires FFmpeg executables for its Compression capabilities. Follow these dedicated Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it automatically fallbacks to Non-Compression Mode.</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug any issues/errors easily and make suitable adjustments accordingly. </p> </li> </ul> <p>You can speed up the execution time by disabling logging (.i.e <code>logging = False</code>) for production use, and by tweaking FFmpeg parameters in <code>output_params</code> values. Look into FFmpeg docs \u27b6 for such hacks.</p> <p> </p>"},{"location":"gears/writegear/compression/overview/#custom-ffmpeg-commands-in-writegear-api","title":"Custom FFmpeg Commands in WriteGear API","text":"<p>WriteGear API now provides the <code>execute_ffmpeg_cmd</code> Function in Compression Mode, that enables the user to pass any custom CLI commands as an input to its internal FFmpeg Pipeline by formating it as a list. </p> <p>This function opens endless possibilities of exploiting any FFmpeg supported parameter within WriteGear, without relying on a third-party library/API to do the same, and while doing that it robustly handles all errors/warnings quietly.</p> <p>A complete guide on <code>execute_ffmpeg_cmd</code> Function can be found here \u27b6</p> <p> </p>"},{"location":"gears/writegear/compression/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/writegear/compression/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/writegear/compression/params/","title":"WriteGear API Parameters: Compression Mode","text":""},{"location":"gears/writegear/compression/params/#output","title":"<code>output</code>","text":"<p>This parameter sets the valid filename/path/URL for the video output.</p> <p>Warning</p> <p>WriteGear API will throw <code>ValueError</code> if <code>output</code> provided is empty or invalid.</p> <p>Data-Type: String</p> <p>Usage:</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p>Path to directory: Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename (with a default extension i.e.<code>.mp4</code>) as follows:</p> <pre><code>writer = WriteGear(output = '/home/foo/foo1') #Define writer \n</code></pre> </li> <li> <p>Filename (with/without path): Valid filename(with valid extension) of the output video file. In case filename is provided without path, then current working directory will be used.</p> <pre><code>writer = WriteGear(output = 'output.mp4') #Define writer \n</code></pre> <p>Make sure to provide valid filename with valid file-extension based on the encoder in use.</p> </li> <li> <p>URL: Valid URL of a network stream with a protocol supported by installed FFmpeg (verify with command <code>ffmpeg -protocols</code>) only. This is useful for building a Video-Streaming Server with FFmpeg in WriteGear API. For example, you can stream on a <code>rtmp</code> protocol URL as follows:</p> <pre><code>writer = WriteGear(output = 'rtmp://localhost/live/test') #Define writer \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/writegear/compression/params/#compression_mode","title":"<code>compression_mode</code>","text":"<p>This parameter selects the WriteGear's Primary Mode of Operation, i.e. if this parameter is enabled (.i.e <code>compression_mode = True</code>) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e <code>compression_mode = False</code>), the OpenCV's VideoWriter API will be used for encoding files/streams. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>True</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', compression_mode=True)\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>This parameter assigns the custom path/directory where the custom FFmpeg executables are located in Compression Mode only.</p> <p>Compression Mode Behavior on Windows</p> <p>In Compression Mode, if a custom FFmpeg executable's path | directory is not provided through <code>custom_ffmpeg</code> parameter on Windows machine, then WriteGear API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine. More information can be found here \u27b6.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># if ffmpeg executables are located at \"/foo/foo1/FFmpeg\"\nWriteGear(output = 'output.mp4', custom_ffmpeg=\"/foo/foo1/FFmpeg\")\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/params/#output_params","title":"<code>output_params</code>","text":"<p>This parameter allows us to exploit almost all FFmpeg supported parameters effortlessly and flexibly for encoding in Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and encoders for compression mode discussed below:</p> <p>Kindly read FFmpeg Docs carefully, before passing any values to <code>output_param</code> dictionary parameter. Wrong values may result in undesired Errors or no output at all.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p>"},{"location":"gears/writegear/compression/params/#supported-parameters","title":"Supported Parameters","text":"<ul> <li> <p>FFmpeg Parameters: All parameters based on selected encoder in use, are supported, and can be passed as dictionary attributes in <code>output_param</code>. For example, for using <code>libx264 encoder</code> to produce a lossless output video, we can pass required FFmpeg parameters as dictionary attributes, as follows:</p> <p>While providing additional av-source with <code>-i</code> FFmpeg parameter in <code>output_params</code> make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things!</p> <p>All ffmpeg parameters are case-sensitive. Remember to double check every parameter if any error occurs.</p> <p>Kindly check H.264 docs \u27b6 and other FFmpeg Docs \u27b6 for more information on these parameters</p> <pre><code> output_params = {\"-vcodec\":\"libx264\", \"-crf\": 0, \"-preset\": \"fast\", \"-tune\": \"zerolatency\"} \n</code></pre> </li> <li> <p>Special Internal Parameters: In addition to FFmpeg parameters, WriteGear API also supports some Special Parameters to tweak its internal properties. These parameters are discussed below:</p> <ul> <li> <p><code>-ffmpeg_download_path</code> (string): sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. <code>C:/User/temp</code>) on your windows machine. It can be used as follows: </p> <pre><code>output_params = {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"} # will be saved to \"C:/User/foo/foo1\"\n</code></pre> </li> <li> <p><code>-input_framerate</code> (float/int) : sets the constant framerate of the output. It can be used as follows: </p> <pre><code>output_params = {\"-input_framerate\": 60.0} # set the constant framerate to 60fps\n</code></pre> <p>Its usage example can be found here \u27b6</p> </li> <li> <p><code>-output_dimensions</code> (tuple/list) : sets the custom dimensions(size/resolution) of the output video (otherwise input video-frame size will be used). Its value can either be a tuple =&gt; <code>(width,height)</code> or a list =&gt; <code>[width, height]</code>, Its usage is as follows: </p> <pre><code>output_params = {\"-output_dimensions\": (1280,720)} # to produce a 1280x720 resolution/scale output video\n</code></pre> </li> <li> <p><code>-clones</code> (list): required to set special FFmpeg parameters that are repeated more than once in the command (For more info., see this issue) or in cases where you want to preserve order of multiple FFmpeg parameters. This attribute only accepts list datatype as value. Its usage is as follows:</p> <p>Turn on logging(<code>logging = True</code>) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <p>WriteGear by automatically applies <code>-format</code> or <code>-f</code>, <code>-pix_fmt</code> and <code>-vcodec</code> or <code>-v:f</code> like critical input parameters for every stream. Therefore if you need multiple values for these parameter just define them with <code>-clones</code> attribute.</p> <pre><code>output_params = {\n\"-i\": \"plug:dsnoopUSB\",\n\"-f\": \"alsa\",\n\"-ac\": \"1\",\n\"-ar\": \"48000\",\n\"-clones\": [\"-vcodec\", \"mpeg1video\", \"-f\", \"mpegts\"],\n}\n</code></pre> </li> <li> <p><code>-ffpreheaders</code> (list): required to set special FFmpeg parameters that are present at the starting of command(such as <code>-re</code>). This attribute only accepts list datatype as value. Its usage is as follows:</p> <p>This attribute is quite powerful and can break FFmpeg pipeline easily if not used correctly. User Discretion is advised!</p> <p>Turn on logging(<code>logging = True</code>) to see the FFmpeg command that is being executed in WriteGear's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <pre><code>output_params = {\n\"-ffpreheaders\": [\"-re\"], # executes as `ffmpeg -re &lt;rest of command&gt;`\n}\n</code></pre> </li> <li> <p><code>-disable_force_termination</code> (bool): sets a special flag to manually disable the default forced-termination behaviour in WriteGear API when <code>-i</code> FFmpeg parameter is used (For more details, see issue: #149). Its usage is as follows:</p> <p><code>-disable_force_termination</code> flag is a absolute necessity when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> <pre><code>output_params = {\"-disable_force_termination\": True} # disable the default forced-termination behaviour\n</code></pre> </li> </ul> </li> </ul>"},{"location":"gears/writegear/compression/params/#supported-encoders","title":"Supported Encoders","text":"<p>All the encoders that are compiled with FFmpeg in use, are supported by WriteGear API. You can easily check the compiled encoders by running following command in your terminal:</p> <p>Similarily, supported demuxers and filters depends upons compiled FFmpeg in use.</p> <pre><code>ffmpeg -encoders           # use `ffmpeg.exe -encoders` on windows\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', logging=True)\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/","title":"WriteGear API Usage Examples: Compression Mode","text":"<p>Important Information</p> <ul> <li> <p>WriteGear MUST requires FFmpeg executables for its Compression capabilities in Compression Mode. Follow these dedicated Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it automatically fallbacks to Non-Compression Mode.</p> </li> <li> <p>DO NOT feed frames with different dimensions or channels to WriteGear, otherwise WriteGear will exit with <code>ValueError</code>.</p> </li> <li> <p>While providing additional av-source with <code>-i</code> FFmpeg parameter in <code>output_params</code> make sure it don't interfere with WriteGear's frame pipeline otherwise it will break things!</p> </li> <li> <p>Use <code>-disable_force_termination</code> flag when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> </li> <li> <p>Heavy resolution multimedia files take time to render which can last up to 0.1-1 seconds. Kindly wait till the WriteGear API terminates itself, and DO NOT try to kill the process instead.</p> </li> <li> <p>Always use <code>writer.close()</code> at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.</p> </li> </ul> <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/writegear/compression/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with WriteGear API in Compression Mode:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = CamGear(source=\"myvideo.avi\").start()\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-in-rgb-mode","title":"Using Compression Mode in RGB Mode","text":"<p>In Compression Mode, WriteGear API contains <code>rgb_mode</code> boolean parameter for RGB Mode, which when enabled (i.e. <code>rgb_mode=True</code>), specifies that incoming frames are of RGB format (instead of default BGR format). This mode makes WriteGear directly compatible with libraries that only supports RGB format. </p> <p>The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# simulating RGB frame for example\nframe_rgb = frame[:, :, ::-1]\n# writing RGB frame to writer\nwriter.write(frame_rgb, rgb_mode=True)  # activate RGB Mode\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-controlled-framerate","title":"Using Compression Mode with controlled FrameRate","text":"<p>WriteGear API provides <code>-input_framerate</code>  attribute for its <code>options</code> dictionary parameter in Compression Mode, which allow us to control/set the constant framerate of the output video. </p> Advanced Tip for setting constant framerate <p>If <code>-input_framerate</code> attribute doesn't works for you, then define it in conjunction with another <code>-r</code> FFmpeg parameter as attribute:</p> <pre><code># set output constant framerate to (say 60 fps)\noutput_params = {\"-input_framerate\":60, \"-r\":60}\n# assign that to WriteGear\nwriter = WriteGear(output=\"out.mp4\", logging =True, **output_params)\n</code></pre> <p>But make sure you MUST set value of <code>-r</code> and <code>-input_framerate</code> parameter less than or equal to your input source framerate.</p> <p>In this code we will retrieve framerate from video stream, and set it as <code>-input_framerate</code> attribute for <code>option</code> parameter in WriteGear API:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = CamGear(source=0).start()\n# retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter\noutput_params = {\"-input_framerate\": stream.framerate}\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-for-live-streaming","title":"Using Compression Mode for live streaming","text":"<p>In Compression Mode, WriteGear also allows URL strings (as output) for live streaming realtime frames with its <code>output</code> parameter.  </p> <p>In this example, we will stream live camera frames directly to Twitch :</p> <p>For streaming with traditional protocols such as  RTSP/RTP, Checkout this WriteGear's Bonus Examples \u27b6.</p> <p> YouTube-Live Streaming example code also available in WriteGear's Bonus Examples \u27b6</p> <p>This example assume you already have a Twitch Account for publishing video.</p> <p>Make sure to change Twitch Stream Key with yours in following code before running!</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open live webcam video stream on first index(i.e. 0) device\nstream = CamGear(source=0, logging=True).start()\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n\"-preset:v\": \"veryfast\",\n\"-g\": 60,\n\"-keyint_min\": 60,\n\"-sc_threshold\": 0,\n\"-bufsize\": \"2500k\",\n\"-f\": \"flv\",\n}\n# [WARNING] Change your Twitch Stream Key here:\nTWITCH_KEY = \"live_XXXXXXXXXX~XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n# Define writer with defined parameters and\nwriter = WriteGear(\noutput=\"rtmp://live.twitch.tv/app/{}\".format(TWITCH_KEY),\nlogging=True,\n**output_params\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-hardware-encoders","title":"Using Compression Mode with Hardware encoders","text":"<p>By default, WriteGear API uses <code>libx264</code> encoder for encoding output files in Compression Mode. But you can easily change encoder to your suitable supported encoder by passing <code>-vcodec</code> FFmpeg parameter as an attribute with its output_param dictionary parameter. In addition to this, you can also specify the additional properties/features of your system's GPU  easily. </p> User Discretion Advised <p>This example is just conveying the idea on how to use FFmpeg's hardware encoders with WriteGear API in Compression mode, which MAY/MAY NOT suit your system. Kindly use suitable parameters based your system hardware settings only.</p> <p>In this example, we will be using <code>h264_vaapi</code> as our hardware encoder and also optionally be specifying our device hardware's location (i.e. <code>'-vaapi_device':'/dev/dri/renderD128'</code>) and other features such as <code>'-vf':'format=nv12,hwupload'</code>:</p> Remember to check VAAPI support <p>To use <code>h264_vaapi</code> encoder, remember to check if its available and your FFmpeg compiled with VAAPI support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows:</p> <pre><code>ffmpeg  -hide_banner -encoders | grep vaapi V..... h264_vaapi           H.264/AVC (VAAPI) (codec h264)\nV..... hevc_vaapi           H.265/HEVC (VAAPI) (codec hevc)\nV..... mjpeg_vaapi          MJPEG (VAAPI) (codec mjpeg)\nV..... mpeg2_vaapi          MPEG-2 (VAAPI) (codec mpeg2video)\nV..... vp8_vaapi            VP8 (VAAPI) (codec vp8)\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open live webcam video stream on first index(i.e. 0) device\nstream = CamGear(source=0, logging=True).start()\n# define required FFmpeg parameters for your writer\noutput_params = {\n\"-vcodec\": \"h264_vaapi\",\n\"-vaapi_device\": \"/dev/dri/renderD128\",\n\"-vf\": \"format=nv12,hwupload\",\n}\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-opencv","title":"Using Compression Mode with OpenCV","text":"<p>You can easily use WriterGear API directly with any Video Processing library(For e.g OpenCV itself) in Compression Mode. The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nimport cv2\n# define suitable (Codec,CRF,preset) FFmpeg parameters for writer\noutput_params = {\"-vcodec\": \"libx264\", \"-crf\": 0, \"-preset\": \"fast\"}\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# write gray frame to writer\nwriter.write(gray)\n# Show output window\ncv2.imshow(\"Output Gray Frame\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/usage/#using-compression-mode-with-live-audio-input","title":"Using Compression Mode with Live Audio Input","text":"<p>In Compression Mode, WriteGear API allows us to exploit almost all FFmpeg supported parameters that you can think of in its Compression Mode. Hence, combining audio with live video frames is pretty easy. </p> <p>In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic) to live frames incoming from the Video Source (for e.g external webcam), and save the output as a compressed video file, all in real time:</p> <p>Example Assumptions</p> <ul> <li>You're running are Linux machine.</li> <li>You already have appropriate audio driver and software installed on your machine.</li> </ul> Identifying and Specifying sound card on different OS platforms  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details.</p> </li> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg -list_devices true -f dshow -i dummy\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n\"-f\": \"dshow\", # !!! warning: always keep this line above \"-i\" parameter !!!\n\"-i\":\"audio=Microphone (USB2.0 Camera)\",\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-acodec\": \"aac\",\n\"-ar\": \"44100\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel</p> <p>Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> Identify Sound Card: To get the list of all installed cards on your machine, you can type <code>arecord -l</code> or <code>arecord -L</code> (longer output).</p> <pre><code>arecord -l\n\n**** List of CAPTURE Hardware Devices ****\ncard 0: ICH5 [Intel ICH5], device 0: Intel ICH [Intel ICH5]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 1: Intel ICH - MIC ADC [Intel ICH5 - MIC ADC]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 2: Intel ICH - MIC2 ADC [Intel ICH5 - MIC2 ADC]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 3: Intel ICH - ADC2 [Intel ICH5 - ADC2]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: U0x46d0x809 [USB Device 0x46d:0x809], device 0: USB Audio [USB Audio]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <p>The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as <code>hw:0</code> or <code>hw:1</code></p> <pre><code># assign appropriate input audio-source\noutput_params = {\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-ar\": \"48000\",\n\"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n\"-i\": \"hw:1\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines:</p> <ul> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>avfoundation</code> as follows:</p> <pre><code>ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-ar\": \"48000\",\n\"-f\": \"avfoundation\", # !!! warning: always keep this line above \"-audio_device_index\" parameter !!!\n\"-audio_device_index\": \"0\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>Make sure this <code>-i</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer\noutput_params = {\n\"-input_framerate\": stream.framerate,\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-ar\": \"48000\",\n\"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n\"-i\": \"hw:1\",\n}\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/","title":"Custom FFmpeg Commands in WriteGear API","text":"<p>WriteGear API now provides the <code>execute_ffmpeg_cmd</code> Method in Compression Mode that enables the user to pass any custom FFmpeg CLI (Command Line Interface) commands as input to its internal FFmpeg Pipeline by formating it as a list. </p> <p>This opens endless possibilities of exploiting every FFmpeg params within WriteGear without relying on a third-party API to do the same and while doing that it robustly handles all errors/warnings quietly.</p> <p> </p> <p>Important Information</p> <ul> <li> <p>This Feature Requires WriteGear's Compression Mode enabled(<code>compression_mode = True</code>). Follow these dedicated Installation Instructions \u27b6 for its installation.</p> </li> <li> <p>Only python list is a valid datatype as input for this function, any other value will throw <code>ValueError</code>.</p> </li> <li> <p>Kindly read FFmpeg Docs carefully, before passing any values to <code>output_param</code> dictionary parameter. Wrong values may result in undesired Errors or no output at all.</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#features","title":"Features","text":"<ul> <li> <p> Provides the ability to pass any custom command to WriteGear FFmpeg Pipeline.</p> </li> <li> <p> Compatible with any FFmpeg terminal command.</p> </li> <li> <p> Standalone On-the-fly functioning.</p> </li> <li> <p> Can work without interfering with WriteGear API's Writer pipeline.</p> </li> <li> <p> Minimum hassle and extremely easy to enable and use. </p> </li> </ul> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#methods","title":"Methods","text":""},{"location":"gears/writegear/compression/advanced/cciw/#execute_ffmpeg_cmd","title":"<code>execute_ffmpeg_cmd</code>","text":"<p>This method allows the users to pass the custom FFmpeg terminal commands as a formatted list directly to WriteGear API's FFmpeg pipeline for processing/execution. Its usage is as follows: </p> <pre><code># format FFmpeg terminal command `ffmpeg -y -i source_video -acodec copy input_audio.aac` as a list\nffmpeg_command = [\"-y\", \"-i\", source_video, \"-acodec\", \"copy\", \"input_audio.aac\"]\n# execute this list using this function\nexecute_ffmpeg_cmd(ffmpeg_command)\n</code></pre> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#usage-examples","title":"Usage Examples","text":"<p>Following usage examples is just an idea of what can be done with this powerful function. So just Tinker with various FFmpeg parameters/commands yourself and see it working. Also, if you're unable to run any terminal FFmpeg command, then report an issue.</p>"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-separate-audio-from-video","title":"Using WriteGear to separate Audio from Video","text":"<p>In this example, we will extract and save audio from a URL stream:</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n# define a valid url\nurl_to_stream = (\n\"http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\"\n)\n# Define writer with default parameters\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n# format command to convert stream audio as 'output_audio.aac' as list\nffmpeg_command_to_save_audio = [\n\"-y\",\n\"-i\",\nurl_to_stream,\n\"output_audio.aac\",\n]  # `-y` parameter is to overwrite outputfile if exists\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command_to_save_audio)\n# safely close writer\nwriter.close()\n</code></pre> <p>After running this script, You will get the final <code>'output_audio.aac'</code> audio file.</p> <p> </p>"},{"location":"gears/writegear/compression/advanced/cciw/#using-writegear-to-merge-audio-with-video","title":"Using WriteGear to merge Audio with Video","text":"<p>In this example, we will merge audio with video:</p> <p>You can also directly add external audio input to video-frames in WriteGear. For more information, See this FAQ example \u27b6</p> <p>Example Assumptions</p> <ul> <li> <p>You already have a separate video(i.e <code>'input-video.mp4'</code>) and audio(i.e <code>'input-audio.aac'</code>) files.</p> </li> <li> <p>Both these Audio and Video files are compatible.</p> </li> </ul> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\nimport time\n# Open input video stream\nstream = VideoGear(source=\"input-video.mp4\").start()\n# set input audio stream path\ninput_audio = \"input-audio.aac\"\n# define your parameters\noutput_params = {\n\"-input_framerate\": stream.framerate\n}  # output framerate must match source framerate\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n# sleep 1 sec as the above video might still be rendering\ntime.sleep(1)\n# format FFmpeg command to generate `Output_with_audio.mp4` by merging input_audio in above rendered `Output.mp4`\nffmpeg_command = [\n\"-y\",\n\"-i\",\n\"Output.mp4\",\n\"-i\",\ninput_audio,\n\"-c:v\",\n\"copy\",\n\"-c:a\",\n\"copy\",\n\"-map\",\n\"0:v:0\",\n\"-map\",\n\"1:a:0\",\n\"-shortest\",\n\"Output_with_audio.mp4\",\n]  # `-y` parameter is to overwrite outputfile if exists\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n</code></pre> <p>After running this script, You will get the final <code>'Output_with_audio.mp4'</code> file with both video and audio merged.</p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/","title":"FFmpeg Installation Instructions","text":"<p>WriteGear must requires FFmpeg executables for its Compression capabilities in Compression Mode. You can following machine-specific instructions for its installation:</p> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it automatically fallbacks to Non-Compression Mode.</p> <p> </p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#linux-ffmpeg-installation","title":"Linux FFmpeg Installation","text":"<p>The WriteGear API supports Auto-Detection and Manual Configuration methods on a Linux machine:</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection","title":"A. Auto-Detection","text":"<p>This is a recommended approach on Linux Machines</p> <p>If WriteGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Linux system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module. </p> <p>Installation: You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Linux Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Linux Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>)  or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the WriteGear API.</p> <p>If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#windows-ffmpeg-installation","title":"Windows FFmpeg Installation","text":"<p>The WriteGear API supports Auto-Installation and Manual Configuration methods on Windows systems.</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-installation","title":"A. Auto-Installation","text":"<p>This is a recommended approach on Windows Machines</p> <p>If WriteGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on Windows system WriteGear API auto-generates the required FFmpeg Static Binaries from a dedicated Github Server into the temporary directory (for e.g. <code>C:\\Temp</code>) of your machine.</p> <p>Warning</p> <ul> <li> <p>The files downloaded to temporary directory (for e.g. <code>C:\\TEMP</code>), may get erased if your machine shutdowns/restarts.</p> </li> <li> <p>You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through <code>-ffmpeg_download_path</code> parameter.</p> </li> <li> <p>If binaries were found at the specified path, WriteGear automatically skips the auto-installation step.</p> </li> <li> <p>If the required FFmpeg static binary fails to download, or extract, or validate during auto-installation, then, WriteGear API will auto-disable the Compression Mode and switches to Non-Compression Mode!</p> </li> </ul>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_1","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Windows Static Binaries(based on your machine arch(x86/x64)) from the link below:</p> <p>Windows Static Binaries: https://ffmpeg.org/download.html#build-windows</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'C:/foo/Downloads/ffmpeg/bin'</code>) or path of <code>ffmpeg.exe</code> executable itself to the <code>custom_ffmpeg</code> parameter in the WriteGear API.</p> <p>If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#macos-ffmpeg-installation","title":"MacOS FFmpeg Installation","text":"<p>The WriteGear API supports Auto-Detection and Manual Configuration methods on a macOS machine.</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#a-auto-detection_1","title":"A. Auto-Detection","text":"<p>This is a recommended approach on MacOS Machines</p> <p>If WriteGear API not receives any input from the user on <code>custom_ffmpeg</code> parameter, then on macOS system, it tries to auto-detects the required FFmpeg installed binaries through validation test that employs <code>subprocess</code> python module.</p> <p>Installation: You can easily install FFmpeg on your macOS machine by following this tutorial \u27b6</p>"},{"location":"gears/writegear/compression/advanced/ffmpeg_install/#b-manual-configuration_2","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest macOS Static Binaries(only x64 Binaries) from the link below:</p> <p>MacOS Static Binaries: http://johnvansickle.com/ffmpeg/</p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>) or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the WriteGear API.</p> <p>If binaries were not found at the manually specified path, WriteGear API will disable the Compression Mode!</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/non_compression/overview/","title":"WriteGear API: Non-Compression Mode","text":"WriteGear API's Non-Compression Mode generalized workflow"},{"location":"gears/writegear/non_compression/overview/#overview","title":"Overview","text":"<p>When <code>compression_mode</code> parameter is disabled (.i.e <code>compression_mode = False</code>), WriteGear API uses basic OpenCV's inbuilt VideoWriter API tools for encoding multimedia files but without compression.</p> <p>This mode provides flexible access to OpenCV's VideoWriter API,and also supports various parameters available within this API, but lacks the ability to control output quality, compression, and other important features like lossless video compression, audio encoding, etc. which are only available in Compression Mode. Thereby, the resultant output video-file size will be many times larger as compared to Compression Mode.</p> <p> </p> <p>Important Information</p> <ul> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system, it will automatically switches to this(Non-Compression) Mode.</p> </li> <li> <p>It is advised to enable logging(<code>logging = True</code>) on the first run for easily identifying any runtime errors.</p> </li> </ul> <p> </p>"},{"location":"gears/writegear/non_compression/overview/#usage-examples","title":"Usage Examples","text":"See here \ud83d\ude80 <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p>"},{"location":"gears/writegear/non_compression/overview/#parameters","title":"Parameters","text":"See here \ud83d\ude80"},{"location":"gears/writegear/non_compression/params/","title":"WriteGear API Parameters: Non-Compression Mode","text":""},{"location":"gears/writegear/non_compression/params/#output","title":"<code>output</code>","text":"<p>This parameter sets the valid output Video filename/path for the output video.</p> <p>WriteGear API will throw <code>RuntimeError</code> if <code>output</code> provided is empty or invalid.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>0</code>. </p> <p>Usage:</p> <p>Make sure to provide valid filename with valid file-extension based on the encoder in use (default is <code>.mp4</code>).</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p>Path to directory: Valid path of the directory to save the output video file. In this case, WriteGear API will automatically assign a unique filename (with a default extension i.e.<code>.mp4</code>) as follows:</p> <pre><code>writer = WriteGear(output = '/home/foo/foo1', compression_mode=False) # Define writer \n</code></pre> </li> <li> <p>Filename (with/without path): Valid filename(with valid extension) of the output video file. In case filename is provided without path, then current working directory will be used.</p> <pre><code>writer = WriteGear(output = 'output.mp4', compression_mode=False) # Define writer \n</code></pre> </li> <li> <p>GStreamer Pipeline: </p> <p>WriteGear API also supports GStreamer Pipeline as input to its <code>output</code> parameter in Non-Compression Mode, when GStreamer Pipeline Mode is enabled. It can be used as follows:</p> <p>Requirement for GStreamer Pipelining</p> <p>GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> New in v0.2.5 <p>This feature was added in <code>v0.2.5</code>.</p> <pre><code># enable GStreamer Pipeline Mode for writer\noutput_params = {\"-gst_pipeline_mode\": True}\n# Define writer\nwriter = WriteGear(\noutput=\"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location=foo.mp4\", compression_mode=False) \n</code></pre> </li> </ul> <p> </p>"},{"location":"gears/writegear/non_compression/params/#compression_mode","title":"<code>compression_mode</code>","text":"<p>This parameter selects the WriteGear's Primary Mode of Operation, i.e. if this parameter is enabled (.i.e <code>compression_mode = True</code>) WriteGear will use FFmpeg to encode output video, and if disabled (.i.e <code>compression_mode = False</code>), the OpenCV's VideoWriter API will be used for encoding files/streams. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>True</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', compression_mode=False)\n</code></pre> <p> </p>"},{"location":"gears/writegear/non_compression/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>Not supported in Non-Compression Mode!</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#output_params","title":"<code>output_params</code>","text":"<p>This parameter allows us to exploit almost all OpenCV's VideoWriter API supported parameters effortlessly and flexibly for video-encoding in Non-Compression Mode, by formatting desired FFmpeg Parameters as this parameter's attributes. All supported parameters and FOURCC codecs for compression mode discussed below:</p> <p>Remember, Non-Compression mode lacks the ability to control output quality and other important features like lossless video compression, audio encoding, etc., which are available with WriteGear's Compression Mode only.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#supported-attributes","title":"Supported Attributes","text":"<p>Non-Compression Mode only gives access to a limited number of Parameters through its <code>output_params</code> parameter's attributes, which are as follows:</p>"},{"location":"gears/writegear/non_compression/params/#a-opencv-parameters","title":"A. OpenCV Parameters","text":"<p>WriteGear provides access to all available OpenCV's VideoWriter API parameters in Non-Compression Mode.</p> Parameters Description <code>-fourcc</code> 4-character code of codec used to encode frames <code>-fps</code> controls the framerate of output video(Default value: 25) <code>-backend</code> (optional) In case of multiple backends, this parameter allows us to specify VideoWriter API's backends to use. Its valid values are <code>CAP_FFMPEG</code> or <code>CAP_GSTREAMER</code>(if enabled) <code>-color</code> (optional) If it is not zero(0), the encoder will expect and encode color frames, otherwise it will work with grayscale frames (the flag is currently supported on Windows only) <p><code>-height</code> and <code>-width</code> parameter are no longer supported and are automatically derived from the input frames.</p>"},{"location":"gears/writegear/non_compression/params/#b-exclusive-parameters","title":"B. Exclusive Parameters","text":"<p>In addition to OpenCV Parameters, WriteGear API also provides few exclusive attribute, which are as follows: </p> <ul> <li> <p><code>-gst_pipeline_mode</code>: a boolean attribute to enable GStreamer Pipeline Mode to supports GStreamer Pipeline as input to its <code>output</code> parameter in Non-Compression Mode.</p> <p>Enabling <code>-gst_pipeline_mode</code> will enforce <code>-backend</code> parameter value to <code>\"CAP_GSTREAMER\"</code></p> New in v0.2.5 <p><code>-gst_pipeline_mode</code> attribute was added in <code>v0.2.5</code>.</p> <p>Its usage example can be found here \u27b6.</p> </li> </ul> <p>Usage:</p> <p>To assign desired parameters in Non-Compression Mode, you can format it as dictionary attribute and pass through this(<code>output_params</code>) parameter as follows:</p> <pre><code># format parameter as dictionary attribute\noutput_params = {\"-fps\":30} \n# and then, assign it\nWriteGear(output = 'output.mp4', **output_params)\n</code></pre> <p>Its usage example can be found here \u27b6.</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#supported-fourcc-codecs","title":"Supported FOURCC Codecs","text":"<p>FOURCC is a 4-character code of the codec used to encode video in Non-Compression Mode(OpenCV's VideoWriter API) without compression.</p> <p>List of all supported FOURCC codecs can found here \u27b6</p> <p>Usage:</p> <p>To select desired FOURCC codec in Non-Compression Mode, you can format it as dictionary attribute and pass through this(<code>output_params</code>) parameter. For example, using <code>MJPG</code> as codec, we can:</p> <pre><code># format codec as dictionary attribute\noutput_params = {\"-fourcc\":\"MJPG\"} \n# and then, assign it\nWriteGear(output = 'output.mp4', **output_params)\n</code></pre> <p>Its usage example can be found here \u27b6.</p> <p> </p>"},{"location":"gears/writegear/non_compression/params/#logging","title":"<code>logging</code>","text":"<p>This parameter enables logging (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code>WriteGear(output = 'output.mp4', logging=True)\n</code></pre> <p> </p>"},{"location":"gears/writegear/non_compression/usage/","title":"WriteGear API Usage Examples: Non-Compression Mode","text":"<p>Important Information</p> <ul> <li> <p>DO NOT feed frames to WriteGear with different dimensions or channels, or-else WriteGear API will exit with <code>ValueError</code>.</p> </li> <li> <p>In case WriteGear API fails to detect valid FFmpeg executables on your system, it will auto-switches to this(Non-Compression) Mode.</p> </li> <li> <p>Always use <code>writer.close()</code> at the very end of the main code. NEVER USE IT INBETWEEN CODE to avoid undesired behavior.</p> </li> </ul> <p>After going through WriteGear Usage Examples, Checkout more bonus examples here \u27b6</p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#bare-minimum-usage","title":"Bare-Minimum Usage","text":"<p>Following is the bare-minimum code you need to get started with WriteGear API in Non-Compression Mode:</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# open any valid video stream(for e.g `myvideo.avi` file)\nstream = CamGear(source=\"myvideo.avi\").start()\n# Define writer with Non-compression mode and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\", compression_mode=False)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-videocapture-gears","title":"Using Non-Compression Mode with VideoCapture Gears","text":"<p>In Non-Compression mode, WriteGear API provides flexible control over OpenCV's VideoWriter API parameters through its <code>output_param</code> dictionary parameter by formating them as dictionary attributes. Moreover, WriteGear API can be used in conjunction with any other Gears/APIs effortlessly. </p> <p>All supported attributes for <code>output_param</code> can be found  here \u27b6</p> <p>The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# define suitable tweak parameters for writer\noutput_params = {\"-fourcc\": \"MJPG\", \"-fps\": 30}\n# open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0, logging=True).start()\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(\noutput=\"Output.mp4\", compression_mode=False, logging=True, **output_params\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# write gray frame to writer\nwriter.write(gray)\n# Show output window\ncv2.imshow(\"Output Gray Frame\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-opencv","title":"Using Non-Compression Mode with OpenCV","text":"<p>You can easily use WriterGear API directly with any Video Processing library(For e.g OpenCV itself) in Non-Compression Mode. The complete usage example is as follows:</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nimport cv2\n# define suitable tweak parameters for writer\noutput_params = {\"-fourcc\": \"MJPG\", \"-fps\": 30}\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(\noutput=\"Output.mp4\", compression_mode=False, logging=True, **output_params\n)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# lets convert frame to gray for this example\ngray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n# write gray frame to writer\nwriter.write(gray)\n# Show output window\ncv2.imshow(\"Output Gray Frame\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p> <p> </p>"},{"location":"gears/writegear/non_compression/usage/#using-non-compression-mode-with-gstreamer-pipeline","title":"Using Non-Compression Mode with GStreamer Pipeline","text":"<p>WriteGear API's Non-Compression Mode also supports GStreamer Pipeline as input to its <code>output</code> parameter, when GStreamer Pipeline Mode is enabled. This provides flexible way to write video frames to file or network stream with controlled framerate and bitrate. The complete usage example is as follows:</p> <p>Requirement for GStreamer Pipelining</p> <p>GStreamer Pipelining in WriteGear requires your OpenCV to be built with GStreamer support. Checkout this FAQ for compiling OpenCV with GStreamer support.</p> New in v0.2.5 <p>This example was added in <code>v0.2.5</code>.</p> <p>In this example we will be constructing GStreamer pipeline to write video-frames into a file(<code>foo.mp4</code>) at 1M video-bitrate.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nimport cv2\n# enable GStreamer Pipeline Mode for writer\noutput_params = {\"-gst_pipeline_mode\": True}\n# open live video stream on webcam at first index(i.e. 0) device\nstream = cv2.VideoCapture(0)\n# gst pipeline to write to a file `foo.mp4` at 1M video-bitrate\nGSTPipeline = \"appsrc ! videoconvert ! avenc_mpeg4 bitrate=100000 ! mp4mux ! filesink location={}\".format(\n\"foo.mp4\"\n)\n# Define writer with defined parameters and with our Gstreamer pipeline\nwriter = WriteGear(\noutput=GSTPipeline, compression_mode=False, logging=True, **output_params\n)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.release()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/camgear_ex/","title":"CamGear Examples","text":""},{"location":"help/camgear_ex/#synchronizing-two-sources-in-camgear","title":"Synchronizing Two Sources in CamGear","text":"<p>In this example both streams and corresponding frames will be processed synchronously i.e. with no delay:</p> <p>Using same source with more than one instances of CamGear can lead to Global Interpreter Lock (GIL) that degrades performance even when it is not a bottleneck.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\nimport time\n# define and start the stream on first source ( For e.g #0 index device)\nstream1 = CamGear(source=0, logging=True).start() \n# define and start the stream on second source ( For e.g #1 index device)\nstream2 = CamGear(source=1, logging=True).start() \n# infinite loop\nwhile True:\nframeA = stream1.read()\n# read frames from stream1\nframeB = stream2.read()\n# read frames from stream2\n# check if any of two frame is None\nif frameA is None or frameB is None:\n#if True break the infinite loop\nbreak\n# do something with both frameA and frameB here\ncv2.imshow(\"Output Frame1\", frameA)\ncv2.imshow(\"Output Frame2\", frameB)\n# Show output window of stream1 and stream 2 separately\nkey = cv2.waitKey(1) &amp; 0xFF\n# check for 'q' key-press\nif key == ord(\"q\"):\n#if 'q' key-pressed break out\nbreak\nif key == ord(\"w\"):\n#if 'w' key-pressed save both frameA and frameB at same time\ncv2.imwrite(\"Image-1.jpg\", frameA)\ncv2.imwrite(\"Image-2.jpg\", frameB)\n#break   #uncomment this line to break out after taking images\ncv2.destroyAllWindows()\n# close output window\n# safely close both video streams\nstream1.stop()\nstream2.stop()\n</code></pre> <p> </p>"},{"location":"help/camgear_ex/#using-variable-yt_dlp-parameters-in-camgear","title":"Using variable <code>yt_dlp</code> parameters in CamGear","text":"<p>CamGear provides exclusive attributes <code>STREAM_RESOLUTION</code> (for specifying stream resolution) &amp; <code>STREAM_PARAMS</code> (for specifying underlying API(e.g. <code>yt_dlp</code>) parameters) with its <code>options</code> dictionary parameter. </p> <p>The complete usage example is as follows: </p> <p>More information on <code>STREAM_RESOLUTION</code> &amp; <code>STREAM_PARAMS</code> attributes can be found here \u27b6</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nimport cv2\n# specify attributes\noptions = {\"STREAM_RESOLUTION\": \"720p\", \"STREAM_PARAMS\": {\"nocheckcertificate\": True}}\n# Add YouTube Video URL as input source (for e.g https://youtu.be/bvetuLwJIkA)\n# and enable Stream Mode (`stream_mode = True`)\nstream = CamGear(\nsource=\"https://youtu.be/bvetuLwJIkA\", stream_mode=True, logging=True, **options\n).start()\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/camgear_ex/#using-camgear-for-capturing-rtsprtmp-urls","title":"Using CamGear for capturing RTSP/RTMP URLs","text":"<p>You can open any network stream (such as RTSP/RTMP) just by providing its URL directly to CamGear's <code>source</code> parameter. </p> <p>Here's a high-level wrapper code around CamGear API to enable auto-reconnection during capturing: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> Enforcing UDP stream <p>You can easily enforce UDP for RTSP streams inplace of default TCP, by putting following lines of code on the top of your existing code:</p> <pre><code># import required libraries\nimport os\n# enforce UDP\nos.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;udp\"\n</code></pre> <p>Finally, use <code>backend</code> parameter value as <code>backend=cv2.CAP_FFMPEG</code> in CamGear.</p> <pre><code>from vidgear.gears import CamGear\nimport cv2\nimport datetime\nimport time\nclass Reconnecting_CamGear:\ndef __init__(self, cam_address, reset_attempts=50, reset_delay=5):\nself.cam_address = cam_address\nself.reset_attempts = reset_attempts\nself.reset_delay = reset_delay\nself.source = CamGear(source=self.cam_address).start()\nself.running = True\ndef read(self):\nif self.source is None:\nreturn None\nif self.running and self.reset_attempts &gt; 0:\nframe = self.source.read()\nif frame is None:\nself.source.stop()\nself.reset_attempts -= 1\nprint(\n\"Re-connection Attempt-{} occured at time:{}\".format(\nstr(self.reset_attempts),\ndatetime.datetime.now().strftime(\"%m-%d-%Y %I:%M:%S%p\"),\n)\n)\ntime.sleep(self.reset_delay)\nself.source = CamGear(source=self.cam_address).start()\n# return previous frame\nreturn self.frame\nelse:\nself.frame = frame\nreturn frame\nelse:\nreturn None\ndef stop(self):\nself.running = False\nself.reset_attempts = 0\nself.frame = None\nif not self.source is None:\nself.source.stop()\nif __name__ == \"__main__\":\n# open any valid video stream\nstream = Reconnecting_CamGear(\ncam_address=\"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\",\nreset_attempts=20,\nreset_delay=5,\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/camgear_faqs/","title":"CamGear FAQs","text":""},{"location":"help/camgear_faqs/#what-is-camgear-api-and-what-does-it-do","title":"What is CamGear API and what does it do?","text":"<p>Answer: CamGear supports a diverse range of video streams which can handle/control video stream almost any IP/USB Cameras, multimedia video file format (upto 4k tested), any network stream URL such as http(s), rtp, rtsp, rtmp, mms, etc. In addition to this, it also supports live Gstreamer's RAW pipelines and YouTube video/livestreams URLs. For more info. see CamGear doc \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-camgear-api","title":"I'm only familiar with OpenCV, how to get started with CamGear API?","text":"<p>Answer: First, see Switching from OpenCV, then go through CamGear doc. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-change-opencv-source-backend-in-camgear-api","title":"How to change OpenCV source backend in CamGear API?","text":"<p>Answer: See its Parameters \u27b6. Its, <code>backend</code>(int) parameter sets the backend of the source. Its value can be for e.g. <code>backend = cv2.CAP_DSHOW</code> in case of Direct Show.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-get-framerate-of-the-source-in-camgear-api","title":"How to get framerate of the source in CamGear API?","text":"<p>Answer: CamGear's <code>framerate</code> global variable can be used to retrieve framerate of the input video stream.  See this example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-compile-opencv-with-gstreamer-support","title":"How to compile OpenCV with GStreamer support?","text":"<p>Answer: For compiling OpenCV with GSstreamer(<code>&gt;=v1.0.0</code>) support:</p>  Linux Windows MacOS <ul> <li> Follow this tutorial \u27b6</li> </ul> <ul> <li> Follow this tutorial \u27b6</li> </ul> <ul> <li> Follow this tutorial \u27b6</li> </ul> <p> </p>"},{"location":"help/camgear_faqs/#how-to-change-quality-and-parameters-of-youtube-streams-with-camgear","title":"How to change quality and parameters of YouTube Streams with CamGear?","text":"<p>Answer: CamGear provides exclusive attributes <code>STREAM_RESOLUTION</code> (for specifying stream resolution) &amp; <code>STREAM_PARAMS</code> (for specifying underlying API(e.g. <code>yt_dlp</code>) parameters) with its <code>options</code> dictionary parameter. See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-open-rtsp-network-streams-with-camgear","title":"How to open RTSP network streams with CamGear?","text":"<p>Answer: You can open any local network stream (such as RTSP) just by providing its URL directly to CamGear's <code>source</code> parameter. See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-set-camera-settings-with-camgear","title":"How to set Camera Settings with CamGear?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#can-i-play-4k8k-video-with-camgear-api","title":"Can I play 4K/8k video with CamGear API?","text":"<p>Answer: Yes, you can if your System Hardware supports it.</p> <p> </p>"},{"location":"help/camgear_faqs/#how-to-synchronize-between-two-cameras","title":"How to synchronize between two cameras?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#can-i-use-gpu-to-decode-the-video-source","title":"Can I use GPU to decode the video source?","text":"<p>Answer: See this issue comment \u27b6.</p> <p> </p>"},{"location":"help/camgear_faqs/#why-camgear-is-throwing-warning-that-threaded-queue-mode-is-disabled","title":"Why CamGear is throwing warning that Threaded Queue Mode is disabled?","text":"<p>Answer: That's a normal behavior. Please read about Threaded Queue Mode \u27b6</p> <p> </p>"},{"location":"help/general_faqs/","title":"General FAQs","text":""},{"location":"help/general_faqs/#im-new-to-python-programming-or-its-usage-in-opencv-library-how-to-use-vidgear-in-my-projects","title":"\"I'm new to Python Programming or its usage in OpenCV Library\", How to use vidgear in my projects?","text":"<p>Answer: Before using vidgear, It's recommended to first go through the following dedicated blog sites and learn how OpenCV-Python syntax works (with examples):</p> <ul> <li> <p>PyImageSearch.com \u27b6 is the best resource for learning OpenCV and its Python implementation. Adrian Rosebrock provides many practical OpenCV techniques with tutorials, code examples, blogs, and books at PyImageSearch.com. Highly recommended!</p> </li> <li> <p>learnopencv.com \u27b6  Maintained by OpenCV CEO Satya Mallick. This blog is for programmers, hackers, engineers, scientists, students, and self-starters interested in Computer Vision and Machine Learning.</p> </li> <li> <p>There's also the official OpenCV Tutorials \u27b6 curated by the OpenCV developers.</p> </li> </ul> <p>Once done, visit Switching from OpenCV \u27b6 to easily replace OpenCV APIs with suitable Gears \u27b6 in your project. All the best! </p> <p>If you run into any trouble or have any questions, then refer our Help section.</p> <p> </p>"},{"location":"help/general_faqs/#vidgear-is-using-multi-threading-but-python-is-notorious-for-its-poor-performance-in-multithreading","title":"\"VidGear is using Multi-threading, but Python is notorious for its poor performance in multithreading?\"","text":"<p>Answer: Refer vidgear's Threaded-Queue-Mode \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#modulenotfounderror-no-module-named-vidgeargears-vidgear-is-not-a-package","title":"ModuleNotFoundError: No module named 'vidgear.gears'. 'vidgear' is not a package?","text":"<p>Answer: This error means you either have a file named <code>vidgear.py</code> in your python path or you've named your python script <code>vidgear.py</code>. Replace <code>vidgear</code> name with anything else to fix this error.</p> <p> </p>"},{"location":"help/general_faqs/#how-to-log-to-a-file-in-vidgear","title":"How to log to a file in VidGear?","text":"<p>Answer: VidGear provides exclusive <code>VIDGEAR_LOGFILE</code> environment variable to enable logging to a file while logging is enabled (i.e. <code>logging=True</code>) on respective Gear. You just have to set directory pathname (automatically creates <code>vidgear.log</code> file) or a log file pathname itself as value for this  environment variable. This can be done on various platfroms/OSes as follows:</p> <p>Remember enabling this logging to a file will completely disable any output on the terminal.</p> Linux OSWindows OS (Powershell)OSX/Mac OS <pre><code># path to file\nexport VIDGEAR_LOGFILE=\"$HOME/foo.log\"\n# or just directory path \n# !!! Make sure `foo` path already exists !!!\nexport VIDGEAR_LOGFILE=\"$HOME/foo\"\n# to remove\nunset VIDGEAR_LOGFILE\n</code></pre> <pre><code># path to file\n$Env:VIDGEAR_LOGFILE = \"D:\\foo.log\"\n# or just directory path \n# !!! Make sure `foo` path already exists !!!\n$Env:VIDGEAR_LOGFILE = \"D:\\foo\"\n# to remove\n$Env:VIDGEAR_LOGFILE = \"\"\n</code></pre> <pre><code># path to file\nexport VIDGEAR_LOGFILE=\"$HOME/foo.log\"\n# or just directory path \n# !!! Make sure `foo` path already exists !!!\nexport VIDGEAR_LOGFILE=\"$HOME/foo\"\n# to remove\nunset VIDGEAR_LOGFILE\n</code></pre> <p> </p>"},{"location":"help/general_faqs/#can-i-perform-deep-learning-task-with-vidgear","title":"Can I perform Deep Learning task with VidGear?","text":"<p>Answer: VidGear is a powerful Video Processing library (similar to OpenCV, FFmpeg, etc.) that can read, write, process, send &amp; receive a sequence of video-frames in an optimized manner. But for Deep Learning or Machine Learning tasks, you have to use a third-party library. That being said, all VidGear's APIs can be used with any third-party Library(such as PyTorch, Tensorflow, etc.) that can leverage the overall performance if you're processing video/audio streams/frames in your application with Deep Learning tasks. Also, it eases the workflow since you have to write way fewer lines of code to read/store/process output videos.</p> <p> </p>"},{"location":"help/general_faqs/#can-i-ask-my-question-directly-without-raising-an-issue","title":"Can I ask my question directly without raising an issue?","text":"<p>Answer: Yes, please join our Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/general_faqs/#how-to-contribute-to-vidgear-development","title":"How to contribute to VidGear development?","text":"<p>Answer: See our Contribution Guidelines \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#what-oses-are-supported-by-vidgear","title":"What OSes are supported by VidGear?","text":"<p>Answer: See Supported Systems \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#what-python-versions-are-supported-by-vidgear","title":"What Python versions are supported by VidGear?","text":"<p>Answer: See Supported Python legacies \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#can-i-include-vidgear-in-my-project-commercially-or-not","title":"Can I include VidGear in my project commercially or not?","text":"<p>Answer: Yes, you can, but strictly under the Terms and Conditions given in VidGear License \u27b6</p> <p> </p>"},{"location":"help/general_faqs/#i-love-using-vidgear-for-my-projects-how-can-i-support-it","title":"\"I Love using VidGear for my projects\", How can I support it?","text":"<p>Answer: See Helping VidGear \u27b6 </p> <p> </p>"},{"location":"help/get_help/","title":"Getting Help","text":"Courtesy - Pinterest <p>Would you like to get help with VidGear?</p> <p>There are several ways such as:</p> <p> </p>"},{"location":"help/get_help/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Got a question related to VidGear Working?  </p> <p>Checkout the Frequently Asked Questions - a curated list of all the questions with adequate answer that we commonly receive for quickly troubleshooting your problems:</p> <ul> <li>General FAQs \u27b6</li> <li>CamGear FAQs \u27b6</li> <li>PiGear FAQs \u27b6</li> <li>ScreenGear FAQs \u27b6</li> <li>StreamGear FAQs \u27b6</li> <li>WriteGear FAQs \u27b6</li> <li>NetGear FAQs \u27b6</li> <li>WebGear FAQs \u27b6</li> <li>WebGear_RTC FAQs \u27b6</li> <li>VideoGear FAQs \u27b6</li> <li>NetGear_Async FAQs \u27b6</li> <li>Stabilizer Class FAQs \u27b6</li> </ul> <p> </p>"},{"location":"help/get_help/#bonus-examples","title":"Bonus Examples","text":"<p>How we do this with that API?  </p> <p>Checkout the Bonus Examples - a curated list of all experimental examples with unusual configuration that aren't included in general usage examples:</p> <ul> <li>CamGear Examples \u27b6</li> <li>PiGear Examples \u27b6</li> <li>ScreenGear Examples \u27b6</li> <li>StreamGear Examples \u27b6</li> <li>WriteGear Examples \u27b6</li> <li>NetGear Examples \u27b6</li> <li>WebGear Examples \u27b6</li> <li>WebGear_RTC Examples \u27b6</li> <li>VideoGear Examples \u27b6</li> <li>NetGear_Async Examples \u27b6</li> <li>Stabilizer Class Examples \u27b6</li> </ul> <p> </p>"},{"location":"help/get_help/#join-our-gitter-community-channel","title":"Join our Gitter Community channel","text":"<p>Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems</p> <p>Join and chat on our Gitter Community channel: </p> <p>There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas &amp; information, etc. </p> <p> </p>"},{"location":"help/get_help/#this-is-what-you-do-when","title":"This is what you do when...","text":"<ul> <li> Got a question or problem?</li> <li> Found a typo?</li> <li> Found a bug?</li> <li> Missing a feature/improvement?</li> </ul>"},{"location":"help/get_help/#reporting-an-issues","title":"Reporting an issues","text":"<p>Want to report a bug? Suggest a new feature?</p> <p>Before you do, please read our guidelines \u27b6</p> <p> </p>"},{"location":"help/get_help/#preparing-a-pull-request","title":"Preparing a Pull Request","text":"<p>Interested in contributing to VidGear?</p> <p>Before you do, please read our guidelines \u27b6</p> <p> </p>"},{"location":"help/netgear_async_ex/","title":"NetGear_Async Examples","text":""},{"location":"help/netgear_async_ex/#using-netgear_async-with-webgear","title":"Using NetGear_Async with WebGear","text":"<p>The complete usage example is as follows: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p>"},{"location":"help/netgear_async_ex/#client-webgear-server","title":"Client + WebGear Server","text":"<p>Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code:</p> <p>After running this code, Make sure to open Browser immediately otherwise NetGear_Async will soon exit with <code>TimeoutError</code>. You can also try setting <code>timeout</code> parameter to a higher value to extend this timeout.</p> <p>Make sure you use different <code>port</code> value for NetGear_Async and WebGear API.</p> <p>High CPU utilization may occur on Client's end. User discretion is advised.</p> <p>Note down the IP-address of this system (required at Server's end) by executing the  <code>hostname -I</code> command and also replace it in the following code.\"</p> <pre><code># import libraries\nfrom vidgear.gears.asyncio import NetGear_Async\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\nimport uvicorn, asyncio, cv2\n# Define NetGear_Async Client at given IP address and define parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear_Async(\nreceive_mode=True,\npattern=1,\nlogging=True,\n).launch()\n# create your own custom frame producer\nasync def my_frame_producer():\n# loop over Client's Asynchronous Frame Generator\nasync for frame in client.recv_generator():\n# {do something with received frames here}\n# reducer frames size if you want more performance otherwise comment this line\nframe = await reducer(\nframe, percentage=30, interpolation=cv2.INTER_AREA\n)  # reduce frame by 30%\n# handle JPEG encoding\nencodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n# yield frame in byte format\nyield (b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\nawait asyncio.sleep(0)\nif __name__ == \"__main__\":\n# Set event loop to client's\nasyncio.set_event_loop(client.loop)\n# initialize WebGear app without any source\nweb = WebGear(logging=True)\n# add your custom frame producer to config with adequate IP address\nweb.config[\"generator\"] = my_frame_producer\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# safely close client\nclient.close()\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.</p>"},{"location":"help/netgear_async_ex/#server","title":"Server","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index 0), and execute the following python code:</p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <pre><code># import library\nfrom vidgear.gears.asyncio import NetGear_Async\nimport cv2, asyncio\n# initialize Server without any source\nserver = NetGear_Async(\nsource=None,\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n)\n# Create a async frame generator as custom source\nasync def my_frame_generator():\n# !!! define your own video source here !!!\n# Open any video stream such as live webcam\n# video stream on first index(i.e. 0) device\nstream = cv2.VideoCapture(0)\n# loop over stream until its terminated\nwhile True:\n# read frames\n(grabbed, frame) = stream.read()\n# check if frame empty\nif not grabbed:\nbreak\n# do something with the frame to be sent here\n# yield frame\nyield frame\n# sleep for sometime\nawait asyncio.sleep(0)\n# close stream\nstream.release()\nif __name__ == \"__main__\":\n# set event loop\nasyncio.set_event_loop(server.loop)\n# Add your custom source generator to Server configuration\nserver.config[\"generator\"] = my_frame_generator()\n# Launch the Server\nserver.launch()\ntry:\n# run your main function task until it is complete\nserver.loop.run_until_complete(server.task)\nexcept (KeyboardInterrupt, SystemExit):\n# wait for interrupts\npass\nfinally:\n# finally close the server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/netgear_async_faqs/","title":"NetGear_Async FAQs","text":""},{"location":"help/netgear_async_faqs/#what-is-netgear_async-api-and-what-does-it-do","title":"What is NetGear_Async API and what does it do?","text":"<p>Answer: NetGear_Async is an asyncio videoframe messaging framework, built on <code>zmq.asyncio</code>, and powered by high-performance asyncio event loop called <code>uvloop</code> to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. Basically, this API is able to transfer thousands of frames in just a few seconds without causing any significant load on your system. For more info. see NetGear_Async doc \u27b6</p> <p> </p>"},{"location":"help/netgear_async_faqs/#how-to-get-started-with-netgear_async-api","title":"How to get started with NetGear_Async API?","text":"<p>Answer: See NetGear_Async doc \u27b6. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/netgear_async_faqs/#netgear_async-is-throwing-modulenotfounderror-on-importing-why","title":"\"NetGear_Async is throwing <code>ModuleNotFoundError</code> on importing\", Why?","text":"<p>Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6.</p> <p> </p>"},{"location":"help/netgear_async_faqs/#what-is-the-key-difference-between-netgear_async-and-netgear-apis","title":"What is the key difference between NetGear_Async and NetGear APIs?","text":"<p>Answer: </p> <ul> <li> <p>NetGear: implements a high-level wrapper around PyZmQ python library that contains python bindings for ZeroMQ - a high-performance asynchronous distributed messaging library that provides a message queue, but unlike message-oriented middleware, its system can run without a dedicated message broker. </p> </li> <li> <p>NetGear_Async: is an asyncio videoframe messaging framework, built on <code>zmq.asyncio</code>, and powered by high-performance asyncio event loop called <code>uvloop</code> to high-speed and lag-free video streaming over the network with minimal resource constraints.</p> </li> </ul> <p>Key Difference: NetGear_Async is highly memory efficient, but has less features as compared to NetGear API which is marginally faster too. </p> <p> </p>"},{"location":"help/netgear_async_faqs/#can-i-use-multi-server-bi-directional-like-modes-in-netgear_async","title":"Can I use Multi-Server, Bi-Directional like modes in NetGear_Async?","text":"<p>Answer: No, NetGear_Async does NOT provide support for any NetGear's Exclusive modes yet.</p> <p> </p>"},{"location":"help/netgear_async_faqs/#how-to-use-netgear_async-with-custom-server-source-from-opencv","title":"How to use NetGear_Async with custom Server Source from OpenCV?","text":"<p>Answer: See this usage example \u27b6. </p> <p> </p>"},{"location":"help/netgear_async_faqs/#why-netgear_async-is-running-slow","title":"Why NetGear_Async is running slow?","text":"<p>Answer: Checkout tips suggested in this answer \u27b6</p> <p> </p>"},{"location":"help/netgear_ex/","title":"NetGear Examples","text":""},{"location":"help/netgear_ex/#using-netgear-with-webgear","title":"Using NetGear with WebGear","text":"<p>The complete usage example is as follows: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p>"},{"location":"help/netgear_ex/#client-webgear-server","title":"Client + WebGear Server","text":"<p>Open a terminal on Client System where you want to display the input frames (and setup WebGear server) received from the Server and execute the following python code:</p> <p>After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with <code>RuntimeError</code>. You can also try setting <code>max_retries</code> and <code>request_timeout</code> like attributes to a higher value to avoid this.</p> <p>Make sure you use different <code>port</code> value for NetGear and WebGear API.</p> <p>High CPU utilization may occur on Client's end. User discretion is advised.</p> <p>Note down the local IP-address of this system (required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <pre><code># import necessary libs\nimport uvicorn, asyncio, cv2\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\n# initialize WebGear app without any source\nweb = WebGear(logging=True)\n# activate jpeg encoding and specify other related parameters\noptions = {\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# create your own custom frame producer\nasync def my_frame_producer():\n# initialize global params\n# Define NetGear Client at given IP address and define parameters\n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\nreceive_mode=True,\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options,\n)\n# loop over frames\nwhile True:\n# receive frames from network\nframe = client.recv()\n# if NoneType\nif frame is None:\nbreak\n# do something with your OpenCV frame here\n# reducer frames size if you want more performance otherwise comment this line\nframe = await reducer(\nframe, percentage=30, interpolation=cv2.INTER_AREA\n)  # reduce frame by 30%\n# handle JPEG encoding\nencodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n# yield frame in byte format\nyield (b\"--frame\\r\\nContent-Type:image/jpeg\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\nawait asyncio.sleep(0)\n# close stream\nclient.close()\n# add your custom frame producer to config with adequate IP address\nweb.config[\"generator\"] = my_frame_producer\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.</p>"},{"location":"help/netgear_ex/#server","title":"Server","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index 0), and execute the following python code:</p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n# activate jpeg encoding and specify other related parameters\noptions = {\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/netgear_ex/#using-netgear-with-webgear_rtc","title":"Using NetGear with WebGear_RTC","text":"<p>The complete usage example is as follows: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p>"},{"location":"help/netgear_ex/#client-webgear_rtc-server","title":"Client + WebGear_RTC Server","text":"<p>Open a terminal on Client System where you want to display the input frames (and setup WebGear_RTC server) received from the Server and execute the following python code:</p> <p>After running this code, Make sure to open Browser immediately otherwise NetGear will soon exit with <code>RuntimeError</code>. You can also try setting <code>max_retries</code> and <code>request_timeout</code> like attributes to a higher value to avoid this.</p> <p>Make sure you use different <code>port</code> value for NetGear and WebGear_RTC API.</p> <p>High CPU utilization may occur on Client's end. User discretion is advised.</p> <p>Note down the local IP-address of this system(required at Server's end) and also replace it in the following code. You can follow this FAQ for this purpose.</p> <p>For VideoCapture APIs you also need to implement <code>start()</code> in addition to <code>read()</code> and <code>stop()</code> methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work!</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears import NetGear\nfrom vidgear.gears.helper import reducer\nfrom vidgear.gears.asyncio import WebGear_RTC\n# create your own custom streaming class\nclass Custom_Stream_Class:\n\"\"\"\n    Custom Streaming using NetGear Receiver\n    \"\"\"\ndef __init__(\nself,\naddress=None,\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options,\n):\n# initialize global params\n# Define NetGear Client at given IP address and define parameters\nself.client = NetGear(\nreceive_mode=True,\naddress=address,\nport=port,\nprotocol=protocol,\npattern=pattern,\nlogging=logging,\n**options\n)\nself.running = False\ndef start(self):\n# don't forget this function!!!\n# This function is specific to VideoCapture APIs only\nif not self.source is None:\nself.source.start()\ndef read(self):\n# don't forget this function!!!\n# check if source was initialized or not\nif self.source is None:\nreturn None\n# check if we're still running\nif self.running:\n# receive frames from network\nframe = self.client.recv()\n# check if frame is available\nif not (frame is None):\n# do something with your OpenCV frame here\n# reducer frames size if you want more performance otherwise comment this line\nframe = reducer(frame, percentage=20)  # reduce frame by 20%\n# return our gray frame\nreturn frame\nelse:\n# signal we're not running now\nself.running = False\n# return None-type\nreturn None\ndef stop(self):\n# don't forget this function!!!\n# flag that we're not running\nself.running = False\n# close stream\nif not (self.client is None):\nself.client.close()\nself.client = None\n# activate jpeg encoding and specify NetGear related parameters\noptions = {\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# assign your Custom Streaming Class with adequate NetGear parameters\n# to `custom_stream` attribute in options parameter of WebGear_RTC.\noptions = {\n\"custom_stream\": Custom_Stream_Class(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n}\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in your Client's Browser.</p>"},{"location":"help/netgear_ex/#server_1","title":"Server","text":"<p>Now, Open the terminal on another Server System (with a webcam connected to it at index 0), and execute the following python code:</p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import NetGear\nimport cv2\n# activate jpeg encoding and specify other related parameters\noptions = {\n\"jpeg_compression\": True,\n\"jpeg_compression_quality\": 90,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": True,\n}\n# Open live video stream on webcam at first index(i.e. 0) device\nstream = VideoGear(source=0).start()\n# Define NetGear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/netgear_faqs/","title":"NetGear FAQs","text":""},{"location":"help/netgear_faqs/#what-is-netgear-api-and-what-does-it-do","title":"What is NetGear API and what does it do?","text":"<p>Answer: NetGear is exclusively designed to transfer video frames &amp; data synchronously (Pair &amp; Request/Reply) as well as asynchronously (Publish/Subscribe) between various interconnecting systems over the network in real-time. For more info. see NetGear doc \u27b6</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-get-started-with-netgear-api","title":"How to get started with NetGear API?","text":"<p>Answer: See NetGear doc \u27b6. Still in doubt, then discuss on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/netgear_faqs/#what-exclusive-modes-are-compatible-with-each-other-in-netgear-api","title":"What Exclusive Modes are compatible with each other in NetGear API?","text":"<p>Here's the compatibility chart for NetGear's Exclusive Modes:</p> Exclusive Modes Multi-Servers Multi-Clients Secure Bidirectional SSH Tunneling Multi-Servers - No (throws error) Yes Yes No (throws error) Multi-Clients No (throws error) - Yes Yes No (throws error) Secure Yes Yes - Yes Yes Bidirectional Yes Yes Yes - Yes SSH Tunneling No (throws error) No (throws error) Yes Yes - <p> </p>"},{"location":"help/netgear_faqs/#why-netgear-is-running-slow","title":"Why NetGear is running slow?","text":"<p>Answer: Here are few tips to troubleshoot performance on your machine:</p> <ul> <li> <p>Update ZMQ to latest: Update your <code>pyzmq</code> lib as follows:</p> <pre><code>sudo pip3 install -U pyzmq\n</code></pre> </li> <li> <p>Install testing branch: The <code>testing</code> branch may contain many latest performance updates, which are not yet merged into master branch. Therefore, you can try them earlier, by installing <code>testing</code> branch directly \u27b6.</p> </li> <li> <p>Use PUB/SUB pattern if you're live streaming:  Try different <code>pattern</code> values, as each of them suits different settings. For example, you can use its Publisher/Subscriber pattern (i.e. <code>pattern=2</code>) for asynchronous high-speed transmission over real-time streams, and it works faster than other synchronous patterns for this scenario.</p> </li> <li> <p>Use Wired connection instead of Wireless connection: Remember typical 802.11g Wireless has a theoretical maximum of 54Mbps. Typical wired 10/100/1000 Ethernet has a theoretical maximum of 100 Gbps. So in theory wired is faster. However, these speeds are only on your local network. So chose your network configuration wisely.</p> </li> <li> <p>Enable all Performance Attributes with Frame Compression: You can also try enabling Frame Compression with its all Performance Attributes for NetGear API.</p> </li> <li> <p>Reduce Frame Size: Use VidGear's real-time Frame-Size Reducer(<code>reducer</code>) method for reducing frame-size on-the-go for additional performance (see this usage example \u27b6). Remember, sending large HQ video-frames may required more network bandwidth and packet size, which can lead to additional latency!</p> </li> <li> <p>Systematically, check for Hardware/Network Issues \u27b6</p> </li> <li> <p>Finally, if nothing works then, checkout NetGear_Async API \u27b6</p> </li> </ul> <p> </p>"},{"location":"help/netgear_faqs/#how-to-find-local-ip-address-on-different-os-platforms","title":"How to find local IP-address on different OS platforms?","text":"<p>Answer: For finding local IP-address of your machine:</p> On Linux OSOn Windows OSOn MAC OS <ul> <li> Follow this tutorial \u27b6</li> </ul> <ul> <li> Follow this tutorial \u27b6</li> </ul> <ul> <li> Follow this tutorial \u27b6</li> </ul> <p> </p>"},{"location":"help/netgear_faqs/#how-to-send-data-along-with-frames-in-multi-servers-and-multi-clients-modes","title":"How to send data along with frames in Multi-Servers and Multi-Clients Modes?","text":"<p>Answer: See Multi-Servers usage example \u27b6 and Multi-Clients usage example \u27b6</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-use-enable-encryption-and-authentication-in-netgear-api","title":"How to use enable Encryption and Authentication in NetGear API?","text":"<p>Answer: See its Secure Mode doc \u27b6.</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-send-custom-data-along-with-frames-bidirectionally-in-netgear-api","title":"How to send custom data along with frames bidirectionally in NetGear API?","text":"<p>Answer: See its Bidirectional Mode doc \u27b6.</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-access-netgear-api-outside-network-or-remotely","title":"How to access NetGear API outside network or remotely?","text":"<p>Answer: See its SSH Tunneling Mode doc \u27b6.</p> <p> </p>"},{"location":"help/netgear_faqs/#are-there-any-side-effect-of-sending-data-with-frames","title":"Are there any side-effect of sending data with frames?","text":"<p>Answer: Yes, it may lead to additional LATENCY depending upon the size/amount of the data being transferred. User discretion is advised.</p> <p> </p>"},{"location":"help/netgear_faqs/#why-netgear-api-not-working-correctly","title":"Why NetGear API not working correctly?","text":"<p>Answer: First, carefully go through NetGear doc \u27b6 that contains detailed information. Also, checkout PyZmq Docs \u27b6 for its various settings/parameters. If still it doesn't work for you, then let us know on Gitter \u27b6</p> <p> </p>"},{"location":"help/netgear_faqs/#how-to-solve-zmqerrorzmqerror-errors","title":"How to solve <code>zmq.error.ZMQError</code> errors?","text":"<p>Answer: For those used to the idea that a \"server\" provides their address to a client, then you should recheck your preconceptions! Please read the Netgear instructions carefully, and you will note that it is the client device that defines the IP that is provided to the server config. If you get this the wrong way (using the server IP on the client), then you will get a <code>zmq.error.ZMQError</code> error. Make sure it is the client's IP shared across the two systems.</p> <p> </p>"},{"location":"help/pigear_ex/","title":"PiGear Examples","text":""},{"location":"help/pigear_ex/#setting-variable-picamera-parameters-for-camera-module-at-runtime","title":"Setting variable <code>picamera</code> parameters for Camera Module at runtime","text":"<p>You can use <code>stream</code> global parameter in PiGear to feed any <code>picamera</code> parameters at runtime. </p> <p>In this example we will set initial Camera Module's <code>brightness</code> value <code>80</code>, and will change it <code>50</code> when <code>z</code> key is pressed at runtime:</p> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nimport cv2\n# initial parameters\noptions = {\"brightness\": 80} # set brightness to 80\n# open pi video stream with default parameters\nstream = PiGear(logging=True, **options).start() \n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# check for 'z' key if pressed\nif key == ord(\"z\"):\n# change brightness to 50\nstream.stream.brightness = 50\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/pigear_faqs/","title":"PiGear FAQs","text":""},{"location":"help/pigear_faqs/#what-is-pigear-api-and-what-does-it-do","title":"What is PiGear API and what does it do?","text":"<p>Answer: PiGear is similar to CamGear but exclusively made to support various Raspberry Pi Camera Modules (such as OmniVision OV5647 Camera Module and Sony IMX219 Camera Module). For more info. see PiGear doc \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-pigear-api","title":"I'm only familiar with OpenCV, how to get started with PiGear API?","text":"<p>Answer: First, see Switching from OpenCV, then go through PiGear doc. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/pigear_faqs/#why-my-camera-module-is-not-detected-by-pigear","title":"Why my camera module is not detected by PiGear?","text":"<p>Answer: Make sure to enable Raspberry Pi hardware-specific settings \u27b6 before using PiGear. Also, recheck/change your Camera Module's ribbon-cable and Camera Module itself, if it damaged or got broken somehow.</p> <p> </p>"},{"location":"help/pigear_faqs/#how-to-select-camera-index-on-pi-compute-io-board-with-two-cameras-attached","title":"How to select camera index on Pi Compute IO board with two Cameras attached?","text":"<p>Answer: See PiGear's <code>camera_num</code> parameter \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#why-pigear-is-throwing-systemerror","title":"Why PiGear is throwing <code>SystemError</code>?","text":"<p>Answer: This means your Raspberry Pi CSI ribbon-cable is not connected properly to your Camera Module, or damaged, or even both. </p> <p> </p>"},{"location":"help/pigear_faqs/#how-to-assign-picamera-settings-for-camera-module-with-pigear","title":"How to assign <code>picamera</code> settings for Camera Module with PiGear?","text":"<p>Answer: See this usage example \u27b6</p> <p> </p>"},{"location":"help/pigear_faqs/#video-output-is-too-dark-with-pigear-why","title":"\"Video output is too dark with PiGear\", Why?","text":"<p>Answer: Seems like the settings are wrong. Kindly see picamera docs for available parameters, and look for parameters are <code>sensor_mode</code>, <code>shutter_speed</code> and <code>exposure_mode</code>, try changing those values. Also, maybe your <code>framerate</code> value is too high. Try lowering it.</p> <p> </p>"},{"location":"help/pigear_faqs/#how-to-change-picamera-settings-for-camera-module-at-runtime","title":"How to change <code>picamera</code> settings for Camera Module at runtime?","text":"<p>Answer: You can use <code>stream</code> global parameter in PiGear to feed any <code>picamera</code> setting at runtime. See this bonus example \u27b6</p> <p> </p>"},{"location":"help/screengear_ex/","title":"ScreenGear Examples","text":""},{"location":"help/screengear_ex/#using-screengear-with-netgear-and-writegear","title":"Using ScreenGear with NetGear and WriteGear","text":"<p>The complete usage example is as follows: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p>"},{"location":"help/screengear_ex/#client-writegear","title":"Client + WriteGear","text":"<p>Open a terminal on Client System (where you want to save the input frames received from the Server) and execute the following python code: </p> <p>Note down the IP-address of this system(required at Server's end) by executing the command: <code>hostname -I</code> and also replace it in the following code.</p> <p>You can terminate client anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import NetGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# define various tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Define Netgear Client at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with yours !!!\nclient = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nreceive_mode=True,\nlogging=True,\n**options\n)\n# Define writer with default parameters and suitable output filename for e.g. `Output.mp4`\nwriter = WriteGear(output=\"Output.mp4\")\n# loop over\nwhile True:\n# receive frames from network\nframe = client.recv()\n# check for received frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# close output window\ncv2.destroyAllWindows()\n# safely close client\nclient.close()\n# safely close writer\nwriter.close()\n</code></pre>"},{"location":"help/screengear_ex/#server-screengear","title":"Server + ScreenGear","text":"<p>Now, Open the terminal on another Server System (with a montior/display attached to it), and execute the following python code: </p> <p>Replace the IP address in the following code with Client's IP address you noted earlier.</p> <p>You can terminate stream on both side anytime by pressing Ctrl+C on your keyboard!</p> <pre><code># import required libraries\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears import NetGear\n# define dimensions of screen w.r.t to given monitor to be captured\noptions = {\"top\": 40, \"left\": 0, \"width\": 100, \"height\": 100}\n# open stream with defined parameters\nstream = ScreenGear(logging=True, **options).start()\n# define various netgear tweak flags\noptions = {\"flag\": 0, \"copy\": False, \"track\": False}\n# Define Netgear server at given IP address and define parameters \n# !!! change following IP address '192.168.x.xxx' with client's IP address !!!\nserver = NetGear(\naddress=\"192.168.x.xxx\",\nport=\"5454\",\nprotocol=\"tcp\",\npattern=1,\nlogging=True,\n**options\n)\n# loop over until KeyBoard Interrupted\nwhile True:\ntry:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to server\nserver.send(frame)\nexcept KeyboardInterrupt:\nbreak\n# safely close video stream\nstream.stop()\n# safely close server\nserver.close()\n</code></pre> <p> </p>"},{"location":"help/screengear_ex/#using-screengear-with-webgear_rtc","title":"Using ScreenGear with WebGear_RTC","text":"<p>The complete usage example is as follows: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> Bare-MinimumAdvanced <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears.asyncio import WebGear_RTC\n# assign your ScreenGear class with adequate parameters \n# to `custom_stream` attribute in options parameter\noptions = {\"custom_stream\": ScreenGear(logging=True)}\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>For VideoCapture APIs you also need to implement <code>start()</code> in addition to <code>read()</code> and <code>stop()</code> methods in your Custom Streaming Class as shown in following example, otherwise WebGear_RTC will fail to work!</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nfrom vidgear.gears import ScreenGear\nfrom vidgear.gears.helper import reducer\nfrom vidgear.gears.asyncio import WebGear_RTC\n# create your own custom streaming class\nclass Custom_Stream_Class:\n\"\"\"\n    Custom Streaming using ScreenGear\n    \"\"\"\ndef __init__(self, backend=\"mss\", logging=False):\n# !!! define your own video source here !!!\nself.source = ScreenGear(backend=backend, logging=logging)\n# define running flag\nself.running = True\ndef start(self):\n# don't forget this function!!!\n# This function is specific to VideoCapture APIs only\nif not self.source is None:\nself.source.start()\ndef read(self):\n# don't forget this function!!!\n# check if source was initialized or not\nif self.source is None:\nreturn None\n# check if we're still running\nif self.running:\n# read frame from provided source\nframe = self.source.read()\n# check if frame is available\nif not(frame is None):\n# do something with your OpenCV frame here\n# reducer frames size if you want more performance otherwise comment this line\nframe = reducer(frame, percentage=20)  # reduce frame by 20%\n# return our gray frame\nreturn frame\nelse:\n# signal we're not running now\nself.running = False\n# return None-type\nreturn None\ndef stop(self):\n# don't forget this function!!!\n# flag that we're not running\nself.running = False\n# close stream\nif not self.source is None:\nself.source.stop()\n# assign your Custom Streaming Class with adequate ScreenGear parameters\n# to `custom_stream` attribute in options parameter\noptions = {\"custom_stream\": Custom_Stream_Class(backend=\"pil\", logging=True)}\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/screengear_faqs/","title":"ScreenGear FAQs","text":""},{"location":"help/screengear_faqs/#what-is-screengear-api-and-what-does-it-do","title":"What is ScreenGear API and what does it do?","text":"<p>Answer: ScreenGear is designed exclusively for ultra-fast Screencasting, that means it can grab frames from your monitor in real-time, either by define an area on the computer screen, or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends. For more info. see ScreenGear doc \u27b6</p> <p> </p>"},{"location":"help/screengear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-screengear-api","title":"I'm only familiar with OpenCV, how to get started with ScreenGear API?","text":"<p>Answer: First, see Switching from OpenCV, then go through ScreenGear doc. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/screengear_faqs/#screengear-is-slow","title":"ScreenGear is Slow?","text":"<p>Answer: This maybe due to selected <code>backend</code> for ScreenGear API is not compatibile with your machine. See this usage example to change backend \u27b6. Try different backends, and select which works the best for your machine.</p> <p> </p>"},{"location":"help/screengear_faqs/#how-to-define-area-on-screen-to-record-with-screengear","title":"How to define area on screen to record with ScreenGear?","text":"<p>Answer: See this usage example \u27b6</p> <p> </p>"},{"location":"help/screengear_faqs/#how-to-record-video-from-all-connected-screens","title":"How to record video from all connected screens?","text":"<p>Answer: See ScreenGear's <code>monitor</code> parameter that sets the index of the monitor to grab a frame from. If its value is <code>-1</code>, it will record from all monitors. More information can be found here  \u27b6</p> <p> </p>"},{"location":"help/stabilizer_ex/","title":"Stabilizer Class Examples","text":""},{"location":"help/stabilizer_ex/#saving-stabilizer-class-output-with-live-audio-input","title":"Saving Stabilizer Class output with Live Audio Input","text":"<p>In this example code, we will merging the audio from a Audio Device (for e.g. Webcam inbuilt mic input) with Stabilized frames incoming from the Stabilizer Class (which is also using same Webcam video input through OpenCV), and save the final output as a compressed video file, all in real time:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>Example Assumptions</p> <ul> <li>You're running are Linux machine.</li> <li>You already have appropriate audio driver and software installed on your machine.</li> </ul> Identifying and Specifying sound card on different OS platforms On WindowsOn LinuxOn MacOS <p>Windows OS users can use the dshow (DirectShow) to list audio input device which is the preferred option for Windows users. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> [OPTIONAL] Enable sound card(if disabled): First enable your Stereo Mix by opening the \"Sound\" window and select the \"Recording\" tab, then right click on the window and select \"Show Disabled Devices\" to toggle the Stereo Mix device visibility. Follow this post \u27b6 for more details.</p> </li> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg -list_devices true -f dshow -i dummy\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n\"-f\": \"dshow\", # !!! warning: always keep this line above \"-i\" parameter !!!\n\"-i\":\"audio=Microphone (USB2.0 Camera)\",\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-acodec\": \"aac\",\n\"-ar\": \"44100\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then checkout this troubleshooting guide \u27b6 or reach us out on Gitter \u27b6 Community channel</p> <p>Linux OS users can use the alsa to list input device to capture live audio input such as from a webcam. You can refer following steps to identify and specify your sound card:</p> <ul> <li> <p> Identify Sound Card: To get the list of all installed cards on your machine, you can type <code>arecord -l</code> or <code>arecord -L</code> (longer output).</p> <pre><code>arecord -l\n\n**** List of CAPTURE Hardware Devices ****\ncard 0: ICH5 [Intel ICH5], device 0: Intel ICH [Intel ICH5]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 1: Intel ICH - MIC ADC [Intel ICH5 - MIC ADC]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 2: Intel ICH - MIC2 ADC [Intel ICH5 - MIC2 ADC]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: ICH5 [Intel ICH5], device 3: Intel ICH - ADC2 [Intel ICH5 - ADC2]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: U0x46d0x809 [USB Device 0x46d:0x809], device 0: USB Audio [USB Audio]\nSubdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in WriteGear as follows:</p> <p>The easiest thing to do is to reference sound card directly, namely \"card 0\" (Intel ICH5) and \"card 1\" (Microphone on the USB web cam), as <code>hw:0</code> or <code>hw:1</code></p> <pre><code># assign appropriate input audio-source\noutput_params = {\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-ar\": \"48000\",\n\"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n\"-i\": \"hw:1\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>MAC OS users can use the avfoundation to list input devices for grabbing audio from integrated iSight cameras as well as cameras connected via USB or FireWire. You can refer following steps to identify and specify your sound card on MacOS/OSX machines:</p> <ul> <li> <p> Identify Sound Card: Then, You can locate your soundcard using <code>avfoundation</code> as follows:</p> <pre><code>ffmpeg -f qtkit -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Sound Card: Then, you can specify your located soundcard in StreamGear as follows:</p> <pre><code># assign appropriate input audio-source\noutput_params = {\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-ar\": \"48000\",\n\"-f\": \"avfoundation\", # !!! warning: always keep this line above \"-audio_device_index\" parameter !!!\n\"-audio_device_index\": \"0\",\n}\n</code></pre> </li> </ul> <p>If audio still doesn't work then reach us out on Gitter \u27b6 Community channel</p> <p>Make sure this <code>-i</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nfrom vidgear.gears.stabilizer import Stabilizer\nimport cv2\n# Open suitable video stream, such as webcam on first index(i.e. 0)\nstream = cv2.VideoCapture(0)\n# initiate stabilizer object with defined parameters\nstab = Stabilizer(smoothing_radius=30, crop_n_zoom=True, border_size=5, logging=True)\n# change with your webcam soundcard, plus add additional required FFmpeg parameters for your writer\noutput_params = {\n\"-input_framerate\": stream.get(cv2.CAP_PROP_FPS),\n\"-thread_queue_size\": \"512\",\n\"-ac\": \"2\",\n\"-ar\": \"48000\",\n\"-f\": \"alsa\", # !!! warning: always keep this line above \"-i\" parameter !!!\n\"-i\": \"hw:1\",\n}\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# send current frame to stabilizer for processing\nstabilized_frame = stab.stabilize(frame)\n# wait for stabilizer which still be initializing\nif stabilized_frame is None:\ncontinue\n# {do something with the stabilized frame here}\n# write stabilized frame to writer\nwriter.write(stabilized_frame)\n# clear stabilizer resources\nstab.clean()\n# safely close video stream\nstream.release()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/stabilizer_ex/#saving-stabilizer-class-output-with-file-audio-input","title":"Saving Stabilizer Class output with File Audio Input","text":"<p>In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time:</p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <p>Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>Use <code>-disable_force_termination</code> flag when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nfrom vidgear.gears.stabilizer import Stabilizer\nimport cv2\n# Give suitable video file path to be stabilized\nunstabilized_videofile = \"test.mp4\"\n# open stream on given path\nstream = cv2.VideoCapture(unstabilized_videofile)\n# initiate stabilizer object with defined parameters\nstab = Stabilizer(smoothing_radius=30, crop_n_zoom=True, border_size=5, logging=True)\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n\"-i\": unstabilized_videofile,\n\"-c:a\": \"aac\",\n\"-input_framerate\": stream.get(cv2.CAP_PROP_FPS),\n\"-clones\": [\"-shortest\"],\n# !!! Uncomment following line if video duration is too short(&lt;60sec). !!!\n#\"-disable_force_termination\": True,\n}\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\n(grabbed, frame) = stream.read()\n# check for frame if not grabbed\nif not grabbed:\nbreak\n# send current frame to stabilizer for processing\nstabilized_frame = stab.stabilize(frame)\n# wait for stabilizer which still be initializing\nif stabilized_frame is None:\ncontinue\n# {do something with the stabilized frame here}\n# write stabilized frame to writer\nwriter.write(stabilized_frame)\n# clear stabilizer resources\nstab.clean()\n# safely close video stream\nstream.release()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/stabilizer_faqs/","title":"Stabilizer Class FAQs","text":""},{"location":"help/stabilizer_faqs/#what-is-stabilizer-class-and-what-does-it-do","title":"What is Stabilizer Class and what does it do?","text":"<p>Answer: Stabilizer Class is an auxiliary class that enables Video Stabilization for vidgear with minimalistic latency, and at the expense of little to no additional computational requirements. For more info. see Stabilizer Class doc \u27b6</p> <p> </p>"},{"location":"help/stabilizer_faqs/#how-much-latency-you-would-typically-expect-with-stabilizer-class","title":"How much latency you would typically expect with Stabilizer Class?","text":"<p>Answer: The stabilizer will be Slower for High-Quality videos-frames. Try reducing frames size (Use <code>reducer()</code> method) before feeding them for reducing latency. Also, see <code>smoothing_radius</code> parameter of Stabilizer class that handles the quality of stabilization at the expense of latency and sudden panning. The larger its value, the less will be panning, more will be latency, and vice-versa.</p> <p> </p>"},{"location":"help/stabilizer_faqs/#how-to-remove-black-borders-in-output-video-after-stabilizing-it","title":"How to remove black borders in output video after stabilizing it?","text":"<p>Answer: See <code>crop_n_zoom</code> parameter of Stabilizer class, that enables the feature, where it crops and zooms frames(to original size) to reduce the black borders from stabilization being too noticeable (similar to the feature available in Adobe AfterEffects). It works in conjunction with the <code>border_size</code> parameter, i.e. when this parameter is enabled border_size will be used for cropping border instead of making them. Its default value is <code>False</code>.</p> <p> </p>"},{"location":"help/stabilizer_faqs/#can-i-use-stabilizer-directly-with-opencv","title":"Can I use Stabilizer directly with OpenCV?","text":"<p>Answer: Yes, see this usage example \u27b6.</p> <p> </p>"},{"location":"help/stabilizer_faqs/#why-stabilization-is-not-working-properly-for-my-video","title":"Why stabilization is not working properly for my video?","text":"<p>Answer: The Stabilizer may not perform well against High-frequency jitter in video. But,you can check if increasing <code>smoothing_radius</code> parameter value helps but it will add latency too.</p> <p> </p>"},{"location":"help/streamgear_ex/","title":"StreamGear Examples","text":""},{"location":"help/streamgear_ex/#streamgear-live-streaming-usage-with-pigear","title":"StreamGear Live-Streaming Usage with PiGear","text":"<p>In this example, we will be Live-Streaming video-frames from Raspberry Pi (with Camera Module connected)  using PiGear API and StreamGear API's Real-time Frames Mode:</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>Use <code>-window_size</code> &amp; <code>-extra_window_size</code> FFmpeg parameters for controlling number of frames to be kept in Chunks. Less these value, less will be latency.</p> <p>After every few chunks (equal to the sum of <code>-window_size</code> &amp; <code>-extra_window_size</code> values), all chunks will be overwritten in Live-Streaming. Thereby, since newer chunks in manifest/playlist will contain NO information of any older ones, and therefore resultant DASH/HLS stream will play only the most recent frames.</p> <p>In this mode, StreamGear DOES NOT automatically maps video-source audio to generated streams. You need to manually assign separate audio-source through <code>-audio</code> attribute of <code>stream_params</code> dictionary parameter.</p> DASHHLS <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"dash_out.mpd\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import PiGear\nfrom vidgear.gears import StreamGear\nimport cv2\n# add various Picamera tweak parameters to dictionary\noptions = {\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n# enable livestreaming and retrieve framerate from CamGear Stream and\n# pass it as `-input_framerate` parameter for controlled framerate\nstream_params = {\"-input_framerate\": stream.framerate, \"-livestream\": True}\n# describe a suitable manifest-file location/name\nstreamer = StreamGear(output=\"hls_out.m3u8\", format = \"hls\", **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# send frame to streamer\nstreamer.stream(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close streamer\nstreamer.terminate()\n</code></pre> <p> </p>"},{"location":"help/streamgear_faqs/","title":"StreamGear FAQs","text":""},{"location":"help/streamgear_faqs/#what-is-streamgear-api-and-what-does-it-do","title":"What is StreamGear API and what does it do?","text":"<p>Answer: StreamGear automates transcoding workflow for generating Ultra-Low Latency, High-Quality, Dynamic &amp; Adaptive Streaming Formats (such as MPEG-DASH) in just few lines of python code. For more info. see StreamGear doc \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-get-started-with-streamgear-api","title":"How to get started with StreamGear API?","text":"<p>Answer: See StreamGear doc \u27b6. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/streamgear_faqs/#what-is-mpd-file-created-with-streamgear","title":"What is <code>.mpd</code> file created with StreamGear?","text":"<p>Answer: SteamGear also creates a Manifest file (such as MPD in-case of DASH) besides segments that describe these segment information (timing, URL, media characteristics like video resolution and bit rates) and is provided to the client before the streaming session.</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-play-streaming-assets-created-with-streamgear-api","title":"How to play Streaming Assets created with StreamGear API?","text":"<p>Answer: You can easily feed Manifest file(<code>.mpd</code>) to DASH Supported Players Input but sure encoded chunks are present along with it. See this list of recommended players \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#what-adaptive-streaming-formats-are-supported-yet","title":"What Adaptive Streaming Formats are supported yet?","text":"<p>Answer: SteamGear currently only supports MPEG-DASH (Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1) , but other adaptive streaming technologies such as Apple HLS, Microsoft Smooth Streaming, will be added soon.</p> <p> </p>"},{"location":"help/streamgear_faqs/#is-drm-encryption-supported-in-streamgear-api","title":"Is DRM Encryption supported in StreamGear API?","text":"<p>Answer: No, DRM Encryption is NOT supported yet.</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-create-additional-streams-in-streamgear-api","title":"How to create additional streams in StreamGear API?","text":"<p>Answer: See this example \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-opencv","title":"How to use StreamGear API with OpenCV?","text":"<p>Answer: See this example \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#how-to-use-streamgear-api-with-real-time-frames","title":"How to use StreamGear API with real-time frames?","text":"<p>Answer: See Real-time Frames Mode \u27b6</p> <p> </p>"},{"location":"help/streamgear_faqs/#is-real-time-frames-mode-only-used-for-live-streaming","title":"Is Real-time Frames Mode only used for Live-Streaming?","text":"<p>Answer: Real-time Frame Modes and Live-Streaming are completely different terms and not directly related. </p> <ul> <li> <p>Real-time Frame Mode is one of primary mode for directly transcoding real-time <code>numpy.ndarray</code> video-frames (as opposed to a entire file) into a sequence of multiple smaller chunks/segments for streaming. </p> </li> <li> <p>Live-Streaming is feature of StreamGear's primary modes that activates behaviour where chunks will contain information for few new frames only and forgets all previous ones for low latency streaming. It can be activated for any primary mode using exclusive <code>-livestream</code> attribute of <code>stream_params</code> dictionary parameter.</p> </li> </ul>"},{"location":"help/streamgear_faqs/#how-to-use-hardwaregpu-encoder-for-streamgear-trancoding","title":"How to use Hardware/GPU encoder for StreamGear trancoding?","text":"<p>Answer: See this example \u27b6</p> <p> </p>"},{"location":"help/videogear_ex/","title":"VideoGear Examples","text":""},{"location":"help/videogear_ex/#using-videogear-with-rosrobot-operating-system","title":"Using VideoGear with ROS(Robot Operating System)","text":"<p>We will be using <code>cv_bridge</code> to convert OpenCV frames to ROS image messages and vice-versa. </p> <p>In this example, we'll create a node that convert OpenCV frames into ROS image messages, and then publishes them over ROS.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example is vidgear implementation of this wiki example.</p> <pre><code># import roslib\nimport roslib\nroslib.load_manifest(\"my_package\")\n# import other required libraries\nimport sys\nimport rospy\nimport cv2\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom vidgear.gears import VideoGear\n# custom publisher class\nclass image_publisher:\ndef __init__(self, source=0, logging=False):\n# create CV bridge\nself.bridge = CvBridge()\n# define publisher topic\nself.image_pub = rospy.Publisher(\"image_topic_pub\", Image)\n# open stream with given parameters\nself.stream = VideoGear(source=source, logging=logging).start()\n# define publisher topic\nrospy.Subscriber(\"image_topic_sub\", Image, self.callback)\ndef callback(self, data):\n# {do something with received ROS node data here}\n# read frames\nframe = self.stream.read()\n# check for frame if None-type\nif not (frame is None):\n# {do something with the frame here}\n# publish our frame\ntry:\nself.image_pub.publish(self.bridge.cv2_to_imgmsg(frame, \"bgr8\"))\nexcept CvBridgeError as e:\n# catch any errors\nprint(e)\ndef close(self):\n# stop stream\nself.stream.stop()\ndef main(args):\n# !!! define your own video source here !!!\n# Open any video stream such as live webcam\n# video stream on first index(i.e. 0) device\n# define publisher\nic = image_publisher(source=0, logging=True)\n# initiate ROS node on publisher\nrospy.init_node(\"image_publisher\", anonymous=True)\ntry:\n# run node\nrospy.spin()\nexcept KeyboardInterrupt:\nprint(\"Shutting down\")\nfinally:\n# close publisher\nic.close()\nif __name__ == \"__main__\":\nmain(sys.argv)\n</code></pre> <p> </p>"},{"location":"help/videogear_ex/#using-videogear-for-capturing-rtsprtmp-urls","title":"Using VideoGear for capturing RTSP/RTMP URLs","text":"<p>Here's a high-level wrapper code around VideoGear API to enable auto-reconnection during capturing, plus stabilization is enabled (<code>stabilize=True</code>) in order to stabilize captured frames on-the-go: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> Enforcing UDP stream <p>You can easily enforce UDP for RTSP streams inplace of default TCP, by putting following lines of code on the top of your existing code:</p> <pre><code># import required libraries\nimport os\n# enforce UDP\nos.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;udp\"\n</code></pre> <p>Finally, use <code>backend</code> parameter value as <code>backend=cv2.CAP_FFMPEG</code> in VideoGear.</p> <pre><code>from vidgear.gears import VideoGear\nimport cv2\nimport datetime\nimport time\nclass Reconnecting_VideoGear:\ndef __init__(self, cam_address, stabilize=False, reset_attempts=50, reset_delay=5):\nself.cam_address = cam_address\nself.stabilize = stabilize\nself.reset_attempts = reset_attempts\nself.reset_delay = reset_delay\nself.source = VideoGear(\nsource=self.cam_address, stabilize=self.stabilize\n).start()\nself.running = True\ndef read(self):\nif self.source is None:\nreturn None\nif self.running and self.reset_attempts &gt; 0:\nframe = self.source.read()\nif frame is None:\nself.source.stop()\nself.reset_attempts -= 1\nprint(\n\"Re-connection Attempt-{} occured at time:{}\".format(\nstr(self.reset_attempts),\ndatetime.datetime.now().strftime(\"%m-%d-%Y %I:%M:%S%p\"),\n)\n)\ntime.sleep(self.reset_delay)\nself.source = VideoGear(\nsource=self.cam_address, stabilize=self.stabilize\n).start()\n# return previous frame\nreturn self.frame\nelse:\nself.frame = frame\nreturn frame\nelse:\nreturn None\ndef stop(self):\nself.running = False\nself.reset_attempts = 0\nself.frame = None\nif not self.source is None:\nself.source.stop()\nif __name__ == \"__main__\":\n# open any valid video stream\nstream = Reconnecting_VideoGear(\ncam_address=\"rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov\",\nreset_attempts=20,\nreset_delay=5,\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n</code></pre> <p> </p>"},{"location":"help/videogear_ex/#using-videogear-for-real-time-stabilization-with-audio-encoding","title":"Using VideoGear for Real-time Stabilization with Audio Encoding","text":"<p>In this example code, we will be directly merging the audio from a Video-File (to be stabilized) with its processed stabilized frames into a compressed video output in real time:</p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <p>Make sure this input video-file (to be stabilized) contains valid audio source, otherwise you could encounter multiple errors or no output at all.</p> <p>You MUST use <code>-input_framerate</code> attribute to set exact value of input framerate when using external audio in Real-time Frames mode, otherwise audio delay will occur in output streams.</p> <p>Use <code>-disable_force_termination</code> flag when video duration is too short(&lt;60sec), otherwise WriteGear will not produce any valid output.</p> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\nfrom vidgear.gears import VideoGear\nimport cv2\n# Give suitable video file path to be stabilized\nunstabilized_videofile = \"test.mp4\"\n# open any valid video path with stabilization enabled(`stabilize = True`)\nstream_stab = VideoGear(source=unstabilized_videofile, stabilize=True, logging=True).start()\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n\"-i\": unstabilized_videofile,\n\"-c:a\": \"aac\",\n\"-input_framerate\": stream_stab.framerate,\n\"-clones\": [\"-shortest\"],\n# !!! Uncomment following line if video duration is too short(&lt;60sec). !!!\n#\"-disable_force_termination\": True,\n}\n# Define writer with defined parameters and suitable output filename for e.g. `Output.mp4\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe_stab = stream_stab.read()\n# check for frame if not grabbed\nif frame_stab is None:\nbreak\n# {do something with the stabilized frame here}\n# write stabilized frame to writer\nwriter.write(frame_stab)\n# safely close streams\nstream_stab.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/videogear_faqs/","title":"VideoGear FAQs","text":""},{"location":"help/videogear_faqs/#what-is-videogear-api-and-what-does-it-do","title":"What is VideoGear API and what does it do?","text":"<p>Answer: VideoGear provides a special internal wrapper around VidGear's exclusive Video Stabilizer class. It also act as a Common API, that provided an internal access to both CamGear and PiGear APIs and their parameters, with a special <code>enablePiCamera</code> boolean flag. For more info. see VideoGear doc \u27b6</p> <p> </p>"},{"location":"help/videogear_faqs/#whats-the-need-of-videogear-api","title":"What's the need of VideoGear API?","text":"<p>Answer: VideoGear is basically ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams (real-time or not)  with minimum efforts and using way fewer lines of code. It also serve as backend for other powerful APIs, such WebGear and NetGear_Async.</p> <p> </p>"},{"location":"help/videogear_faqs/#which-apis-are-accessible-with-videogear-api","title":"Which APIs are accessible with VideoGear API?","text":"<p>Answer: VideoGear provided an internal access to both CamGear and PiGear APIs and their parameters, also it contains wrapper around Video Stabilizer class.</p> <p> </p>"},{"location":"help/videogear_faqs/#can-we-access-writegear-api-or-netgear-api-too-with-videogear","title":"Can we access WriteGear API or NetGear API too with VideoGear?","text":"<p>Answer: No, only selected VideoCapture APIs (anwsered above) are accessible.</p> <p> </p>"},{"location":"help/videogear_faqs/#does-using-videogear-instead-of-camgear-api-directly-affects-performance","title":"Does using VideoGear instead of CamGear API directly, affects performance?","text":"<p>Answer: No, there's no difference, as VideoGear just a high-level wrapper around CamGear API and without any modifications in-between.</p> <p> </p>"},{"location":"help/webgear_ex/","title":"WebGear Examples","text":""},{"location":"help/webgear_ex/#using-webgear-with-raspberrypi-camera-module","title":"Using WebGear with RaspberryPi Camera Module","text":"<p>Because of WebGear API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs.</p> <p>Following usage examples are just an idea of what can be done with WebGear API, you can try various VideoGear, CamGear and PiGear parameters directly in WebGear API in the similar manner.</p> <p>Here's a bare-minimum example of using WebGear API with the Raspberry Pi camera module while tweaking its various properties in just one-liner:</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n# various webgear performance and Raspberry Pi camera tweaks\noptions = {\n\"frame_size_reduction\": 40,\n\"jpeg_compression_quality\": 80,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": False,\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# initialize WebGear app\nweb = WebGear(\nenablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_ex/#using-webgear-with-real-time-video-stabilization-enabled","title":"Using WebGear with real-time Video Stabilization enabled","text":"<p>Here's an example of using WebGear API with real-time Video Stabilization enabled:</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n# various webgear performance tweaks\noptions = {\n\"frame_size_reduction\": 40,\n\"jpeg_compression_quality\": 80,\n\"jpeg_compression_fastdct\": True,\n\"jpeg_compression_fastupsample\": False,\n}\n# initialize WebGear app  with a raw source and enable video stabilization(`stabilize=True`)\nweb = WebGear(source=\"foo.mp4\", stabilize=True, logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_ex/#display-two-sources-simultaneously-in-webgear","title":"Display Two Sources Simultaneously in WebGear","text":"<p>In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear API by defining two separate frame generators: </p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>Step-1 (Trigger Auto-Generation Process): Firstly, run this bare-minimum code to trigger the Auto-generation process, this will create <code>.vidgear</code> directory at current location (directory where you'll run this code):</p> <pre><code># import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n# provide current directory to save data files\noptions = {\"custom_data_location\": \"./\"}\n# initialize WebGear app\nweb = WebGear(source=0, logging=True, **options)\n# close app safely\nweb.shutdown()\n</code></pre> <p>Step-2 (Replace HTML file): Now, go inside <code>.vidgear</code> <code>webgear</code> <code>templates</code> directory at current location of your machine, and there replace content of <code>index.html</code> file with following:</p> <pre><code>{% extends \"base.html\" %}\n{% block content %}\n  &lt;h1 class=\"glow\"&gt;WebGear Video Feed&lt;/h1&gt;\n&lt;div class=\"rows\"&gt;\n&lt;img src=\"/video\" alt=\"Feed\"/&gt;\n&lt;img src=\"/video2\" alt=\"Feed\"/&gt;\n&lt;/div&gt;\n{% endblock %}\n</code></pre> <p>Step-3 (Build your own Frame Producers): Now, create a python script code with OpenCV source, as follows:</p> <pre><code># import necessary libs\nimport uvicorn, asyncio, cv2\nfrom vidgear.gears.asyncio import WebGear\nfrom vidgear.gears.asyncio.helper import reducer\nfrom starlette.responses import StreamingResponse\nfrom starlette.routing import Route\n# provide current directory to load data files\noptions = {\"custom_data_location\": \"./\"}\n# initialize WebGear app without any source\nweb = WebGear(logging=True, **options)\n# create your own custom frame producer\nasync def my_frame_producer1():\n# !!! define your first video source here !!!\n# Open any video stream such as \"foo1.mp4\"\nstream = cv2.VideoCapture(\"foo1.mp4\")\n# loop over frames\nwhile True:\n# read frame from provided source\n(grabbed, frame) = stream.read()\n# break if NoneType\nif not grabbed:\nbreak\n# do something with your OpenCV frame here\n# reducer frames size if you want more performance otherwise comment this line\nframe = await reducer(frame, percentage=30)  # reduce frame by 30%\n# handle JPEG encoding\nencodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n# yield frame in byte format\nyield (b\"--frame\\r\\nContent-Type:video/jpeg2000\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\nawait asyncio.sleep(0.00001)\n# close stream\nstream.release()\n# create your own custom frame producer\nasync def my_frame_producer2():\n# !!! define your second video source here !!!\n# Open any video stream such as \"foo2.mp4\"\nstream = cv2.VideoCapture(\"foo2.mp4\")\n# loop over frames\nwhile True:\n# read frame from provided source\n(grabbed, frame) = stream.read()\n# break if NoneType\nif not grabbed:\nbreak\n# do something with your OpenCV frame here\n# reducer frames size if you want more performance otherwise comment this line\nframe = await reducer(frame, percentage=30)  # reduce frame by 30%\n# handle JPEG encoding\nencodedImage = cv2.imencode(\".jpg\", frame)[1].tobytes()\n# yield frame in byte format\nyield (b\"--frame\\r\\nContent-Type:video/jpeg2000\\r\\n\\r\\n\" + encodedImage + b\"\\r\\n\")\nawait asyncio.sleep(0.00001)\n# close stream\nstream.release()\nasync def custom_video_response(scope):\n\"\"\"\n   Return a async video streaming response for `my_frame_producer2` generator\n   \"\"\"\nassert scope[\"type\"] in [\"http\", \"https\"]\nawait asyncio.sleep(0.00001)\nreturn StreamingResponse(\nmy_frame_producer2(),\nmedia_type=\"multipart/x-mixed-replace; boundary=frame\",\n)\n# add your custom frame producer to config\nweb.config[\"generator\"] = my_frame_producer1\n# append new route i.e. new custom route with custom response\nweb.routes.append(\nRoute(\"/video2\", endpoint=custom_video_response)\n)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.</p> <p> </p>"},{"location":"help/webgear_faqs/","title":"WebGear FAQs","text":""},{"location":"help/webgear_faqs/#what-is-webgear-api-and-what-does-it-do","title":"What is WebGear API and what does it do?","text":"<p>Answer: WebGear is a powerful ASGI Video-Broadcaster API ideal for transmitting Motion-JPEG-frames from a single source to multiple recipients via the browser. For more info. see WebGear doc \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#how-to-get-started-with-webgear-api","title":"How to get started with WebGear API?","text":"<p>Answer: See WebGear doc \u27b6. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/webgear_faqs/#webgear-is-throwing-modulenotfounderror-on-importing-why","title":"\"WebGear is throwing <code>ModuleNotFoundError</code> on importing\", Why?","text":"<p>Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-webgear-always-need-active-internet-connection","title":"Can WebGear always need Active Internet Connection?","text":"<p>Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server, otherwise you can also add your own custom files. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#is-it-possible-to-stream-on-a-different-device-on-the-network-with-webgear","title":"Is it possible to stream on a different device on the network with WebGear?","text":"<p>If you set <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine, then you must still use http://localhost:8000/ to access stream on that same host machine browser.</p> <p>For accessing WebGear on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. Then type the IP-address of source machine followed by the defined <code>port</code> value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000) to access the stream.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-i-manually-place-default-files-for-webgear","title":"Can I manually place default files for WebGear?","text":"<p>Answer: Yes, you can either download default files from Github Server, and manually place at default location, OR, you can yourself create the require three critical files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>)  inside <code>templates</code> folder at the default location, thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#how-to-send-opencv-frames-directly-to-webgear-server","title":"How to send OpenCV frames directly to Webgear Server?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#how-can-i-add-my-custom-webpage-to-webgear","title":"How can I add my custom WebPage to WebGear?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#how-can-to-add-cors-headers-to-webgear","title":"How can to add CORS headers to WebGear?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-i-change-the-default-location","title":"Can I change the default location?","text":"<p>Answer: Yes, you can use WebGear's <code>custom_data_location</code> attribute of <code>option</code> parameter in WebGear API, to change default location to somewhere else.</p> <p> </p>"},{"location":"help/webgear_faqs/#can-i-deleterename-the-webgear-default-data","title":"Can I delete/rename the WebGear default data?","text":"<p>Answer: Yes, but you've to follow these rules \u27b6</p> <p> </p>"},{"location":"help/webgear_faqs/#what-web-browser-are-supported-by-webgear-api","title":"What Web browser are supported by WebGear API?","text":"<p>Answer: All modern browser with Javascript support are supported by WebGear. If not, then discuss with us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/webgear_rtc_ex/","title":"WebGear_RTC_RTC Examples","text":""},{"location":"help/webgear_rtc_ex/#using-webgear_rtc-with-raspberrypi-camera-module","title":"Using WebGear_RTC with RaspberryPi Camera Module","text":"<p>Because of WebGear_RTC API's flexible internal wapper around VideoGear, it can easily access any parameter of CamGear and PiGear videocapture APIs.</p> <p>Following usage examples are just an idea of what can be done with WebGear_RTC API, you can try various VideoGear, CamGear and PiGear parameters directly in WebGear_RTC API in the similar manner.</p> <p>Here's a bare-minimum example of using WebGear_RTC API with the Raspberry Pi camera module while tweaking its various properties in just one-liner:</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n# various webgear_rtc performance and Raspberry Pi camera tweaks\noptions = {\n\"frame_size_reduction\": 25,\n\"hflip\": True,\n\"exposure_mode\": \"auto\",\n\"iso\": 800,\n\"exposure_compensation\": 15,\n\"awb_mode\": \"horizon\",\n\"sensor_mode\": 0,\n}\n# initialize WebGear_RTC app\nweb = WebGear_RTC(\nenablePiCamera=True, resolution=(640, 480), framerate=60, logging=True, **options\n)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_rtc_ex/#using-webgear_rtc-with-real-time-video-stabilization-enabled","title":"Using WebGear_RTC with real-time Video Stabilization enabled","text":"<p>Here's an example of using WebGear_RTC API with real-time Video Stabilization enabled:</p> <pre><code># import libs\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n# various webgear_rtc performance tweaks\noptions = {\n\"frame_size_reduction\": 25,\n}\n# initialize WebGear_RTC app  with a raw source and enable video stabilization(`stabilize=True`)\nweb = WebGear_RTC(source=\"foo.mp4\", stabilize=True, logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p> </p>"},{"location":"help/webgear_rtc_ex/#display-two-sources-simultaneously-in-webgear_rtc","title":"Display Two Sources Simultaneously in WebGear_RTC","text":"<p>In this example, we'll be displaying two video feeds side-by-side simultaneously on browser using WebGear_RTC API by simply concatenating frames in real-time: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <pre><code># import necessary libs\nimport uvicorn, cv2\nimport numpy as np\nfrom vidgear.gears.helper import reducer\nfrom vidgear.gears.asyncio import WebGear_RTC\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True)\n# frame concatenator\ndef get_conc_frame(frame1, frame2):\nh1, w1 = frame1.shape[:2]\nh2, w2 = frame2.shape[:2]\n# create empty matrix\nvis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)\n# combine 2 frames\nvis[:h1, :w1, :3] = frame1\nvis[:h2, w1 : w1 + w2, :3] = frame2\nreturn vis\n# create your own custom streaming class\nclass Custom_Stream_Class:\n\"\"\"\n    Custom Streaming using two OpenCV sources\n    \"\"\"\ndef __init__(self, source1=None, source2=None):\n# !!! define your own video source here !!!\n# check is source are provided\nif source1 is None or source2 is None:\nraise ValueError(\"Provide both source\")\n# initialize global params\n# define both source here\nself.stream1 = cv2.VideoCapture(source1)\nself.stream2 = cv2.VideoCapture(source2)\n# define running flag\nself.running = True\ndef read(self):\n# don't forget this function!!!\n# check if sources were initialized or not\nif self.stream1 is None or self.stream2 is None:\nreturn None\n# check if we're still running\nif self.running:\n# read video frame\n(grabbed1, frame1) = self.stream1.read()\n(grabbed2, frame2) = self.stream2.read()\n# if NoneType\nif not grabbed1 or not grabbed2:\n# do something with your OpenCV frame here\n# concatenate frame\nframe = get_conc_frame(frame1, frame2)\n# reducer frames size if you want more performance otherwise comment this line\n# frame = await reducer(frame, percentage=30)  # reduce frame by 30%\n# return our gray frame\nreturn frame\nelse:\n# signal we're not running now\nself.running = False\n# return None-type\nreturn None\ndef stop(self):\n# don't forget this function!!!\n# flag that we're not running\nself.running = False\n# close stream\nif not (self.stream1 is None):\nself.stream1.release()\nself.stream1 = None\nif not (self.stream2 is None):\nself.stream2.release()\nself.stream2 = None\n# assign your Custom Streaming Class with adequate two sources\n# to `custom_stream` attribute in options parameter\noptions = {\n\"custom_stream\": Custom_Stream_Class(\nsource1=\"foo1.mp4\", source2=\"foo2.mp4\"\n)\n}\n# initialize WebGear_RTC app without any source\nweb = WebGear_RTC(logging=True, **options)\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n# close app safely\nweb.shutdown()\n</code></pre> <p>On successfully running this code, the output stream will be displayed at address http://localhost:8000/ in Browser.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/","title":"WebGear_RTC FAQs","text":""},{"location":"help/webgear_rtc_faqs/#what-is-webgear_rtc-api-and-what-does-it-do","title":"What is WebGear_RTC API and what does it do?","text":"<p>Answer: WebGear_RTC utilizes WebRTC technology under the hood, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms. For more info. see WebGear_RTC doc \u27b6</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-to-get-started-with-webgear_rtc-api","title":"How to get started with WebGear_RTC API?","text":"<p>Answer: See WebGear_RTC doc \u27b6. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-webgear_rtc-is-different-to-webgear-api-which-should-i-choose","title":"How WebGear_RTC is different to WebGear API, which should I choose?","text":"<p>Answer: WebGear_RTC is similar to WeGear API in many aspects but utilizes WebRTC technology under the hood instead of Motion JPEG. You can choose any API according to your application, but the quality would be better on WebGear API, on-the-other-hand latency would be better on WebGear_RTC API. Also, WebRTC protocol accepts a wide range of devices, whereas WebGear is limited only to modern browsers. </p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#webgear_rtc-is-throwing-modulenotfounderror-on-importing-why","title":"\"WebGear_RTC is throwing <code>ModuleNotFoundError</code> on importing\", Why?","text":"<p>Answer: This error means, VidGear is installed WITHOUT asyncio package support on your machine. For this support, see Requirements \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-webgear_rtc-always-need-active-internet-connection","title":"Can WebGear_RTC always need Active Internet Connection?","text":"<p>Answer: No, it just need internet only once during its Auto-Generation Process \u27b6 to download default data-files and it takes few seconds. You can also download files manually from Github Server, otherwise you can also add your own custom files. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#is-it-possible-to-stream-on-a-different-device-on-the-network-with-webgear_rtc","title":"Is it possible to stream on a different device on the network with WebGear_RTC?","text":"<p>If you set <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine, then you must still use http://localhost:8000/ to access stream on your host machine browser.</p> <p>For accessing WebGear_RTC on different Client Devices on the network, use <code>\"0.0.0.0\"</code> as host value instead of <code>\"localhost\"</code> on Host Machine. Then type the IP-address of source machine followed by the defined <code>port</code> value in your desired Client Device's browser (for e.g. http://192.27.0.101:8000) to access the stream.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-i-manually-place-default-files-for-webgear_rtc","title":"Can I manually place default files for WebGear_RTC?","text":"<p>Answer: Yes, you can either download default files from Github Server, and manually place at default location, OR, you can yourself create the require three critical files (i.e <code>index.html</code>, <code>404.html</code> &amp; <code>500.html</code>)  inside <code>templates</code> folder at the default location, thereby you don't need any internet connection at all. For more information see Data-Files Auto-Generation WorkFlow \u27b6</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-to-stream-webgear_rtc-server-output-to-multiple-clients","title":"How to stream Webgear_RTC Server output to multiple clients?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-to-send-opencv-frames-directly-to-webgear_rtc-server","title":"How to send OpenCV frames directly to Webgear_RTC Server?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-can-i-add-my-custom-webpage-to-webgear_rtc","title":"How can I add my custom WebPage to WebGear_RTC?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#how-can-to-add-cors-headers-to-webgear_rtc","title":"How can to add CORS headers to WebGear_RTC?","text":"<p>Answer: See this usage example \u27b6.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-i-change-the-default-location","title":"Can I change the default location?","text":"<p>Answer: Yes, you can use WebGear_RTC's <code>custom_data_location</code> attribute of <code>option</code> parameter in WebGear_RTC API, to change default location to somewhere else.</p> <p> </p>"},{"location":"help/webgear_rtc_faqs/#can-i-deleterename-the-webgear_rtc-default-data","title":"Can I delete/rename the WebGear_RTC default data?","text":"<p>Answer: Yes, but you've to follow these rules \u27b6</p> <p> </p>"},{"location":"help/writegear_ex/","title":"WriteGear Examples","text":""},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-rtsprtp-live-streaming","title":"Using WriteGear's Compression Mode for RTSP/RTP Live-Streaming","text":"<p>In Compression Mode, you can use WriteGear for livestreaming with traditional protocols such as RTSP/RTP. The example to achieve that is as follows:   </p> New in v0.2.6 <p>This example was added in <code>v0.2.6</code>.</p> <p>This example assume you already have a RTSP Server running at specified RTSP address with format <code>rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH]</code> for publishing video frames.</p> Creating your own RTSP Server locally <p>If you want to create your RTSP Server locally, then checkout rtsp-simple-server - a ready-to-use and zero-dependency server and proxy that allows users to publish, read and proxy live video and audio streams through various protocols such as RTSP, RTMP etc.</p> <p>Make sure to change RTSP address <code>rtsp://localhost:8554/mystream</code> with yours in following code before running!</p> <pre><code># import required libraries\nimport cv2\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\n# open any valid video stream(for e.g `foo.mp4` file)\nstream = CamGear(source=\"foo.mp4\").start()\n# define required FFmpeg parameters for your writer\noutput_params = {\"-f\": \"rtsp\", \"-rtsp_transport\": \"tcp\"}\n# Define writer with defined parameters and RTSP address\n# [WARNING] Change your RTSP address `rtsp://localhost:8554/mystream` with yours!\nwriter = WriteGear(\noutput=\"rtsp://localhost:8554/mystream\", logging=True, **output_params\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-youtube-live-streaming","title":"Using WriteGear's Compression Mode for YouTube-Live Streaming","text":"<p>In Compression Mode, you can also use WriteGear for Youtube-Livestreaming. The example is as follows:   </p> New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <p>This example assume you already have a YouTube Account with Live-Streaming enabled for publishing video.</p> <p>Make sure to change YouTube-Live Stream Key with yours in following code before running!</p> Without AudioWith Audio <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# define and open video source\nstream = CamGear(source=\"/home/foo/foo.mp4\", logging=True).start()\n# define required FFmpeg parameters for your writer\noutput_params = {\n\"-clones\": [\"-f\", \"lavfi\", \"-i\", \"anullsrc\"],\n\"-vcodec\": \"libx264\",\n\"-preset\": \"medium\",\n\"-b:v\": \"4500k\",\n\"-bufsize\": \"512k\",\n\"-pix_fmt\": \"yuv420p\",\n\"-f\": \"flv\",\n}\n# [WARNING] Change your YouTube-Live Stream Key here:\nYOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\"\n# Define writer with defined parameters\nwriter = WriteGear(\noutput=\"rtmp://a.rtmp.youtube.com/live2/{}\".format(YOUTUBE_STREAM_KEY),\nlogging=True,\n**output_params\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p>This code assume given input video source contains valid audio stream.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# define video source(with audio) here\nVIDEO_SOURCE = \"/home/foo/foo.mp4\"\n# Open stream\nstream = CamGear(source=VIDEO_SOURCE, logging=True).start()\n# define required FFmpeg parameters for your writer\n# [NOTE]: Added VIDEO_SOURCE as audio-source\noutput_params = {\n\"-i\": VIDEO_SOURCE,\n\"-acodec\": \"aac\",\n\"-ar\": 44100,\n\"-b:a\": 712000,\n\"-vcodec\": \"libx264\",\n\"-preset\": \"medium\",\n\"-b:v\": \"4500k\",\n\"-bufsize\": \"512k\",\n\"-pix_fmt\": \"yuv420p\",\n\"-f\": \"flv\",\n}\n# [WARNING] Change your YouTube-Live Stream Key here:\nYOUTUBE_STREAM_KEY = \"xxxx-xxxx-xxxx-xxxx-xxxx\"\n# Define writer with defined parameters\nwriter = WriteGear(\noutput=\"rtmp://a.rtmp.youtube.com/live2/{}\".format(YOUTUBE_STREAM_KEY),\nlogging=True,\n**output_params\n)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-with-v4l2loopback-virtual-cameras","title":"Using WriteGear's Compression Mode with v4l2loopback Virtual Cameras","text":"<p>With WriteGear's Compression Mode, you can directly feed video-frames to <code>v4l2loopback</code> generated Virtual Camera devices on Linux Machines. The complete usage example is as follows:</p> New in v0.3.0 <p>This example was added in <code>v0.3.0</code>.</p> Example Assumptions <ul> <li>You're running are a Linux machine.</li> <li>WriteGear API's backend FFmpeg binaries are compiled with <code>v4l2/v4l2loopback</code> demuxer support.</li> <li>You already have <code>v4l2loopback</code> Virtual Camera device running at address: <code>/dev/video0</code></li> </ul> Creating your own Virtual Camera device with <code>v4l2loopback</code> module. <p>To install and create a v4l2loopback virtual camera device on Linux Mint OS/Ubuntu (may slightly differ for other distros), run following two terminal commands:</p> <pre><code>$ sudo apt-get install v4l2loopback-dkms v4l2loopback-utils linux-modules-extra-$(uname -r)\n$ sudo modprobe v4l2loopback devices=1 video_nr=0 exclusive_caps=1 card_label='VCamera'\n</code></pre> <p>For further information on parameters used, checkout v4l2loopback docs</p> <p>Finally, You can check the loopback device you just created by listing contents of <code>/sys/devices/virtual/video4linux</code> directory with terminal command:</p> <pre><code>$ sudo ls -1 /sys/devices/virtual/video4linux\n\nvideo0 </code></pre> <p>Now you can use <code>/dev/video0</code> Virtual Camera device path in WriteGear API.</p> v4l2: open /dev/videoX: Permission denied <p>If you got this error, then you must add your username to the <code>video</code> group by running following commands: <pre><code>$ sudo adduser $(whoami) video\n$ sudo usermod -a -G video $(whoami)\n</code></pre> Afterwards, restart your computer to finialize these changes.</p> <p>Note: If the problem still persists, then try to run your python script as superuser with <code>sudo</code> command.</p> Default <code>libx264</code> encoder is incompatible with <code>v4l2loopback</code> module. <p>Kindly use other encoders such as <code>libxvid</code>, <code>mpeg4</code> etc.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# open any valid video stream(for e.g `foo.mp4` file)\nstream = CamGear(source=\"foo.mp4\").start()\n# define required FFmpeg parameters for your writer\n# also retrieve framerate from CamGear Stream and pass it as `-input_framerate` parameter\noutput_params = {\n\"-input_framerate\": stream.framerate,\n\"-vcodec\": \"libxvid\",\n\"-f\": \"v4l2\",\n\"-pix_fmt\": \"yuv420p\",\n}\n# Define writer with \"/dev/video0\" as source and user-defined parameters \nwriter = WriteGear(output=\"/dev/video0\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if None-type\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p>The data sent to the v4l2loopback device <code>/dev/video0</code> in this example with WriteGear API, can then be read by any v4l2-capable application (such as OpenCV, VLC, ffplay etc.)</p> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-creating-mp4-segments","title":"Using WriteGear's Compression Mode for creating MP4 segments","text":"<p>In Compression Mode, you can also use WriteGear for creating MP4 segments from almost any video source. The example is as follows:   </p> New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <pre><code># import required libraries\nfrom vidgear.gears import VideoGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# Open any video source `foo.mp4`\nstream = VideoGear(\nsource=\"foo.mp4\", logging=True\n).start()\n# define required FFmpeg optimizing parameters for your writer\noutput_params = {\n\"-c:v\": \"libx264\",\n\"-crf\": 22,\n\"-map\": 0,\n\"-segment_time\": 9,\n\"-g\": 9,\n\"-sc_threshold\": 0,\n\"-force_key_frames\": \"expr:gte(t,n_forced*9)\",\n\"-clones\": [\"-f\", \"segment\"],\n}\n# Define writer with defined parameters\nwriter = WriteGear(output=\"output%03d.mp4\", logging=True, **output_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-to-add-external-audio-file-input-to-video-frames","title":"Using WriteGear's Compression Mode to add external audio file input to video frames","text":"<p>You can also use WriteGear for merging external audio with live video-source:  </p> New in v0.2.1 <p>This example was added in <code>v0.2.1</code>.</p> <p>Make sure this <code>-i</code> audio-source it compatible with provided video-source, otherwise you could encounter multiple errors or no output at all.</p> <pre><code># import required libraries\nfrom vidgear.gears import CamGear\nfrom vidgear.gears import WriteGear\nimport cv2\n# open any valid video stream(for e.g `foo_video.mp4` file)\nstream = CamGear(source=\"foo_video.mp4\").start()\n# add various parameters, along with custom audio\nstream_params = {\n\"-input_framerate\": stream.framerate,  # controlled framerate for audio-video sync !!! don't forget this line !!!\n\"-i\": \"foo_audio.aac\",  # assigns input audio-source: \"foo_audio.aac\"\n}\n# Define writer with defined parameters\nwriter = WriteGear(output=\"Output.mp4\", logging=True, **stream_params)\n# loop over\nwhile True:\n# read frames from stream\nframe = stream.read()\n# check for frame if Nonetype\nif frame is None:\nbreak\n# {do something with the frame here}\n# write frame to writer\nwriter.write(frame)\n# Show output window\ncv2.imshow(\"Output Frame\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# safely close video stream\nstream.stop()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegears-compression-mode-for-generating-timely-accurate-video","title":"Using WriteGear's Compression Mode for generating Timely Accurate Video","text":"<p>If you need timely accurate video with exactly same speed as real-time input, then you need to use FFmpeg directly through its <code>execute_ffmpeg_cmd</code> method: </p> New in v0.2.4 <p>This example was added in <code>v0.2.4</code>.</p> <p>In this example we are capturing video from desktop screen in a Timely Accurate manner.</p> WindowsLinuxmacOS <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n# Define writer with defined parameters and with some dummy name\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n# format FFmpeg command to generate time accurate video\nffmpeg_command = [\n\"-y\",\n\"-f\",\n\"gdigrab\",\n\"-framerate\",\n\"30\",\n\"-i\",\n\"desktop\",\n\"Output.mkv\",\n]  # `-y` parameter is to overwrite outputfile if exists\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n# safely close writer\nwriter.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n# Define writer with defined parameters and with some dummy name\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n# format FFmpeg command to generate time accurate video\nffmpeg_command = [\n\"-y\",\n\"-f\",\n\"x11grab\",\n\"-framerate\",\n\"30\",\n\"-i\",\n\"default\",\n\"Output.mkv\",\n]  # `-y` parameter is to overwrite outputfile if exists\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n# safely close writer\nwriter.close()\n</code></pre> <pre><code># import required libraries\nfrom vidgear.gears import WriteGear\n# Define writer with defined parameters and with some dummy name\nwriter = WriteGear(output=\"Output.mp4\", logging=True)\n# format FFmpeg command to generate time accurate video\nffmpeg_command = [\n\"-y\",\n\"-f\",\n\"avfoundation\",\n\"-framerate\",\n\"30\",\n\"-i\",\n\"default\",\n\"Output.mkv\",\n]  # `-y` parameter is to overwrite outputfile if exists\n# execute FFmpeg command\nwriter.execute_ffmpeg_cmd(ffmpeg_command)\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"help/writegear_ex/#using-writegear-with-rosrobot-operating-system","title":"Using WriteGear with ROS(Robot Operating System)","text":"<p>We will be using <code>cv_bridge</code> to convert OpenCV frames to ROS image messages and vice-versa. </p> <p>In this example, we'll create a node that listens to a ROS image message topic, converts the received images messages into OpenCV frames, draws a circle on it, and then process these frames into a lossless compressed file format in real-time.</p> New in v0.2.2 <p>This example was added in <code>v0.2.2</code>.</p> <p>This example is vidgear implementation of this wiki example.</p> <pre><code># import roslib\nimport roslib\nroslib.load_manifest(\"my_package\")\n# import other required libraries\nimport sys\nimport rospy\nimport cv2\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge, CvBridgeError\nfrom vidgear.gears import WriteGear\n# custom publisher class\nclass image_subscriber:\ndef __init__(self, output=\"Output.mp4\"):\n# create CV bridge\nself.bridge = CvBridge()\n# define publisher topic\nself.image_pub = rospy.Subscriber(\"image_topic_sub\", Image, self.callback)\n# Define writer with default parameters\nself.writer = WriteGear(output=output)\ndef callback(self, data):\n# convert received data to frame\ntry:\ncv_image = self.bridge.imgmsg_to_cv2(data, \"bgr8\")\nexcept CvBridgeError as e:\nprint(e)\n# check if frame is valid\nif cv_image:\n# {do something with the frame here}\n# let's add a circle\n(rows, cols, channels) = cv_image.shape\nif cols &gt; 60 and rows &gt; 60:\ncv2.circle(cv_image, (50, 50), 10, 255)\n# write frame to writer\nself.writer.write(cv_image)\ndef close(self):\n# safely close video stream\nself.writer.close()\ndef main(args):\n# define publisher with suitable output filename\n# such as `Output.mp4` for saving output\nic = image_subscriber(output=\"Output.mp4\")\n# initiate ROS node on publisher\nrospy.init_node(\"image_subscriber\", anonymous=True)\ntry:\n# run node\nrospy.spin()\nexcept KeyboardInterrupt:\nprint(\"Shutting down\")\nfinally:\n# close publisher\nic.close()\nif __name__ == \"__main__\":\nmain(sys.argv)\n</code></pre> <p> </p>"},{"location":"help/writegear_faqs/","title":"WriteGear FAQs","text":""},{"location":"help/writegear_faqs/#what-is-writegear-api-and-what-does-it-do","title":"What is WriteGear API and what does it do?","text":"<p>Answer: WriteGear handles various powerful Writer Tools that provide us the freedom to do almost anything imagine with multimedia files. For more info. see WriteGear doc \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#im-only-familiar-with-opencv-how-to-get-started-with-writegear-api","title":"I'm only familiar with OpenCV, how to get started with WriteGear API?","text":"<p>Answer: First, see Switching from OpenCV, then go through WriteGear doc. Still in doubt, then ask us on Gitter \u27b6 Community channel.</p> <p> </p>"},{"location":"help/writegear_faqs/#why-writegear-is-throwing-valueerror","title":"Why WriteGear is throwing <code>ValueError</code>?","text":"<p>Answer: WriteGear will exit with <code>ValueError</code> if you feed frames of different dimensions or channels.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-install-and-configure-ffmpeg-correctly-for-writegear-on-my-machine","title":"How to install and configure FFmpeg correctly for WriteGear on my machine?","text":"<p>Answer: Follow these Installation Instructions \u27b6 for its installation.</p> <p> </p>"},{"location":"help/writegear_faqs/#can-i-use-writegear-directly-with-opencv","title":"Can I use WriteGear directly with OpenCV?","text":"<p>Answer: Yes,</p> <ul> <li>For Compression Mode: See this usage example \u27b6.</li> <li>For  Non-Compression Mode: See this usage example \u27b6</li> </ul> <p> </p>"},{"location":"help/writegear_faqs/#what-ffmpegs-encoders-and-parameters-are-supported-by-writegear-in-compression-mode","title":"What FFmpeg's encoders and parameters are supported by WriteGear in compression mode?","text":"<p>Answer: See Supported Parameters \u27b6 and Supported encoders \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#what-opencvs-fourcc-and-parameters-are-supported-by-writegear-in-non-compression-mode","title":"What OpenCV's FOURCC and parameters are supported by WriteGear in non-compression mode?","text":"<p>Answer: See Supported Parameters \u27b6 and Supported FOURCC \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#why-this-fourcc-is-not-working-for-me","title":"Why this FOURCC is not working for me?","text":"<p>Answer: Remember not all the FOURCC and Video extensions are compatible and supported by OpenCV VideoWriter Class. You\u2019ll need to try different combinations of FourCC and file extensions. Furthermore, OpenCV does not return any helpful error messages regarding this problem, so it\u2019s pretty much based on trial and error.</p> <p> </p>"},{"location":"help/writegear_faqs/#can-i-pass-my-custom-ffmpeg-commands-directly-in-writegear-api","title":"Can I pass my custom FFmpeg commands directly in WriteGear API?","text":"<p>Answer: Yes, See Custom FFmpeg Commands in WriteGear API \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-use-specific-hardware-encoder-in-writegear","title":"How to use specific Hardware Encoder in WriteGear?","text":"<p>Answer: See this usage example \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-add-live-audio-to-writegear","title":"How to add live audio to WriteGear?","text":"<p>Answer: See this doc \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-separate-and-merge-audio-fromto-video","title":"How to separate and merge audio from/to video?","text":"<p>Answer: See these usage examples \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#can-i-live-stream-to-twitch-with-writegear-api","title":"Can I live stream to Twitch with WriteGear API?","text":"<p>Answer: Yes, See this usage example \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#is-youtube-live-streaming-possible-with-writegear","title":"Is YouTube-Live Streaming possible with WriteGear?","text":"<p>Answer: Yes, See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-live-streaming-using-rtsprtp-protocol-with-writegear","title":"How to Live-Streaming using RTSP/RTP protocol with WriteGear?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-to-create-mp4-segments-from-a-video-stream-with-writegear","title":"How to create MP4 segments from a video stream with WriteGear?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#how-add-external-audio-file-input-to-video-frames","title":"How add external audio file input to video frames?","text":"<p>Answer: See this bonus example \u27b6.</p> <p> </p>"},{"location":"help/writegear_faqs/#why-this-ffmpeg-parameter-is-not-working-for-me-in-compression-mode","title":"Why this FFmpeg parameter is not working for me in compression mode?","text":"<p>Answer: If some FFmpeg parameter doesn't work for you, then tell us on Gitter \u27b6, and if that doesn't help, then finally report an issue \u27b6</p> <p> </p>"},{"location":"help/writegear_faqs/#why-writegear-is-switching-to-non-compression-mode-even-if-it-is-not-enable","title":"Why WriteGear is switching to Non-compression Mode, even if it is not enable?","text":"<p>Answer: In case WriteGear API fails to detect valid FFmpeg executables on your system (even if Compression Mode is enabled), it will automatically fallback to Non-Compression Mode. Follow Installation Instructions \u27b6 for FFmpeg installation.</p> <p> </p>"},{"location":"installation/pip_install/","title":"Install using pip","text":"<p>Best option for easily getting stable VidGear installed.</p>"},{"location":"installation/pip_install/#prerequisites","title":"Prerequisites","text":"<p>When installing VidGear with pip, you need to manually install following prerequisites:</p>  Upgrade your <code>pip</code> <p>It strongly advised to upgrade to latest <code>pip</code> before installing vidgear to avoid any undesired installation error(s).</p> <p>There are two mechanisms to upgrade <code>pip</code>:</p> <code>pip</code><code>ensurepip</code> <p>You can use existing <code>pip</code> to upgrade itself:</p> Install <code>pip</code> if not present <ul> <li>Download the script, from https://bootstrap.pypa.io/get-pip.py.</li> <li>Open a terminal/command prompt, <code>cd</code> to the folder containing the <code>get-pip.py</code> file and run:</li> </ul>  Linux /  MacOS Windows <pre><code>python get-pip.py\n</code></pre> <pre><code>py get-pip.py\n</code></pre> <p>More details about this script can be found in pypa/get-pip\u2019s README.</p>  Linux /  MacOS Windows <pre><code>python -m pip install pip --upgrade\n</code></pre> <pre><code>py -m pip install pip --upgrade\n</code></pre> <p>Python also comes with an <code>ensurepip</code> module1, which can easily upgrade/install <code>pip</code> in any Python environment.</p>  Linux /  MacOS Windows <pre><code>python -m ensurepip --upgrade\n</code></pre> <pre><code>py -m ensurepip --upgrade\n</code></pre>"},{"location":"installation/pip_install/#critical-prerequisites","title":"Critical Prerequisites","text":""},{"location":"installation/pip_install/#opencv","title":"OpenCV","text":"<p>Must require OpenCV(3.0+) python binaries installed for all core functions. You easily install it directly via pip:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre>"},{"location":"installation/pip_install/#api-specific-prerequisites","title":"API Specific Prerequisites","text":""},{"location":"installation/pip_install/#ffmpeg","title":"FFmpeg","text":"<p>Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode. </p> <p>FFmpeg Installation</p> <ul> <li>For WriteGear API's Compression Mode: Follow this dedicated FFmpeg Installation doc for its installation.</li> <li>For StreamGear API: Follow this dedicated FFmpeg Installation doc for its installation.</li> </ul>"},{"location":"installation/pip_install/#picamera","title":"Picamera","text":"<p>Required only if you're using Raspberry Pi  Camera Modules with its PiGear API. You can easily install it via pip:</p> <p>Make sure to enable Raspberry Pi hardware-specific settings prior to using this library, otherwise it won't work.</p> <pre><code>pip install picamera\n</code></pre>"},{"location":"installation/pip_install/#uvloop","title":"Uvloop","text":"<p>Required only if you're using the NetGear_Async API on UNIX machines for maximum performance. You can easily install it via pip:</p> <p>uvloop is NOT yet supported on Windows  Machines.</p> <pre><code>pip install uvloop\n</code></pre>"},{"location":"installation/pip_install/#installation","title":"Installation","text":"Installation command with <code>pip</code> has been changed in <code>v0.2.4</code> <p>The legacy <code>pip install vidgear</code> command now installs critical bare-minimum dependencies only. Therefore in order to automatically install all the API specific dependencies as previous versions, use <code>pip install vidgear[core]</code> command instead.</p> <code>v0.2.4</code> and newerOlder <pre><code># Install latest stable release with all Core dependencies\npip install -U vidgear[core]\n</code></pre> <p><code>[core]</code> keyword isn't available in versions older than <code>v0.2.4</code></p> <pre><code># Install older stable release with all Core dependencies\npip install vidgear&lt;0.2.4\n</code></pre> <p>Similarly in your python project files like <code>setup.py</code> or <code>requirements.txt</code> or <code>setup.cfg</code>, use vidgear dependency as <code>vidgear[core]&gt;=0.2.4</code>  instead.</p> <p>This change does not affects <code>pip install vidgear[asyncio]</code> command.</p> <p>Installation is as simple as:</p> Installing vidgear with only selective dependencies <p>Starting with version <code>v0.2.2</code>, you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). </p> <p>This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system:</p> <ul> <li> <p>Install bare-minimum vidgear as follows:</p> <code>v0.2.4</code> and newerOlder <pre><code># Install stable release with bare-minimum dependencies\npip install -U vidgear\n</code></pre> <pre><code># Install stable without any dependencies\npip install --no-deps vidgear&lt;0.2.4\n</code></pre> </li> <li> <p>Then, you must install Critical dependencies(if not already):</p> <code>v0.2.4</code> and newerOlder <pre><code># Install opencv(only if not installed previously)\npip install opencv-python </code></pre> <pre><code># Install critical dependencies\npip install cython, numpy, requests, tqdm, colorlog\n\n# Install opencv(only if not installed previously)\npip install opencv-python </code></pre> </li> <li> <p>Finally, manually install your API-specific dependencies as required by your API(in use):</p> <pre><code># Just copy-&amp;-paste from table below\npip install &lt;API-specific dependencies&gt;\n</code></pre> <code>v0.2.4</code> and newerOlder APIs Dependencies CamGear <code>yt_dlp</code> PiGear <code>picamera</code> VideoGear Based on CamGear or PiGear backend in use ScreenGear <code>mss</code>, <code>pyscreenshot</code>, <code>Pillow</code> WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear <code>pyzmq</code>, <code>simplejpeg</code> WebGear <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code>, <code>simplejpeg</code> WebGear_RTC <code>aiortc</code>, <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code> NetGear_Async <code>pyzmq</code>, <code>msgpack</code>, <code>msgpack_numpy</code>, <code>uvloop</code> Stabilizer Class - APIs Dependencies CamGear <code>pafy</code>, <code>yt_dlp</code>, <code>streamlink</code> PiGear <code>picamera</code> VideoGear Based on CamGear or PiGear backend in use ScreenGear <code>mss</code>, <code>pyscreenshot</code>, <code>Pillow</code> WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear <code>pyzmq</code>, <code>simplejpeg</code> WebGear <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code>, <code>simplejpeg</code> WebGear_RTC <code>aiortc</code>, <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code> NetGear_Async <code>pyzmq</code>, <code>msgpack</code>, <code>msgpack_numpy</code>, <code>uvloop</code> Stabilizer Class - </li> </ul>  Windows Installation <p>If you are using Windows, some of the commands given below, may not work out-of-the-box.</p> <p>A quick solution may be to preface every Python command with <code>python -m</code> like this:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install -U vidgear[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install -U vidgear[asyncio]\n</code></pre> <p>And, If you don't have the privileges to the directory you're installing package. Then use <code>--user</code> flag, that makes pip install packages in your home directory instead:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install --upgrade --user vidgear[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install --upgrade --user vidgear[asyncio]\n</code></pre> <p>Or, If you're using <code>py</code> as alias for installed python, then:</p> <pre><code># Install latest stable release with all Core dependencies\npy -m pip install --upgrade --user vidgear[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npy -m pip install --upgrade --user vidgear[asyncio]\n</code></pre> <pre><code># Install latest stable release with all Core dependencies\npip install -U vidgear[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install -U vidgear[asyncio]\n</code></pre> <p>And if you prefer to install VidGear directly from the repository:</p> <pre><code># Install latest stable release with all Core dependencies\npip install git+git://github.com/abhiTronix/vidgear@master#egg=vidgear[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install git+git://github.com/abhiTronix/vidgear@master#egg=vidgear[asyncio]\n</code></pre> <p>Or you can also download its wheel (<code>.whl</code>) package from our repository's releases section, and thereby can be installed as follows:</p> <pre><code># Install latest stable release with all Core dependencies\npip install vidgear-0.2.5-py3-none-any.whl[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install vidgear-0.2.5-py3-none-any.whl[asyncio]\n</code></pre> <p> </p> <ol> <li> <p> The <code>ensurepip</code> module is missing/disabled on Ubuntu. Use <code>pip</code> method only.\u00a0\u21a9</p> </li> </ol>"},{"location":"installation/source_install/","title":"Install from source","text":"<p>Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions).</p>"},{"location":"installation/source_install/#prerequisites","title":"Prerequisites","text":"<p>When installing VidGear from source, FFmpeg is the only API specific prerequisites you need to install manually:</p> <p>What about rest of the prerequisites?</p> <p>Any other python prerequisites (Critical/API specific) will be automatically installed based on your OS/System specifications.</p>  Upgrade your <code>pip</code> <p>It strongly advised to upgrade to latest <code>pip</code> before installing vidgear to avoid any undesired installation error(s).</p> <p>There are two mechanisms to upgrade <code>pip</code>:</p> <code>pip</code><code>ensurepip</code> <p>You can use existing <code>pip</code> to upgrade itself:</p> Install <code>pip</code> if not present <ul> <li>Download the script, from https://bootstrap.pypa.io/get-pip.py.</li> <li>Open a terminal/command prompt, <code>cd</code> to the folder containing the <code>get-pip.py</code> file and run:</li> </ul> Linux/MacOSWindows <pre><code>python get-pip.py\n</code></pre> <pre><code>py get-pip.py\n</code></pre> <p>More details about this script can be found in pypa/get-pip\u2019s README.</p> Linux/MacOSWindows <pre><code>python -m pip install pip --upgrade\n</code></pre> <pre><code>py -m pip install pip --upgrade\n</code></pre> <p>Python also comes with an <code>ensurepip</code> module1, which can easily upgrade/install <code>pip</code> in any Python environment.</p> Linux/MacOSWindows <pre><code>python -m ensurepip --upgrade\n</code></pre> <pre><code>py -m ensurepip --upgrade\n</code></pre>"},{"location":"installation/source_install/#api-specific-prerequisites","title":"API Specific Prerequisites","text":""},{"location":"installation/source_install/#ffmpeg","title":"FFmpeg","text":"<p>Require only for the video compression and encoding compatibility within StreamGear API and WriteGear API's Compression Mode. </p> <p>FFmpeg Installation</p> <ul> <li>For WriteGear API's Compression Mode: Follow this dedicated FFmpeg Installation doc for its installation.</li> <li>For StreamGear API: Follow this dedicated FFmpeg Installation doc for its installation.</li> </ul>"},{"location":"installation/source_install/#installation","title":"Installation","text":"<p>If you want to checkout the latest beta <code>testing</code> branch , you can do so with the following commands:</p> <p>This can be useful if you want to provide feedback for a new feature or bug fix in the <code>testing</code> branch.</p> <p>DO NOT clone or install any other branch other than <code>testing</code> unless advised, as it is not tested with CI environments and possibly very unstable or unusable.</p> Installing vidgear with only selective dependencies <p>Starting with version <code>v0.2.2</code>, you can now run any VidGear API by installing only just specific dependencies required by the API in use(except for some Core dependencies). </p> <p>This is useful when you want to manually review, select and install minimal API-specific dependencies on bare-minimum vidgear from scratch on your system:</p> <ul> <li> <p>To clone and install bare-minimum vidgear without any dependencies do as follows:</p> <pre><code># clone the repository and get inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest testing branch\ngit checkout testing\n\n# Install stable release with bare-minimum dependencies\npip install .\n</code></pre> </li> <li> <p>Then, you must install Critical dependencies(if not already):</p> <pre><code># Install opencv(only if not installed previously)\npip install opencv-python </code></pre> </li> <li> <p>Finally, manually install your API-specific dependencies as required by your API(in use):</p> <pre><code># Just copy-&amp;-paste from table below\npip install &lt;API-specific dependencies&gt;\n</code></pre> APIs Dependencies CamGear <code>yt_dlp</code> PiGear <code>picamera</code> VideoGear Based on CamGear or PiGear backend in use ScreenGear <code>mss</code>, <code>pyscreenshot</code>, <code>Pillow</code> WriteGear FFmpeg: See this doc \u27b6 StreamGear FFmpeg: See this doc \u27b6 NetGear <code>pyzmq</code>, <code>simplejpeg</code> WebGear <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code>, <code>simplejpeg</code> WebGear_RTC <code>aiortc</code>, <code>starlette</code>, <code>jinja2</code>, <code>uvicorn</code> NetGear_Async <code>pyzmq</code>, <code>msgpack</code>, <code>msgpack_numpy</code>, <code>uvloop</code> Stabilizer Class - </li> </ul>  Windows Installation <p>If you are using Windows, some of the commands given below, may not work out-of-the-box.</p> <p>A quick solution may be to preface every Python command with <code>python -m</code> like this:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install -U .[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install -U .[asyncio]\n</code></pre> <p>And, If you don't have the privileges to the directory you're installing package. Then use <code>--user</code> flag, that makes pip install packages in your home directory instead:</p> <pre><code># Install latest stable release with all Core dependencies\npython -m pip install --upgrade --user .[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npython -m pip install --upgrade --user .[asyncio]\n</code></pre> <p>Or, If you're using <code>py</code> as alias for installed python, then:</p> <pre><code># Install latest stable release with all Core dependencies\npy -m pip install --upgrade --user .[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npy -m pip install --upgrade --user .[asyncio]\n</code></pre> <pre><code># clone the repository and get inside\ngit clone https://github.com/abhiTronix/vidgear.git &amp;&amp; cd vidgear\n\n# checkout the latest testing branch\ngit checkout testing\n\n# Install latest stable release with all Core dependencies\npip install -U .[core]\n# Or Install latest stable release with all Core &amp; Asyncio dependencies\npip install -U .[asyncio]\n</code></pre> <p> </p> <ol> <li> <p> The <code>ensurepip</code> module is missing/disabled on Ubuntu. Use <code>pip</code> method only.\u00a0\u21a9</p> </li> </ol>"}]}